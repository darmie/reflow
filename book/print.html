<!DOCTYPE HTML>
<html lang="en" class="navy sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Reflow Documentation</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="Comprehensive documentation for the Reflow workflow automation engine - featuring distributed graph network and multi-graph composition">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "navy";
            const default_dark_theme = "navy";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>‚Üê</kbd> or <kbd>‚Üí</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('navy')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Reflow Documentation</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/reflow-project/reflow" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="reflow-documentation"><a class="header" href="#reflow-documentation">Reflow Documentation</a></h1>
<p>Welcome to the Reflow documentation! Reflow is a powerful, actor-based workflow execution engine built in Rust that supports multi-language scripting and cross-platform deployment.</p>
<h2 id="what-is-reflow"><a class="header" href="#what-is-reflow">What is Reflow?</a></h2>
<p>Reflow is a modular workflow engine that uses the actor model for concurrent, message-passing execution. It supports:</p>
<ul>
<li><strong>Multi-Language Scripting</strong>: JavaScript (Deno), Python, and WebAssembly</li>
<li><strong>Actor-Based Architecture</strong>: Isolated, concurrent actors with message passing</li>
<li><strong>Graph-Based Workflows</strong>: Visual workflow representation with history/undo</li>
<li><strong>Cross-Platform</strong>: Native Rust execution + WebAssembly for browsers</li>
<li><strong>Real-Time Capabilities</strong>: Networking, WebSockets, and live data processing</li>
</ul>
<h2 id="documentation-structure"><a class="header" href="#documentation-structure">Documentation Structure</a></h2>
<h3 id="-getting-started"><a class="header" href="#-getting-started">üöÄ <a href="./getting-started/README.html">Getting Started</a></a></h3>
<p>Quick start guide, installation, and basic concepts</p>
<h3 id="-architecture"><a class="header" href="#-architecture">üèóÔ∏è <a href="./architecture/overview.html">Architecture</a></a></h3>
<p>System architecture, actor model, and design patterns</p>
<h3 id="-core-api"><a class="header" href="#-core-api">üìö <a href="./api/actors/creating-actors.html">Core API</a></a></h3>
<p>Detailed API documentation for actors, messaging, and graphs</p>
<h3 id="-scripting"><a class="header" href="#-scripting">üîß <a href="./scripting/javascript/deno-runtime.html">Scripting</a></a></h3>
<p>Multi-language runtime support (Deno, Python, WASM)</p>
<h3 id="-components"><a class="header" href="#-components">üì¶ <a href="./components/standard-library.html">Components</a></a></h3>
<p>Standard component library and custom component creation</p>
<h3 id="-deployment"><a class="header" href="#-deployment">üöÄ <a href="./deployment/native-deployment.html">Deployment</a></a></h3>
<p>Deployment options and operational considerations</p>
<h3 id="-tutorials"><a class="header" href="#-tutorials">üéØ <a href="./tutorials/building-visual-editor.html">Tutorials</a></a></h3>
<p>Visual editor tutorial and performance optimization</p>
<h3 id="-reference"><a class="header" href="#-reference">üìñ <a href="./reference/api-reference.html">Reference</a></a></h3>
<p>Complete API reference and configuration options</p>
<h3 id="-examples"><a class="header" href="#-examples">üí° <a href="./examples/README.html">Examples</a></a></h3>
<p>Tutorials, use cases, and code samples</p>
<h2 id="quick-links"><a class="header" href="#quick-links">Quick Links</a></h2>
<ul>
<li><a href="./getting-started/installation.html">Installation Guide</a></li>
<li><a href="./getting-started/first-workflow.html">First Workflow Tutorial</a></li>
<li><a href="./api/actors/creating-actors.html">Actor Creation Guide</a></li>
<li><a href="./components/standard-library.html">Component Library</a></li>
<li><a href="./deployment/native-deployment.html">Deployment Guide</a></li>
</ul>
<h2 id="community-and-support"><a class="header" href="#community-and-support">Community and Support</a></h2>
<ul>
<li><strong>GitHub Issues</strong>: Report bugs and request features</li>
<li><strong>Discussions</strong>: Community Q&amp;A and announcements</li>
<li><strong>Contributing</strong>: See CONTRIBUTING.md for development guidelines</li>
</ul>
<h2 id="license"><a class="header" href="#license">License</a></h2>
<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="getting-started-with-reflow"><a class="header" href="#getting-started-with-reflow">Getting Started with Reflow</a></h1>
<p>Welcome to Reflow! This guide will help you get up and running with the actor-based workflow engine.</p>
<h2 id="what-youll-learn"><a class="header" href="#what-youll-learn">What You'll Learn</a></h2>
<p>This getting started guide covers:</p>
<ol>
<li><strong><a href="getting-started/./installation.html">Installation</a></strong> - Setting up Reflow on your system</li>
<li><strong><a href="getting-started/./basic-concepts.html">Basic Concepts</a></strong> - Understanding actors, messages, and workflows</li>
<li><strong><a href="getting-started/./development-setup.html">Development Setup</a></strong> - Setting up your development environment</li>
<li><strong><a href="getting-started/./first-workflow.html">First Workflow</a></strong> - Creating your first workflow</li>
</ol>
<h2 id="quick-overview"><a class="header" href="#quick-overview">Quick Overview</a></h2>
<p>Reflow is an actor-based workflow engine that allows you to:</p>
<ul>
<li>Create <strong>actors</strong> that process data and communicate via messages</li>
<li>Connect actors into <strong>workflows</strong> that define data flow and processing logic</li>
<li>Execute workflows with <strong>multi-language support</strong> (JavaScript/Deno, Python, WASM)</li>
<li>Deploy workflows <strong>natively</strong> or in <strong>WebAssembly</strong> environments</li>
</ul>
<h2 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h2>
<p>Before getting started with Reflow, you should have:</p>
<ul>
<li><strong>Rust</strong> (1.70 or later) - for building and running Reflow</li>
<li><strong>Basic understanding</strong> of concurrent programming concepts</li>
<li><strong>Familiarity</strong> with at least one of: JavaScript, Python, or Rust</li>
</ul>
<h2 id="architecture-at-a-glance"><a class="header" href="#architecture-at-a-glance">Architecture at a Glance</a></h2>
<pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Actor A   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Actor B   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Actor C   ‚îÇ
‚îÇ (JavaScript)‚îÇ    ‚îÇ  (Python)   ‚îÇ    ‚îÇ    (Rust)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                  ‚îÇ                  ‚îÇ
       ‚ñº                  ‚ñº                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Message Bus &amp; Routing                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre>
<h2 id="key-concepts"><a class="header" href="#key-concepts">Key Concepts</a></h2>
<ul>
<li><strong>Actor</strong>: An isolated unit of computation that processes messages</li>
<li><strong>Message</strong>: Data passed between actors</li>
<li><strong>Port</strong>: Input/output connections on actors</li>
<li><strong>Workflow</strong>: A graph of connected actors</li>
<li><strong>Runtime</strong>: The execution environment (Deno, Python, etc.)</li>
</ul>
<h2 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h2>
<ol>
<li>Start with <strong><a href="getting-started/./installation.html">Installation</a></strong> to set up Reflow</li>
<li>Read <strong><a href="getting-started/./basic-concepts.html">Basic Concepts</a></strong> to understand the fundamentals</li>
<li>Follow the <strong><a href="getting-started/./first-workflow.html">First Workflow</a></strong> tutorial</li>
<li>Explore the <strong><a href="getting-started/../examples/README.html">Examples</a></strong> for more complex use cases</li>
</ol>
<h2 id="getting-help"><a class="header" href="#getting-help">Getting Help</a></h2>
<ul>
<li>Check the <strong><a href="getting-started/../reference/troubleshooting-guide.html">Troubleshooting Guide</a></strong></li>
<li>Browse the <strong><a href="getting-started/../reference/api-reference.html">API Reference</a></strong></li>
<li>Look at <strong><a href="getting-started/../examples/README.html">Examples</a></strong> for working code</li>
<li>Open an issue on GitHub for bugs or feature requests</li>
</ul>
<p>Ready to start? Let's <strong><a href="getting-started/./installation.html">install Reflow</a></strong>!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="installation"><a class="header" href="#installation">Installation</a></h1>
<p>This guide covers installing and setting up Reflow on your system.</p>
<h2 id="prerequisites-1"><a class="header" href="#prerequisites-1">Prerequisites</a></h2>
<p>Before installing Reflow, ensure you have:</p>
<h3 id="required"><a class="header" href="#required">Required</a></h3>
<ul>
<li><strong>Rust</strong> 1.70 or later</li>
<li><strong>Git</strong> for cloning the repository</li>
</ul>
<h3 id="optional-for-scripting-support"><a class="header" href="#optional-for-scripting-support">Optional (for scripting support)</a></h3>
<ul>
<li><strong>Deno</strong> 1.30+ for JavaScript/TypeScript actors</li>
<li><strong>Python</strong> 3.8+ for Python actors</li>
<li><strong>Docker</strong> for isolated Python execution</li>
</ul>
<h2 id="installation-methods"><a class="header" href="#installation-methods">Installation Methods</a></h2>
<h3 id="method-1-install-from-cratesio-recommended"><a class="header" href="#method-1-install-from-cratesio-recommended">Method 1: Install from Crates.io (Recommended)</a></h3>
<pre><code class="language-bash">cargo install reflow
</code></pre>
<h3 id="method-2-build-from-source"><a class="header" href="#method-2-build-from-source">Method 2: Build from Source</a></h3>
<ol>
<li>
<p><strong>Clone the repository:</strong></p>
<pre><code class="language-bash">git clone https://github.com/your-org/reflow.git
cd reflow
</code></pre>
</li>
<li>
<p><strong>Build the project:</strong></p>
<pre><code class="language-bash">cargo build --release
</code></pre>
</li>
<li>
<p><strong>Install globally (optional):</strong></p>
<pre><code class="language-bash">cargo install --path .
</code></pre>
</li>
</ol>
<h3 id="method-3-use-as-a-library"><a class="header" href="#method-3-use-as-a-library">Method 3: Use as a Library</a></h3>
<p>Add Reflow to your <code>Cargo.toml</code>:</p>
<pre><code class="language-toml">[dependencies]
reflow_network = "0.1.0"
reflow_script = { version = "0.1.0", features = ["deno"] }
reflow_components = "0.1.0"
</code></pre>
<h2 id="feature-flags"><a class="header" href="#feature-flags">Feature Flags</a></h2>
<p>Reflow uses feature flags to control which runtimes are included:</p>
<pre><code class="language-toml">[dependencies]
reflow_script = { 
    version = "0.1.0", 
    features = [
        "deno",      # JavaScript/TypeScript support via Deno
        "python",    # Python script support
        "extism"     # WebAssembly plugin support
    ] 
}
</code></pre>
<h3 id="available-features"><a class="header" href="#available-features">Available Features</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Feature</th><th>Description</th><th>Requirements</th></tr></thead><tbody>
<tr><td><code>deno</code></td><td>JavaScript/TypeScript runtime</td><td>Deno installed</td></tr>
<tr><td><code>python</code></td><td>Python script execution</td><td>Python 3.8+</td></tr>
<tr><td><code>extism</code></td><td>WebAssembly plugin support</td><td>None</td></tr>
<tr><td><code>flowtrace</code></td><td>Debug tracing support</td><td>None</td></tr>
</tbody></table>
</div>
<h2 id="runtime-dependencies"><a class="header" href="#runtime-dependencies">Runtime Dependencies</a></h2>
<h3 id="javascripttypescript-deno"><a class="header" href="#javascripttypescript-deno">JavaScript/TypeScript (Deno)</a></h3>
<p>Install Deno:</p>
<pre><code class="language-bash"># macOS/Linux
curl -fsSL https://deno.land/x/install/install.sh | sh

# Windows (PowerShell)
iwr https://deno.land/x/install/install.ps1 -useb | iex

# Using package managers
brew install deno          # macOS
scoop install deno         # Windows
snap install deno          # Linux
</code></pre>
<h3 id="python-support"><a class="header" href="#python-support">Python Support</a></h3>
<p>Install Python 3.8+:</p>
<pre><code class="language-bash"># macOS
brew install python

# Ubuntu/Debian
sudo apt update
sudo apt install python3 python3-pip

# Windows
# Download from https://python.org
</code></pre>
<p>For Docker-based Python execution:</p>
<pre><code class="language-bash"># Install Docker
# macOS/Windows: Docker Desktop
# Linux: docker.io package
sudo apt install docker.io  # Ubuntu/Debian
</code></pre>
<h2 id="verification"><a class="header" href="#verification">Verification</a></h2>
<p>Verify your installation:</p>
<pre><code class="language-bash"># If installed globally
reflow --version

# If built from source
./target/release/reflow --version

# Test basic functionality
reflow test-actors
</code></pre>
<h2 id="platform-specific-notes"><a class="header" href="#platform-specific-notes">Platform-Specific Notes</a></h2>
<h3 id="macos"><a class="header" href="#macos">macOS</a></h3>
<ul>
<li>Use Homebrew for easy dependency management</li>
<li>Xcode Command Line Tools required for Rust compilation</li>
</ul>
<h3 id="linux"><a class="header" href="#linux">Linux</a></h3>
<ul>
<li>Ensure <code>build-essential</code> is installed</li>
<li>Some distributions may need <code>pkg-config</code> and <code>libssl-dev</code></li>
</ul>
<pre><code class="language-bash"># Ubuntu/Debian
sudo apt install build-essential pkg-config libssl-dev

# CentOS/RHEL
sudo yum groupinstall "Development Tools"
sudo yum install openssl-devel
</code></pre>
<h3 id="windows"><a class="header" href="#windows">Windows</a></h3>
<ul>
<li>Use Windows Subsystem for Linux (WSL) for best experience</li>
<li>Visual Studio Build Tools required for Rust compilation</li>
<li>Consider using <code>scoop</code> or <code>chocolatey</code> for dependency management</li>
</ul>
<h2 id="configuration"><a class="header" href="#configuration">Configuration</a></h2>
<h3 id="environment-variables"><a class="header" href="#environment-variables">Environment Variables</a></h3>
<p>Set these environment variables for optimal performance:</p>
<pre><code class="language-bash"># Enable shared Python environment (optional)
export USE_SHARED_ENV=true

# Set Python path (if needed)
export PYTHON_PATH=/usr/bin/python3

# Configure Deno permissions (optional)
export DENO_PERMISSIONS="--allow-all"
</code></pre>
<h3 id="config-file"><a class="header" href="#config-file">Config File</a></h3>
<p>Create a <code>reflow.toml</code> configuration file:</p>
<pre><code class="language-toml">[runtime]
default_engine = "deno"
enable_networking = true
enable_filesystem = true

[deno]
allow_all = false
allow_net = true
allow_read = true

[python]
use_docker = false
shared_environment = true

[performance]
thread_pool_size = 8
max_memory_mb = 1024
</code></pre>
<h2 id="next-steps-1"><a class="header" href="#next-steps-1">Next Steps</a></h2>
<p>Now that Reflow is installed:</p>
<ol>
<li><strong>Learn the basics</strong>: Read <a href="getting-started/./basic-concepts.html">Basic Concepts</a></li>
<li><strong>Set up development</strong>: Follow <a href="getting-started/./development-setup.html">Development Setup</a></li>
<li><strong>Create your first workflow</strong>: Try <a href="getting-started/./first-workflow.html">First Workflow</a></li>
<li><strong>Explore examples</strong>: Check out the <a href="getting-started/../examples/README.html">Examples</a></li>
</ol>
<h2 id="troubleshooting"><a class="header" href="#troubleshooting">Troubleshooting</a></h2>
<h3 id="common-issues"><a class="header" href="#common-issues">Common Issues</a></h3>
<p><strong>Rust compilation errors:</strong></p>
<pre><code class="language-bash"># Update Rust to latest version
rustup update
</code></pre>
<p><strong>Deno not found:</strong></p>
<pre><code class="language-bash"># Add Deno to PATH
export PATH="$HOME/.deno/bin:$PATH"
</code></pre>
<p><strong>Python import errors:</strong></p>
<pre><code class="language-bash"># Install required Python packages
pip install numpy pandas  # or other dependencies
</code></pre>
<p><strong>Permission denied errors:</strong></p>
<pre><code class="language-bash"># Fix file permissions
chmod +x reflow
</code></pre>
<p>For more troubleshooting, see the <a href="getting-started/../reference/troubleshooting-guide.html">Troubleshooting Guide</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="basic-concepts"><a class="header" href="#basic-concepts">Basic Concepts</a></h1>
<p>This guide introduces the fundamental concepts of Reflow's actor-based workflow engine.</p>
<h2 id="core-concepts"><a class="header" href="#core-concepts">Core Concepts</a></h2>
<h3 id="actors"><a class="header" href="#actors">Actors</a></h3>
<p><strong>Actors</strong> are the building blocks of Reflow workflows. Each actor is an isolated unit of computation that:</p>
<ul>
<li>Processes incoming messages</li>
<li>Maintains its own state</li>
<li>Communicates only through message passing</li>
<li>Runs concurrently with other actors</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Example: Simple actor that doubles numbers (using actor macro)
use std::collections::HashMap;
use reflow_network::{
    actor::ActorContext,
    message::Message,
};
use actor_macro::actor;

#[actor(
    DoublerActor,
    inports::&lt;100&gt;(number),
    outports::&lt;50&gt;(result)
)]
async fn doubler_actor(context: ActorContext) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt; {
    let payload = context.get_payload();
    
    if let Some(Message::Integer(n)) = payload.get("number") {
        Ok([
            ("result".to_owned(), Message::integer(n * 2))
        ].into())
    } else {
        Err(anyhow::anyhow!("Expected integer input"))
    }
}

// Alternative: Manual implementation
use reflow_network::actor::{Actor, ActorBehavior, Port, ActorLoad};
use parking_lot::Mutex;
use std::sync::Arc;

pub struct ManualDoublerActor {
    inports: Port,
    outports: Port,
    load: Arc&lt;Mutex&lt;ActorLoad&gt;&gt;,
}

impl ManualDoublerActor {
    pub fn new() -&gt; Self {
        Self {
            inports: flume::unbounded(),
            outports: flume::unbounded(),
            load: Arc::new(Mutex::new(ActorLoad::new(0))),
        }
    }
}

impl Actor for ManualDoublerActor {
    fn get_behavior(&amp;self) -&gt; ActorBehavior {
        Box::new(|context: ActorContext| {
            Box::pin(async move {
                let payload = context.get_payload();
                if let Some(Message::Integer(n)) = payload.get("number") {
                    Ok([
                        ("result".to_owned(), Message::Integer(n * 2))
                    ].into())
                } else {
                    Err(anyhow::anyhow!("Expected integer input"))
                }
            })
        })
    }
    
    fn get_inports(&amp;self) -&gt; Port { self.inports.clone() }
    fn get_outports(&amp;self) -&gt; Port { self.outports.clone() }
    fn load_count(&amp;self) -&gt; Arc&lt;Mutex&lt;ActorLoad&gt;&gt; { self.load.clone() }
    
    fn create_process(&amp;self) -&gt; std::pin::Pin&lt;Box&lt;dyn std::future::Future&lt;Output = ()&gt; + 'static + Send&gt;&gt; {
        // Process creation implementation...
        todo!("See creating-actors.md for complete implementation")
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="messages"><a class="header" href="#messages">Messages</a></h3>
<p><strong>Messages</strong> are the data that flows between actors. Reflow supports various message types:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum Message {
    String(String),
    Integer(i64),
    Float(f64),
    Boolean(bool),
    Array(Vec&lt;Message&gt;),
    Object(HashMap&lt;String, Message&gt;),
    Binary(Vec&lt;u8&gt;),
    Null,
    Error(String),
}
<span class="boring">}</span></code></pre></pre>
<h3 id="ports"><a class="header" href="#ports">Ports</a></h3>
<p><strong>Ports</strong> are the communication channels between actors:</p>
<ul>
<li><strong>Input ports (inports)</strong>: Receive messages from other actors</li>
<li><strong>Output ports (outports)</strong>: Send messages to other actors</li>
</ul>
<pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    Actor    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Logic ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ             ‚îÇ
‚îÇ in1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí out1
‚îÇ in2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí out2
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre>
<h3 id="workflows-graphs"><a class="header" href="#workflows-graphs">Workflows (Graphs)</a></h3>
<p><strong>Workflows</strong> are directed graphs of connected actors that define:</p>
<ul>
<li>Data flow between actors</li>
<li>Processing logic and transformations</li>
<li>Execution order and dependencies</li>
</ul>
<pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Source  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇTransform‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Sink   ‚îÇ
‚îÇ Actor   ‚îÇ    ‚îÇ Actor   ‚îÇ    ‚îÇ Actor   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre>
<h3 id="actor-state"><a class="header" href="#actor-state">Actor State</a></h3>
<p>Each actor can maintain its own <strong>state</strong> that persists between message processing:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Example: Counter actor with state (using actor macro)
use reflow_network::actor::MemoryState;

#[actor(
    CounterActor,
    state(MemoryState),
    inports::&lt;100&gt;(increment),
    outports::&lt;50&gt;(count)
)]
async fn counter_actor(context: ActorContext) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt; {
    let payload = context.get_payload();
    let state = context.get_state();
    
    let mut state_guard = state.lock();
    let memory_state = state_guard
        .as_mut_any()
        .downcast_mut::&lt;MemoryState&gt;()
        .expect("Expected MemoryState");
    
    // Initialize state if needed
    if !memory_state.contains_key("count") {
        memory_state.insert("count", serde_json::json!(0));
    }
    
    // Get current count
    let current_count = memory_state.get("count")
        .and_then(|v| v.as_i64())
        .unwrap_or(0);
    
    // Increment by 1 or by specified amount
    let increment_by = if let Some(Message::Integer(amount)) = payload.get("increment") {
        *amount
    } else {
        1 // Default increment
    };
    
    let new_count = current_count + increment_by;
    
    // Update state
    memory_state.insert("count", serde_json::json!(new_count));
    
    Ok([
        ("count".to_owned(), Message::Integer(new_count))
    ].into())
}
<span class="boring">}</span></code></pre></pre>
<h2 id="actor-types"><a class="header" href="#actor-types">Actor Types</a></h2>
<h3 id="native-actors-rust"><a class="header" href="#native-actors-rust">Native Actors (Rust)</a></h3>
<p>Built directly in Rust for maximum performance:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct ProcessorActor {
    // Implementation in Rust
}
<span class="boring">}</span></code></pre></pre>
<h3 id="script-actors"><a class="header" href="#script-actors">Script Actors</a></h3>
<p>Execute scripts in various languages:</p>
<h4 id="javascripttypescript-deno-1"><a class="header" href="#javascripttypescript-deno-1">JavaScript/TypeScript (Deno)</a></h4>
<pre><code class="language-javascript">// JavaScript actor function
function process(inputs, context) {
    const data = inputs.data;
    return { result: data.toUpperCase() };
}
</code></pre>
<h4 id="python"><a class="header" href="#python">Python</a></h4>
<pre><code class="language-python"># Python actor script
import numpy as np

inputs = Context.get_inputs()
data = np.array(inputs["data"])
__return_value = data.sum()
</code></pre>
<h4 id="webassembly"><a class="header" href="#webassembly">WebAssembly</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// WASM actor (compiled from Rust, C++, etc.)
#[no_mangle]
pub extern "C" fn process(input: &amp;str) -&gt; String {
    // Process input and return result
    format!("Processed: {}", input)
}
<span class="boring">}</span></code></pre></pre>
<h2 id="message-passing-patterns"><a class="header" href="#message-passing-patterns">Message Passing Patterns</a></h2>
<h3 id="point-to-point"><a class="header" href="#point-to-point">Point-to-Point</a></h3>
<p>One actor sends to one specific actor:</p>
<pre><code>Actor A ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ Actor B
</code></pre>
<h3 id="broadcast"><a class="header" href="#broadcast">Broadcast</a></h3>
<p>One actor sends to multiple actors:</p>
<pre><code>        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ Actor B
Actor A ‚î§
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ Actor C
</code></pre>
<h3 id="collectmerge"><a class="header" href="#collectmerge">Collect/Merge</a></h3>
<p>Multiple actors send to one actor:</p>
<pre><code>Actor A ‚îê
        ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ Actor C
Actor B ‚îò
</code></pre>
<h2 id="concurrency-model"><a class="header" href="#concurrency-model">Concurrency Model</a></h2>
<h3 id="actor-isolation"><a class="header" href="#actor-isolation">Actor Isolation</a></h3>
<ul>
<li>Each actor runs in its own execution context</li>
<li>No shared memory between actors</li>
<li>Thread-safe by design</li>
</ul>
<h3 id="message-processing"><a class="header" href="#message-processing">Message Processing</a></h3>
<ul>
<li>Actors process messages asynchronously</li>
<li>Messages are queued for processing</li>
<li>Backpressure handling prevents overflow</li>
</ul>
<h3 id="parallelism"><a class="header" href="#parallelism">Parallelism</a></h3>
<ul>
<li>Multiple actors can run simultaneously</li>
<li>Work is distributed across available CPU cores</li>
<li>Network can span multiple machines</li>
</ul>
<h2 id="error-handling"><a class="header" href="#error-handling">Error Handling</a></h2>
<h3 id="actor-level-errors"><a class="header" href="#actor-level-errors">Actor-Level Errors</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Errors are returned as Error messages
Err(anyhow::anyhow!("Processing failed"))
<span class="boring">}</span></code></pre></pre>
<h3 id="network-level-errors"><a class="header" href="#network-level-errors">Network-Level Errors</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Error propagation through the network
HashMap::from([
    ("error".to_string(), Message::Error("Network timeout".to_string()))
])
<span class="boring">}</span></code></pre></pre>
<h3 id="recovery-patterns"><a class="header" href="#recovery-patterns">Recovery Patterns</a></h3>
<ul>
<li>Dead letter queues for failed messages</li>
<li>Circuit breakers for failing actors</li>
<li>Supervisor actors for monitoring</li>
</ul>
<h2 id="lifecycle-management"><a class="header" href="#lifecycle-management">Lifecycle Management</a></h2>
<h3 id="actor-creation"><a class="header" href="#actor-creation">Actor Creation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let actor = MyActor::new(config);
let process = actor.create_process();
tokio::spawn(process);
<span class="boring">}</span></code></pre></pre>
<h3 id="actor-termination"><a class="header" href="#actor-termination">Actor Termination</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Graceful shutdown
drop(inports); // Closes input channels
// Actor completes current message and exits
<span class="boring">}</span></code></pre></pre>
<h3 id="state-persistence"><a class="header" href="#state-persistence">State Persistence</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// State can be persisted and restored
let state = actor.get_state();
// Serialize state for persistence
<span class="boring">}</span></code></pre></pre>
<h2 id="advanced-concepts"><a class="header" href="#advanced-concepts">Advanced Concepts</a></h2>
<h3 id="hot-code-reloading"><a class="header" href="#hot-code-reloading">Hot Code Reloading</a></h3>
<ul>
<li>Script actors can be updated without stopping the workflow</li>
<li>State preservation during updates</li>
</ul>
<h3 id="multi-tenancy"><a class="header" href="#multi-tenancy">Multi-tenancy</a></h3>
<ul>
<li>Isolated workspaces for different users/projects</li>
<li>Resource quotas and permissions</li>
</ul>
<h3 id="distributed-execution"><a class="header" href="#distributed-execution">Distributed Execution</a></h3>
<ul>
<li>Actors can run on different machines</li>
<li>Network-transparent message passing</li>
</ul>
<h2 id="best-practices"><a class="header" href="#best-practices">Best Practices</a></h2>
<h3 id="actor-design"><a class="header" href="#actor-design">Actor Design</a></h3>
<ul>
<li>Keep actors small and focused</li>
<li>Avoid blocking operations in actor logic</li>
<li>Use async/await for I/O operations</li>
</ul>
<h3 id="message-design"><a class="header" href="#message-design">Message Design</a></h3>
<ul>
<li>Use typed messages when possible</li>
<li>Keep messages small and serializable</li>
<li>Include error context in error messages</li>
</ul>
<h3 id="workflow-design"><a class="header" href="#workflow-design">Workflow Design</a></h3>
<ul>
<li>Design for failure (circuit breakers, timeouts)</li>
<li>Monitor actor performance and health</li>
<li>Use appropriate parallelism levels</li>
</ul>
<h2 id="next-steps-2"><a class="header" href="#next-steps-2">Next Steps</a></h2>
<p>Now that you understand the basic concepts:</p>
<ol>
<li><strong>Set up development</strong>: <a href="getting-started/./development-setup.html">Development Setup</a></li>
<li><strong>Create your first workflow</strong>: <a href="getting-started/./first-workflow.html">First Workflow</a></li>
<li><strong>Learn about specific actors</strong>: <a href="getting-started/../api/actors/creating-actors.html">Actor API</a></li>
<li><strong>Explore scripting</strong>: <a href="getting-started/../scripting/javascript/deno-runtime.html">JavaScript Runtime</a></li>
</ol>
<h2 id="further-reading"><a class="header" href="#further-reading">Further Reading</a></h2>
<ul>
<li><a href="getting-started/../architecture/actor-model.html">Actor Model Theory</a></li>
<li><a href="getting-started/../architecture/message-passing.html">Message Passing Details</a></li>
<li><a href="getting-started/../architecture/performance-considerations.html">Performance Considerations</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="development-setup"><a class="header" href="#development-setup">Development Setup</a></h1>
<p>This guide helps you set up a development environment for building workflows with Reflow.</p>
<h2 id="development-environment"><a class="header" href="#development-environment">Development Environment</a></h2>
<h3 id="recommended-tools"><a class="header" href="#recommended-tools">Recommended Tools</a></h3>
<ul>
<li><strong>IDE</strong>: Visual Studio Code or RustRover</li>
<li><strong>Version Control</strong>: Git</li>
<li><strong>Package Manager</strong>: Cargo for Rust dependencies</li>
<li><strong>Terminal</strong>: Modern terminal with good Unicode support</li>
</ul>
<h3 id="vs-code-extensions"><a class="header" href="#vs-code-extensions">VS Code Extensions</a></h3>
<p>For the best development experience with VS Code:</p>
<pre><code class="language-json">{
  "recommendations": [
    "rust-lang.rust-analyzer",
    "vadimcn.vscode-lldb",
    "serayuzgur.crates",
    "tamasfe.even-better-toml",
    "ms-vscode.vscode-json"
  ]
}
</code></pre>
<h2 id="project-structure"><a class="header" href="#project-structure">Project Structure</a></h2>
<h3 id="creating-a-new-reflow-project"><a class="header" href="#creating-a-new-reflow-project">Creating a New Reflow Project</a></h3>
<pre><code class="language-bash"># Create a new Rust project
cargo new my-reflow-app
cd my-reflow-app

# Add Reflow dependencies
cargo add reflow_network reflow_script reflow_components
</code></pre>
<h3 id="recommended-project-structure"><a class="header" href="#recommended-project-structure">Recommended Project Structure</a></h3>
<pre><code>my-reflow-app/
‚îú‚îÄ‚îÄ Cargo.toml
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.rs
‚îÇ   ‚îú‚îÄ‚îÄ actors/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mod.rs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ custom_actor.rs
‚îÇ   ‚îú‚îÄ‚îÄ workflows/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mod.rs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data_pipeline.rs
‚îÇ   ‚îî‚îÄ‚îÄ scripts/
‚îÇ       ‚îú‚îÄ‚îÄ process.js
‚îÇ       ‚îî‚îÄ‚îÄ transform.py
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ reflow.toml
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ integration_tests.rs
‚îî‚îÄ‚îÄ examples/
    ‚îî‚îÄ‚îÄ basic_workflow.rs
</code></pre>
<h3 id="cargotoml-configuration"><a class="header" href="#cargotoml-configuration">Cargo.toml Configuration</a></h3>
<pre><code class="language-toml">[package]
name = "my-reflow-app"
version = "0.1.0"
edition = "2021"

[dependencies]
reflow_network = "0.1.0"
reflow_script = { version = "0.1.0", features = ["deno", "python"] }
reflow_components = "0.1.0"
tokio = { version = "1.0", features = ["full"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
anyhow = "1.0"

[dev-dependencies]
tokio-test = "0.4"

[[example]]
name = "basic_workflow"
path = "examples/basic_workflow.rs"
</code></pre>
<h2 id="development-workflow"><a class="header" href="#development-workflow">Development Workflow</a></h2>
<h3 id="1-setting-up-the-main-application"><a class="header" href="#1-setting-up-the-main-application">1. Setting Up the Main Application</a></h3>
<p>Create <code>src/main.rs</code>:</p>
<pre><pre class="playground"><code class="language-rust">use reflow_network::network::Network;
use reflow_script::{ScriptActor, ScriptConfig, ScriptRuntime, ScriptEnvironment};
use tokio;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Initialize logging
    env_logger::init();
    
    // Create a network
    let mut network = Network::new();
    
    // Add actors to the network
    // ... your workflow setup
    
    // Start the network
    network.start().await?;
    
    Ok(())
}</code></pre></pre>
<h3 id="2-creating-custom-actors"><a class="header" href="#2-creating-custom-actors">2. Creating Custom Actors</a></h3>
<p>Create <code>src/actors/mod.rs</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub mod custom_actor;

pub use custom_actor::CustomActor;
<span class="boring">}</span></code></pre></pre>
<p>Create <code>src/actors/custom_actor.rs</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::actor::{Actor, ActorBehavior, ActorContext, Port};
use reflow_network::message::Message;
use std::collections::HashMap;

pub struct CustomActor {
    inports: Port,
    outports: Port,
}

impl CustomActor {
    pub fn new() -&gt; Self {
        Self {
            inports: flume::unbounded(),
            outports: flume::unbounded(),
        }
    }
}

impl Actor for CustomActor {
    fn get_behavior(&amp;self) -&gt; ActorBehavior {
        Box::new(|context: ActorContext| {
            Box::pin(async move {
                let payload = context.get_payload();
                
                // Your processing logic here
                let result = HashMap::from([
                    ("output".to_string(), Message::String("processed".to_string()))
                ]);
                
                Ok(result)
            })
        })
    }
    
    fn get_inports(&amp;self) -&gt; Port {
        self.inports.clone()
    }
    
    fn get_outports(&amp;self) -&gt; Port {
        self.outports.clone()
    }
    
    fn create_process(&amp;self) -&gt; std::pin::Pin&lt;Box&lt;dyn std::future::Future&lt;Output = ()&gt; + 'static + Send&gt;&gt; {
        // Default implementation from trait
        todo!("Implement process creation")
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="3-organizing-workflows"><a class="header" href="#3-organizing-workflows">3. Organizing Workflows</a></h3>
<p>Create <code>src/workflows/mod.rs</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub mod data_pipeline;

pub use data_pipeline::create_data_pipeline;
<span class="boring">}</span></code></pre></pre>
<p>Create <code>src/workflows/data_pipeline.rs</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::network::Network;
use crate::actors::CustomActor;

pub async fn create_data_pipeline() -&gt; Result&lt;Network, Box&lt;dyn std::error::Error&gt;&gt; {
    let mut network = Network::new();
    
    // Create actors
    let source_actor = CustomActor::new();
    let transform_actor = CustomActor::new();
    let sink_actor = CustomActor::new();
    
    // Add actors to network
    network.add_actor("source", Box::new(source_actor)).await?;
    network.add_actor("transform", Box::new(transform_actor)).await?;
    network.add_actor("sink", Box::new(sink_actor)).await?;
    
    // Connect actors
    network.connect("source", "output", "transform", "input").await?;
    network.connect("transform", "output", "sink", "input").await?;
    
    Ok(network)
}
<span class="boring">}</span></code></pre></pre>
<h2 id="testing-setup"><a class="header" href="#testing-setup">Testing Setup</a></h2>
<h3 id="unit-tests"><a class="header" href="#unit-tests">Unit Tests</a></h3>
<p>Create <code>src/actors/custom_actor.rs</code> with tests:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod tests {
    use super::*;
    use tokio_test;
    
    #[tokio::test]
    async fn test_custom_actor() {
        let actor = CustomActor::new();
        let behavior = actor.get_behavior();
        
        // Create test context
        let payload = HashMap::from([
            ("input".to_string(), Message::String("test".to_string()))
        ]);
        
        // Test behavior
        // Note: You'll need to create proper ActorContext for testing
        let result = behavior(/* test context */).await;
        assert!(result.is_ok());
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="integration-tests"><a class="header" href="#integration-tests">Integration Tests</a></h3>
<p>Create <code>tests/integration_tests.rs</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use my_reflow_app::workflows::create_data_pipeline;

#[tokio::test]
async fn test_data_pipeline() {
    let network = create_data_pipeline().await.unwrap();
    
    // Test the complete workflow
    // Send test data and verify output
}
<span class="boring">}</span></code></pre></pre>
<h2 id="configuration-management"><a class="header" href="#configuration-management">Configuration Management</a></h2>
<h3 id="environment-configuration"><a class="header" href="#environment-configuration">Environment Configuration</a></h3>
<p>Create <code>config/reflow.toml</code>:</p>
<pre><code class="language-toml">[development]
log_level = "debug"
thread_pool_size = 4

[production]
log_level = "info"
thread_pool_size = 8

[scripting]
deno_permissions = ["--allow-net", "--allow-read"]
python_interpreter = "python3"

[networking]
bind_address = "127.0.0.1:8080"
enable_metrics = true
</code></pre>
<h3 id="loading-configuration"><a class="header" href="#loading-configuration">Loading Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use serde::{Deserialize, Serialize};
use std::fs;

#[derive(Debug, Deserialize, Serialize)]
struct Config {
    development: Option&lt;EnvConfig&gt;,
    production: Option&lt;EnvConfig&gt;,
    scripting: Option&lt;ScriptingConfig&gt;,
    networking: Option&lt;NetworkingConfig&gt;,
}

#[derive(Debug, Deserialize, Serialize)]
struct EnvConfig {
    log_level: String,
    thread_pool_size: usize,
}

fn load_config() -&gt; Result&lt;Config, Box&lt;dyn std::error::Error&gt;&gt; {
    let config_str = fs::read_to_string("config/reflow.toml")?;
    let config: Config = toml::from_str(&amp;config_str)?;
    Ok(config)
}
<span class="boring">}</span></code></pre></pre>
<h2 id="development-scripts"><a class="header" href="#development-scripts">Development Scripts</a></h2>
<h3 id="makefile"><a class="header" href="#makefile">Makefile</a></h3>
<p>Create a <code>Makefile</code> for common tasks:</p>
<pre><code class="language-makefile">.PHONY: build test run clean docs

build:
	cargo build

test:
	cargo test

run:
	cargo run

clean:
	cargo clean

docs:
	cargo doc --open

check:
	cargo check
	cargo clippy -- -D warnings
	cargo fmt -- --check

dev:
	cargo watch -x run

install-tools:
	cargo install cargo-watch
	cargo install cargo-expand
</code></pre>
<h3 id="development-commands"><a class="header" href="#development-commands">Development Commands</a></h3>
<pre><code class="language-bash"># Development workflow
make build          # Build the project
make test           # Run tests
make check          # Run linting and formatting checks
make dev            # Run with auto-reload on changes

# Documentation
make docs           # Generate and open documentation
cargo doc --document-private-items  # Include private items
</code></pre>
<h2 id="debugging"><a class="header" href="#debugging">Debugging</a></h2>
<h3 id="logging-setup"><a class="header" href="#logging-setup">Logging Setup</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tracing::{info, warn, error, debug};
use tracing_subscriber;

// In main.rs
fn init_logging() {
    tracing_subscriber::fmt()
        .with_max_level(tracing::Level::DEBUG)
        .init();
}

// In your actors
debug!("Processing message: {:?}", message);
info!("Actor started successfully");
warn!("High memory usage detected");
error!("Failed to process message: {}", error);
<span class="boring">}</span></code></pre></pre>
<h3 id="debug-configuration"><a class="header" href="#debug-configuration">Debug Configuration</a></h3>
<p>Add to <code>Cargo.toml</code>:</p>
<pre><code class="language-toml">[profile.dev]
debug = true
debug-assertions = true
overflow-checks = true

[dependencies]
tracing = "0.1"
tracing-subscriber = "0.3"
</code></pre>
<h3 id="using-debugger"><a class="header" href="#using-debugger">Using Debugger</a></h3>
<p>For VS Code, create <code>.vscode/launch.json</code>:</p>
<pre><code class="language-json">{
    "version": "0.2.0",
    "configurations": [
        {
            "type": "lldb",
            "request": "launch",
            "name": "Debug Reflow App",
            "cargo": {
                "args": ["build", "--bin=my-reflow-app"],
                "filter": {
                    "name": "my-reflow-app",
                    "kind": "bin"
                }
            },
            "args": [],
            "cwd": "${workspaceFolder}"
        }
    ]
}
</code></pre>
<h2 id="performance-profiling"><a class="header" href="#performance-profiling">Performance Profiling</a></h2>
<h3 id="basic-profiling"><a class="header" href="#basic-profiling">Basic Profiling</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::time::Instant;

// Time critical sections
let start = Instant::now();
// ... your code
let duration = start.elapsed();
println!("Time elapsed: {:?}", duration);
<span class="boring">}</span></code></pre></pre>
<h3 id="advanced-profiling-tools"><a class="header" href="#advanced-profiling-tools">Advanced Profiling Tools</a></h3>
<pre><code class="language-bash"># Install profiling tools
cargo install cargo-profiler
cargo install flamegraph

# Generate flame graphs
cargo flamegraph --bin my-reflow-app

# Memory profiling with valgrind (Linux)
cargo build --release
valgrind --tool=massif ./target/release/my-reflow-app
</code></pre>
<h2 id="continuous-integration"><a class="header" href="#continuous-integration">Continuous Integration</a></h2>
<h3 id="github-actions"><a class="header" href="#github-actions">GitHub Actions</a></h3>
<p>Create <code>.github/workflows/ci.yml</code>:</p>
<pre><code class="language-yaml">name: CI

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - uses: actions-rs/toolchain@v1
      with:
        toolchain: stable
    - name: Build
      run: cargo build --verbose
    - name: Run tests
      run: cargo test --verbose
    - name: Check formatting
      run: cargo fmt -- --check
    - name: Run clippy
      run: cargo clippy -- -D warnings
</code></pre>
<h2 id="next-steps-3"><a class="header" href="#next-steps-3">Next Steps</a></h2>
<p>Now that your development environment is set up:</p>
<ol>
<li><strong>Create your first workflow</strong>: <a href="getting-started/./first-workflow.html">First Workflow</a></li>
<li><strong>Learn about actors</strong>: <a href="getting-started/../api/actors/creating-actors.html">Creating Actors</a></li>
<li><strong>Explore scripting</strong>: <a href="getting-started/../scripting/javascript/deno-runtime.html">Deno Runtime</a></li>
<li><strong>See examples</strong>: <a href="getting-started/../examples/README.html">Examples</a></li>
</ol>
<h2 id="resources"><a class="header" href="#resources">Resources</a></h2>
<ul>
<li><a href="https://doc.rust-lang.org/book/">Rust Book</a></li>
<li><a href="https://tokio.rs/tokio/tutorial">Tokio Tutorial</a></li>
<li><a href="getting-started/../examples/README.html">Reflow Examples</a></li>
<li><a href="getting-started/../reference/api-reference.html">API Reference</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="your-first-workflow"><a class="header" href="#your-first-workflow">Your First Workflow</a></h1>
<p>This tutorial will guide you through creating and running your first Reflow workflow using the actual implementation patterns. We'll build a simple data processing pipeline that demonstrates the core concepts.</p>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>We'll create a workflow that:</p>
<ol>
<li>Processes input numbers (Sum Actor)</li>
<li>Squares the result (Square Actor)</li>
<li>Validates the output (Assert Actor)</li>
</ol>
<pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Sum   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Square  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Assert  ‚îÇ
‚îÇ Actor   ‚îÇ    ‚îÇ Actor   ‚îÇ    ‚îÇ Actor   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre>
<h2 id="prerequisites-2"><a class="header" href="#prerequisites-2">Prerequisites</a></h2>
<p>Before starting, make sure you have:</p>
<ul>
<li>Completed the <a href="getting-started/./installation.html">Installation</a> guide</li>
<li>Set up your <a href="getting-started/./development-setup.html">Development Environment</a></li>
<li>Understanding of <a href="getting-started/./basic-concepts.html">Basic Concepts</a></li>
</ul>
<h2 id="step-1-create-a-new-project"><a class="header" href="#step-1-create-a-new-project">Step 1: Create a New Project</a></h2>
<pre><code class="language-bash"># Create a new Rust project
cargo new hello-reflow
cd hello-reflow

# Add Reflow dependencies
cargo add reflow_network
cargo add actor_macro
cargo add tokio --features full
cargo add serde --features derive
cargo add serde_json anyhow
cargo add parking_lot
</code></pre>
<p>Your <code>Cargo.toml</code> should look like this:</p>
<pre><code class="language-toml">[package]
name = "hello-reflow"
version = "0.1.0"
edition = "2021"

[dependencies]
reflow_network = { path = "../path/to/reflow/crates/reflow_network" }
actor_macro = { path = "../path/to/reflow/crates/actor_macro" }
tokio = { version = "1.0", features = ["full"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
anyhow = "1.0"
parking_lot = "0.12"
</code></pre>
<h2 id="step-2-create-your-first-actors"><a class="header" href="#step-2-create-your-first-actors">Step 2: Create Your First Actors</a></h2>
<p>Create <code>src/main.rs</code> with the correct actor patterns:</p>
<pre><pre class="playground"><code class="language-rust">use std::collections::HashMap;
use reflow_network::{
    actor::{ActorContext, MemoryState},
    network::{Network, NetworkConfig},
    connector::{ConnectionPoint, Connector, InitialPacket},
    message::Message,
};
use actor_macro::actor;

// Sum Actor - adds two input numbers
#[actor(
    SumActor,
    inports::&lt;100&gt;(A, B),
    outports::&lt;100&gt;(Out),
    await_all_inports
)]
async fn sum_actor(context: ActorContext) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt; {
    let payload = context.get_payload();

    let a_msg = payload.get("A").expect("expected to get data from port A");
    let b_msg = payload.get("B").expect("expected to get data from port B");

    let a = match a_msg {
        Message::Integer(value) =&gt; *value,
        _ =&gt; 0,
    };

    let b = match b_msg {
        Message::Integer(value) =&gt; *value,
        _ =&gt; 0,
    };

    let result = a + b;
    println!("Sum Actor: {} + {} = {}", a, b, result);

    Ok([("Out".to_owned(), Message::integer(result))].into())
}

// Square Actor - squares the input number
#[actor(
    SquareActor,
    inports::&lt;100&gt;(In),
    outports::&lt;50&gt;(Out)
)]
async fn square_actor(context: ActorContext) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt; {
    let payload = context.get_payload();
    let message = payload.get("In").expect("expected input");
    
    let input = match message {
        Message::Integer(value) =&gt; *value,
        _ =&gt; 0,
    };

    let result = input * input;
    println!("Square Actor: {} squared = {}", input, result);

    Ok([("Out".to_owned(), Message::Integer(result))].into())
}

// Print Actor - displays the final result
#[actor(
    PrintActor,
    inports::&lt;100&gt;(Value),
    outports::&lt;50&gt;(Done)
)]
async fn print_actor(context: ActorContext) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt; {
    let payload = context.get_payload();
    let message = payload.get("Value").expect("expected value");
    
    match message {
        Message::Integer(value) =&gt; {
            println!("üéâ Final Result: {}", value);
        },
        _ =&gt; {
            println!("üìÑ Final Result: {:?}", message);
        }
    }

    Ok([("Done".to_owned(), Message::Boolean(true))].into())
}

#[tokio::main]
async fn main() -&gt; Result&lt;(), anyhow::Error&gt; {
    println!("üöÄ Starting Hello Reflow workflow...");
    
    // Create network with default configuration
    let mut network = Network::new(NetworkConfig::default());

    // Register actor types
    network.register_actor("sum_process", SumActor::new())?;
    network.register_actor("square_process", SquareActor::new())?;
    network.register_actor("print_process", PrintActor::new())?;

    // Add actor instances (nodes)
    network.add_node("sum", "sum_process")?;
    network.add_node("square", "square_process")?;
    network.add_node("print", "print_process")?;

    // Connect the workflow: sum -&gt; square -&gt; print
    network.add_connection(Connector {
        from: ConnectionPoint {
            actor: "sum".to_owned(),
            port: "Out".to_owned(),
            ..Default::default()
        },
        to: ConnectionPoint {
            actor: "square".to_owned(),
            port: "In".to_owned(),
            ..Default::default()
        },
    });

    network.add_connection(Connector {
        from: ConnectionPoint {
            actor: "square".to_owned(),
            port: "Out".to_owned(),
            ..Default::default()
        },
        to: ConnectionPoint {
            actor: "print".to_owned(),
            port: "Value".to_owned(),
            ..Default::default()
        },
    });

    // Add initial data to start the workflow
    network.add_initial(InitialPacket {
        to: ConnectionPoint {
            actor: "sum".to_owned(),
            port: "A".to_owned(),
            initial_data: Some(Message::Integer(5)),
        },
    });

    network.add_initial(InitialPacket {
        to: ConnectionPoint {
            actor: "sum".to_owned(),
            port: "B".to_owned(),
            initial_data: Some(Message::Integer(3)),
        },
    });

    // Start the network
    network.start().await?;

    // Give the workflow time to complete
    tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;

    println!("‚úÖ Workflow completed!");
    
    Ok(())
}</code></pre></pre>
<h2 id="step-3-run-the-workflow"><a class="header" href="#step-3-run-the-workflow">Step 3: Run the Workflow</a></h2>
<pre><code class="language-bash">cargo run
</code></pre>
<p>You should see output like:</p>
<pre><code>üöÄ Starting Hello Reflow workflow...
Sum Actor: 5 + 3 = 8
Square Actor: 8 squared = 64
üéâ Final Result: 64
‚úÖ Workflow completed!
</code></pre>
<h2 id="step-4-understanding-the-code"><a class="header" href="#step-4-understanding-the-code">Step 4: Understanding the Code</a></h2>
<h3 id="actor-macro-usage"><a class="header" href="#actor-macro-usage">Actor Macro Usage</a></h3>
<p>The <code>#[actor]</code> macro simplifies actor creation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[actor(
    SumActor,                    // Generated struct name
    inports::&lt;100&gt;(A, B),        // Input ports with capacity
    outports::&lt;100&gt;(Out),        // Output ports with capacity
    await_all_inports            // Wait for all inputs before processing
)]
async fn sum_actor(context: ActorContext) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt;
<span class="boring">}</span></code></pre></pre>
<h3 id="function-signature"><a class="header" href="#function-signature">Function Signature</a></h3>
<p>All actor functions must have this exact signature:</p>
<ul>
<li><code>async fn</code> - Asynchronous function</li>
<li><code>context: ActorContext</code> - Single parameter containing payload, state, config</li>
<li><code>Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt;</code> - Return type</li>
</ul>
<h3 id="network-api-pattern"><a class="header" href="#network-api-pattern">Network API Pattern</a></h3>
<ol>
<li><strong>Register</strong> actor types: <code>network.register_actor("name", ActorStruct::new())</code></li>
<li><strong>Add</strong> node instances: <code>network.add_node("instance_id", "actor_type")</code></li>
<li><strong>Connect</strong> with <code>Connector</code> structs</li>
<li><strong>Initialize</strong> with <code>InitialPacket</code> structs</li>
</ol>
<h2 id="step-5-add-state-management"><a class="header" href="#step-5-add-state-management">Step 5: Add State Management</a></h2>
<p>Let's create a stateful actor that counts operations:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Counter Actor - keeps track of how many values it has processed
#[actor(
    CounterActor,
    state(MemoryState),
    inports::&lt;100&gt;(Value),
    outports::&lt;50&gt;(Count, Total)
)]
async fn counter_actor(context: ActorContext) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt; {
    let payload = context.get_payload();
    let state = context.get_state();
    let input = payload.get("Value").expect("expected value");
    
    let value = match input {
        Message::Integer(n) =&gt; *n,
        _ =&gt; 0,
    };

    // Update state
    let (count, total) = {
        let mut state_guard = state.lock();
        let memory_state = state_guard
            .as_mut_any()
            .downcast_mut::&lt;MemoryState&gt;()
            .expect("Expected MemoryState");
        
        // Get current count and total
        let current_count = memory_state
            .get("count")
            .and_then(|v| v.as_i64())
            .unwrap_or(0);
        
        let current_total = memory_state
            .get("total")
            .and_then(|v| v.as_i64())
            .unwrap_or(0);
        
        // Update values
        let new_count = current_count + 1;
        let new_total = current_total + value;
        
        memory_state.insert("count", serde_json::json!(new_count));
        memory_state.insert("total", serde_json::json!(new_total));
        
        (new_count, new_total)
    };

    println!("Counter Actor: processed {} values, total sum: {}", count, total);

    Ok([
        ("Count".to_owned(), Message::Integer(count)),
        ("Total".to_owned(), Message::Integer(total)),
    ].into())
}
<span class="boring">}</span></code></pre></pre>
<h2 id="step-6-multiple-input-example"><a class="header" href="#step-6-multiple-input-example">Step 6: Multiple Input Example</a></h2>
<p>Create an actor that waits for multiple inputs:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Multiply Actor - multiplies two inputs
#[actor(
    MultiplyActor,
    inports::&lt;100&gt;(X, Y),
    outports::&lt;50&gt;(Result),
    await_all_inports  // This makes it wait for both X and Y
)]
async fn multiply_actor(context: ActorContext) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt; {
    let payload = context.get_payload();

    let x = match payload.get("X").expect("expected X") {
        Message::Integer(value) =&gt; *value,
        _ =&gt; 1,
    };

    let y = match payload.get("Y").expect("expected Y") {
        Message::Integer(value) =&gt; *value,
        _ =&gt; 1,
    };

    let result = x * y;
    println!("Multiply Actor: {} √ó {} = {}", x, y, result);

    Ok([("Result".to_owned(), Message::Integer(result))].into())
}
<span class="boring">}</span></code></pre></pre>
<h2 id="step-7-complex-workflow-example"><a class="header" href="#step-7-complex-workflow-example">Step 7: Complex Workflow Example</a></h2>
<p>Here's a more complex workflow that demonstrates multiple patterns:</p>
<pre><pre class="playground"><code class="language-rust">#[tokio::main]
async fn main() -&gt; Result&lt;(), anyhow::Error&gt; {
    println!("üöÄ Starting Complex Reflow workflow...");
    
    let mut network = Network::new(NetworkConfig::default());

    // Register all actor types
    network.register_actor("sum_process", SumActor::new())?;
    network.register_actor("multiply_process", MultiplyActor::new())?;
    network.register_actor("counter_process", CounterActor::new())?;
    network.register_actor("print_process", PrintActor::new())?;

    // Create network topology
    network.add_node("sum1", "sum_process")?;
    network.add_node("multiply1", "multiply_process")?;
    network.add_node("counter1", "counter_process")?;
    network.add_node("print1", "print_process")?;

    // Connect workflow
    network.add_connection(Connector {
        from: ConnectionPoint {
            actor: "sum1".to_owned(),
            port: "Out".to_owned(),
            ..Default::default()
        },
        to: ConnectionPoint {
            actor: "multiply1".to_owned(),
            port: "X".to_owned(),
            ..Default::default()
        },
    });

    network.add_connection(Connector {
        from: ConnectionPoint {
            actor: "multiply1".to_owned(),
            port: "Result".to_owned(),
            ..Default::default()
        },
        to: ConnectionPoint {
            actor: "counter1".to_owned(),
            port: "Value".to_owned(),
            ..Default::default()
        },
    });

    network.add_connection(Connector {
        from: ConnectionPoint {
            actor: "counter1".to_owned(),
            port: "Total".to_owned(),
            ..Default::default()
        },
        to: ConnectionPoint {
            actor: "print1".to_owned(),
            port: "Value".to_owned(),
            ..Default::default()
        },
    });

    // Initial data
    network.add_initial(InitialPacket {
        to: ConnectionPoint {
            actor: "sum1".to_owned(),
            port: "A".to_owned(),
            initial_data: Some(Message::Integer(10)),
        },
    });

    network.add_initial(InitialPacket {
        to: ConnectionPoint {
            actor: "sum1".to_owned(),
            port: "B".to_owned(),
            initial_data: Some(Message::Integer(5)),
        },
    });

    network.add_initial(InitialPacket {
        to: ConnectionPoint {
            actor: "multiply1".to_owned(),
            port: "Y".to_owned(),
            initial_data: Some(Message::Integer(3)),
        },
    });

    // Start the network
    network.start().await?;
    
    tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;
    
    println!("‚úÖ Complex workflow completed!");
    
    Ok(())
}</code></pre></pre>
<p>Expected output:</p>
<pre><code>üöÄ Starting Complex Reflow workflow...
Sum Actor: 10 + 5 = 15
Multiply Actor: 15 √ó 3 = 45
Counter Actor: processed 1 values, total sum: 45
üéâ Final Result: 45
‚úÖ Complex workflow completed!
</code></pre>
<h2 id="key-concepts-demonstrated"><a class="header" href="#key-concepts-demonstrated">Key Concepts Demonstrated</a></h2>
<h3 id="actor-macro-features"><a class="header" href="#actor-macro-features">Actor Macro Features</a></h3>
<ul>
<li><strong>Port Definitions</strong>: <code>inports::&lt;capacity&gt;(Port1, Port2)</code></li>
<li><strong>State Management</strong>: <code>state(MemoryState)</code> for stateful actors</li>
<li><strong>Input Synchronization</strong>: <code>await_all_inports</code> waits for all inputs</li>
</ul>
<h3 id="network-configuration"><a class="header" href="#network-configuration">Network Configuration</a></h3>
<ul>
<li><strong>Registration</strong>: Register actor types before use</li>
<li><strong>Instantiation</strong>: Create specific instances with unique IDs</li>
<li><strong>Connection</strong>: Use structured <code>Connector</code> objects</li>
<li><strong>Initialization</strong>: Send initial data with <code>InitialPacket</code></li>
</ul>
<h3 id="message-flow"><a class="header" href="#message-flow">Message Flow</a></h3>
<ul>
<li>Messages flow through typed ports</li>
<li>Actors process inputs and produce outputs</li>
<li>State is maintained per actor instance</li>
</ul>
<h2 id="error-handling-1"><a class="header" href="#error-handling-1">Error Handling</a></h2>
<p>Actors can return errors that will be logged:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[actor(
    ValidatorActor,
    inports::&lt;100&gt;(Input),
    outports::&lt;50&gt;(Valid, Invalid)
)]
async fn validator_actor(context: ActorContext) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt; {
    let payload = context.get_payload();
    let input = payload.get("Input").expect("expected input");
    
    match input {
        Message::Integer(n) if *n &gt; 0 =&gt; {
            Ok([("Valid".to_owned(), input.clone())].into())
        },
        Message::Integer(n) if *n &lt;= 0 =&gt; {
            Ok([("Invalid".to_owned(), input.clone())].into())
        },
        _ =&gt; {
            Err(anyhow::anyhow!("Expected integer input, got {:?}", input))
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="next-steps-4"><a class="header" href="#next-steps-4">Next Steps</a></h2>
<p>Now that you understand the basic patterns:</p>
<ol>
<li><strong>Learn more actor patterns</strong>: <a href="getting-started/../api/actors/creating-actors.html">Creating Actors</a></li>
<li><strong>Explore message types</strong>: <a href="getting-started/../architecture/message-passing.html">Message Passing</a></li>
<li><strong>Add scripting</strong>: <a href="getting-started/../scripting/javascript/deno-runtime.html">JavaScript Integration</a></li>
<li><strong>Use pre-built components</strong>: <a href="getting-started/../components/standard-library.html">Standard Library</a></li>
<li><strong>See more examples</strong>: <a href="getting-started/../examples/README.html">Examples</a></li>
</ol>
<h2 id="troubleshooting-1"><a class="header" href="#troubleshooting-1">Troubleshooting</a></h2>
<h3 id="common-issues-1"><a class="header" href="#common-issues-1">Common Issues</a></h3>
<p><strong>Compilation errors with actor macro</strong>: Make sure <code>actor_macro</code> is in your dependencies</p>
<p><strong>Port connection errors</strong>: Verify port names match exactly between connections</p>
<p><strong>Runtime panics</strong>: Check that initial data types match what actors expect</p>
<p><strong>Deadlocks</strong>: Ensure <code>await_all_inports</code> actors receive all required inputs</p>
<p>For more help, see the <a href="getting-started/../reference/troubleshooting-guide.html">Troubleshooting Guide</a>.</p>
<h2 id="complete-example-code"><a class="header" href="#complete-example-code">Complete Example Code</a></h2>
<p>The complete working examples are available in the <a href="getting-started/../examples/tutorials/hello-reflow/">examples directory</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="architecture-overview"><a class="header" href="#architecture-overview">Architecture Overview</a></h1>
<p>This document provides a high-level overview of Reflow's architecture, covering its core components, design principles, and system interactions.</p>
<h2 id="system-architecture"><a class="header" href="#system-architecture">System Architecture</a></h2>
<p>Reflow follows a modular, actor-based architecture designed for scalability, reliability, and multi-language support.</p>
<pre><code class="language-mermaid">graph TB
    subgraph "Application Layer"
        WF[Workflows]
        SC[Scripts]
        CP[Components]
    end
    
    subgraph "Actor System"
        AC[Actor Core]
        MSG[Message System]
        NET[Network Layer]
    end
    
    subgraph "Runtime Layer"
        DR[Deno Runtime]
        PR[Python Runtime]
        WR[WASM Runtime]
        NR[Native Runtime]
    end
    
    subgraph "Infrastructure"
        THR[Thread Pool]
        SER[Serialization]
        NET_IO[Network I/O]
        FS[File System]
    end
    
    WF --&gt; AC
    SC --&gt; DR
    SC --&gt; PR
    SC --&gt; WR
    CP --&gt; NR
    
    AC --&gt; MSG
    MSG --&gt; NET
    
    NET --&gt; THR
    NET --&gt; SER
    NET --&gt; NET_IO
    NET --&gt; FS
</code></pre>
<h2 id="core-components"><a class="header" href="#core-components">Core Components</a></h2>
<h3 id="1-actor-system-reflow_network"><a class="header" href="#1-actor-system-reflow_network">1. Actor System (<code>reflow_network</code>)</a></h3>
<p>The foundation of Reflow, implementing the actor model for concurrent computation:</p>
<ul>
<li><strong>Actors</strong>: Isolated units of computation</li>
<li><strong>Messages</strong>: Immutable data passed between actors</li>
<li><strong>Ports</strong>: Communication channels (input/output)</li>
<li><strong>Network</strong>: Manages actor lifecycle and message routing</li>
</ul>
<h3 id="2-script-runtime-reflow_script"><a class="header" href="#2-script-runtime-reflow_script">2. Script Runtime (<code>reflow_script</code>)</a></h3>
<p>Multi-language execution environment supporting:</p>
<ul>
<li><strong>Deno Runtime</strong>: JavaScript/TypeScript execution</li>
<li><strong>Python Engine</strong>: Python script execution (with optional Docker isolation)</li>
<li><strong>WebAssembly</strong>: WASM plugin system via Extism</li>
<li><strong>Script Context</strong>: Execution environment and state management</li>
</ul>
<h3 id="3-component-library-reflow_components"><a class="header" href="#3-component-library-reflow_components">3. Component Library (<code>reflow_components</code>)</a></h3>
<p>Pre-built, reusable workflow components:</p>
<ul>
<li><strong>Flow Control</strong>: Conditional logic, loops, branching</li>
<li><strong>Data Operations</strong>: Transformations, aggregations, validation</li>
<li><strong>Integration</strong>: External API connectivity</li>
<li><strong>Synchronization</strong>: Coordination primitives</li>
</ul>
<h3 id="4-network-layer-reflow_network"><a class="header" href="#4-network-layer-reflow_network">4. Network Layer (<code>reflow_network</code>)</a></h3>
<p>Handles distributed execution and communication:</p>
<ul>
<li><strong>Message Routing</strong>: Efficient message delivery</li>
<li><strong>Graph Management</strong>: Workflow topology and execution</li>
<li><strong>Connection Management</strong>: Inter-actor connectivity</li>
<li><strong>Load Balancing</strong>: Work distribution</li>
</ul>
<h2 id="design-principles"><a class="header" href="#design-principles">Design Principles</a></h2>
<h3 id="actor-model"><a class="header" href="#actor-model">Actor Model</a></h3>
<p>Reflow is built on the <strong>Actor Model</strong> of computation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait Actor {
    fn get_behavior(&amp;self) -&gt; ActorBehavior;
    fn get_inports(&amp;self) -&gt; Port;
    fn get_outports(&amp;self) -&gt; Port;
    fn create_process(&amp;self) -&gt; Pin&lt;Box&lt;dyn Future&lt;Output = ()&gt; + Send + 'static&gt;&gt;;
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Key Properties:</strong></p>
<ul>
<li><strong>Isolation</strong>: No shared state between actors</li>
<li><strong>Concurrency</strong>: Actors run concurrently</li>
<li><strong>Message Passing</strong>: Communication via immutable messages</li>
<li><strong>Location Transparency</strong>: Actors can be local or remote</li>
</ul>
<h3 id="immutable-messages"><a class="header" href="#immutable-messages">Immutable Messages</a></h3>
<p>All communication uses immutable message types:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum Message {
    String(String),
    Integer(i64),
    Float(f64),
    Boolean(bool),
    Array(Vec&lt;Message&gt;),
    Object(HashMap&lt;String, Message&gt;),
    Binary(Vec&lt;u8&gt;),
    Null,
    Error(String),
}
<span class="boring">}</span></code></pre></pre>
<h3 id="async-first-design"><a class="header" href="#async-first-design">Async-First Design</a></h3>
<p>Built on Rust's async/await system using Tokio:</p>
<ul>
<li>Non-blocking I/O operations</li>
<li>Efficient resource utilization</li>
<li>Scalable concurrent execution</li>
<li>Backpressure handling</li>
</ul>
<h2 id="execution-model"><a class="header" href="#execution-model">Execution Model</a></h2>
<h3 id="actor-lifecycle"><a class="header" href="#actor-lifecycle">Actor Lifecycle</a></h3>
<pre><code class="language-mermaid">stateDiagram-v2
    [*] --&gt; Created
    Created --&gt; Initialized
    Initialized --&gt; Running
    Running --&gt; Processing
    Processing --&gt; Running
    Running --&gt; Stopping
    Stopping --&gt; Stopped
    Stopped --&gt; [*]
    
    Processing --&gt; Error
    Error --&gt; Running
    Error --&gt; Stopping
</code></pre>
<ol>
<li><strong>Creation</strong>: Actor instance created with configuration</li>
<li><strong>Initialization</strong>: Resources allocated, connections established</li>
<li><strong>Running</strong>: Actor ready to process messages</li>
<li><strong>Processing</strong>: Executing behavior function on incoming messages</li>
<li><strong>Stopping</strong>: Graceful shutdown initiated</li>
<li><strong>Stopped</strong>: All resources cleaned up</li>
</ol>
<h3 id="message-flow-1"><a class="header" href="#message-flow-1">Message Flow</a></h3>
<pre><code class="language-mermaid">sequenceDiagram
    participant S as Source Actor
    participant M as Message Bus
    participant T as Target Actor
    
    S-&gt;&gt;M: Send Message
    M-&gt;&gt;M: Route Message
    M-&gt;&gt;T: Deliver Message
    T-&gt;&gt;T: Process Message
    T-&gt;&gt;M: Send Response
    M-&gt;&gt;S: Deliver Response
</code></pre>
<h3 id="graph-execution"><a class="header" href="#graph-execution">Graph Execution</a></h3>
<p>Workflows are executed as directed acyclic graphs (DAGs):</p>
<ul>
<li><strong>Topological Ordering</strong>: Ensures correct execution sequence</li>
<li><strong>Parallel Execution</strong>: Independent branches run concurrently</li>
<li><strong>Backpressure</strong>: Prevents resource exhaustion</li>
<li><strong>Error Propagation</strong>: Failures are handled gracefully</li>
</ul>
<h2 id="runtime-architecture"><a class="header" href="#runtime-architecture">Runtime Architecture</a></h2>
<h3 id="native-runtime-rust"><a class="header" href="#native-runtime-rust">Native Runtime (Rust)</a></h3>
<p>Direct Rust implementation for maximum performance:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct NativeActor {
    behavior: Box&lt;dyn Fn(ActorContext) -&gt; Pin&lt;Box&lt;dyn Future&lt;Output = Result&lt;HashMap&lt;String, Message&gt;, Error&gt;&gt; + Send&gt;&gt;&gt;,
    // ... other fields
}
<span class="boring">}</span></code></pre></pre>
<h3 id="script-runtimes"><a class="header" href="#script-runtimes">Script Runtimes</a></h3>
<h4 id="deno-runtime"><a class="header" href="#deno-runtime">Deno Runtime</a></h4>
<ul>
<li><strong>Sandbox</strong>: Secure execution environment</li>
<li><strong>Permissions</strong>: Fine-grained access control</li>
<li><strong>TypeScript</strong>: Full TypeScript support</li>
<li><strong>NPM</strong>: Package ecosystem access</li>
</ul>
<h4 id="python-runtime"><a class="header" href="#python-runtime">Python Runtime</a></h4>
<ul>
<li><strong>Isolation</strong>: Process-level or Docker isolation</li>
<li><strong>Libraries</strong>: Full Python ecosystem support</li>
<li><strong>Async</strong>: Async/await support</li>
<li><strong>Error Handling</strong>: Exception propagation</li>
</ul>
<h4 id="webassembly-runtime"><a class="header" href="#webassembly-runtime">WebAssembly Runtime</a></h4>
<ul>
<li><strong>Portability</strong>: Cross-platform execution</li>
<li><strong>Security</strong>: Sandboxed execution</li>
<li><strong>Performance</strong>: Near-native speed</li>
<li><strong>Multi-language</strong>: Support for multiple source languages</li>
</ul>
<h2 id="memory-management"><a class="header" href="#memory-management">Memory Management</a></h2>
<h3 id="ownership-model"><a class="header" href="#ownership-model">Ownership Model</a></h3>
<p>Follows Rust's ownership principles:</p>
<ul>
<li><strong>Single Ownership</strong>: Each value has a single owner</li>
<li><strong>Borrowing</strong>: Temporary access without ownership transfer</li>
<li><strong>Lifetimes</strong>: Compile-time memory safety guarantees</li>
<li><strong>Reference Counting</strong>: Shared ownership where needed</li>
</ul>
<h3 id="message-serialization"><a class="header" href="#message-serialization">Message Serialization</a></h3>
<p>Efficient serialization for message passing:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Compressed serialization for performance
let compressed = compress_message(&amp;message)?;
let serialized = bitcode::serialize(&amp;compressed)?;

// Network transmission
send_over_network(serialized).await?;

// Deserialization
let message = bitcode::deserialize(&amp;received_data)?;
let decompressed = decompress_message(&amp;message)?;
<span class="boring">}</span></code></pre></pre>
<h2 id="networking-architecture"><a class="header" href="#networking-architecture">Networking Architecture</a></h2>
<h3 id="local-communication"><a class="header" href="#local-communication">Local Communication</a></h3>
<pre><code class="language-mermaid">graph LR
    A1[Actor 1] --&gt; C1[Channel]
    C1 --&gt; A2[Actor 2]
    A2 --&gt; C2[Channel]
    C2 --&gt; A3[Actor 3]
</code></pre>
<p><strong>Local Channels:</strong></p>
<ul>
<li><strong>Flume</strong>: High-performance async channels</li>
<li><strong>Zero-copy</strong>: Direct memory access where possible</li>
<li><strong>Backpressure</strong>: Flow control mechanisms</li>
</ul>
<h3 id="distributed-communication"><a class="header" href="#distributed-communication">Distributed Communication</a></h3>
<pre><code class="language-mermaid">graph TB
    subgraph "Node 1"
        A1[Actor A]
        A2[Actor B]
    end
    
    subgraph "Network Layer"
        N1[Network Bridge]
        N2[Network Bridge]
    end
    
    subgraph "Node 2"
        A3[Actor C]
        A4[Actor D]
    end
    
    A1 --&gt; N1
    N1 --&gt; N2
    N2 --&gt; A3
</code></pre>
<p><strong>Network Features:</strong></p>
<ul>
<li><strong>WebSocket</strong>: Real-time communication</li>
<li><strong>Compression</strong>: Efficient data transfer</li>
<li><strong>Encryption</strong>: Secure communication</li>
<li><strong>Discovery</strong>: Automatic node discovery</li>
</ul>
<h2 id="error-handling-2"><a class="header" href="#error-handling-2">Error Handling</a></h2>
<h3 id="hierarchical-error-management"><a class="header" href="#hierarchical-error-management">Hierarchical Error Management</a></h3>
<pre><code class="language-mermaid">graph TD
    A[Actor Error] --&gt; B[Network Error Handler]
    B --&gt; C[Workflow Error Handler]
    C --&gt; D[Application Error Handler]
    
    B --&gt; E[Circuit Breaker]
    C --&gt; F[Retry Logic]
    D --&gt; G[Dead Letter Queue]
</code></pre>
<p><strong>Error Strategies:</strong></p>
<ul>
<li><strong>Isolation</strong>: Errors don't affect other actors</li>
<li><strong>Propagation</strong>: Structured error reporting</li>
<li><strong>Recovery</strong>: Automatic retry and fallback</li>
<li><strong>Monitoring</strong>: Error tracking and alerting</li>
</ul>
<h2 id="security-model"><a class="header" href="#security-model">Security Model</a></h2>
<h3 id="sandboxing"><a class="header" href="#sandboxing">Sandboxing</a></h3>
<p>Each runtime environment provides isolation:</p>
<ul>
<li><strong>Deno</strong>: V8 isolates with permission system</li>
<li><strong>Python</strong>: Process isolation or containerization</li>
<li><strong>WASM</strong>: Memory-safe execution environment</li>
<li><strong>Native</strong>: Rust's memory safety guarantees</li>
</ul>
<h3 id="permission-system"><a class="header" href="#permission-system">Permission System</a></h3>
<p>Fine-grained access control:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct Permissions {
    pub file_system: FileSystemPermissions,
    pub network: NetworkPermissions,
    pub environment: EnvironmentPermissions,
}
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-characteristics"><a class="header" href="#performance-characteristics">Performance Characteristics</a></h2>
<h3 id="throughput"><a class="header" href="#throughput">Throughput</a></h3>
<ul>
<li><strong>Message Rate</strong>: &gt;1M messages/second (local)</li>
<li><strong>Latency</strong>: &lt;1ms (local), &lt;10ms (network)</li>
<li><strong>Memory</strong>: ~1KB per actor overhead</li>
<li><strong>CPU</strong>: Scales with core count</li>
</ul>
<h3 id="scalability"><a class="header" href="#scalability">Scalability</a></h3>
<ul>
<li><strong>Horizontal</strong>: Distribute across machines</li>
<li><strong>Vertical</strong>: Utilize all CPU cores</li>
<li><strong>Elastic</strong>: Dynamic resource allocation</li>
<li><strong>Backpressure</strong>: Graceful degradation under load</li>
</ul>
<h2 id="configuration-1"><a class="header" href="#configuration-1">Configuration</a></h2>
<h3 id="runtime-configuration"><a class="header" href="#runtime-configuration">Runtime Configuration</a></h3>
<pre><code class="language-toml">[actor_system]
thread_pool_size = 8
max_actors_per_node = 10000
message_buffer_size = 1000

[networking]
bind_address = "0.0.0.0:8080"
compression_enabled = true
encryption_enabled = true

[runtimes.deno]
permissions = ["--allow-net", "--allow-read"]
memory_limit = "512MB"

[runtimes.python]
use_docker = false
shared_environment = true
</code></pre>
<h2 id="monitoring-and-observability"><a class="header" href="#monitoring-and-observability">Monitoring and Observability</a></h2>
<h3 id="metrics"><a class="header" href="#metrics">Metrics</a></h3>
<ul>
<li><strong>Actor Performance</strong>: Processing time, message rates</li>
<li><strong>Network Statistics</strong>: Bandwidth, latency, errors</li>
<li><strong>Resource Usage</strong>: Memory, CPU, disk I/O</li>
<li><strong>Error Rates</strong>: Failure frequencies and patterns</li>
</ul>
<h3 id="tracing"><a class="header" href="#tracing">Tracing</a></h3>
<p>Distributed tracing support:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tracing::{info, span, Level};

let span = span!(Level::INFO, "actor_processing", actor_id = %actor.id());
let _enter = span.enter();

info!("Processing message: {:?}", message);
<span class="boring">}</span></code></pre></pre>
<h2 id="extension-points"><a class="header" href="#extension-points">Extension Points</a></h2>
<h3 id="custom-actors"><a class="header" href="#custom-actors">Custom Actors</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl Actor for CustomActor {
    fn get_behavior(&amp;self) -&gt; ActorBehavior {
        Box::new(|context| {
            Box::pin(async move {
                // Custom processing logic
                Ok(HashMap::new())
            })
        })
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="custom-runtimes"><a class="header" href="#custom-runtimes">Custom Runtimes</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[async_trait]
impl ScriptEngine for CustomEngine {
    async fn init(&amp;mut self, config: &amp;ScriptConfig) -&gt; Result&lt;()&gt;;
    async fn call(&amp;mut self, context: &amp;ScriptContext) -&gt; Result&lt;HashMap&lt;String, Message&gt;&gt;;
    async fn cleanup(&amp;mut self) -&gt; Result&lt;()&gt;;
}
<span class="boring">}</span></code></pre></pre>
<h2 id="next-steps-5"><a class="header" href="#next-steps-5">Next Steps</a></h2>
<p>For detailed information on specific components:</p>
<ul>
<li><a href="architecture/./actor-model.html">Actor Model</a> - Deep dive into actor implementation</li>
<li><a href="architecture/./message-passing.html">Message Passing</a> - Message system details</li>
<li><a href="architecture/./graph-system.html">Graph System</a> - Workflow graph management</li>
<li><a href="architecture/./multi-language-support.html">Multi-Language Support</a> - Runtime integration</li>
<li><a href="architecture/./performance-considerations.html">Performance Considerations</a> - Optimization strategies</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="actor-model-1"><a class="header" href="#actor-model-1">Actor Model</a></h1>
<p>This document provides an in-depth look at how Reflow implements the Actor Model of computation.</p>
<h2 id="introduction"><a class="header" href="#introduction">Introduction</a></h2>
<p>The Actor Model is a mathematical model of concurrent computation that treats "actors" as the universal primitives of concurrent computation. In Reflow, actors are isolated computational units that communicate exclusively through message passing.</p>
<h2 id="core-principles"><a class="header" href="#core-principles">Core Principles</a></h2>
<h3 id="1-everything-is-an-actor"><a class="header" href="#1-everything-is-an-actor">1. Everything is an Actor</a></h3>
<p>In Reflow's actor system:</p>
<ul>
<li>Data processing units are actors</li>
<li>Message routers are actors</li>
<li>Database connections are actors</li>
<li>Network services are actors</li>
</ul>
<h3 id="2-actors-communicate-via-messages"><a class="header" href="#2-actors-communicate-via-messages">2. Actors Communicate via Messages</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Messages are immutable and serializable
pub enum Message {
    String(String),
    Integer(i64),
    Float(f64),
    Boolean(bool),
    Array(Vec&lt;Message&gt;),
    Object(HashMap&lt;String, Message&gt;),
    Binary(Vec&lt;u8&gt;),
    Null,
    Error(String),
}
<span class="boring">}</span></code></pre></pre>
<h3 id="3-actors-have-private-state"><a class="header" href="#3-actors-have-private-state">3. Actors Have Private State</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait ActorState: Send + Sync + 'static {
    fn as_any(&amp;self) -&gt; &amp;dyn Any;
    fn as_mut_any(&amp;mut self) -&gt; &amp;mut dyn Any;
}

#[derive(Default, Debug, Clone)]
pub struct MemoryState(pub HashMap&lt;String, Value&gt;);
<span class="boring">}</span></code></pre></pre>
<h3 id="4-actors-process-messages-sequentially"><a class="header" href="#4-actors-process-messages-sequentially">4. Actors Process Messages Sequentially</a></h3>
<p>Each actor processes one message at a time, ensuring thread safety without locks.</p>
<h2 id="actor-implementation"><a class="header" href="#actor-implementation">Actor Implementation</a></h2>
<h3 id="actor-trait"><a class="header" href="#actor-trait">Actor Trait</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait Actor: Send + Sync + 'static {
    /// Defines how the actor processes messages
    fn get_behavior(&amp;self) -&gt; ActorBehavior;
    
    /// Access to input ports
    fn get_inports(&amp;self) -&gt; Port;
    
    /// Access to output ports
    fn get_outports(&amp;self) -&gt; Port;
    
    /// Create the actor's execution process
    fn create_process(&amp;self) -&gt; Pin&lt;Box&lt;dyn Future&lt;Output = ()&gt; + 'static + Send&gt;&gt;;
    
    /// Load counting for backpressure (optional)
    fn load_count(&amp;self) -&gt; Arc&lt;Mutex&lt;ActorLoad&gt;&gt; {
        Arc::new(Mutex::new(ActorLoad::new(0)))
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="actor-behavior"><a class="header" href="#actor-behavior">Actor Behavior</a></h3>
<p>The behavior function defines how an actor responds to messages:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub type ActorBehavior = Box&lt;
    dyn Fn(ActorContext) -&gt; Pin&lt;Box&lt;dyn Future&lt;Output = Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt;&gt; + Send + 'static&gt;&gt;
        + Send + Sync + 'static,
&gt;;
<span class="boring">}</span></code></pre></pre>
<h3 id="actor-context"><a class="header" href="#actor-context">Actor Context</a></h3>
<p>The context provides access to the actor's environment:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct ActorContext {
    pub payload: ActorPayload,
    pub outports: Port,
    pub state: Arc&lt;Mutex&lt;dyn ActorState&gt;&gt;,
    pub config: HashMap&lt;String, Value&gt;,
    load: Arc&lt;Mutex&lt;ActorLoad&gt;&gt;,
}

impl ActorContext {
    pub fn get_state(&amp;self) -&gt; Arc&lt;Mutex&lt;dyn ActorState&gt;&gt;;
    pub fn get_config(&amp;self) -&gt; &amp;HashMap&lt;String, Value&gt;;
    pub fn get_payload(&amp;self) -&gt; &amp;ActorPayload;
    pub fn get_outports(&amp;self) -&gt; Port;
    pub fn done(&amp;self);
}
<span class="boring">}</span></code></pre></pre>
<h2 id="actor-types-1"><a class="header" href="#actor-types-1">Actor Types</a></h2>
<h3 id="1-native-actors"><a class="header" href="#1-native-actors">1. Native Actors</a></h3>
<p>Written directly in Rust for maximum performance:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::actor::{Actor, ActorBehavior, ActorContext, Port, MemoryState};
use reflow_network::message::Message;
use std::collections::HashMap;

pub struct FilterActor {
    threshold: f64,
    inports: Port,
    outports: Port,
}

impl FilterActor {
    pub fn new(threshold: f64) -&gt; Self {
        Self {
            threshold,
            inports: flume::unbounded(),
            outports: flume::unbounded(),
        }
    }
}

impl Actor for FilterActor {
    fn get_behavior(&amp;self) -&gt; ActorBehavior {
        let threshold = self.threshold;
        
        Box::new(move |context: ActorContext| {
            Box::pin(async move {
                let payload = context.get_payload();
                let mut results = HashMap::new();
                
                if let Some(Message::Float(value)) = payload.get("input") {
                    if *value &gt; threshold {
                        results.insert("output".to_string(), Message::Float(*value));
                    }
                }
                
                Ok(results)
            })
        })
    }
    
    fn get_inports(&amp;self) -&gt; Port { self.inports.clone() }
    fn get_outports(&amp;self) -&gt; Port { self.outports.clone() }
    
    fn create_process(&amp;self) -&gt; Pin&lt;Box&lt;dyn Future&lt;Output = ()&gt; + 'static + Send&gt;&gt; {
        // Implementation details...
        todo!()
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="2-script-actors"><a class="header" href="#2-script-actors">2. Script Actors</a></h3>
<p>Execute scripts in various languages:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_script::{ScriptActor, ScriptConfig, ScriptRuntime, ScriptEnvironment};

// JavaScript Actor
let js_config = ScriptConfig {
    environment: ScriptEnvironment::SYSTEM,
    runtime: ScriptRuntime::JavaScript,
    source: include_bytes!("script.js").to_vec(),
    entry_point: "process".to_string(),
    packages: None,
};

let js_actor = ScriptActor::new(js_config);
<span class="boring">}</span></code></pre></pre>
<h3 id="3-component-actors"><a class="header" href="#3-component-actors">3. Component Actors</a></h3>
<p>Pre-built components from the library:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::flow_control::ConditionalActor;
use reflow_components::data_operations::MapActor;

let conditional = ConditionalActor::new(|msg| {
    if let Message::Integer(n) = msg {
        *n &gt; 0
    } else {
        false
    }
});

let mapper = MapActor::new(|msg| {
    if let Message::Integer(n) = msg {
        Message::Integer(n * 2)
    } else {
        msg.clone()
    }
});
<span class="boring">}</span></code></pre></pre>
<h2 id="message-passing-semantics"><a class="header" href="#message-passing-semantics">Message Passing Semantics</a></h2>
<h3 id="asynchronous-messaging"><a class="header" href="#asynchronous-messaging">Asynchronous Messaging</a></h3>
<p>Messages are sent asynchronously without blocking:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Send message without waiting
outport.send_async(message).await?;

// Receive message when available
let message = inport.recv_async().await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="message-ordering"><a class="header" href="#message-ordering">Message Ordering</a></h3>
<ul>
<li>Messages between the same pair of actors maintain order</li>
<li>No global ordering guarantees across different actor pairs</li>
<li>Use synchronization actors for coordination when needed</li>
</ul>
<h3 id="message-delivery"><a class="header" href="#message-delivery">Message Delivery</a></h3>
<ul>
<li><strong>At-most-once</strong>: Messages may be lost but never duplicated</li>
<li><strong>Best-effort</strong>: System attempts delivery but doesn't guarantee it</li>
<li><strong>Backpressure</strong>: Slow consumers cause senders to block</li>
</ul>
<h2 id="actor-lifecycle-management"><a class="header" href="#actor-lifecycle-management">Actor Lifecycle Management</a></h2>
<h3 id="creation-and-initialization"><a class="header" href="#creation-and-initialization">Creation and Initialization</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create actor
let actor = MyActor::new(config);

// Initialize ports and state
let inports = actor.get_inports();
let outports = actor.get_outports();

// Start actor process
let process = actor.create_process();
tokio::spawn(process);
<span class="boring">}</span></code></pre></pre>
<h3 id="message-processing-loop"><a class="header" href="#message-processing-loop">Message Processing Loop</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn create_process(&amp;self) -&gt; Pin&lt;Box&lt;dyn Future&lt;Output = ()&gt; + 'static + Send&gt;&gt; {
    let inports = self.get_inports();
    let behavior = self.get_behavior();
    let state = Arc::new(Mutex::new(MemoryState::default()));
    let outports = self.get_outports();
    
    Box::pin(async move {
        while let Ok(payload) = inports.1.recv_async().await {
            let context = ActorContext::new(
                payload,
                outports.clone(),
                state.clone(),
                HashMap::new(),
                Arc::new(Mutex::new(ActorLoad::new(0))),
            );
            
            match behavior(context).await {
                Ok(result) =&gt; {
                    if !result.is_empty() {
                        let _ = outports.0.send_async(result).await;
                    }
                },
                Err(e) =&gt; {
                    let error_msg = HashMap::from([
                        ("error".to_string(), Message::Error(e.to_string()))
                    ]);
                    let _ = outports.0.send_async(error_msg).await;
                }
            }
        }
    })
}
<span class="boring">}</span></code></pre></pre>
<h3 id="termination"><a class="header" href="#termination">Termination</a></h3>
<p>Actors terminate when:</p>
<ul>
<li>Input ports are closed (no more messages)</li>
<li>Explicit shutdown signal</li>
<li>Unrecoverable error occurs</li>
</ul>
<h2 id="state-management"><a class="header" href="#state-management">State Management</a></h2>
<h3 id="actor-state-types"><a class="header" href="#actor-state-types">Actor State Types</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Simple memory state
let state = MemoryState::default();

// Custom state implementation
struct CounterState {
    count: AtomicU64,
}

impl ActorState for CounterState {
    fn as_any(&amp;self) -&gt; &amp;dyn Any { self }
    fn as_mut_any(&amp;mut self) -&gt; &amp;mut dyn Any { self }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="state-persistence-1"><a class="header" href="#state-persistence-1">State Persistence</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Access state in behavior
fn get_behavior(&amp;self) -&gt; ActorBehavior {
    Box::new(|context: ActorContext| {
        Box::pin(async move {
            let state = context.get_state();
            let mut state_guard = state.lock();
            
            // Read/modify state
            if let Some(memory_state) = state_guard.as_mut_any().downcast_mut::&lt;MemoryState&gt;() {
                memory_state.insert("counter", serde_json::json!(42));
            }
            
            Ok(HashMap::new())
        })
    })
}
<span class="boring">}</span></code></pre></pre>
<h2 id="error-handling-3"><a class="header" href="#error-handling-3">Error Handling</a></h2>
<h3 id="actor-level-errors-1"><a class="header" href="#actor-level-errors-1">Actor-Level Errors</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Return error from behavior
Err(anyhow::anyhow!("Processing failed: {}", reason))

// Handle errors in message processing
match behavior(context).await {
    Ok(result) =&gt; send_result(result).await,
    Err(e) =&gt; send_error(e).await,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="error-propagation"><a class="header" href="#error-propagation">Error Propagation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Error message format
let error_message = HashMap::from([
    ("error".to_string(), Message::Error("Database connection failed".to_string())),
    ("code".to_string(), Message::Integer(500)),
    ("timestamp".to_string(), Message::String(Utc::now().to_rfc3339())),
]);
<span class="boring">}</span></code></pre></pre>
<h3 id="supervision-strategies"><a class="header" href="#supervision-strategies">Supervision Strategies</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Supervisor actor monitors children
struct SupervisorActor {
    children: Vec&lt;ActorRef&gt;,
    restart_policy: RestartPolicy,
}

enum RestartPolicy {
    OneForOne,    // Restart only failed actor
    OneForAll,    // Restart all actors
    RestForOne,   // Restart failed and subsequent actors
}
<span class="boring">}</span></code></pre></pre>
<h2 id="concurrency-and-parallelism"><a class="header" href="#concurrency-and-parallelism">Concurrency and Parallelism</a></h2>
<h3 id="actor-isolation-1"><a class="header" href="#actor-isolation-1">Actor Isolation</a></h3>
<ul>
<li>Each actor runs in isolation</li>
<li>No shared mutable state</li>
<li>Communication only via messages</li>
<li>Thread-safe by design</li>
</ul>
<h3 id="parallel-execution"><a class="header" href="#parallel-execution">Parallel Execution</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Multiple actors can run simultaneously
tokio::spawn(actor1.create_process());
tokio::spawn(actor2.create_process());
tokio::spawn(actor3.create_process());

// Actors on different CPU cores
let rt = tokio::runtime::Builder::new_multi_thread()
    .worker_threads(num_cpus::get())
    .build()?;
<span class="boring">}</span></code></pre></pre>
<h3 id="load-balancing"><a class="header" href="#load-balancing">Load Balancing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Round-robin message distribution
struct LoadBalancerActor {
    workers: Vec&lt;Port&gt;,
    current: AtomicUsize,
}

impl LoadBalancerActor {
    fn next_worker(&amp;self) -&gt; &amp;Port {
        let index = self.current.fetch_add(1, Ordering::Relaxed) % self.workers.len();
        &amp;self.workers[index]
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-considerations"><a class="header" href="#performance-considerations">Performance Considerations</a></h2>
<h3 id="memory-usage"><a class="header" href="#memory-usage">Memory Usage</a></h3>
<ul>
<li>Actors have minimal overhead (~1KB per actor)</li>
<li>Messages are reference-counted when possible</li>
<li>State is lazily allocated</li>
</ul>
<h3 id="message-throughput"><a class="header" href="#message-throughput">Message Throughput</a></h3>
<ul>
<li>Local messages: &gt;1M messages/second</li>
<li>Network messages: 10K-100K messages/second</li>
<li>Batch processing for high throughput</li>
</ul>
<h3 id="backpressure-handling"><a class="header" href="#backpressure-handling">Backpressure Handling</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Check actor load before sending
let load = actor.load_count();
if load.lock().get() &gt; MAX_LOAD {
    // Apply backpressure
    tokio::time::sleep(Duration::from_millis(10)).await;
}
<span class="boring">}</span></code></pre></pre>
<h2 id="advanced-patterns"><a class="header" href="#advanced-patterns">Advanced Patterns</a></h2>
<h3 id="actor-pooling"><a class="header" href="#actor-pooling">Actor Pooling</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct ActorPool&lt;T: Actor&gt; {
    actors: Vec&lt;T&gt;,
    distributor: LoadBalancerActor,
}

impl&lt;T: Actor&gt; ActorPool&lt;T&gt; {
    pub fn new(size: usize, factory: impl Fn() -&gt; T) -&gt; Self {
        let actors: Vec&lt;T&gt; = (0..size).map(|_| factory()).collect();
        // ... setup distributor
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="hot-swapping"><a class="header" href="#hot-swapping">Hot Swapping</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Replace actor behavior without stopping
actor.update_behavior(new_behavior).await?;

// Migrate state to new actor version
let old_state = old_actor.get_state();
new_actor.set_state(old_state).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="circuit-breaker"><a class="header" href="#circuit-breaker">Circuit Breaker</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct CircuitBreakerActor {
    target: ActorRef,
    failure_count: AtomicU32,
    state: AtomicU8, // Open, Closed, HalfOpen
}

impl CircuitBreakerActor {
    fn should_allow_request(&amp;self) -&gt; bool {
        match self.state.load(Ordering::Relaxed) {
            0 =&gt; true,  // Closed
            1 =&gt; false, // Open
            2 =&gt; true,  // HalfOpen
            _ =&gt; false,
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="testing-actors"><a class="header" href="#testing-actors">Testing Actors</a></h2>
<h3 id="unit-testing"><a class="header" href="#unit-testing">Unit Testing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[tokio::test]
async fn test_filter_actor() {
    let actor = FilterActor::new(5.0);
    let behavior = actor.get_behavior();
    
    // Create test context
    let payload = HashMap::from([
        ("input".to_string(), Message::Float(10.0))
    ]);
    
    let context = create_test_context(payload);
    let result = behavior(context).await.unwrap();
    
    assert!(result.contains_key("output"));
}
<span class="boring">}</span></code></pre></pre>
<h3 id="integration-testing"><a class="header" href="#integration-testing">Integration Testing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[tokio::test]
async fn test_actor_pipeline() {
    let source = SourceActor::new();
    let filter = FilterActor::new(5.0);
    let sink = SinkActor::new();
    
    // Connect actors
    connect_actors(&amp;source, &amp;filter).await;
    connect_actors(&amp;filter, &amp;sink).await;
    
    // Start pipeline
    let handles = vec![
        tokio::spawn(source.create_process()),
        tokio::spawn(filter.create_process()),
        tokio::spawn(sink.create_process()),
    ];
    
    // Test data flow
    // ... assertions
}
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-1"><a class="header" href="#best-practices-1">Best Practices</a></h2>
<h3 id="actor-design-1"><a class="header" href="#actor-design-1">Actor Design</a></h3>
<ol>
<li><strong>Keep actors small and focused</strong> - Single responsibility principle</li>
<li><strong>Avoid blocking operations</strong> - Use async/await for I/O</li>
<li><strong>Handle errors gracefully</strong> - Don't let actors crash</li>
<li><strong>Design for failure</strong> - Expect message loss and actor failures</li>
</ol>
<h3 id="message-design-1"><a class="header" href="#message-design-1">Message Design</a></h3>
<ol>
<li><strong>Keep messages immutable</strong> - Never modify messages after sending</li>
<li><strong>Use appropriate message sizes</strong> - Balance between batching and latency</li>
<li><strong>Include context</strong> - Messages should carry enough information</li>
<li><strong>Handle malformed messages</strong> - Validate input gracefully</li>
</ol>
<h3 id="state-management-1"><a class="header" href="#state-management-1">State Management</a></h3>
<ol>
<li><strong>Minimize state</strong> - Less state means fewer bugs</li>
<li><strong>Make state serializable</strong> - Enable persistence and distribution</li>
<li><strong>Avoid shared state</strong> - Each actor owns its state</li>
<li><strong>Design for recovery</strong> - State should be reconstructible</li>
</ol>
<h2 id="next-steps-6"><a class="header" href="#next-steps-6">Next Steps</a></h2>
<ul>
<li><a href="architecture/./message-passing.html">Message Passing</a> - Detailed message system</li>
<li><a href="architecture/./graph-system.html">Graph System</a> - Workflow composition</li>
<li><a href="architecture/../api/actors/creating-actors.html">Creating Actors</a> - Practical guide</li>
<li><a href="architecture/./performance-considerations.html">Performance Optimization</a> - Tuning guidelines</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="message-passing"><a class="header" href="#message-passing">Message Passing</a></h1>
<p>This document details Reflow's message passing system, which is the primary communication mechanism between actors.</p>
<h2 id="message-types"><a class="header" href="#message-types">Message Types</a></h2>
<p>Reflow uses a strongly-typed message system with built-in serialization support:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(Clone, Debug, Serialize, Deserialize, Encode, Decode, PartialEq)]
pub enum Message {
    Flow,
    Event(EncodableValue),
    Boolean(bool),
    Integer(i64),
    Float(f64),
    String(Arc&lt;String&gt;),
    Object(Arc&lt;EncodableValue&gt;),
    Array(Arc&lt;Vec&lt;EncodableValue&gt;&gt;),
    Stream(Arc&lt;Vec&lt;u8&gt;&gt;),
    Encoded(Arc&lt;Vec&lt;u8&gt;&gt;),
    Optional(Option&lt;Arc&lt;EncodableValue&gt;&gt;),
    Any(Arc&lt;EncodableValue&gt;),
    Error(Arc&lt;String&gt;),
}
<span class="boring">}</span></code></pre></pre>
<h3 id="encodablevalue"><a class="header" href="#encodablevalue">EncodableValue</a></h3>
<p>Reflow uses <code>EncodableValue</code> as a wrapper for complex data types:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(Clone, Debug, Serialize, Deserialize, Encode, Decode, PartialEq, Eq)]
pub struct EncodableValue {
    pub(crate) data: Vec&lt;u8&gt;,
}

impl EncodableValue {
    pub fn new&lt;T: Encode&gt;(value: &amp;T) -&gt; Self {
        Self {
            data: bitcode::encode(value),
        }
    }

    pub fn decode&lt;'a, T: Decode&lt;'a&gt;&gt;(&amp;'a self) -&gt; Option&lt;T&gt; {
        bitcode::decode(&amp;self.data).ok()
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="message-conversion"><a class="header" href="#message-conversion">Message Conversion</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use serde_json::Value;

// From JSON values
let msg = Message::from(serde_json::json!(42));

// To JSON values  
let json: Value = message.into();

// Type checking
if let Message::Integer(n) = message {
    println!("Number: {}", n);
}

// Working with EncodableValue - modern approach
let data = serde_json::json!({"key": "value"});
let encodable = EncodableValue::from(data);
let object_msg = Message::object(encodable);

// Create arrays with EncodableValue - modern approach
let array_items = vec![
    EncodableValue::from(serde_json::json!("hello")),
    EncodableValue::from(serde_json::json!(42)),
];
let array_msg = Message::array(array_items);

// Alternative: using helper methods for simple values
let string_msg = Message::string("hello world".to_string());
let int_msg = Message::integer(42);
let bool_msg = Message::boolean(true);
let float_msg = Message::float(3.14);
let error_msg = Message::error("Something went wrong".to_string());
<span class="boring">}</span></code></pre></pre>
<h2 id="communication-channels"><a class="header" href="#communication-channels">Communication Channels</a></h2>
<h3 id="ports-1"><a class="header" href="#ports-1">Ports</a></h3>
<p>Ports are the communication endpoints for actors:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub type Port = (
    flume::Sender&lt;HashMap&lt;String, Message&gt;&gt;,
    flume::Receiver&lt;HashMap&lt;String, Message&gt;&gt;,
);

// Actor payload format
pub type ActorPayload = HashMap&lt;String, Message&gt;;
<span class="boring">}</span></code></pre></pre>
<h3 id="channel-properties"><a class="header" href="#channel-properties">Channel Properties</a></h3>
<ul>
<li><strong>Asynchronous</strong>: Non-blocking send/receive operations</li>
<li><strong>Bounded</strong>: Configurable buffer sizes for backpressure</li>
<li><strong>Multi-producer, Single-consumer</strong>: Multiple senders, one receiver per port</li>
<li><strong>Type-safe</strong>: Compile-time message type checking</li>
</ul>
<h2 id="message-flow-patterns"><a class="header" href="#message-flow-patterns">Message Flow Patterns</a></h2>
<h3 id="point-to-point-1"><a class="header" href="#point-to-point-1">Point-to-Point</a></h3>
<p>Direct communication between two actors:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Actor A sends to Actor B - using helper method
let message = HashMap::from([
    ("data".to_string(), Message::string("hello".to_string()))
]);
sender.send_async(message).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="broadcast-1"><a class="header" href="#broadcast-1">Broadcast</a></h3>
<p>One actor sends to multiple receivers:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Using actor macro for broadcast
#[actor(
    BroadcastActor,
    inports::&lt;100&gt;(input),
    outports::&lt;50&gt;(output1, output2, output3)
)]
async fn broadcast_actor(context: ActorContext) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt; {
    let payload = context.get_payload();
    
    if let Some(input_msg) = payload.get("input") {
        // Broadcast to all output ports
        Ok([
            ("output1".to_owned(), input_msg.clone()),
            ("output2".to_owned(), input_msg.clone()),
            ("output3".to_owned(), input_msg.clone()),
        ].into())
    } else {
        Err(anyhow::anyhow!("No input to broadcast"))
    }
}

// Manual implementation for dynamic outputs
struct ManualBroadcastActor {
    inports: Port,
    outports: Port,
    outputs: Vec&lt;flume::Sender&lt;HashMap&lt;String, Message&gt;&gt;&gt;,
    load: Arc&lt;Mutex&lt;ActorLoad&gt;&gt;,
}

impl ManualBroadcastActor {
    async fn broadcast(&amp;self, message: HashMap&lt;String, Message&gt;) -&gt; Result&lt;(), anyhow::Error&gt; {
        for output in &amp;self.outputs {
            output.send_async(message.clone()).await?;
        }
        Ok(())
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="fan-in-merge"><a class="header" href="#fan-in-merge">Fan-In (Merge)</a></h3>
<p>Multiple actors send to one receiver:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct MergeActor {
    inputs: Vec&lt;flume::Receiver&lt;HashMap&lt;String, Message&gt;&gt;&gt;,
    output: flume::Sender&lt;HashMap&lt;String, Message&gt;&gt;,
}

impl MergeActor {
    async fn merge_loop(&amp;self) {
        use futures::stream::{FuturesUnordered, StreamExt};
        
        let mut streams: FuturesUnordered&lt;_&gt; = self.inputs
            .iter()
            .map(|rx| rx.recv_async())
            .collect();
            
        while let Some(result) = streams.next().await {
            if let Ok(message) = result {
                let _ = self.output.send_async(message).await;
            }
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="serialization-and-transport"><a class="header" href="#serialization-and-transport">Serialization and Transport</a></h2>
<h3 id="local-serialization"><a class="header" href="#local-serialization">Local Serialization</a></h3>
<p>For local communication, messages use efficient in-memory representation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Zero-copy for simple types
let msg = Message::Integer(42); // No allocation

// Reference counting for complex types
let complex = Message::Object(data); // Rc&lt;HashMap&lt;String, Message&gt;&gt;
<span class="boring">}</span></code></pre></pre>
<h3 id="network-serialization"><a class="header" href="#network-serialization">Network Serialization</a></h3>
<p>For distributed communication:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bitcode;
use flate2::Compression;

// Compress and serialize
let compressed = compress_message(&amp;message, Compression::default())?;
let bytes = bitcode::serialize(&amp;compressed)?;

// Send over network
network_send(bytes).await?;

// Receive and deserialize
let received = network_receive().await?;
let message = bitcode::deserialize(&amp;received)?;
let decompressed = decompress_message(&amp;message)?;
<span class="boring">}</span></code></pre></pre>
<h2 id="message-routing"><a class="header" href="#message-routing">Message Routing</a></h2>
<h3 id="router-actor"><a class="header" href="#router-actor">Router Actor</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct RouterActor {
    routes: HashMap&lt;String, flume::Sender&lt;HashMap&lt;String, Message&gt;&gt;&gt;,
    default_route: Option&lt;flume::Sender&lt;HashMap&lt;String, Message&gt;&gt;&gt;,
}

impl RouterActor {
    pub fn route_message(&amp;self, key: &amp;str, message: HashMap&lt;String, Message&gt;) -&gt; Result&lt;()&gt; {
        if let Some(sender) = self.routes.get(key) {
            sender.try_send(message)?;
        } else if let Some(default) = &amp;self.default_route {
            default.try_send(message)?;
        }
        Ok(())
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="content-based-routing"><a class="header" href="#content-based-routing">Content-Based Routing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl RouterActor {
    fn route_by_content(&amp;self, message: &amp;HashMap&lt;String, Message&gt;) -&gt; Option&lt;&amp;str&gt; {
        // Route based on message content
        if let Some(Message::String(msg_type)) = message.get("type") {
            match msg_type.as_str() {
                "user_event" =&gt; Some("user_handler"),
                "system_event" =&gt; Some("system_handler"),
                "error" =&gt; Some("error_handler"),
                _ =&gt; None,
            }
        } else {
            None
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="error-handling-4"><a class="header" href="#error-handling-4">Error Handling</a></h2>
<h3 id="error-message-format"><a class="header" href="#error-message-format">Error Message Format</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Standard error message structure
let error_msg = HashMap::from([
    ("error".to_string(), Message::error("Processing failed".to_string())),
    ("code".to_string(), Message::integer(500)),
    ("source".to_string(), Message::string("database_actor".to_string())),
    ("timestamp".to_string(), Message::string(Utc::now().to_rfc3339())),
    ("details".to_string(), Message::object(error_details)),
]);
<span class="boring">}</span></code></pre></pre>
<h3 id="dead-letter-queue"><a class="header" href="#dead-letter-queue">Dead Letter Queue</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct DeadLetterQueue {
    storage: Arc&lt;Mutex&lt;Vec&lt;(String, HashMap&lt;String, Message&gt;)&gt;&gt;&gt;,
    max_size: usize,
}

impl DeadLetterQueue {
    pub async fn store_failed_message(
        &amp;self, 
        reason: String, 
        message: HashMap&lt;String, Message&gt;
    ) {
        let mut storage = self.storage.lock();
        if storage.len() &gt;= self.max_size {
            storage.remove(0); // Remove oldest
        }
        storage.push((reason, message));
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="backpressure-management"><a class="header" href="#backpressure-management">Backpressure Management</a></h2>
<h3 id="flow-control"><a class="header" href="#flow-control">Flow Control</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct FlowControlActor {
    input: flume::Receiver&lt;HashMap&lt;String, Message&gt;&gt;,
    output: flume::Sender&lt;HashMap&lt;String, Message&gt;&gt;,
    buffer_size: usize,
    current_load: Arc&lt;AtomicUsize&gt;,
}

impl FlowControlActor {
    async fn process_with_backpressure(&amp;self) {
        while let Ok(message) = self.input.recv_async().await {
            // Check current load
            let load = self.current_load.load(Ordering::Relaxed);
            
            if load &gt; self.buffer_size {
                // Apply backpressure - slow down
                tokio::time::sleep(Duration::from_millis(10)).await;
            }
            
            self.current_load.fetch_add(1, Ordering::Relaxed);
            
            // Process message
            if let Err(_) = self.output.try_send(message) {
                // Output buffer full, apply backpressure
                tokio::time::sleep(Duration::from_millis(1)).await;
            }
            
            self.current_load.fetch_sub(1, Ordering::Relaxed);
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="message-ordering-1"><a class="header" href="#message-ordering-1">Message Ordering</a></h2>
<h3 id="ordered-delivery"><a class="header" href="#ordered-delivery">Ordered Delivery</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct OrderedDeliveryActor {
    sequence_number: AtomicU64,
    expected_sequence: AtomicU64,
    buffer: Arc&lt;Mutex&lt;BTreeMap&lt;u64, HashMap&lt;String, Message&gt;&gt;&gt;&gt;,
}

impl OrderedDeliveryActor {
    fn add_sequence_number(&amp;self, mut message: HashMap&lt;String, Message&gt;) -&gt; HashMap&lt;String, Message&gt; {
        let seq = self.sequence_number.fetch_add(1, Ordering::Relaxed);
        message.insert("sequence".to_string(), Message::Integer(seq as i64));
        message
    }
    
    async fn deliver_in_order(&amp;self, message: HashMap&lt;String, Message&gt;) {
        if let Some(Message::Integer(seq)) = message.get("sequence") {
            let seq = *seq as u64;
            let expected = self.expected_sequence.load(Ordering::Relaxed);
            
            if seq == expected {
                // Deliver immediately
                self.deliver_message(message).await;
                self.expected_sequence.fetch_add(1, Ordering::Relaxed);
                
                // Check buffer for next messages
                self.deliver_buffered_messages().await;
            } else {
                // Buffer out-of-order message
                self.buffer.lock().insert(seq, message);
            }
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-optimization"><a class="header" href="#performance-optimization">Performance Optimization</a></h2>
<h3 id="message-batching"><a class="header" href="#message-batching">Message Batching</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use crate::message::{Message, EncodableValue};

pub struct BatchingActor {
    batch_size: usize,
    batch_timeout: Duration,
    current_batch: Vec&lt;HashMap&lt;String, Message&gt;&gt;,
    input: flume::Receiver&lt;HashMap&lt;String, Message&gt;&gt;,
    output: flume::Sender&lt;HashMap&lt;String, Message&gt;&gt;,
}

impl BatchingActor {
    async fn process_with_batching(&amp;mut self) {
        let mut interval = tokio::time::interval(self.batch_timeout);
        
        loop {
            tokio::select! {
                // Receive new message
                Ok(message) = self.input.recv_async() =&gt; {
                    self.current_batch.push(message);
                    
                    if self.current_batch.len() &gt;= self.batch_size {
                        self.flush_batch().await;
                    }
                }
                
                // Timeout - flush partial batch
                _ = interval.tick() =&gt; {
                    if !self.current_batch.is_empty() {
                        self.flush_batch().await;
                    }
                }
            }
        }
    }
    
    async fn flush_batch(&amp;mut self) {
        if !self.current_batch.is_empty() {
            // Convert to EncodableValue for proper serialization
            let batch_items: Vec&lt;EncodableValue&gt; = self.current_batch
                .drain(..)
                .map(|msg| EncodableValue::from(serde_json::to_value(msg).unwrap()))
                .collect();
            
            let batch = Message::Array(batch_items);
            
            let batch_message = HashMap::from([
                ("batch".to_string(), batch)
            ]);
            
            let _ = self.output.send_async(batch_message).await;
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="zero-copy-optimization"><a class="header" href="#zero-copy-optimization">Zero-Copy Optimization</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bytes::Bytes;

// Use Bytes for zero-copy binary data
let data = Bytes::from(vec![1, 2, 3, 4]);
let message = Message::Binary(data.to_vec());

// Reference counting for large objects
use std::sync::Arc;

struct LargeData {
    content: Vec&lt;u8&gt;,
}

let large_data = Arc::new(LargeData { content: vec![0; 1000000] });
// Pass Arc around instead of cloning large data
<span class="boring">}</span></code></pre></pre>
<h2 id="message-validation"><a class="header" href="#message-validation">Message Validation</a></h2>
<h3 id="schema-validation"><a class="header" href="#schema-validation">Schema Validation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use serde_json::Value;

pub struct MessageValidator {
    schemas: HashMap&lt;String, Value&gt;, // JSON Schema
}

impl MessageValidator {
    pub fn validate_message(
        &amp;self, 
        message_type: &amp;str, 
        message: &amp;HashMap&lt;String, Message&gt;
    ) -&gt; Result&lt;(), ValidationError&gt; {
        if let Some(schema) = self.schemas.get(message_type) {
            let json_value: Value = message.clone().into();
            validate_json_schema(&amp;json_value, schema)?;
        }
        Ok(())
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="type-safety"><a class="header" href="#type-safety">Type Safety</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Type-safe message builders
pub struct UserEventBuilder {
    user_id: Option&lt;String&gt;,
    event_type: Option&lt;String&gt;,
    timestamp: Option&lt;String&gt;,
}

impl UserEventBuilder {
    pub fn user_id(mut self, id: String) -&gt; Self {
        self.user_id = Some(id);
        self
    }
    
    pub fn event_type(mut self, event_type: String) -&gt; Self {
        self.event_type = Some(event_type);
        self
    }
    
    pub fn build(self) -&gt; Result&lt;HashMap&lt;String, Message&gt;, BuildError&gt; {
        let user_id = self.user_id.ok_or(BuildError::MissingUserId)?;
        let event_type = self.event_type.ok_or(BuildError::MissingEventType)?;
        
        Ok(HashMap::from([
            ("user_id".to_string(), Message::string(user_id)),
            ("event_type".to_string(), Message::string(event_type)),
            ("timestamp".to_string(), Message::string(Utc::now().to_rfc3339())),
        ]))
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="testing-message-passing"><a class="header" href="#testing-message-passing">Testing Message Passing</a></h2>
<h3 id="mock-channels"><a class="header" href="#mock-channels">Mock Channels</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct MockChannel {
    sent_messages: Arc&lt;Mutex&lt;Vec&lt;HashMap&lt;String, Message&gt;&gt;&gt;&gt;,
    responses: Arc&lt;Mutex&lt;VecDeque&lt;HashMap&lt;String, Message&gt;&gt;&gt;&gt;,
}

impl MockChannel {
    pub fn new() -&gt; Self {
        Self {
            sent_messages: Arc::new(Mutex::new(Vec::new())),
            responses: Arc::new(Mutex::new(VecDeque::new())),
        }
    }
    
    pub fn expect_message(&amp;self, message: HashMap&lt;String, Message&gt;) {
        self.responses.lock().push_back(message);
    }
    
    pub fn verify_sent(&amp;self, expected: &amp;HashMap&lt;String, Message&gt;) -&gt; bool {
        self.sent_messages.lock().contains(expected)
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="integration-testing-1"><a class="header" href="#integration-testing-1">Integration Testing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[tokio::test]
async fn test_message_pipeline() {
    let (tx1, rx1) = flume::unbounded();
    let (tx2, rx2) = flume::unbounded();
    
    // Create test actors
    let source = TestSourceActor::new(tx1);
    let processor = TestProcessorActor::new(rx1, tx2);
    let sink = TestSinkActor::new(rx2);
    
    // Start actors
    tokio::spawn(source.run());
    tokio::spawn(processor.run());
    tokio::spawn(sink.run());
    
    // Test message flow
    let test_message = HashMap::from([
        ("data".to_string(), Message::string("test".to_string()))
    ]);
    
    source.send(test_message.clone()).await;
    
    // Verify message received
    let received = sink.receive_next().await;
    assert_eq!(received.get("data"), test_message.get("data"));
}
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-2"><a class="header" href="#best-practices-2">Best Practices</a></h2>
<h3 id="message-design-2"><a class="header" href="#message-design-2">Message Design</a></h3>
<ol>
<li><strong>Keep messages immutable</strong> - Never modify after creation</li>
<li><strong>Use appropriate granularity</strong> - Not too fine, not too coarse</li>
<li><strong>Include enough context</strong> - Messages should be self-contained</li>
<li><strong>Design for evolution</strong> - Use versioned message formats</li>
</ol>
<h3 id="performance"><a class="header" href="#performance">Performance</a></h3>
<ol>
<li><strong>Batch when possible</strong> - Reduce overhead</li>
<li><strong>Use appropriate data types</strong> - Binary for large data</li>
<li><strong>Implement backpressure</strong> - Prevent resource exhaustion</li>
<li><strong>Monitor message rates</strong> - Track performance metrics</li>
</ol>
<h3 id="error-handling-5"><a class="header" href="#error-handling-5">Error Handling</a></h3>
<ol>
<li><strong>Use structured errors</strong> - Include error codes and context</li>
<li><strong>Implement dead letter queues</strong> - Don't lose failed messages</li>
<li><strong>Design for retry</strong> - Make operations idempotent</li>
<li><strong>Log message failures</strong> - Enable debugging</li>
</ol>
<h2 id="next-steps-7"><a class="header" href="#next-steps-7">Next Steps</a></h2>
<ul>
<li><a href="architecture/./graph-system.html">Graph System</a> - Workflow composition</li>
<li><a href="architecture/./multi-language-support.html">Multi-Language Support</a> - Script integration</li>
<li><a href="architecture/./performance-considerations.html">Performance Considerations</a> - Optimization</li>
<li><a href="architecture/../api/actors/creating-actors.html">Creating Actors</a> - Practical implementation</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="graph-system-architecture"><a class="header" href="#graph-system-architecture">Graph System Architecture</a></h1>
<p>Reflow's graph system provides a comprehensive flow-based programming (FBP) foundation for building visual workflow editors, data processing pipelines, and complex computational graphs. The system supports real-time validation, automatic layout, performance analysis, and both native Rust and WebAssembly implementations.</p>
<h2 id="core-concepts-1"><a class="header" href="#core-concepts-1">Core Concepts</a></h2>
<h3 id="graph-structure"><a class="header" href="#graph-structure">Graph Structure</a></h3>
<p>A Reflow graph consists of:</p>
<ul>
<li><strong>Nodes</strong>: Processing units that represent actors or components</li>
<li><strong>Connections</strong>: Data flow paths between node ports</li>
<li><strong>Ports</strong>: Input/output endpoints with typed interfaces</li>
<li><strong>Initial Information Packets (IIPs)</strong>: Static data injected into the graph</li>
<li><strong>Groups</strong>: Logical collections of related nodes</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{Graph, GraphNode, GraphConnection, GraphEdge, PortType};
use std::collections::HashMap;

// Create a new graph
let mut graph = Graph::new("MyWorkflow", false, None);

// Add nodes
graph.add_node("source", "DataSource", None);
graph.add_node("processor", "DataProcessor", None);
graph.add_node("sink", "DataSink", None);

// Connect nodes
graph.add_connection("source", "output", "processor", "input", None);
graph.add_connection("processor", "output", "sink", "input", None);
<span class="boring">}</span></code></pre></pre>
<h3 id="port-type-system"><a class="header" href="#port-type-system">Port Type System</a></h3>
<p>Reflow uses a sophisticated type system to ensure data compatibility between connected nodes:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(Debug, Clone, PartialEq)]
pub enum PortType {
    Any,                              // Accepts any data type
    Flow,                            // Control flow signals
    Event,                           // Event-driven data
    Boolean,                         // Boolean values
    Integer,                         // Integer numbers
    Float,                          // Floating-point numbers
    String,                         // Text data
    Object(String),                 // Structured objects with schema
    Array(Box&lt;PortType&gt;),          // Arrays of typed elements
    Stream,                        // Streaming data
    Encoded,                       // Binary encoded data
    Option(Box&lt;PortType&gt;),         // Optional values
}
<span class="boring">}</span></code></pre></pre>
<h3 id="type-compatibility"><a class="header" href="#type-compatibility">Type Compatibility</a></h3>
<p>The system automatically validates type compatibility when connections are made:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// These connections are valid
graph.add_connection("int_source", "out", "float_sink", "in", None); // Integer ‚Üí Float
graph.add_connection("any_source", "out", "string_sink", "in", None); // Any ‚Üí String
graph.add_connection("data", "out", "stream", "in", None);            // Any ‚Üí Stream

// This would be invalid and rejected
// graph.add_connection("string_source", "out", "int_sink", "in", None); // String ‚Üõ Integer
<span class="boring">}</span></code></pre></pre>
<h2 id="graph-operations"><a class="header" href="#graph-operations">Graph Operations</a></h2>
<h3 id="node-management"><a class="header" href="#node-management">Node Management</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Add node with metadata
let metadata = HashMap::from([
    ("x".to_string(), json!(100)),
    ("y".to_string(), json!(200)),
    ("description".to_string(), json!("Processes incoming data"))
]);
graph.add_node("processor", "DataProcessor", Some(metadata));

// Update node metadata
graph.set_node_metadata("processor", HashMap::from([
    ("color".to_string(), json!("#ff0000"))
]));

// Remove node (also removes all connections)
graph.remove_node("processor");
<span class="boring">}</span></code></pre></pre>
<h3 id="connection-management"><a class="header" href="#connection-management">Connection Management</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Add connection with metadata
let conn_metadata = HashMap::from([
    ("weight".to_string(), json!(0.8)),
    ("priority".to_string(), json!("high"))
]);
graph.add_connection("source", "data", "sink", "input", Some(conn_metadata));

// Get connection details
if let Some(connection) = graph.get_connection("source", "data", "sink", "input") {
    println!("Connection: {:?}", connection);
}

// Remove specific connection
graph.remove_connection("source", "data", "sink", "input");
<span class="boring">}</span></code></pre></pre>
<h3 id="initial-information-packets-iips"><a class="header" href="#initial-information-packets-iips">Initial Information Packets (IIPs)</a></h3>
<p>IIPs allow you to inject static data into the graph at startup:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use serde_json::json;

// Add configuration data
graph.add_initial(
    json!({"database_url": "postgresql://localhost/mydb"}),
    "database_connector",
    "config",
    None
);

// Add initial data with index for array ports
graph.add_initial_index(
    json!("input_file.txt"),
    "file_reader",
    "filenames",
    0,
    None
);
<span class="boring">}</span></code></pre></pre>
<h3 id="graph-ports"><a class="header" href="#graph-ports">Graph Ports</a></h3>
<p>Expose internal node ports as graph-level interfaces:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Add input port to graph
graph.add_inport(
    "data_input",           // External port name
    "processor",            // Internal node
    "input",               // Internal port
    PortType::Any,         // Port type
    None                   // Metadata
);

// Add output port to graph
graph.add_outport(
    "processed_data",      // External port name
    "processor",           // Internal node
    "output",              // Internal port
    PortType::Object("ProcessedData".to_string()),
    None
);
<span class="boring">}</span></code></pre></pre>
<h2 id="graph-validation"><a class="header" href="#graph-validation">Graph Validation</a></h2>
<h3 id="automatic-validation"><a class="header" href="#automatic-validation">Automatic Validation</a></h3>
<p>The graph system performs continuous validation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Validate entire graph
let validation_result = graph.validate_flow()?;

if !validation_result.cycles.is_empty() {
    println!("Cycles detected: {:?}", validation_result.cycles);
}

if !validation_result.orphaned_nodes.is_empty() {
    println!("Orphaned nodes: {:?}", validation_result.orphaned_nodes);
}

for mismatch in validation_result.port_mismatches {
    println!("Port mismatch: {}", mismatch);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="cycle-detection"><a class="header" href="#cycle-detection">Cycle Detection</a></h3>
<p>Advanced cycle detection with path tracking:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Detect first cycle
if let Some(cycle) = graph.detect_cycles() {
    println!("Cycle found: {:?}", cycle);
}

// Comprehensive cycle analysis
let cycle_analysis = graph.analyze_cycles();
println!("Total cycles: {}", cycle_analysis.total_cycles);
println!("Nodes in cycles: {:?}", cycle_analysis.nodes_in_cycles);
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-analysis"><a class="header" href="#performance-analysis">Performance Analysis</a></h2>
<h3 id="parallelism-detection"><a class="header" href="#parallelism-detection">Parallelism Detection</a></h3>
<p>Identify opportunities for parallel execution:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let parallelism = graph.analyze_parallelism();

// Parallel branches that can execute simultaneously
for branch in parallelism.parallel_branches {
    println!("Parallel branch: {:?}", branch.nodes);
}

// Pipeline stages for sequential execution
for stage in parallelism.pipeline_stages {
    println!("Stage {}: {:?}", stage.level, stage.nodes);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="bottleneck-analysis"><a class="header" href="#bottleneck-analysis">Bottleneck Analysis</a></h3>
<p>Find performance bottlenecks:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let bottlenecks = graph.detect_bottlenecks();

for bottleneck in bottlenecks {
    match bottleneck {
        Bottleneck::HighDegree(node) =&gt; {
            println!("High-degree bottleneck at node: {}", node);
        }
        Bottleneck::SequentialChain(chain) =&gt; {
            println!("Sequential chain that could be parallelized: {:?}", chain);
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="resource-analysis"><a class="header" href="#resource-analysis">Resource Analysis</a></h3>
<p>Estimate execution requirements:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let analysis = graph.analyze_for_runtime();

println!("Estimated execution time: {:.2}s", analysis.estimated_execution_time);
println!("Resource requirements: {:?}", analysis.resource_requirements);

for suggestion in analysis.optimization_suggestions {
    match suggestion {
        OptimizationSuggestion::ParallelizableChain { nodes } =&gt; {
            println!("Consider parallelizing: {:?}", nodes);
        }
        OptimizationSuggestion::RedundantNode { node, reason } =&gt; {
            println!("Redundant node {}: {}", node, reason);
        }
        OptimizationSuggestion::ResourceBottleneck { resource, severity } =&gt; {
            println!("Resource bottleneck in {}: {:.1}%", resource, severity * 100.0);
        }
        OptimizationSuggestion::DataTypeOptimization { from, to, suggestion } =&gt; {
            println!("Optimize {} ‚Üí {}: {}", from, to, suggestion);
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="graph-layout"><a class="header" href="#graph-layout">Graph Layout</a></h2>
<h3 id="automatic-layout"><a class="header" href="#automatic-layout">Automatic Layout</a></h3>
<p>The system provides intelligent automatic layout:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Calculate optimal positions
let positions = graph.calculate_layout();

for (node_id, position) in positions {
    println!("Node {}: x={:.1}, y={:.1}", node_id, position.x, position.y);
}

// Apply layout to graph metadata
graph.auto_layout()?;
<span class="boring">}</span></code></pre></pre>
<h3 id="manual-positioning"><a class="header" href="#manual-positioning">Manual Positioning</a></h3>
<p>Set custom node positions:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Set specific position
graph.set_node_position("processor", 150.0, 100.0)?;

// Set position with custom dimensions and anchor
let metadata = HashMap::from([
    ("position".to_string(), json!({"x": 200, "y": 150})),
    ("dimensions".to_string(), json!({
        "width": 120,
        "height": 80,
        "anchor": {"x": 0.5, "y": 0.5}  // Center anchor
    }))
]);
graph.set_node_metadata("custom_node", metadata);
<span class="boring">}</span></code></pre></pre>
<h2 id="event-system"><a class="header" href="#event-system">Event System</a></h2>
<h3 id="real-time-updates"><a class="header" href="#real-time-updates">Real-time Updates</a></h3>
<p>Subscribe to graph changes:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::GraphEvents;

// Graph creates event channel automatically
let (sender, receiver) = graph.event_channel;

// Listen for events
while let Ok(event) = receiver.recv() {
    match event {
        GraphEvents::AddNode(node_data) =&gt; {
            println!("Node added: {:?}", node_data);
        }
        GraphEvents::AddConnection(conn_data) =&gt; {
            println!("Connection added: {:?}", conn_data);
        }
        GraphEvents::RemoveNode(node_data) =&gt; {
            println!("Node removed: {:?}", node_data);
        }
        // ... handle other events
        _ =&gt; {}
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="event-types"><a class="header" href="#event-types">Event Types</a></h3>
<p>Complete list of graph events:</p>
<ul>
<li><code>AddNode</code> / <code>RemoveNode</code> / <code>RenameNode</code> / <code>ChangeNode</code></li>
<li><code>AddConnection</code> / <code>RemoveConnection</code> / <code>ChangeConnection</code></li>
<li><code>AddInitial</code> / <code>RemoveInitial</code></li>
<li><code>AddGroup</code> / <code>RemoveGroup</code> / <code>RenameGroup</code> / <code>ChangeGroup</code></li>
<li><code>AddInport</code> / <code>RemoveInport</code> / <code>RenameInport</code> / <code>ChangeInport</code></li>
<li><code>AddOutport</code> / <code>RemoveOutport</code> / <code>RenameOutport</code> / <code>ChangeOutport</code></li>
<li><code>ChangeProperties</code></li>
<li><code>StartTransaction</code> / <code>EndTransaction</code> / <code>Transaction</code></li>
</ul>
<h2 id="serialization"><a class="header" href="#serialization">Serialization</a></h2>
<h3 id="export-format"><a class="header" href="#export-format">Export Format</a></h3>
<p>Graphs can be serialized to JSON for storage and interchange:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Export to JSON-compatible format
let export = graph.export();
let json_string = serde_json::to_string_pretty(&amp;export)?;

// Load from JSON
let loaded_graph = Graph::load(export, Some(metadata));
<span class="boring">}</span></code></pre></pre>
<h3 id="export-structure"><a class="header" href="#export-structure">Export Structure</a></h3>
<pre><code class="language-json">{
  "caseSensitive": false,
  "properties": {
    "name": "MyWorkflow",
    "description": "A sample workflow"
  },
  "processes": {
    "source": {
      "id": "source",
      "component": "DataSource",
      "metadata": {"x": 0, "y": 0}
    }
  },
  "connections": [
    {
      "from": {"nodeId": "source", "portId": "output"},
      "to": {"nodeId": "sink", "portId": "input"},
      "metadata": {}
    }
  ],
  "inports": {},
  "outports": {},
  "groups": []
}
</code></pre>
<h2 id="webassembly-support"><a class="header" href="#webassembly-support">WebAssembly Support</a></h2>
<h3 id="browser-integration"><a class="header" href="#browser-integration">Browser Integration</a></h3>
<p>The graph system compiles to WebAssembly for browser usage:</p>
<pre><code class="language-javascript">import { Graph } from 'reflow-network';

// Create graph in browser
const graph = new Graph("WebWorkflow", false, {});

// Add nodes and connections
graph.addNode("input", "InputNode", {x: 0, y: 0});
graph.addNode("output", "OutputNode", {x: 200, y: 0});
graph.addConnection("input", "out", "output", "in", {});

// Subscribe to events
graph.subscribe((event) =&gt; {
    console.log("Graph event:", event);
});

// Export for persistence
const exported = graph.toJSON();
localStorage.setItem('workflow', JSON.stringify(exported));
</code></pre>
<h3 id="typescript-support"><a class="header" href="#typescript-support">TypeScript Support</a></h3>
<p>Full TypeScript definitions are generated:</p>
<pre><code class="language-typescript">interface GraphNode {
    id: string;
    component: string;
    metadata?: Map&lt;string, any&gt;;
}

interface GraphConnection {
    from: GraphEdge;
    to: GraphEdge;
    metadata?: Map&lt;string, any&gt;;
    data?: any;
}

type PortType = 
  | { type: "flow" }
  | { type: "event" }
  | { type: "boolean" }
  | { type: "integer" }
  | { type: "float" }
  | { type: "string" }
  | { type: "object", value: string }
  | { type: "array", value: PortType }
  | { type: "stream" }
  | { type: "encoded" }
  | { type: "any" }
  | { type: "option", value: PortType };
</code></pre>
<h2 id="graph-history"><a class="header" href="#graph-history">Graph History</a></h2>
<h3 id="undoredo-system"><a class="header" href="#undoredo-system">Undo/Redo System</a></h3>
<p>Track changes for undo/redo functionality:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create graph with history tracking
let (mut graph, mut history) = Graph::with_history();

// Make changes
graph.add_node("test", "TestNode", None);
graph.add_connection("test", "out", "sink", "in", None);

// Undo last change
if let Some(event) = history.undo() {
    // Apply inverse operation
    history.apply_inverse(&amp;mut graph, event)?;
}

// Redo change
if let Some(event) = history.redo() {
    // Reapply operation
    history.apply_event(&amp;mut graph, event)?;
}
<span class="boring">}</span></code></pre></pre>
<h2 id="advanced-features"><a class="header" href="#advanced-features">Advanced Features</a></h2>
<h3 id="subgraph-analysis"><a class="header" href="#subgraph-analysis">Subgraph Analysis</a></h3>
<p>Extract and analyze subgraphs:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Get reachable subgraph from a node
if let Some(subgraph) = graph.get_reachable_subgraph("start_node") {
    let analysis = graph.analyze_subgraph(&amp;subgraph);
    
    println!("Subgraph nodes: {}", analysis.node_count);
    println!("Max depth: {}", analysis.max_depth);
    println!("Is cyclic: {}", analysis.is_cyclic);
    println!("Branching factor: {:.2}", analysis.branching_factor);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="graph-traversal"><a class="header" href="#graph-traversal">Graph Traversal</a></h3>
<p>Efficient traversal algorithms:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Depth-first traversal
graph.traverse_depth_first("start_node", |node| {
    println!("Visiting node: {}", node.id);
})?;

// Breadth-first traversal
graph.traverse_breadth_first("start_node", |node| {
    println!("Processing: {} ({})", node.id, node.component);
})?;
<span class="boring">}</span></code></pre></pre>
<h3 id="node-groups"><a class="header" href="#node-groups">Node Groups</a></h3>
<p>Organize nodes into logical groups:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create group
graph.add_group("data_processing", vec!["filter".to_string(), "transform".to_string()], None);

// Add node to existing group
graph.add_to_group("data_processing", "validator");

// Remove from group
graph.remove_from_group("data_processing", "validator");
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-3"><a class="header" href="#best-practices-3">Best Practices</a></h2>
<h3 id="performance-optimization-1"><a class="header" href="#performance-optimization-1">Performance Optimization</a></h3>
<ol>
<li><strong>Use indexed operations</strong>: The graph uses internal indices for O(1) lookups</li>
<li><strong>Batch modifications</strong>: Group related changes to minimize event overhead</li>
<li><strong>Validate incrementally</strong>: Use targeted validation for better performance</li>
<li><strong>Cache analysis results</strong>: Store expensive analysis results when graph is stable</li>
</ol>
<h3 id="memory-management-1"><a class="header" href="#memory-management-1">Memory Management</a></h3>
<ol>
<li><strong>Clean up connections</strong>: Always remove connections before removing nodes</li>
<li><strong>Limit history size</strong>: Use <code>with_history_and_limit()</code> for bounded memory usage</li>
<li><strong>Dispose of event listeners</strong>: Unsubscribe from events when no longer needed</li>
</ol>
<h3 id="error-handling-6"><a class="header" href="#error-handling-6">Error Handling</a></h3>
<ol>
<li><strong>Check return values</strong>: Most operations return Result types</li>
<li><strong>Validate before execution</strong>: Use validation methods before running workflows</li>
<li><strong>Handle cycles gracefully</strong>: Implement cycle detection in your workflow runtime</li>
<li><strong>Monitor resource usage</strong>: Track memory and CPU usage for large graphs</li>
</ol>
<h2 id="integration-examples"><a class="header" href="#integration-examples">Integration Examples</a></h2>
<h3 id="visual-editor-integration"><a class="header" href="#visual-editor-integration">Visual Editor Integration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// In a visual editor, sync UI with graph events
graph.subscribe(|event| {
    match event {
        GraphEvents::AddNode(data) =&gt; ui.add_node_widget(data),
        GraphEvents::RemoveNode(data) =&gt; ui.remove_node_widget(data.id),
        GraphEvents::AddConnection(data) =&gt; ui.draw_connection(data),
        _ =&gt; {}
    }
});
<span class="boring">}</span></code></pre></pre>
<h3 id="workflow-execution"><a class="header" href="#workflow-execution">Workflow Execution</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Convert graph to executable network
let network = Network::from_graph(&amp;graph)?;

// Execute with runtime
let runtime = Runtime::new();
runtime.execute(network).await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="next-steps-8"><a class="header" href="#next-steps-8">Next Steps</a></h2>
<ul>
<li><a href="architecture/../api/graph/creating-graphs.html">Creating Graphs</a> - Detailed API guide</li>
<li><a href="architecture/../api/graph/analysis.html">Graph Analysis</a> - Validation and performance analysis</li>
<li><a href="architecture/../api/graph/layout.html">Layout System</a> - Positioning and visualization</li>
<li><a href="architecture/../api/graph/advanced.html">Advanced Features</a> - History, subgraphs, and optimization</li>
<li><a href="architecture/../tutorials/building-visual-editor.html">Building Visual Editors</a> - Complete tutorial</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="distributed-networks"><a class="header" href="#distributed-networks">Distributed Networks</a></h1>
<p>Reflow's distributed network system enables bi-directional communication between separate Reflow instances, allowing you to build scalable, multi-node workflows while maintaining the familiar actor-based programming model.</p>
<h2 id="overview-1"><a class="header" href="#overview-1">Overview</a></h2>
<p>The distributed network architecture extends Reflow's local actor model to support remote communication across network boundaries. This enables:</p>
<ul>
<li><strong>Cross-Network Actor Communication</strong>: Actors in one Reflow instance can send messages to actors in remote instances</li>
<li><strong>Network-Transparent Operation</strong>: Remote actors appear as local actors in your workflows</li>
<li><strong>Bi-directional Message Flow</strong>: Full duplex communication between distributed nodes</li>
<li><strong>Automatic Discovery</strong>: Networks can discover and register with each other automatically</li>
<li><strong>Conflict Resolution</strong>: Smart handling of actor name conflicts across networks</li>
</ul>
<h2 id="architecture-components"><a class="header" href="#architecture-components">Architecture Components</a></h2>
<pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Distributed Reflow Network                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Instance A (Server)           ‚îÇ  Instance B (Client)               ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ Local Network               ‚îÇ ‚îÇ ‚îÇ Local Network                   ‚îÇ ‚îÇ
‚îÇ ‚îÇ ‚îú‚îÄ Actor A1 ‚îÄ‚îê              ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ Actor B1 ‚îÄ‚îê                  ‚îÇ ‚îÇ
‚îÇ ‚îÇ ‚îú‚îÄ Actor A2 ‚îÄ‚î§              ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ Actor B2 ‚îÄ‚î§                  ‚îÇ ‚îÇ
‚îÇ ‚îÇ ‚îî‚îÄ Actor A3 ‚îÄ‚îò              ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ Actor B3 ‚îÄ‚îò                  ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ            ‚îÇ                    ‚îÇ                    ‚îÇ                ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ Network Bridge              ‚îÇ‚óÑ‚îÄ‚î§ ‚îÇ Network Bridge                  ‚îÇ ‚îÇ
‚îÇ ‚îÇ ‚îú‚îÄ Discovery Service        ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ Discovery Service             ‚îÇ ‚îÇ
‚îÇ ‚îÇ ‚îú‚îÄ Message Router           ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ Message Router                ‚îÇ ‚îÇ
‚îÇ ‚îÇ ‚îú‚îÄ Connection Manager       ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ Connection Manager            ‚îÇ ‚îÇ
‚îÇ ‚îÇ ‚îî‚îÄ Remote Actor Proxy       ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ Remote Actor Proxy            ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ            ‚îÇ                    ‚îÇ                    ‚îÇ                ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ Transport Layer             ‚îÇ‚óÑ‚îÄ‚î§ ‚îÇ Transport Layer                 ‚îÇ ‚îÇ
‚îÇ ‚îÇ ‚îú‚îÄ WebSocket/TCP Server     ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ WebSocket/TCP Client          ‚îÇ ‚îÇ
‚îÇ ‚îÇ ‚îú‚îÄ Protocol Handler         ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ Protocol Handler              ‚îÇ ‚îÇ
‚îÇ ‚îÇ ‚îî‚îÄ Serialization            ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ Serialization                 ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre>
<h3 id="core-components-1"><a class="header" href="#core-components-1">Core Components</a></h3>
<ol>
<li><strong>DistributedNetwork</strong>: Main orchestrator that combines local networks with distributed communication</li>
<li><strong>NetworkBridge</strong>: Handles all cross-network communication and actor registration</li>
<li><strong>DiscoveryService</strong>: Automatic network discovery and registration</li>
<li><strong>MessageRouter</strong>: Routes messages between local and remote actors</li>
<li><strong>RemoteActorProxy</strong>: Local representatives of remote actors</li>
<li><strong>TransportLayer</strong>: WebSocket/TCP communication infrastructure</li>
</ol>
<h2 id="basic-setup"><a class="header" href="#basic-setup">Basic Setup</a></h2>
<h3 id="creating-a-distributed-network"><a class="header" href="#creating-a-distributed-network">Creating a Distributed Network</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::distributed_network::{DistributedNetwork, DistributedConfig};
use reflow_network::network::NetworkConfig;

// Configure the distributed network
let config = DistributedConfig {
    network_id: "main_workflow_engine".to_string(),
    instance_id: "server_001".to_string(),
    bind_address: "0.0.0.0".to_string(),
    bind_port: 8080,
    discovery_endpoints: vec![
        "http://discovery.example.com:3000".to_string()
    ],
    auth_token: Some("secure_token".to_string()),
    max_connections: 100,
    heartbeat_interval_ms: 30000,
    local_network_config: NetworkConfig::default(),
};

// Create and start the distributed network
let mut distributed_network = DistributedNetwork::new(config).await?;
distributed_network.start().await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="registering-local-actors"><a class="header" href="#registering-local-actors">Registering Local Actors</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use your_actors::DataProcessorActor;

// Register actors that will be available to remote networks
distributed_network.register_local_actor(
    "data_processor",
    DataProcessorActor::new(),
    Some(HashMap::from([
        ("capability".to_string(), serde_json::Value::String("data_processing".to_string())),
        ("version".to_string(), serde_json::Value::String("1.0.0".to_string())),
    ]))
)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="connecting-to-remote-networks"><a class="header" href="#connecting-to-remote-networks">Connecting to Remote Networks</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Connect to another network
distributed_network.connect_to_network("192.168.1.100:8080").await?;

// Register a remote actor for local use
distributed_network.register_remote_actor(
    "remote_validator",      // Remote actor ID
    "validation_network"     // Remote network ID
).await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="actor-communication-patterns"><a class="header" href="#actor-communication-patterns">Actor Communication Patterns</a></h2>
<h3 id="direct-remote-messaging"><a class="header" href="#direct-remote-messaging">Direct Remote Messaging</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::message::Message;

// Send message to remote actor
distributed_network.send_to_remote_actor(
    "validation_network",    // Target network
    "remote_validator",      // Target actor
    "input",                 // Target port
    Message::String("validate this data".to_string().into())
).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="workflow-integration"><a class="header" href="#workflow-integration">Workflow Integration</a></h3>
<p>Remote actors integrate seamlessly into local workflows:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Get local network handle
let local_network = distributed_network.get_local_network();
let mut network = local_network.write();

// Add local actor
network.add_node("local_collector", "data_collector", None)?;

// Add remote actor (appears as local)
network.add_node("remote_processor", "remote_validator@validation_network", None)?;

// Connect them in a workflow
network.add_connection(Connector {
    from: ConnectionPoint {
        actor: "local_collector".to_string(),
        port: "output".to_string(),
        ..Default::default()
    },
    to: ConnectionPoint {
        actor: "remote_processor".to_string(),
        port: "input".to_string(),
        ..Default::default()
    },
})?;
<span class="boring">}</span></code></pre></pre>
<h2 id="network-discovery"><a class="header" href="#network-discovery">Network Discovery</a></h2>
<h3 id="automatic-discovery"><a class="header" href="#automatic-discovery">Automatic Discovery</a></h3>
<p>The discovery service can automatically find and register remote networks:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Enable automatic discovery
let config = DistributedConfig {
    // ... other config
    discovery_endpoints: vec![
        "http://service-discovery.local:3000".to_string(),
        "http://backup-discovery.local:3000".to_string(),
    ],
    // ...
};
<span class="boring">}</span></code></pre></pre>
<h3 id="manual-network-registration"><a class="header" href="#manual-network-registration">Manual Network Registration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Manually connect to specific networks
let networks_to_connect = vec![
    "analytics.company.com:8080",
    "ml-pipeline.company.com:8080",
    "data-warehouse.company.com:8080",
];

for endpoint in networks_to_connect {
    match distributed_network.connect_to_network(endpoint).await {
        Ok(_) =&gt; println!("Connected to {}", endpoint),
        Err(e) =&gt; eprintln!("Failed to connect to {}: {}", endpoint, e),
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="conflict-resolution"><a class="header" href="#conflict-resolution">Conflict Resolution</a></h2>
<p>When multiple networks have actors with the same name, Reflow provides several resolution strategies:</p>
<h3 id="automatic-aliasing"><a class="header" href="#automatic-aliasing">Automatic Aliasing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Register remote actor with automatic conflict resolution
let alias = distributed_network.register_remote_actor_with_strategy(
    "data_processor",                    // Remote actor name (conflicts with local)
    "analytics_network",                 // Remote network
    ConflictResolutionStrategy::AutoAlias // Strategy
).await?;

println!("Remote actor available as: {}", alias);
// Output: "Remote actor available as: analytics_network_data_processor"
<span class="boring">}</span></code></pre></pre>
<h3 id="manual-aliasing"><a class="header" href="#manual-aliasing">Manual Aliasing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Provide custom aliases for clarity
distributed_network.register_remote_actor_with_strategy(
    "validator",
    "security_network",
    ConflictResolutionStrategy::ManualAlias("security_validator".to_string())
).await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="security-considerations"><a class="header" href="#security-considerations">Security Considerations</a></h2>
<h3 id="authentication"><a class="header" href="#authentication">Authentication</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = DistributedConfig {
    // Use authentication tokens
    auth_token: Some("your_secure_token_here".to_string()),
    // ... other config
};
<span class="boring">}</span></code></pre></pre>
<h3 id="network-isolation"><a class="header" href="#network-isolation">Network Isolation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Restrict which networks can connect
let config = DistributedConfig {
    // Only allow specific discovery endpoints
    discovery_endpoints: vec![
        "https://trusted-discovery.company.com:3000".to_string()
    ],
    max_connections: 10, // Limit concurrent connections
    // ... other config
};
<span class="boring">}</span></code></pre></pre>
<h2 id="monitoring-and-health-checks"><a class="header" href="#monitoring-and-health-checks">Monitoring and Health Checks</a></h2>
<h3 id="connection-status"><a class="header" href="#connection-status">Connection Status</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Check network health
let bridge_status = distributed_network.get_bridge_status().await?;
println!("Connected networks: {}", bridge_status.connected_networks.len());

for (network_id, status) in &amp;bridge_status.connected_networks {
    println!("  {}: {:?}", network_id, status);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="heartbeat-monitoring"><a class="header" href="#heartbeat-monitoring">Heartbeat Monitoring</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = DistributedConfig {
    heartbeat_interval_ms: 15000, // 15 second heartbeats
    // ... other config
};
<span class="boring">}</span></code></pre></pre>
<h2 id="error-handling-7"><a class="header" href="#error-handling-7">Error Handling</a></h2>
<h3 id="connection-failures"><a class="header" href="#connection-failures">Connection Failures</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::distributed_network::DistributedError;

match distributed_network.connect_to_network("unreachable:8080").await {
    Ok(_) =&gt; println!("Connected successfully"),
    Err(DistributedError::ConnectionTimeout) =&gt; {
        eprintln!("Connection timed out - network may be down");
    },
    Err(DistributedError::AuthenticationFailed) =&gt; {
        eprintln!("Authentication failed - check token");
    },
    Err(e) =&gt; eprintln!("Other error: {}", e),
}
<span class="boring">}</span></code></pre></pre>
<h3 id="message-delivery-failures"><a class="header" href="#message-delivery-failures">Message Delivery Failures</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Messages automatically retry with backoff
match distributed_network.send_to_remote_actor(
    "target_network", "target_actor", "input", message
).await {
    Ok(_) =&gt; println!("Message sent successfully"),
    Err(e) =&gt; {
        eprintln!("Failed to send message: {}", e);
        // Message will be retried automatically
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-considerations-1"><a class="header" href="#performance-considerations-1">Performance Considerations</a></h2>
<h3 id="connection-pooling"><a class="header" href="#connection-pooling">Connection Pooling</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = DistributedConfig {
    max_connections: 50, // Adjust based on load
    // ... other config
};
<span class="boring">}</span></code></pre></pre>
<h3 id="message-batching-1"><a class="header" href="#message-batching-1">Message Batching</a></h3>
<p>Messages are automatically batched for efficiency, but you can tune batching behavior:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Large messages are automatically compressed
let large_data = Message::Object(/* large JSON object */);
distributed_network.send_to_remote_actor(
    "target_network", "target_actor", "bulk_input", large_data
).await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-4"><a class="header" href="#best-practices-4">Best Practices</a></h2>
<h3 id="network-design"><a class="header" href="#network-design">Network Design</a></h3>
<ol>
<li><strong>Use Descriptive Network IDs</strong>: Choose meaningful names like <code>analytics_cluster</code> instead of <code>network1</code></li>
<li><strong>Plan for Conflicts</strong>: Use descriptive actor names to minimize naming conflicts</li>
<li><strong>Group Related Services</strong>: Co-locate related actors in the same network for efficiency</li>
<li><strong>Design for Failure</strong>: Always handle network partitions and connection failures gracefully</li>
</ol>
<h3 id="actor-organization"><a class="header" href="#actor-organization">Actor Organization</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Descriptive, specific names
distributed_network.register_local_actor("customer_data_validator", validator, None)?;
distributed_network.register_local_actor("payment_processor", processor, None)?;

// Avoid: Generic names likely to conflict
// distributed_network.register_local_actor("validator", validator, None)?;
// distributed_network.register_local_actor("processor", processor, None)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="resource-management"><a class="header" href="#resource-management">Resource Management</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Always clean up connections
struct DistributedWorkflow {
    network: DistributedNetwork,
}

impl Drop for DistributedWorkflow {
    fn drop(&amp;mut self) {
        // Gracefully shutdown connections
        if let Err(e) = tokio::task::block_in_place(|| {
            tokio::runtime::Handle::current().block_on(self.network.shutdown())
        }) {
            eprintln!("Error during cleanup: {}", e);
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="troubleshooting-2"><a class="header" href="#troubleshooting-2">Troubleshooting</a></h2>
<h3 id="common-issues-2"><a class="header" href="#common-issues-2">Common Issues</a></h3>
<ol>
<li><strong>Connection Refused</strong>: Check firewall settings and ensure target network is running</li>
<li><strong>Authentication Failed</strong>: Verify auth tokens match between networks</li>
<li><strong>Actor Not Found</strong>: Ensure remote actor is registered and network is connected</li>
<li><strong>Message Timeouts</strong>: Check network latency and increase timeout values if needed</li>
</ol>
<h3 id="debug-logging"><a class="header" href="#debug-logging">Debug Logging</a></h3>
<p>Enable detailed logging for troubleshooting:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tracing_subscriber;

// Enable debug logging
tracing_subscriber::fmt()
    .with_max_level(tracing::Level::DEBUG)
    .init();
<span class="boring">}</span></code></pre></pre>
<h3 id="health-check-endpoint"><a class="header" href="#health-check-endpoint">Health Check Endpoint</a></h3>
<p>Networks automatically expose health endpoints:</p>
<pre><code class="language-bash"># Check network health
curl http://your-network:8080/health

# Get network status
curl http://your-network:8080/status
</code></pre>
<h2 id="next-steps-9"><a class="header" href="#next-steps-9">Next Steps</a></h2>
<ul>
<li><a href="architecture/../api/distributed/remote-actors.html">Remote Actors</a> - Detailed remote actor API</li>
<li><a href="architecture/../api/distributed/discovery-registration.html">Discovery &amp; Registration</a> - Network discovery details</li>
<li><a href="architecture/../api/distributed/conflict-resolution.html">Conflict Resolution</a> - Advanced conflict handling</li>
<li><a href="architecture/../tutorials/distributed-workflow-example.html">Distributed Workflow Tutorial</a> - Step-by-step example</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="multi-graph-composition"><a class="header" href="#multi-graph-composition">Multi-Graph Composition</a></h1>
<p>Reflow's multi-graph composition system enables automatic discovery and intelligent composition of multiple graph files into unified, executable workflows. This system transforms complex multi-graph projects into seamlessly integrated workflows through workspace discovery and intelligent stitching.</p>
<h2 id="overview-2"><a class="header" href="#overview-2">Overview</a></h2>
<p>The multi-graph composition architecture provides:</p>
<ul>
<li><strong>Automatic Workspace Discovery</strong>: Recursively finds all <code>*.graph.json</code> and <code>*.graph.yaml</code> files in your project</li>
<li><strong>Folder-Based Namespacing</strong>: Uses directory structure as natural namespaces for organization</li>
<li><strong>Smart Auto-Connections</strong>: Automatically detects compatible interfaces between graphs</li>
<li><strong>Dependency Resolution</strong>: Resolves inter-graph dependencies and execution ordering</li>
<li><strong>One-Command Composition</strong>: Single command transforms entire workspace into executable workflow</li>
<li><strong>Interface Analysis</strong>: Analyzes graph interfaces for compatibility and suggests connections</li>
</ul>
<h2 id="architecture-components-1"><a class="header" href="#architecture-components-1">Architecture Components</a></h2>
<pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Workspace Discovery System                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ File Discovery Layer                                               ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ *.graph.json    ‚îÇ *.graph.yaml    ‚îÇ Pattern Matching ‚îÇ Filters  ‚îÇ ‚îÇ
‚îÇ ‚îÇ (data_flow)     ‚îÇ (ml_pipeline)   ‚îÇ (glob patterns)  ‚îÇ (exclude)‚îÇ ‚îÇ
‚îÇ ‚îÇ - 3 processes   ‚îÇ - 5 processes   ‚îÇ - depth limits   ‚îÇ - test/  ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Namespace &amp; Analysis Layer                                          ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ Namespace Mgr   ‚îÇ Interface Analysis ‚îÇ Dependency Res ‚îÇ Auto-Connect ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Folder-based  ‚îÇ ‚Ä¢ Exposed ports    ‚îÇ ‚Ä¢ Graph deps   ‚îÇ ‚Ä¢ Port match ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Conflict res  ‚îÇ ‚Ä¢ Required ports   ‚îÇ ‚Ä¢ Order deps   ‚îÇ ‚Ä¢ Confidence ‚îÇ ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Custom rules  ‚îÇ ‚Ä¢ Compatibility   ‚îÇ ‚Ä¢ Validation   ‚îÇ ‚Ä¢ Heuristics ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Unified Network Instance                                            ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ data/           ‚îÇ ml/            ‚îÇ monitoring/    ‚îÇ shared/      ‚îÇ ‚îÇ
‚îÇ ‚îÇ ‚îú‚îÄ ingestion/   ‚îÇ ‚îú‚îÄ training/   ‚îÇ ‚îú‚îÄ metrics     ‚îÇ ‚îú‚îÄ logging  ‚îÇ ‚îÇ
‚îÇ ‚îÇ ‚îÇ  ‚îî‚îÄ collector ‚îÇ ‚îÇ  ‚îî‚îÄ trainer   ‚îÇ ‚îú‚îÄ alerts     ‚îÇ ‚îú‚îÄ auth     ‚îÇ ‚îÇ
‚îÇ ‚îÇ ‚îî‚îÄ processing/  ‚îÇ ‚îî‚îÄ inference/  ‚îÇ ‚îî‚îÄ dashboard   ‚îÇ ‚îî‚îÄ config   ‚îÇ ‚îÇ
‚îÇ ‚îÇ    ‚îî‚îÄ transformer‚îÇ   ‚îî‚îÄ predictor‚îÇ                ‚îÇ              ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre>
<h3 id="core-components-2"><a class="header" href="#core-components-2">Core Components</a></h3>
<ol>
<li><strong>WorkspaceDiscovery</strong>: Discovers and loads all graph files in a workspace</li>
<li><strong>GraphLoader</strong>: Loads and validates individual graph files</li>
<li><strong>GraphComposer</strong>: Orchestrates composition of multiple graphs</li>
<li><strong>NamespaceManager</strong>: Manages namespaces and resolves conflicts</li>
<li><strong>DependencyResolver</strong>: Analyzes and resolves graph dependencies</li>
<li><strong>InterfaceAnalyzer</strong>: Detects compatible interfaces for auto-connections</li>
</ol>
<h2 id="workspace-structure"><a class="header" href="#workspace-structure">Workspace Structure</a></h2>
<p>Multi-graph workspaces organize graph files using directory structure as namespaces:</p>
<pre><code>workspace/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api_collector.graph.json      ‚Üí namespace: data/ingestion
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ file_reader.graph.yaml        ‚Üí namespace: data/ingestion
‚îÇ   ‚îú‚îÄ‚îÄ processing/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cleaner.graph.json            ‚Üí namespace: data/processing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transformer.graph.json        ‚Üí namespace: data/processing
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ validator.graph.yaml          ‚Üí namespace: data/processing
‚îÇ   ‚îî‚îÄ‚îÄ storage/
‚îÇ       ‚îú‚îÄ‚îÄ database_writer.graph.json    ‚Üí namespace: data/storage
‚îÇ       ‚îî‚îÄ‚îÄ cache_manager.graph.yaml      ‚Üí namespace: data/storage
‚îú‚îÄ‚îÄ ml/
‚îÇ   ‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_trainer.graph.json      ‚Üí namespace: ml/training
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ feature_engineer.graph.yaml   ‚Üí namespace: ml/training
‚îÇ   ‚îú‚îÄ‚îÄ inference/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predictor.graph.json          ‚Üí namespace: ml/inference
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ batch_scorer.graph.json       ‚Üí namespace: ml/inference
‚îÇ   ‚îî‚îÄ‚îÄ evaluation/
‚îÇ       ‚îî‚îÄ‚îÄ model_evaluator.graph.yaml    ‚Üí namespace: ml/evaluation
‚îú‚îÄ‚îÄ monitoring/
‚îÇ   ‚îú‚îÄ‚îÄ metrics.graph.json                ‚Üí namespace: monitoring
‚îÇ   ‚îú‚îÄ‚îÄ alerts.graph.yaml                 ‚Üí namespace: monitoring
‚îÇ   ‚îî‚îÄ‚îÄ dashboard.graph.json              ‚Üí namespace: monitoring
‚îî‚îÄ‚îÄ shared/
    ‚îú‚îÄ‚îÄ logging.graph.yaml                 ‚Üí namespace: shared
    ‚îú‚îÄ‚îÄ auth.graph.json                    ‚Üí namespace: shared
    ‚îî‚îÄ‚îÄ config.graph.json                  ‚Üí namespace: shared
</code></pre>
<h2 id="basic-usage"><a class="header" href="#basic-usage">Basic Usage</a></h2>
<h3 id="simple-workspace-discovery"><a class="header" href="#simple-workspace-discovery">Simple Workspace Discovery</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::workspace::{WorkspaceDiscovery, WorkspaceConfig};

// Configure workspace discovery
let config = WorkspaceConfig {
    root_path: PathBuf::from("./my_workspace"),
    graph_patterns: vec![
        "**/*.graph.json".to_string(),
        "**/*.graph.yaml".to_string(),
    ],
    excluded_paths: vec![
        "**/node_modules/**".to_string(),
        "**/target/**".to_string(),
        "**/test/**".to_string(),
    ],
    max_depth: Some(8),
    namespace_strategy: NamespaceStrategy::FolderStructure,
    ..WorkspaceConfig::default()
};

// Discover all graphs in workspace
let discovery = WorkspaceDiscovery::new(config);
let workspace = discovery.discover_workspace().await?;

println!("üéâ Discovered {} graphs across {} namespaces", 
    workspace.graphs.len(), 
    workspace.namespaces.len()
);
<span class="boring">}</span></code></pre></pre>
<h3 id="automatic-composition"><a class="header" href="#automatic-composition">Automatic Composition</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::{GraphComposer, GraphComposition};

// Create composer and auto-compose workspace
let mut composer = GraphComposer::new();
let composition = GraphComposition::from_workspace(workspace)?;

// Compose into single executable graph
let unified_graph = composer.compose_graphs(composition).await?;

// The unified graph can now be executed as a single workflow
let mut network = Network::new(NetworkConfig::default());
let graph = Graph::load(unified_graph, None);
// Use the composed graph...
<span class="boring">}</span></code></pre></pre>
<h2 id="graph-dependencies-and-interfaces"><a class="header" href="#graph-dependencies-and-interfaces">Graph Dependencies and Interfaces</a></h2>
<h3 id="declaring-dependencies"><a class="header" href="#declaring-dependencies">Declaring Dependencies</a></h3>
<p>Graphs can declare explicit dependencies on other graphs:</p>
<pre><code class="language-json">{
  "caseSensitive": false,
  "properties": {
    "name": "ml_trainer",
    "namespace": "ml/training",
    "version": "1.0.0"
  },
  "processes": {
    "feature_engineer": {
      "component": "FeatureEngineerActor",
      "metadata": {}
    },
    "model_trainer": {
      "component": "ModelTrainerActor",
      "metadata": {}
    }
  },
  "connections": [
    {
      "from": { "nodeId": "feature_engineer", "portId": "Output" },
      "to": { "nodeId": "model_trainer", "portId": "Input" }
    }
  ],
  "inports": {
    "training_data": {
      "nodeId": "feature_engineer",
      "portId": "Input"
    }
  },
  "outports": {
    "trained_model": {
      "nodeId": "model_trainer",
      "portId": "Output"
    }
  },
  
  "graphDependencies": [
    {
      "graphName": "data_transformer",
      "namespace": "data/processing",
      "versionConstraint": "&gt;=1.0.0",
      "required": true,
      "description": "Requires clean data from transformer"
    }
  ],
  "externalConnections": [
    {
      "connectionId": "transformer_to_trainer",
      "targetGraph": "data_transformer",
      "targetNamespace": "data/processing",
      "fromProcess": "normalizer",
      "fromPort": "Output",
      "toProcess": "feature_engineer",
      "toPort": "Input",
      "description": "Use cleaned data for training"
    }
  ],
  "providedInterfaces": {
    "trained_model_output": {
      "interfaceId": "trained_model_output",
      "processName": "model_trainer",
      "portName": "Output",
      "dataType": "TrainedModel",
      "description": "Trained ML model"
    }
  },
  "requiredInterfaces": {
    "clean_data_input": {
      "interfaceId": "clean_data_input",
      "processName": "feature_engineer",
      "portName": "Input",
      "dataType": "CleanedDataRecord",
      "description": "Clean data from processing pipeline",
      "required": true
    }
  }
}
</code></pre>
<h3 id="interface-based-connections"><a class="header" href="#interface-based-connections">Interface-Based Connections</a></h3>
<p>Graphs can connect via defined interfaces rather than direct process connections:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::GraphConnectionBuilder;

// Build connections between discovered graphs
let mut connection_builder = GraphConnectionBuilder::new(workspace);

// Connect using interfaces (recommended)
connection_builder
    .connect_interface(
        "data_transformer",     // Source graph
        "clean_data_output",    // Source interface
        "ml_trainer",           // Target graph
        "clean_data_input"      // Target interface
    )?
    .connect_interface(
        "ml_trainer",
        "trained_model_output",
        "ml_predictor",
        "model_input"
    )?;

let connections = connection_builder.build();
<span class="boring">}</span></code></pre></pre>
<h2 id="namespace-management"><a class="header" href="#namespace-management">Namespace Management</a></h2>
<h3 id="folder-based-namespacing"><a class="header" href="#folder-based-namespacing">Folder-Based Namespacing</a></h3>
<p>By default, directory structure becomes namespace hierarchy:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// File: data/processing/transformer.graph.json
// Namespace: "data/processing"
// Qualified name: "data/processing/transformer"

// File: ml/training/trainer.graph.json  
// Namespace: "ml/training"
// Qualified name: "ml/training/trainer"
<span class="boring">}</span></code></pre></pre>
<h3 id="custom-namespace-strategies"><a class="header" href="#custom-namespace-strategies">Custom Namespace Strategies</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::NamespaceStrategy;

// Semantic-based namespacing
let config = WorkspaceConfig {
    namespace_strategy: NamespaceStrategy::custom(
        "semantic_based", 
        Some(serde_json::json!({
            "keywords": {
                "ml": ["model", "train", "predict", "feature"],
                "data": ["ingest", "collect", "process", "clean"],
                "monitoring": ["metric", "alert", "dashboard", "log"]
            }
        }))
    )?,
    // ... other config
};
<span class="boring">}</span></code></pre></pre>
<h3 id="conflict-resolution-1"><a class="header" href="#conflict-resolution-1">Conflict Resolution</a></h3>
<p>When graphs have conflicting names, the system provides several resolution strategies:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::NamespaceConflictPolicy;

let namespace_manager = GraphNamespaceManager::new(NamespaceConflictPolicy::AutoResolve);

// Automatic resolution generates unique names:
// "data_processor" -&gt; "data_processor" (first)
// "data_processor" -&gt; "data_processor_1" (second)
// "data_processor" -&gt; "data_processor_2" (third)
<span class="boring">}</span></code></pre></pre>
<h2 id="advanced-features-1"><a class="header" href="#advanced-features-1">Advanced Features</a></h2>
<h3 id="workspace-configuration"><a class="header" href="#workspace-configuration">Workspace Configuration</a></h3>
<pre><code class="language-yaml"># workspace.config.yaml
workspace:
  root_path: "./my_project"
  
  graph_patterns:
    - "**/*.graph.json"
    - "**/*.graph.yaml"
  
  excluded_paths:
    - "**/node_modules/**"
    - "**/target/**" 
    - "**/.git/**"
    - "**/test/**"
  
  max_depth: 8
  
  namespace_strategy:
    type: "folder_structure"
  
  auto_connect: true
  dependency_resolution: "automatic"

composer:
  enable_auto_connections: true
  connection_confidence_threshold: 0.75
  validate_before_compose: true
  output_path: "./workspace.composed.graph.json"
</code></pre>
<h3 id="auto-connection-discovery"><a class="header" href="#auto-connection-discovery">Auto-Connection Discovery</a></h3>
<p>The system can automatically suggest connections between compatible graph interfaces:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::InterfaceAnalyzer;

let analyzer = InterfaceAnalyzer::new();
let suggestions = analyzer.analyze_workspace(&amp;workspace).await?;

for suggestion in suggestions.auto_connections {
    println!("üîó Suggested connection: {} -&gt; {}",
        suggestion.from_interface, suggestion.to_interface);
    println!("   Confidence: {:.2}", suggestion.confidence);
    println!("   Reason: {}", suggestion.reasoning);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="dependency-resolution"><a class="header" href="#dependency-resolution">Dependency Resolution</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::DependencyResolver;

let resolver = DependencyResolver::new();
let ordered_graphs = resolver.resolve_dependencies(&amp;workspace.graphs)?;

println!("üìä Dependency Resolution Order:");
for (i, graph) in ordered_graphs.iter().enumerate() {
    println!("  {}. {}", i + 1, graph.get_name());
}
<span class="boring">}</span></code></pre></pre>
<h2 id="programmatic-api"><a class="header" href="#programmatic-api">Programmatic API</a></h2>
<h3 id="workspace-discovery-api"><a class="header" href="#workspace-discovery-api">Workspace Discovery API</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Programmatic workspace discovery
let mut discovery = WorkspaceDiscovery::new(config);

// Custom filtering
discovery.add_filter(|path: &amp;Path| -&gt; bool {
    // Only include graphs with "production" in the name
    path.to_string_lossy().contains("production")
});

// Custom namespace generation
discovery.set_namespace_generator(|path: &amp;Path| -&gt; String {
    // Custom logic for namespace generation
    if path.to_string_lossy().contains("critical") {
        format!("critical/{}", path.parent().unwrap().file_name().unwrap().to_string_lossy())
    } else {
        path.parent().unwrap().to_string_lossy().to_string()
    }
});

let workspace = discovery.discover_workspace().await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="dynamic-graph-loading"><a class="header" href="#dynamic-graph-loading">Dynamic Graph Loading</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::GraphSource;

// Load graphs from different sources
let sources = vec![
    GraphSource::JsonFile("./graphs/processor.graph.json".to_string()),
    GraphSource::NetworkApi("http://config-server/graphs/ml_model".to_string()),
    GraphSource::JsonContent(json_string),
];

let loader = GraphLoader::new();
let graphs = loader.load_multiple_graphs(sources).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="custom-graph-composition"><a class="header" href="#custom-graph-composition">Custom Graph Composition</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Custom composition logic
let composition = GraphComposition {
    sources: workspace.graph_sources(),
    connections: vec![
        CompositionConnection {
            from: CompositionEndpoint {
                process: "data/processing/cleaner".to_string(),
                port: "Output".to_string(),
                index: None,
            },
            to: CompositionEndpoint {
                process: "ml/training/trainer".to_string(),
                port: "Input".to_string(),
                index: None,
            },
            metadata: Some(HashMap::from([
                ("priority".to_string(), serde_json::Value::String("high".to_string())),
            ])),
        }
    ],
    shared_resources: vec![
        SharedResource {
            name: "logger".to_string(),
            component: "LoggerActor".to_string(),
            metadata: Some(HashMap::from([
                ("level".to_string(), serde_json::Value::String("info".to_string())),
            ])),
        }
    ],
    properties: HashMap::from([
        ("name".to_string(), serde_json::Value::String("workspace_composition".to_string())),
        ("version".to_string(), serde_json::Value::String("1.0.0".to_string())),
    ]),
    case_sensitive: Some(false),
    metadata: None,
};
<span class="boring">}</span></code></pre></pre>
<h2 id="command-line-interface"><a class="header" href="#command-line-interface">Command Line Interface</a></h2>
<h3 id="discovery-commands"><a class="header" href="#discovery-commands">Discovery Commands</a></h3>
<pre><code class="language-bash"># Discover all graphs in workspace
reflow workspace discover --path ./my_project

# Output discovery results
reflow workspace discover --path ./my_project --output workspace.json

# Analyze workspace structure and dependencies
reflow workspace analyze --path ./my_project --output analysis.json

# List discovered graphs and namespaces
reflow workspace list --path ./my_project --format table
</code></pre>
<h3 id="composition-commands"><a class="header" href="#composition-commands">Composition Commands</a></h3>
<pre><code class="language-bash"># Auto-compose with high confidence connections
reflow workspace compose \
    --path ./my_project \
    --auto-connect \
    --confidence-threshold 0.8 \
    --validate \
    --output workspace.composed.graph.json

# Use configuration file
reflow workspace compose --config workspace.config.yaml

# Validate workspace before composition
reflow workspace validate --path ./my_project
</code></pre>
<h3 id="export-commands"><a class="header" href="#export-commands">Export Commands</a></h3>
<pre><code class="language-bash"># Export enhanced graph schemas
reflow workspace export --path ./my_project --enhanced --output enhanced_graphs/

# Generate workspace documentation
reflow workspace docs --path ./my_project --output docs/
</code></pre>
<h2 id="best-practices-5"><a class="header" href="#best-practices-5">Best Practices</a></h2>
<h3 id="graph-organization"><a class="header" href="#graph-organization">Graph Organization</a></h3>
<ol>
<li><strong>Use Descriptive Namespaces</strong>: Organize graphs logically by function, not just technology</li>
<li><strong>Define Clear Interfaces</strong>: Use provided/required interfaces for loose coupling</li>
<li><strong>Minimize Dependencies</strong>: Reduce inter-graph dependencies for flexibility</li>
<li><strong>Version Your Graphs</strong>: Include version information for dependency management</li>
</ol>
<h3 id="directory-structure"><a class="header" href="#directory-structure">Directory Structure</a></h3>
<pre><code>my_project/
‚îú‚îÄ‚îÄ core/                    # Core business logic graphs
‚îÇ   ‚îú‚îÄ‚îÄ user_management/
‚îÇ   ‚îú‚îÄ‚îÄ order_processing/
‚îÇ   ‚îî‚îÄ‚îÄ payment_handling/
‚îú‚îÄ‚îÄ integrations/            # External system integrations
‚îÇ   ‚îú‚îÄ‚îÄ crm_sync/
‚îÇ   ‚îú‚îÄ‚îÄ analytics_export/
‚îÇ   ‚îî‚îÄ‚îÄ notification_service/
‚îú‚îÄ‚îÄ pipelines/              # Data processing pipelines
‚îÇ   ‚îú‚îÄ‚îÄ etl/
‚îÇ   ‚îú‚îÄ‚îÄ ml_training/
‚îÇ   ‚îî‚îÄ‚îÄ reporting/
‚îî‚îÄ‚îÄ utilities/              # Shared utility graphs
    ‚îú‚îÄ‚îÄ logging/
    ‚îú‚îÄ‚îÄ monitoring/
    ‚îî‚îÄ‚îÄ configuration/
</code></pre>
<h3 id="interface-design"><a class="header" href="#interface-design">Interface Design</a></h3>
<pre><code class="language-json">{
  "providedInterfaces": {
    "user_data": {
      "interfaceId": "user_data",
      "processName": "user_processor",
      "portName": "Output",
      "dataType": "UserRecord",
      "description": "Processed user data with validation",
      "required": false,
      "metadata": {
        "schema_version": "1.2.0",
        "format": "json",
        "compression": "none"
      }
    }
  },
  "requiredInterfaces": {
    "raw_user_input": {
      "interfaceId": "raw_user_input",
      "processName": "user_processor", 
      "portName": "Input",
      "dataType": "RawUserData",
      "description": "Raw user data for processing",
      "required": true,
      "metadata": {
        "max_size": "10MB",
        "format": "json"
      }
    }
  }
}
</code></pre>
<h2 id="error-handling-8"><a class="header" href="#error-handling-8">Error Handling</a></h2>
<h3 id="discovery-errors"><a class="header" href="#discovery-errors">Discovery Errors</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::DiscoveryError;

match discovery.discover_workspace().await {
    Ok(workspace) =&gt; {
        // Process workspace
    },
    Err(DiscoveryError::GlobError(e)) =&gt; {
        eprintln!("Pattern matching error: {}", e);
    },
    Err(DiscoveryError::LoadError(path, e)) =&gt; {
        eprintln!("Failed to load {}: {}", path.display(), e);
    },
    Err(DiscoveryError::ValidationError(e)) =&gt; {
        eprintln!("Graph validation failed: {}", e);
    },
    Err(e) =&gt; eprintln!("Discovery error: {}", e),
}
<span class="boring">}</span></code></pre></pre>
<h3 id="composition-errors"><a class="header" href="#composition-errors">Composition Errors</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::CompositionError;

match composer.compose_graphs(composition).await {
    Ok(graph) =&gt; {
        // Use composed graph
    },
    Err(CompositionError::DependencyError(e)) =&gt; {
        eprintln!("Dependency resolution failed: {}", e);
    },
    Err(CompositionError::NamespaceError(e)) =&gt; {
        eprintln!("Namespace conflict: {}", e);
    },
    Err(e) =&gt; eprintln!("Composition error: {}", e),
}
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-considerations-2"><a class="header" href="#performance-considerations-2">Performance Considerations</a></h2>
<h3 id="large-workspaces"><a class="header" href="#large-workspaces">Large Workspaces</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Optimize for large workspaces
let config = WorkspaceConfig {
    max_depth: Some(6),  // Limit directory traversal depth
    excluded_paths: vec![
        "**/node_modules/**".to_string(),
        "**/target/**".to_string(),
        "**/.git/**".to_string(),
        "**/build/**".to_string(),
        "**/dist/**".to_string(),
    ],
    // ... other config
};
<span class="boring">}</span></code></pre></pre>
<h3 id="parallel-loading"><a class="header" href="#parallel-loading">Parallel Loading</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Discovery automatically parallelizes graph loading
let workspace = discovery.discover_workspace().await?;
// Graphs are loaded concurrently for better performance
<span class="boring">}</span></code></pre></pre>
<h3 id="caching"><a class="header" href="#caching">Caching</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Enable caching for repeated discoveries
let config = WorkspaceConfig {
    cache_discoveries: true,
    cache_ttl_seconds: Some(300), // 5 minutes
    // ... other config
};
<span class="boring">}</span></code></pre></pre>
<h2 id="next-steps-10"><a class="header" href="#next-steps-10">Next Steps</a></h2>
<ul>
<li><a href="architecture/../api/graph/workspace-discovery.html">Workspace Discovery API</a> - Detailed API documentation</li>
<li><a href="architecture/../api/graph/graph-stitching.html">Graph Stitching API</a> - Advanced composition features</li>
<li><a href="architecture/../tutorials/multi-graph-workspace.html">Multi-Graph Workspace Tutorial</a> - Step-by-step guide</li>
<li><a href="architecture/../api/actors/actor-config.html">ActorConfig System</a> - Actor configuration system</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="observability-overview"><a class="header" href="#observability-overview">Observability Overview</a></h1>
<p>Reflow provides a comprehensive observability framework that enables deep introspection into distributed actor networks. The observability system captures detailed execution traces, performance metrics, and data flow patterns across all components in your system.</p>
<h2 id="key-features"><a class="header" href="#key-features">Key Features</a></h2>
<h3 id="-comprehensive-event-tracing"><a class="header" href="#-comprehensive-event-tracing">üîç <strong>Comprehensive Event Tracing</strong></a></h3>
<ul>
<li><strong>Actor Lifecycle</strong>: Track creation, startup, execution, completion, and failures</li>
<li><strong>Message Flow</strong>: Monitor all message passing between actors with detailed metadata</li>
<li><strong>Data Flow Tracing</strong>: NEW - Automatic tracing of data flow between connected actors</li>
<li><strong>State Changes</strong>: Capture state transitions with diff support for time-travel debugging</li>
<li><strong>Network Events</strong>: Monitor distributed network operations and health</li>
</ul>
<h3 id="-real-time-monitoring"><a class="header" href="#-real-time-monitoring">üìä <strong>Real-time Monitoring</strong></a></h3>
<ul>
<li><strong>Live Event Streaming</strong>: WebSocket-based real-time event notifications</li>
<li><strong>Performance Metrics</strong>: CPU usage, memory consumption, throughput measurements</li>
<li><strong>Custom Dashboards</strong>: Build monitoring interfaces using the WebSocket API</li>
<li><strong>Alerting</strong>: Set up custom alerts based on event patterns and thresholds</li>
</ul>
<h3 id="-flexible-storage"><a class="header" href="#-flexible-storage">üóÑÔ∏è <strong>Flexible Storage</strong></a></h3>
<ul>
<li><strong>SQLite</strong>: Embedded database perfect for development and small deployments</li>
<li><strong>PostgreSQL</strong>: Production-ready backend with ACID guarantees and concurrent access</li>
<li><strong>Memory</strong>: High-performance in-memory storage for testing and temporary analysis</li>
</ul>
<h3 id="-distributed-tracing"><a class="header" href="#-distributed-tracing">üåê <strong>Distributed Tracing</strong></a></h3>
<ul>
<li><strong>Cross-Network Visibility</strong>: Trace execution across multiple network instances</li>
<li><strong>Causality Tracking</strong>: Maintain event dependency chains across distributed components</li>
<li><strong>Span Integration</strong>: Compatible with OpenTelemetry and Jaeger for unified observability</li>
</ul>
<h2 id="architecture-overview-1"><a class="header" href="#architecture-overview-1">Architecture Overview</a></h2>
<pre><code class="language-mermaid">graph TB
    subgraph "Client Applications"
        A1[Actor Network 1]
        A2[Actor Network 2] 
        A3[Actor Network N]
    end
    
    subgraph "Tracing Infrastructure"
        TC[TracingClient]
        WS[WebSocket Protocol]
        TS[Tracing Server]
    end
    
    subgraph "Storage Layer"
        SQLite[(SQLite)]
        Postgres[(PostgreSQL)]
        Memory[(Memory)]
    end
    
    subgraph "Analysis &amp; Monitoring"
        RT[Real-time Dashboard]
        HQ[Historical Queries]
        AL[Alerting]
    end
    
    A1 --&gt;|Events| TC
    A2 --&gt;|Events| TC
    A3 --&gt;|Events| TC
    TC --&gt;|BatchedEvents| WS
    WS --&gt; TS
    TS --&gt; SQLite
    TS --&gt; Postgres
    TS --&gt; Memory
    TS --&gt;|Live Events| RT
    TS --&gt;|Query Results| HQ
    TS --&gt;|Notifications| AL
</code></pre>
<h2 id="event-types-1"><a class="header" href="#event-types-1">Event Types</a></h2>
<h3 id="core-actor-events"><a class="header" href="#core-actor-events">Core Actor Events</a></h3>
<ul>
<li><strong><code>ActorCreated</code></strong>: Actor instance creation with configuration</li>
<li><strong><code>ActorStarted</code></strong>: Actor begins execution</li>
<li><strong><code>ActorCompleted</code></strong>: Successful actor completion</li>
<li><strong><code>ActorFailed</code></strong>: Actor error with detailed error information</li>
</ul>
<h3 id="communication-events"><a class="header" href="#communication-events">Communication Events</a></h3>
<ul>
<li><strong><code>MessageSent</code></strong>: Message transmission between actors</li>
<li><strong><code>MessageReceived</code></strong>: Message reception confirmation</li>
<li><strong><code>DataFlow</code></strong>:  Automatic data flow tracing between connected actors</li>
<li><strong><code>PortConnected</code></strong>: Port connection establishment</li>
<li><strong><code>PortDisconnected</code></strong>: Port disconnection</li>
</ul>
<h3 id="system-events"><a class="header" href="#system-events">System Events</a></h3>
<ul>
<li><strong><code>StateChanged</code></strong>: Actor state modifications with diffs</li>
<li><strong><code>NetworkEvent</code></strong>: Distributed network operations</li>
</ul>
<h2 id="integration-patterns"><a class="header" href="#integration-patterns">Integration Patterns</a></h2>
<h3 id="automatic-integration"><a class="header" href="#automatic-integration">Automatic Integration</a></h3>
<p>The tracing framework integrates automatically with Reflow networks:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::{Network, NetworkConfig};
use reflow_network::tracing::TracingConfig;

// Enable tracing with minimal configuration
let tracing_config = TracingConfig {
    server_url: "ws://localhost:8080".to_string(),
    enabled: true,
    ..Default::default()
};

let network_config = NetworkConfig {
    tracing: tracing_config,
    ..Default::default()
};

let network = Network::new(network_config);
// All actor operations are now automatically traced!
<span class="boring">}</span></code></pre></pre>
<h3 id="manual-event-recording"><a class="header" href="#manual-event-recording">Manual Event Recording</a></h3>
<p>For custom events and detailed control:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_tracing_protocol::{TraceEvent, TracingIntegration};

// Record custom events
if let Some(tracing) = global_tracing() {
    tracing.trace_actor_created("custom_actor").await?;
    tracing.trace_data_flow(
        "source_actor", "output",
        "target_actor", "input",
        "CustomMessage", 1024
    ).await?;
}
<span class="boring">}</span></code></pre></pre>
<h2 id="data-flow-tracing"><a class="header" href="#data-flow-tracing">Data Flow Tracing</a></h2>
<p>The latest enhancement to the observability framework provides automatic data flow tracing:</p>
<h3 id="automatic-capture"><a class="header" href="#automatic-capture">Automatic Capture</a></h3>
<ul>
<li><strong>Zero Configuration</strong>: Works out-of-the-box with existing actor networks</li>
<li><strong>Connector Integration</strong>: Captures data flow at the connector level for accuracy</li>
<li><strong>Bidirectional Tracking</strong>: Traces both source and destination information</li>
<li><strong>Performance Metadata</strong>: Includes message size, type, and timing information</li>
</ul>
<h3 id="rich-context"><a class="header" href="#rich-context">Rich Context</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Data flow events automatically include:
DataFlow {
    from_actor: "data_processor",
    from_port: "output",
    to_actor: "analytics_engine", 
    to_port: "input",
    message_type: "ProcessedData",
    size_bytes: 2048,
    timestamp: "2025-01-07T06:00:00Z",
    causality_chain: [...],
    performance_metrics: {...}
}
<span class="boring">}</span></code></pre></pre>
<h2 id="use-cases"><a class="header" href="#use-cases">Use Cases</a></h2>
<h3 id="development--debugging"><a class="header" href="#development--debugging">Development &amp; Debugging</a></h3>
<ul>
<li><strong>Execution Visualization</strong>: See exactly how data flows through your system</li>
<li><strong>Performance Profiling</strong>: Identify bottlenecks and optimization opportunities</li>
<li><strong>Error Investigation</strong>: Trace error propagation through actor networks</li>
<li><strong>State Debugging</strong>: Time-travel debugging with state diffs</li>
</ul>
<h3 id="production-monitoring"><a class="header" href="#production-monitoring">Production Monitoring</a></h3>
<ul>
<li><strong>Health Monitoring</strong>: Track system health and detect anomalies</li>
<li><strong>Performance Monitoring</strong>: Monitor throughput, latency, and resource usage</li>
<li><strong>Capacity Planning</strong>: Analyze usage patterns for scaling decisions</li>
<li><strong>Incident Response</strong>: Rapid diagnosis of production issues</li>
</ul>
<h3 id="analytics--optimization"><a class="header" href="#analytics--optimization">Analytics &amp; Optimization</a></h3>
<ul>
<li><strong>Usage Patterns</strong>: Understand how your system is actually used</li>
<li><strong>Performance Optimization</strong>: Data-driven optimization decisions</li>
<li><strong>Architecture Evolution</strong>: Make informed architectural changes</li>
<li><strong>Compliance</strong>: Maintain audit trails for regulatory requirements</li>
</ul>
<h2 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h2>
<ol>
<li><strong><a href="observability/getting-started.html">Quick Start Guide</a></strong> - Get tracing running in 5 minutes</li>
<li><strong><a href="observability/architecture.html">Architecture Deep Dive</a></strong> - Understand the technical details</li>
<li><strong><a href="observability/configuration.html">Configuration Guide</a></strong> - Customize for your environment</li>
<li><strong><a href="observability/deployment.html">Deployment Guide</a></strong> - Production deployment patterns</li>
</ol>
<h2 id="next-steps-11"><a class="header" href="#next-steps-11">Next Steps</a></h2>
<ul>
<li>Learn about <a href="observability/event-types.html">event types and their uses</a></li>
<li>Explore <a href="observability/storage-backends.html">storage backend options</a></li>
<li>Set up <a href="observability/deployment.html">production monitoring</a></li>
<li>Integrate with <a href="observability/../tutorials/advanced-tracing-setup.html">existing monitoring systems</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="observability-quick-start"><a class="header" href="#observability-quick-start">Observability Quick Start</a></h1>
<p>Get Reflow's observability framework running in under 5 minutes. This guide will walk you through setting up tracing for a simple actor network and viewing the results.</p>
<h2 id="prerequisites-3"><a class="header" href="#prerequisites-3">Prerequisites</a></h2>
<ul>
<li>Rust 1.70 or later</li>
<li>Basic familiarity with Reflow actors</li>
</ul>
<h2 id="step-1-start-the-tracing-server"><a class="header" href="#step-1-start-the-tracing-server">Step 1: Start the Tracing Server</a></h2>
<p>First, start the reflow_tracing server:</p>
<pre><code class="language-bash"># From the project root
cd examples/tracing_integration
./scripts/start_server.sh
</code></pre>
<p>This starts the tracing server on <code>ws://127.0.0.1:8080</code> with SQLite storage.</p>
<h2 id="step-2-create-a-simple-traced-network"><a class="header" href="#step-2-create-a-simple-traced-network">Step 2: Create a Simple Traced Network</a></h2>
<p>Create a new Rust project or add to an existing one:</p>
<pre><code class="language-toml"># Cargo.toml
[dependencies]
reflow_network = { path = "../../crates/reflow_network" }
reflow_actor = { path = "../../crates/reflow_actor" }
reflow_tracing_protocol = { path = "../../crates/reflow_tracing_protocol" }
tokio = { version = "1.0", features = ["full"] }
anyhow = "1.0"
tracing = "0.1"
tracing-subscriber = "0.3"
</code></pre>
<p>Create a simple actor network with tracing enabled:</p>
<pre><pre class="playground"><code class="language-rust">// src/main.rs
use anyhow::Result;
use reflow_network::{Network, NetworkConfig};
use reflow_network::tracing::{TracingConfig, init_global_tracing};
use reflow_actor::{Actor, ActorBehavior, ActorContext, Port, ActorLoad, ActorConfig};
use std::collections::HashMap;
use std::sync::Arc;
use std::time::Duration;
use parking_lot::Mutex;

// Simple data processor actor
#[derive(Clone)]
struct DataProcessor {
    name: String,
}

impl DataProcessor {
    fn new(name: &amp;str) -&gt; Self {
        Self { name: name.to_string() }
    }
}

impl Actor for DataProcessor {
    fn get_behavior(&amp;self) -&gt; ActorBehavior {
        let name = self.name.clone();
        Box::new(move |context: ActorContext| {
            let actor_name = name.clone();
            Box::pin(async move {
                println!("üé¨ {} processing messages", actor_name);
                
                let mut results = HashMap::new();
                for (port, message) in context.get_payload() {
                    println!("üì® {} received on {}: {:?}", actor_name, port, message);
                    
                    // Simulate processing
                    tokio::time::sleep(Duration::from_millis(100)).await;
                    
                    let output = reflow_actor::message::Message::string(
                        format!("Processed by {}: {:?}", actor_name, message)
                    );
                    results.insert("output".to_string(), output);
                }
                
                Ok(results)
            })
        })
    }

    fn get_inports(&amp;self) -&gt; Port { flume::unbounded() }
    fn get_outports(&amp;self) -&gt; Port { flume::unbounded() }
    fn load_count(&amp;self) -&gt; Arc&lt;Mutex&lt;ActorLoad&gt;&gt; { 
        Arc::new(Mutex::new(ActorLoad::new(0))) 
    }
    
    fn create_process(&amp;self, _config: ActorConfig) -&gt; std::pin::Pin&lt;Box&lt;dyn std::future::Future&lt;Output = ()&gt; + Send + 'static&gt;&gt; {
        Box::pin(async {})
    }
    
    fn shutdown(&amp;self) {}
}

#[tokio::main]
async fn main() -&gt; Result&lt;()&gt; {
    // Initialize logging
    tracing_subscriber::fmt::init();
    
    println!("üöÄ Starting traced actor network");
    
    // Step 1: Configure tracing
    let tracing_config = TracingConfig {
        server_url: "ws://127.0.0.1:8080".to_string(),
        batch_size: 10,
        batch_timeout: Duration::from_millis(500),
        enable_compression: false,
        enabled: true,
        retry_config: reflow_network::tracing::RetryConfig {
            max_retries: 3,
            initial_delay: Duration::from_millis(100),
            max_delay: Duration::from_secs(5),
            backoff_multiplier: 2.0,
        },
    };
    
    // Step 2: Initialize global tracing
    init_global_tracing(tracing_config.clone())?;
    println!("‚úÖ Global tracing initialized");
    
    // Step 3: Create network with tracing enabled
    let network_config = NetworkConfig {
        tracing: tracing_config,
        ..Default::default()
    };
    
    let mut network = Network::new(network_config);
    println!("‚úÖ Network created with tracing");
    
    // Step 4: Register actors
    let processor1 = DataProcessor::new("processor1");
    let processor2 = DataProcessor::new("processor2");
    
    network.register_actor("processor", processor1)?;
    network.register_actor("formatter", processor2)?;
    
    // Step 5: Add nodes to network
    network.add_node("proc1", "processor", None)?;
    network.add_node("proc2", "formatter", None)?;
    
    // Step 6: Start the network (automatic tracing begins here)
    network.start()?;
    println!("‚úÖ Network started - tracing active");
    
    // Step 7: Send some messages (these will be automatically traced)
    println!("üì® Sending test messages...");
    
    for i in 1..=3 {
        let message = reflow_actor::message::Message::string(
            format!("Test message {}", i)
        );
        network.send_to_actor("proc1", "input", message)?;
        tokio::time::sleep(Duration::from_millis(300)).await;
    }
    
    // Step 8: Execute actors directly for more detailed tracing
    let result = network.execute_actor(
        "proc2",
        HashMap::from([
            ("input".to_string(), reflow_actor::message::Message::string("Direct execution test".to_string()))
        ])
    ).await?;
    
    println!("‚úÖ Direct execution result: {:?}", result);
    
    // Step 9: Let the system run to generate traces
    tokio::time::sleep(Duration::from_secs(2)).await;
    
    // Step 10: Manual tracing API demonstration
    if let Some(tracing) = reflow_network::tracing::global_tracing() {
        println!("üîç Demonstrating manual tracing API...");
        
        tracing.trace_actor_created("manual_actor").await?;
        tracing.trace_message_sent(
            "manual_actor", 
            "output", 
            "ManualMessage", 
            256
        ).await?;
        
        println!("‚úÖ Manual events recorded");
    }
    
    // Graceful shutdown
    println!("üõë Shutting down...");
    network.shutdown();
    tokio::time::sleep(Duration::from_millis(500)).await;
    
    println!("üéâ Quick start complete! Check the tracing server for events.");
    println!("üí° Next: Run the monitoring client to see live events:");
    println!("   cargo run --bin monitoring_client");
    
    Ok(())
}</code></pre></pre>
<h2 id="step-3-run-your-application"><a class="header" href="#step-3-run-your-application">Step 3: Run Your Application</a></h2>
<pre><code class="language-bash">cargo run
</code></pre>
<p>You should see output like:</p>
<pre><code>üöÄ Starting traced actor network
‚úÖ Global tracing initialized
‚úÖ Network created with tracing
‚úÖ Network started - tracing active
üì® Sending test messages...
üé¨ processor1 processing messages
üì® processor1 received on input: String("Test message 1")
...
üéâ Quick start complete! Check the tracing server for events.
</code></pre>
<h2 id="step-4-view-live-events"><a class="header" href="#step-4-view-live-events">Step 4: View Live Events</a></h2>
<p>In another terminal, run the monitoring client:</p>
<pre><code class="language-bash">cd examples/tracing_integration
cargo run --bin monitoring_client
</code></pre>
<p>You'll see real-time trace events:</p>
<pre><code>üîç Monitoring live trace events...
üìä Connected to tracing server at ws://127.0.0.1:8080

[2025-01-07T06:00:00Z] ActorCreated: processor1
[2025-01-07T06:00:00Z] ActorCreated: processor2  
[2025-01-07T06:00:00Z] MessageSent: processor1 -&gt; output (String, 256 bytes)
[2025-01-07T06:00:00Z] DataFlow: processor1:output -&gt; processor2:input (String, 256 bytes)
[2025-01-07T06:00:01Z] ActorCompleted: processor1
...
</code></pre>
<h2 id="what-just-happened"><a class="header" href="#what-just-happened">What Just Happened?</a></h2>
<p>Your simple actor network generated several types of trace events:</p>
<ol>
<li><strong>Actor Creation</strong>: When actors were instantiated</li>
<li><strong>Message Sending</strong>: When messages were sent between actors</li>
<li><strong>Data Flow</strong>: Automatic tracing of data flowing between connected actors</li>
<li><strong>Actor Completion</strong>: When actors finished processing</li>
</ol>
<p>All of this happened <strong>automatically</strong> - the tracing framework integrated seamlessly with your existing Reflow network.</p>
<h2 id="exploring-the-data"><a class="header" href="#exploring-the-data">Exploring the Data</a></h2>
<h3 id="sqlite-database"><a class="header" href="#sqlite-database">SQLite Database</a></h3>
<p>The trace data is stored in <code>examples/tracing_integration/data/traces.db</code>. You can explore it directly:</p>
<pre><code class="language-bash">sqlite3 examples/tracing_integration/data/traces.db
.tables
SELECT * FROM trace_events LIMIT 5;
</code></pre>
<h3 id="query-api"><a class="header" href="#query-api">Query API</a></h3>
<p>Use the monitoring client with query options:</p>
<pre><code class="language-bash"># Get last 10 events
cargo run --bin monitoring_client -- --query --limit 10

# Filter by actor
cargo run --bin monitoring_client -- --actor-ids processor1

# Filter by event type
cargo run --bin monitoring_client -- --event-types ActorCreated,MessageSent
</code></pre>
<h2 id="next-steps-12"><a class="header" href="#next-steps-12">Next Steps</a></h2>
<h3 id="-learn-more-about-event-types"><a class="header" href="#-learn-more-about-event-types">üéØ <strong>Learn More About Event Types</strong></a></h3>
<ul>
<li>Read about all <a href="observability/event-types.html">event types and their uses</a></li>
<li>Understand <a href="observability/data-flow-tracing.html">data flow tracing capabilities</a></li>
</ul>
<h3 id="-customize-your-setup"><a class="header" href="#-customize-your-setup">‚öôÔ∏è <strong>Customize Your Setup</strong></a></h3>
<ul>
<li>Configure <a href="observability/storage-backends.html">different storage backends</a></li>
<li>Explore <a href="observability/configuration.html">configuration options</a></li>
</ul>
<h3 id="-production-deployment"><a class="header" href="#-production-deployment">üöÄ <strong>Production Deployment</strong></a></h3>
<ul>
<li>Set up <a href="observability/deployment.html">production monitoring</a></li>
<li>Learn about <a href="observability/../tutorials/advanced-tracing-setup.html">scaling and performance</a></li>
</ul>
<h3 id="-integration"><a class="header" href="#-integration">üîß <strong>Integration</strong></a></h3>
<ul>
<li>Build <a href="observability/../api/tracing/client-integration.html">custom monitoring dashboards</a></li>
<li>Integrate with <a href="observability/../tutorials/advanced-tracing-setup.html">existing monitoring systems</a></li>
</ul>
<h2 id="troubleshooting-3"><a class="header" href="#troubleshooting-3">Troubleshooting</a></h2>
<h3 id="connection-issues"><a class="header" href="#connection-issues">Connection Issues</a></h3>
<p>If the client can't connect to the tracing server:</p>
<pre><code class="language-bash"># Check if server is running
curl -I http://127.0.0.1:8080
# or
telnet 127.0.0.1 8080
</code></pre>
<h3 id="no-events-appearing"><a class="header" href="#no-events-appearing">No Events Appearing</a></h3>
<ul>
<li>Ensure <code>enabled: true</code> in your <code>TracingConfig</code></li>
<li>Check that <code>init_global_tracing()</code> was called before network operations</li>
<li>Verify the server URL is correct</li>
</ul>
<h3 id="performance-impact"><a class="header" href="#performance-impact">Performance Impact</a></h3>
<p>For production systems, consider:</p>
<ul>
<li>Increasing <code>batch_size</code> to reduce network overhead</li>
<li>Enabling compression with <code>enable_compression: true</code></li>
<li>Using PostgreSQL backend for better concurrent performance</li>
</ul>
<p>Get help in our <a href="observability/../reference/troubleshooting-guide.html">troubleshooting guide</a> or check the <a href="observability/architecture.html">architecture documentation</a> for deeper understanding.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="observability-architecture"><a class="header" href="#observability-architecture">Observability Architecture</a></h1>
<p>The Reflow observability framework is built on a distributed, event-driven architecture that provides comprehensive visibility into actor networks with minimal performance impact.</p>
<h2 id="system-components"><a class="header" href="#system-components">System Components</a></h2>
<h3 id="1-tracing-client-tracingclient"><a class="header" href="#1-tracing-client-tracingclient">1. Tracing Client (<code>TracingClient</code>)</a></h3>
<p>The tracing client is embedded within each Reflow network instance and is responsible for:</p>
<ul>
<li><strong>Event Collection</strong>: Capturing trace events from actor operations</li>
<li><strong>Event Batching</strong>: Aggregating events for efficient transmission</li>
<li><strong>Network Communication</strong>: WebSocket-based communication with the tracing server</li>
<li><strong>Retry Logic</strong>: Robust retry mechanisms for network failures</li>
<li><strong>Compression</strong>: Optional compression of trace data</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct TracingClient {
    config: TracingConfig,
    sender: Arc&lt;TracingSender&gt;,
    connection: Arc&lt;RwLock&lt;Option&lt;WebSocketConnection&gt;&gt;&gt;,
    retry_manager: RetryManager,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="2-tracing-server-reflow_tracing"><a class="header" href="#2-tracing-server-reflow_tracing">2. Tracing Server (<code>reflow_tracing</code>)</a></h3>
<p>The centralized tracing server handles:</p>
<ul>
<li><strong>Connection Management</strong>: WebSocket connections from multiple clients</li>
<li><strong>Event Processing</strong>: Real-time processing of incoming trace events</li>
<li><strong>Storage Coordination</strong>: Routing events to configured storage backends</li>
<li><strong>Query Interface</strong>: Serving historical and real-time queries</li>
<li><strong>Subscription Management</strong>: Managing real-time event subscriptions</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct TracingServer {
    config: ServerConfig,
    storage: Box&lt;dyn TraceStorage&gt;,
    connection_pool: ConnectionPool,
    event_processor: EventProcessor,
    subscription_manager: SubscriptionManager,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="3-storage-layer"><a class="header" href="#3-storage-layer">3. Storage Layer</a></h3>
<p>Pluggable storage backends with different characteristics:</p>
<h4 id="sqlite-backend"><a class="header" href="#sqlite-backend">SQLite Backend</a></h4>
<ul>
<li><strong>Use Case</strong>: Development, small deployments, single-instance scenarios</li>
<li><strong>Advantages</strong>: Zero configuration, embedded, ACID compliant</li>
<li><strong>Limitations</strong>: Single writer, limited concurrent access</li>
<li><strong>Schema</strong>: Optimized for time-series queries with proper indexing</li>
</ul>
<h4 id="postgresql-backend"><a class="header" href="#postgresql-backend">PostgreSQL Backend</a></h4>
<ul>
<li><strong>Use Case</strong>: Production deployments, high-concurrency scenarios</li>
<li><strong>Advantages</strong>: ACID compliance, concurrent access, advanced querying</li>
<li><strong>Features</strong>: Partitioning, indexing, full-text search capabilities</li>
<li><strong>Scalability</strong>: Supports connection pooling and read replicas</li>
</ul>
<h4 id="memory-backend"><a class="header" href="#memory-backend">Memory Backend</a></h4>
<ul>
<li><strong>Use Case</strong>: Testing, temporary analysis, high-performance scenarios</li>
<li><strong>Advantages</strong>: Fastest performance, no I/O overhead</li>
<li><strong>Limitations</strong>: Data loss on restart, memory-bound capacity</li>
<li><strong>Features</strong>: In-memory indexes and efficient filtering</li>
</ul>
<h2 id="event-flow-architecture"><a class="header" href="#event-flow-architecture">Event Flow Architecture</a></h2>
<pre><code class="language-mermaid">sequenceDiagram
    participant A as Actor
    participant C as Connector
    participant TC as TracingClient
    participant TS as TracingServer
    participant S as Storage
    participant M as Monitor
    
    A-&gt;&gt;C: Send Message
    C-&gt;&gt;TC: Record DataFlow Event
    TC-&gt;&gt;TC: Batch Events
    TC-&gt;&gt;TS: Send Batch (WebSocket)
    TS-&gt;&gt;S: Store Events
    TS-&gt;&gt;M: Notify Subscribers
    
    Note over TC,TS: Automatic retry on failure
    Note over TS,S: Pluggable storage backends
</code></pre>
<h2 id="integration-points"><a class="header" href="#integration-points">Integration Points</a></h2>
<h3 id="automatic-integration-1"><a class="header" href="#automatic-integration-1">Automatic Integration</a></h3>
<p>The framework automatically integrates at key points in the Reflow execution flow:</p>
<h4 id="actor-lifecycle-integration"><a class="header" href="#actor-lifecycle-integration">Actor Lifecycle Integration</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Automatic tracing in Network::register_actor
pub fn register_actor(&amp;mut self, name: &amp;str, actor: impl Actor) -&gt; Result&lt;()&gt; {
    // Register actor
    self.actors.insert(name.to_string(), Box::new(actor));
    
    // Automatic tracing
    if let Some(tracing) = &amp;self.tracing {
        tracing.trace_actor_created(name).await?;
    }
    
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h4 id="connector-level-tracing"><a class="header" href="#connector-level-tracing">Connector-Level Tracing</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Automatic data flow tracing in connectors
impl Connector {
    pub async fn send_message(&amp;self, message: Message) -&gt; Result&lt;()&gt; {
        // Send the message
        self.channel.send(message.clone()).await?;
        
        // Automatic tracing
        if let Some(tracing) = global_tracing() {
            tracing.trace_data_flow(
                &amp;self.from_actor, &amp;self.from_port,
                &amp;self.to_actor, &amp;self.to_port,
                message.type_name(), message.size_bytes()
            ).await?;
        }
        
        Ok(())
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="manual-integration"><a class="header" href="#manual-integration">Manual Integration</a></h3>
<p>For custom events and fine-grained control:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Manual event recording
if let Some(tracing) = global_tracing() {
    // Custom actor events
    tracing.trace_actor_started("my_actor").await?;
    tracing.trace_actor_completed("my_actor").await?;
    tracing.trace_actor_failed("my_actor", "Error message").await?;
    
    // Custom message events
    tracing.trace_message_sent("actor", "port", "MessageType", 1024).await?;
    tracing.trace_message_received("actor", "port", "MessageType", 1024).await?;
    
    // State change events
    tracing.trace_state_changed("actor", state_diff).await?;
    
    // Custom events with metadata
    let event = TraceEvent {
        event_type: TraceEventType::Custom("deployment_started".to_string()),
        actor_id: "deployment_manager".to_string(),
        data: TraceEventData {
            custom_attributes: HashMap::from([
                ("environment".to_string(), json!("production")),
                ("version".to_string(), json!("v1.2.3")),
            ]),
            ..Default::default()
        },
        ..Default::default()
    };
    tracing.record_event(trace_id, event).await?;
}
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-architecture"><a class="header" href="#performance-architecture">Performance Architecture</a></h2>
<h3 id="batching-strategy"><a class="header" href="#batching-strategy">Batching Strategy</a></h3>
<p>Events are batched to minimize network overhead:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct BatchingStrategy {
    batch_size: usize,           // Max events per batch
    batch_timeout: Duration,     // Max time to wait for batch
    compression: CompressionType, // Optional compression
}
<span class="boring">}</span></code></pre></pre>
<h3 id="asynchronous-processing"><a class="header" href="#asynchronous-processing">Asynchronous Processing</a></h3>
<p>All tracing operations are asynchronous and non-blocking:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Event collection uses async channels
pub struct TracingClient {
    event_sender: mpsc::UnboundedSender&lt;TraceEvent&gt;,
    batch_processor: JoinHandle&lt;()&gt;,
}

// Background batch processing
async fn process_batches(mut receiver: mpsc::UnboundedReceiver&lt;TraceEvent&gt;) {
    let mut batch = Vec::new();
    let mut batch_timer = interval(batch_timeout);
    
    loop {
        select! {
            event = receiver.recv() =&gt; {
                if let Some(event) = event {
                    batch.push(event);
                    if batch.len() &gt;= batch_size {
                        send_batch(&amp;mut batch).await;
                    }
                }
            }
            _ = batch_timer.tick() =&gt; {
                if !batch.is_empty() {
                    send_batch(&amp;mut batch).await;
                }
            }
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="memory-management-2"><a class="header" href="#memory-management-2">Memory Management</a></h3>
<p>Efficient memory usage through:</p>
<ul>
<li><strong>Event Pooling</strong>: Reuse of event objects</li>
<li><strong>Bounded Channels</strong>: Prevent unbounded memory growth</li>
<li><strong>Compression</strong>: Reduce memory footprint for large traces</li>
<li><strong>Background Processing</strong>: Offload processing from critical paths</li>
</ul>
<h2 id="scalability-considerations"><a class="header" href="#scalability-considerations">Scalability Considerations</a></h2>
<h3 id="horizontal-scaling"><a class="header" href="#horizontal-scaling">Horizontal Scaling</a></h3>
<p>The tracing server can be scaled horizontally:</p>
<pre><code class="language-mermaid">graph TB
    subgraph "Load Balancer"
        LB[WebSocket Load Balancer]
    end
    
    subgraph "Tracing Servers"
        TS1[Tracing Server 1]
        TS2[Tracing Server 2]
        TS3[Tracing Server N]
    end
    
    subgraph "Storage"
        DB[(PostgreSQL Cluster)]
    end
    
    LB --&gt; TS1
    LB --&gt; TS2
    LB --&gt; TS3
    
    TS1 --&gt; DB
    TS2 --&gt; DB
    TS3 --&gt; DB
</code></pre>
<h3 id="storage-partitioning"><a class="header" href="#storage-partitioning">Storage Partitioning</a></h3>
<p>For large-scale deployments:</p>
<pre><code class="language-sql">-- Time-based partitioning
CREATE TABLE trace_events_2025_01 PARTITION OF trace_events
FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');

-- Actor-based partitioning  
CREATE TABLE trace_events_ml PARTITION OF trace_events
FOR VALUES IN ('ml_trainer', 'ml_evaluator', 'ml_predictor');
</code></pre>
<h3 id="performance-optimizations"><a class="header" href="#performance-optimizations">Performance Optimizations</a></h3>
<h4 id="client-side-optimizations"><a class="header" href="#client-side-optimizations">Client-Side Optimizations</a></h4>
<ul>
<li><strong>Local Buffering</strong>: Buffer events locally during network issues</li>
<li><strong>Adaptive Batching</strong>: Adjust batch sizes based on network conditions</li>
<li><strong>Priority Queues</strong>: Prioritize critical events over routine events</li>
<li><strong>Sampling</strong>: Sample high-frequency events to reduce overhead</li>
</ul>
<h4 id="server-side-optimizations"><a class="header" href="#server-side-optimizations">Server-Side Optimizations</a></h4>
<ul>
<li><strong>Connection Pooling</strong>: Reuse database connections</li>
<li><strong>Bulk Inserts</strong>: Batch database operations</li>
<li><strong>Indexing Strategy</strong>: Optimize indexes for common query patterns</li>
<li><strong>Caching</strong>: Cache frequently accessed data</li>
</ul>
<h2 id="security-architecture"><a class="header" href="#security-architecture">Security Architecture</a></h2>
<h3 id="authentication--authorization"><a class="header" href="#authentication--authorization">Authentication &amp; Authorization</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct TracingConfig {
    pub server_url: String,
    pub api_key: Option&lt;String&gt;,        // API key authentication
    pub client_cert: Option&lt;PathBuf&gt;,   // Client certificate
    pub ca_cert: Option&lt;PathBuf&gt;,       // CA certificate for verification
}
<span class="boring">}</span></code></pre></pre>
<h3 id="data-privacy"><a class="header" href="#data-privacy">Data Privacy</a></h3>
<ul>
<li><strong>Field Filtering</strong>: Exclude sensitive data from traces</li>
<li><strong>Data Anonymization</strong>: Hash or tokenize sensitive identifiers</li>
<li><strong>Retention Policies</strong>: Automatic cleanup of old trace data</li>
<li><strong>Access Controls</strong>: Role-based access to trace data</li>
</ul>
<h3 id="network-security"><a class="header" href="#network-security">Network Security</a></h3>
<ul>
<li><strong>TLS Encryption</strong>: All WebSocket connections use TLS</li>
<li><strong>Certificate Validation</strong>: Mutual TLS authentication</li>
<li><strong>Rate Limiting</strong>: Prevent abuse and DoS attacks</li>
<li><strong>Origin Validation</strong>: Validate client origins</li>
</ul>
<h2 id="monitoring-the-monitor"><a class="header" href="#monitoring-the-monitor">Monitoring the Monitor</a></h2>
<h3 id="health-metrics"><a class="header" href="#health-metrics">Health Metrics</a></h3>
<p>The tracing system exposes its own health metrics:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct TracingMetrics {
    pub events_processed: u64,
    pub events_dropped: u64,
    pub connection_count: u32,
    pub storage_latency: Duration,
    pub memory_usage: usize,
    pub error_rate: f64,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="self-monitoring"><a class="header" href="#self-monitoring">Self-Monitoring</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// The tracing system can trace itself
if let Some(tracing) = global_tracing() {
    tracing.trace_system_metric(
        "tracing_server",
        "events_processed_per_second",
        events_per_second as f64
    ).await?;
}
<span class="boring">}</span></code></pre></pre>
<h2 id="error-handling--resilience"><a class="header" href="#error-handling--resilience">Error Handling &amp; Resilience</a></h2>
<h3 id="network-resilience"><a class="header" href="#network-resilience">Network Resilience</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct RetryConfig {
    pub max_retries: usize,
    pub initial_delay: Duration,
    pub max_delay: Duration,
    pub backoff_multiplier: f64,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="graceful-degradation"><a class="header" href="#graceful-degradation">Graceful Degradation</a></h3>
<p>When the tracing server is unavailable:</p>
<ol>
<li><strong>Local Buffering</strong>: Store events locally with size limits</li>
<li><strong>Sampling</strong>: Reduce event volume to essential events only</li>
<li><strong>Alerting</strong>: Notify operators of tracing system issues</li>
<li><strong>Recovery</strong>: Automatic reconnection and buffer flush</li>
</ol>
<h3 id="data-consistency"><a class="header" href="#data-consistency">Data Consistency</a></h3>
<ul>
<li><strong>Idempotent Operations</strong>: Safe to retry operations</li>
<li><strong>Transaction Management</strong>: Atomic batch processing</li>
<li><strong>Conflict Resolution</strong>: Handle duplicate events gracefully</li>
<li><strong>Validation</strong>: Validate event integrity before storage</li>
</ul>
<p>This architecture provides a robust, scalable foundation for comprehensive observability while maintaining the performance characteristics required for production actor networks.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="event-types-reference"><a class="header" href="#event-types-reference">Event Types Reference</a></h1>
<p>The Reflow observability framework captures comprehensive trace events that provide deep insights into actor network behavior. This reference covers all available event types, their structure, and usage patterns.</p>
<h2 id="core-event-structure"><a class="header" href="#core-event-structure">Core Event Structure</a></h2>
<p>All trace events share a common structure defined in <code>TraceEvent</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct TraceEvent {
    pub event_id: EventId,           // Unique event identifier
    pub timestamp: DateTime&lt;Utc&gt;,    // UTC timestamp
    pub event_type: TraceEventType,  // Event type (see below)
    pub actor_id: String,            // Source actor identifier
    pub data: TraceEventData,        // Event-specific data
    pub causality: CausalityInfo,    // Causality tracking
}
<span class="boring">}</span></code></pre></pre>
<h2 id="actor-lifecycle-events"><a class="header" href="#actor-lifecycle-events">Actor Lifecycle Events</a></h2>
<h3 id="actorcreated"><a class="header" href="#actorcreated">ActorCreated</a></h3>
<p>Triggered when an actor instance is created.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>TraceEventType::ActorCreated
<span class="boring">}</span></code></pre></pre>
<p><strong>When Generated</strong>:</p>
<ul>
<li>Actor registration in network</li>
<li>Dynamic actor instantiation</li>
<li>Actor factory creation</li>
</ul>
<p><strong>Event Data</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>TraceEventData {
    port: None,
    message: None,
    state_diff: None,
    error: None,
    performance_metrics: PerformanceMetrics::default(),
    custom_attributes: HashMap::from([
        ("actor_type", json!("DataProcessor")),
        ("config", json!({"timeout": 5000})),
        ("instance_id", json!("proc_001")),
    ]),
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Example</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>if let Some(tracing) = global_tracing() {
    tracing.trace_actor_created("data_processor").await?;
}
<span class="boring">}</span></code></pre></pre>
<h3 id="actorstarted"><a class="header" href="#actorstarted">ActorStarted</a></h3>
<p>Triggered when an actor begins execution.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>TraceEventType::ActorStarted
<span class="boring">}</span></code></pre></pre>
<p><strong>When Generated</strong>:</p>
<ul>
<li>Actor process startup</li>
<li>Actor behavior initialization</li>
<li>Resource allocation completion</li>
</ul>
<p><strong>Event Data</strong>: Includes initialization metrics and startup configuration.</p>
<h3 id="actorcompleted"><a class="header" href="#actorcompleted">ActorCompleted</a></h3>
<p>Triggered when an actor successfully completes execution.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>TraceEventType::ActorCompleted
<span class="boring">}</span></code></pre></pre>
<p><strong>When Generated</strong>:</p>
<ul>
<li>Successful actor termination</li>
<li>Graceful shutdown completion</li>
<li>Task completion</li>
</ul>
<p><strong>Event Data</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>TraceEventData {
    performance_metrics: PerformanceMetrics {
        execution_time_ns: 150_000_000,  // 150ms
        memory_usage_bytes: 1024,
        cpu_usage_percent: 15.5,
        queue_depth: 0,
        throughput_msgs_per_sec: 100.0,
    },
    custom_attributes: HashMap::from([
        ("exit_code", json!(0)),
        ("processed_messages", json!(42)),
    ]),
    ..Default::default()
}
<span class="boring">}</span></code></pre></pre>
<h3 id="actorfailed"><a class="header" href="#actorfailed">ActorFailed</a></h3>
<p>Triggered when an actor encounters an error.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>TraceEventType::ActorFailed
<span class="boring">}</span></code></pre></pre>
<p><strong>When Generated</strong>:</p>
<ul>
<li>Unhandled exceptions</li>
<li>Resource exhaustion</li>
<li>Configuration errors</li>
<li>Network failures</li>
</ul>
<p><strong>Event Data</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>TraceEventData {
    error: Some("Connection timeout: Failed to connect to database".to_string()),
    performance_metrics: PerformanceMetrics {
        execution_time_ns: 5_000_000_000, // 5 seconds before timeout
        memory_usage_bytes: 2048,
        cpu_usage_percent: 95.0,
        queue_depth: 10,
        throughput_msgs_per_sec: 0.0,
    },
    custom_attributes: HashMap::from([
        ("error_code", json!("TIMEOUT")),
        ("retry_count", json!(3)),
        ("last_successful_operation", json!("database_query")),
    ]),
    ..Default::default()
}
<span class="boring">}</span></code></pre></pre>
<h2 id="communication-events-1"><a class="header" href="#communication-events-1">Communication Events</a></h2>
<h3 id="messagesent"><a class="header" href="#messagesent">MessageSent</a></h3>
<p>Triggered when an actor sends a message.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>TraceEventType::MessageSent
<span class="boring">}</span></code></pre></pre>
<p><strong>When Generated</strong>:</p>
<ul>
<li>Message transmission to ports</li>
<li>Inter-actor communication</li>
<li>Network message dispatch</li>
</ul>
<p><strong>Event Data</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>TraceEventData {
    port: Some("output".to_string()),
    message: Some(MessageSnapshot {
        message_type: "ProcessedData".to_string(),
        size_bytes: 1024,
        checksum: "sha256:abc123...".to_string(),
        serialized_data: vec![], // Optional: actual message data
    }),
    performance_metrics: PerformanceMetrics {
        execution_time_ns: 1_000_000, // 1ms serialization time
        ..Default::default()
    },
    ..Default::default()
}
<span class="boring">}</span></code></pre></pre>
<h3 id="messagereceived"><a class="header" href="#messagereceived">MessageReceived</a></h3>
<p>Triggered when an actor receives a message.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>TraceEventType::MessageReceived
<span class="boring">}</span></code></pre></pre>
<p><strong>When Generated</strong>:</p>
<ul>
<li>Message reception on ports</li>
<li>Queue processing</li>
<li>Message deserialization</li>
</ul>
<p><strong>Event Data</strong>: Similar to <code>MessageSent</code> but from receiver perspective.</p>
<h3 id="dataflow-new"><a class="header" href="#dataflow-new">DataFlow (NEW)</a></h3>
<p>Automatically triggered when data flows between connected actors.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>TraceEventType::DataFlow {
    to_actor: String,
    to_port: String,
}
<span class="boring">}</span></code></pre></pre>
<p><strong>When Generated</strong>:</p>
<ul>
<li>Connector-level message transmission</li>
<li>Data pipeline operations</li>
<li>Cross-actor data transfer</li>
</ul>
<p><strong>Event Data</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>TraceEventData {
    port: Some("output".to_string()), // Source port
    message: Some(MessageSnapshot {
        message_type: "SensorReading".to_string(),
        size_bytes: 256,
        checksum: "sha256:def456...".to_string(),
        serialized_data: vec![],
    }),
    performance_metrics: PerformanceMetrics {
        execution_time_ns: 500_000, // 0.5ms transfer time
        queue_depth: 5, // Current queue depth at destination
        throughput_msgs_per_sec: 1000.0,
        ..Default::default()
    },
    custom_attributes: HashMap::from([
        ("source_actor", json!("sensor_reader")),
        ("source_port", json!("output")),
        ("destination_actor", json!("data_validator")),
        ("destination_port", json!("input")),
        ("transfer_protocol", json!("memory")),
    ]),
    ..Default::default()
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Usage</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Automatic - no manual code needed
// Generated when messages flow through connectors

// Manual usage for custom connectors:
tracing.trace_data_flow(
    "source_actor", "output_port",
    "dest_actor", "input_port", 
    "CustomMessage", 512
).await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="state-management-events"><a class="header" href="#state-management-events">State Management Events</a></h2>
<h3 id="statechanged"><a class="header" href="#statechanged">StateChanged</a></h3>
<p>Triggered when an actor's state is modified.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>TraceEventType::StateChanged
<span class="boring">}</span></code></pre></pre>
<p><strong>When Generated</strong>:</p>
<ul>
<li>State updates</li>
<li>Configuration changes</li>
<li>Memory state modifications</li>
</ul>
<p><strong>Event Data</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>TraceEventData {
    state_diff: Some(StateDiff {
        before: Some(previous_state_bytes),
        after: current_state_bytes,
        diff_type: StateDiffType::Incremental,
    }),
    performance_metrics: PerformanceMetrics {
        execution_time_ns: 2_000_000, // 2ms state update time
        memory_usage_bytes: 4096, // Memory used by state
        ..Default::default()
    },
    custom_attributes: HashMap::from([
        ("state_version", json!(42)),
        ("state_size_bytes", json!(4096)),
        ("changed_fields", json!(["counter", "last_update"])),
    ]),
    ..Default::default()
}
<span class="boring">}</span></code></pre></pre>
<h2 id="network-events"><a class="header" href="#network-events">Network Events</a></h2>
<h3 id="portconnected"><a class="header" href="#portconnected">PortConnected</a></h3>
<p>Triggered when actor ports are connected.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>TraceEventType::PortConnected
<span class="boring">}</span></code></pre></pre>
<p><strong>Event Data</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>TraceEventData {
    port: Some("output".to_string()),
    custom_attributes: HashMap::from([
        ("connected_to_actor", json!("downstream_processor")),
        ("connected_to_port", json!("input")),
        ("connection_type", json!("memory_channel")),
        ("buffer_size", json!(1000)),
    ]),
    ..Default::default()
}
<span class="boring">}</span></code></pre></pre>
<h3 id="portdisconnected"><a class="header" href="#portdisconnected">PortDisconnected</a></h3>
<p>Triggered when actor ports are disconnected.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>TraceEventType::PortDisconnected
<span class="boring">}</span></code></pre></pre>
<p><strong>Event Data</strong>: Similar to <code>PortConnected</code> but for disconnection events.</p>
<h3 id="networkevent"><a class="header" href="#networkevent">NetworkEvent</a></h3>
<p>Triggered for network-level operations.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>TraceEventType::NetworkEvent
<span class="boring">}</span></code></pre></pre>
<p><strong>When Generated</strong>:</p>
<ul>
<li>Network startup/shutdown</li>
<li>Actor registration/deregistration</li>
<li>Distributed network operations</li>
<li>Load balancing events</li>
</ul>
<p><strong>Event Data</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>TraceEventData {
    custom_attributes: HashMap::from([
        ("event_subtype", json!("actor_registered")),
        ("network_id", json!("production_cluster")),
        ("node_count", json!(5)),
        ("total_actors", json!(150)),
    ]),
    ..Default::default()
}
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-metrics"><a class="header" href="#performance-metrics">Performance Metrics</a></h2>
<p>All events include performance metrics:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct PerformanceMetrics {
    pub execution_time_ns: u64,      // Nanoseconds
    pub memory_usage_bytes: usize,   // Bytes
    pub cpu_usage_percent: f32,      // 0.0 - 100.0
    pub queue_depth: usize,          // Messages in queue
    pub throughput_msgs_per_sec: f64, // Messages per second
}
<span class="boring">}</span></code></pre></pre>
<h3 id="interpreting-metrics"><a class="header" href="#interpreting-metrics">Interpreting Metrics</a></h3>
<ul>
<li><strong>execution_time_ns</strong>: Time spent on the operation</li>
<li><strong>memory_usage_bytes</strong>: Memory footprint at time of event</li>
<li><strong>cpu_usage_percent</strong>: CPU utilization during operation</li>
<li><strong>queue_depth</strong>: Number of pending messages</li>
<li><strong>throughput_msgs_per_sec</strong>: Recent message processing rate</li>
</ul>
<h2 id="causality-information"><a class="header" href="#causality-information">Causality Information</a></h2>
<p>Events maintain causality chains for dependency tracking:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct CausalityInfo {
    pub parent_event_id: Option&lt;EventId&gt;,    // Direct parent event
    pub root_cause_event_id: EventId,        // Root cause in chain
    pub dependency_chain: Vec&lt;EventId&gt;,      // Full dependency chain
    pub span_id: String,                     // Distributed tracing span
}
<span class="boring">}</span></code></pre></pre>
<h3 id="building-causality-chains"><a class="header" href="#building-causality-chains">Building Causality Chains</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Events can reference parent events
let parent_event_id = previous_event.event_id;

let child_event = TraceEvent {
    causality: CausalityInfo {
        parent_event_id: Some(parent_event_id),
        root_cause_event_id: original_trigger_event_id,
        dependency_chain: vec![original_trigger_event_id, parent_event_id],
        span_id: distributed_span_id,
    },
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h2 id="custom-events"><a class="header" href="#custom-events">Custom Events</a></h2>
<p>Create custom event types for domain-specific tracing:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Custom event type
TraceEventType::Custom("deployment_started".to_string())

// Create custom event
let custom_event = TraceEvent {
    event_type: TraceEventType::Custom("model_training_completed".to_string()),
    actor_id: "ml_trainer".to_string(),
    data: TraceEventData {
        custom_attributes: HashMap::from([
            ("model_type", json!("neural_network")),
            ("training_epochs", json!(100)),
            ("accuracy", json!(0.95)),
            ("model_size_mb", json!(25.4)),
            ("training_time_hours", json!(3.5)),
        ]),
        performance_metrics: PerformanceMetrics {
            execution_time_ns: 12_600_000_000_000, // 3.5 hours in ns
            memory_usage_bytes: 1_073_741_824, // 1GB
            cpu_usage_percent: 85.0,
            ..Default::default()
        },
        ..Default::default()
    },
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h2 id="event-filtering"><a class="header" href="#event-filtering">Event Filtering</a></h2>
<p>Filter events by type for focused analysis:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Subscribe to specific event types
let filters = SubscriptionFilters {
    flow_ids: Some(vec![FlowId::new("production_pipeline")]),
    actor_ids: Some(vec!["data_processor".to_string()]),
    event_types: Some(vec![
        TraceEventType::ActorCreated,
        TraceEventType::ActorFailed,
        TraceEventType::DataFlow { 
            to_actor: "analytics_engine".to_string(),
            to_port: "input".to_string(),
        },
    ]),
    status_filter: Some(vec![ExecutionStatus::Failed]),
};
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-6"><a class="header" href="#best-practices-6">Best Practices</a></h2>
<h3 id="event-granularity"><a class="header" href="#event-granularity">Event Granularity</a></h3>
<ul>
<li><strong>High-Frequency Operations</strong>: Use sampling for message passing in high-throughput scenarios</li>
<li><strong>Critical Operations</strong>: Always trace actor lifecycle events and failures</li>
<li><strong>Debug Information</strong>: Use custom attributes for debugging context</li>
</ul>
<h3 id="performance-considerations-3"><a class="header" href="#performance-considerations-3">Performance Considerations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Efficient event creation
let event = TraceEvent::data_flow(
    source_actor, source_port,
    dest_actor, dest_port,
    message_type, message_size
);

// Batch similar events
if batch.len() &gt;= batch_size {
    tracing.record_batch(batch).await?;
    batch.clear();
}
<span class="boring">}</span></code></pre></pre>
<h3 id="security--privacy"><a class="header" href="#security--privacy">Security &amp; Privacy</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Filter sensitive data
let safe_attributes = attributes.into_iter()
    .filter(|(key, _)| !SENSITIVE_FIELDS.contains(key))
    .collect();

// Hash sensitive identifiers
let user_hash = format!("user_{}", hash(&amp;user_id));
attributes.insert("user_hash", json!(user_hash));
<span class="boring">}</span></code></pre></pre>
<h2 id="query-patterns"><a class="header" href="#query-patterns">Query Patterns</a></h2>
<h3 id="common-queries"><a class="header" href="#common-queries">Common Queries</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Find all failed actors in last hour
let query = TraceQuery {
    time_range: Some((Utc::now() - Duration::hours(1), Utc::now())),
    status: Some(ExecutionStatus::Failed),
    ..Default::default()
};

// Trace data flow for specific message type
let query = TraceQuery {
    actor_filter: Some(".*processor.*".to_string()), // Regex
    event_types: Some(vec![TraceEventType::DataFlow { 
        to_actor: "*".to_string(), 
        to_port: "*".to_string() 
    }]),
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h3 id="performance-analysis-1"><a class="header" href="#performance-analysis-1">Performance Analysis</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Find slowest operations
SELECT actor_id, AVG(execution_time_ns) as avg_time_ns
FROM trace_events 
WHERE event_type = 'ActorCompleted'
  AND timestamp &gt; NOW() - INTERVAL '1 hour'
GROUP BY actor_id
ORDER BY avg_time_ns DESC;
<span class="boring">}</span></code></pre></pre>
<p>This comprehensive event reference provides the foundation for effective observability in Reflow actor networks. Each event type serves specific monitoring and debugging use cases, enabling deep insights into system behavior and performance.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="data-flow-tracing-1"><a class="header" href="#data-flow-tracing-1">Data Flow Tracing</a></h1>
<p>Data Flow Tracing is a core component of Reflow's observability framework, providing automatic and comprehensive tracking of data movement between actors in your network. This feature gives you unprecedented visibility into how information flows through your system.</p>
<h2 id="overview-3"><a class="header" href="#overview-3">Overview</a></h2>
<p>Traditional actor monitoring focuses on individual actor behavior - creation, completion, and failures. Data Flow Tracing extends this by capturing the <strong>connections</strong> between actors, providing insights into:</p>
<ul>
<li><strong>Message Routing</strong>: How messages travel through your actor network</li>
<li><strong>Data Lineage</strong>: Complete paths of data transformation</li>
<li><strong>Performance Bottlenecks</strong>: Where data flow slows down or gets congested</li>
<li><strong>System Dependencies</strong>: Which actors depend on which data sources</li>
</ul>
<h2 id="how-data-flow-tracing-works"><a class="header" href="#how-data-flow-tracing-works">How Data Flow Tracing Works</a></h2>
<h3 id="automatic-capture-1"><a class="header" href="#automatic-capture-1">Automatic Capture</a></h3>
<p>Data Flow Tracing operates at the <strong>connector level</strong>, intercepting messages as they flow between actors:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Automatic tracing in connector implementation
impl Connector {
    pub async fn send_message(&amp;self, message: Message) -&gt; Result&lt;()&gt; {
        // Send the actual message
        self.channel.send(message.clone()).await?;
        
        // Automatically record data flow event
        if let Some(tracing) = global_tracing() {
            tracing.trace_data_flow(
                &amp;self.from_actor, &amp;self.from_port,
                &amp;self.to_actor, &amp;self.to_port,
                message.type_name(), message.size_bytes()
            ).await?;
        }
        
        Ok(())
    }
}
<span class="boring">}</span></code></pre></pre>
<p>This approach provides several advantages:</p>
<ul>
<li><strong>Zero Configuration</strong>: Works immediately with existing actor networks</li>
<li><strong>Complete Coverage</strong>: Captures all message flows without missing any</li>
<li><strong>Accurate Timing</strong>: Records actual transmission times</li>
<li><strong>Minimal Overhead</strong>: Efficient implementation with batching</li>
</ul>
<h3 id="event-structure"><a class="header" href="#event-structure">Event Structure</a></h3>
<p>Data Flow events contain rich metadata about the message transfer:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct DataFlowEvent {
    // Standard event fields
    event_id: EventId,
    timestamp: DateTime&lt;Utc&gt;,
    event_type: TraceEventType::DataFlow {
        to_actor: String,    // Destination actor
        to_port: String,     // Destination port
    },
    actor_id: String,        // Source actor (from_actor)
    
    // Data flow specific information
    data: TraceEventData {
        port: Some("output".to_string()),  // Source port
        message: Some(MessageSnapshot {
            message_type: "SensorReading".to_string(),
            size_bytes: 256,
            checksum: "sha256:abc123...",
            serialized_data: vec![], // Optional data capture
        }),
        performance_metrics: PerformanceMetrics {
            execution_time_ns: 1_500_000,  // 1.5ms transfer time
            queue_depth: 3,                // Destination queue depth
            throughput_msgs_per_sec: 1000.0,
            memory_usage_bytes: 512,       // Memory for message processing
            cpu_usage_percent: 2.5,
        },
        custom_attributes: HashMap::from([
            ("source_actor", json!("sensor_reader")),
            ("source_port", json!("data")),
            ("destination_actor", json!("data_processor")),
            ("destination_port", json!("input")),
            ("message_id", json!("msg_12345")),
            ("protocol", json!("memory_channel")),
            ("compression", json!("none")),
        ]),
        ..Default::default()
    },
}
<span class="boring">}</span></code></pre></pre>
<h2 id="use-cases-1"><a class="header" href="#use-cases-1">Use Cases</a></h2>
<h3 id="1-data-lineage-tracking"><a class="header" href="#1-data-lineage-tracking">1. Data Lineage Tracking</a></h3>
<p>Track how data flows and transforms through your entire pipeline:</p>
<pre><code class="language-mermaid">graph LR
    A[Sensor Reader] --&gt;|SensorReading| B[Data Validator]
    B --&gt;|ValidatedReading| C[Data Transformer]
    C --&gt;|ProcessedData| D[Analytics Engine]
    D --&gt;|Insights| E[Dashboard]
    
    style A fill:#e1f5fe
    style E fill:#f3e5f5
</code></pre>
<p>Query for complete data lineage:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Find all data flow for a specific message
let query = TraceQuery {
    event_types: Some(vec![TraceEventType::DataFlow { 
        to_actor: "*".to_string(), 
        to_port: "*".to_string() 
    }]),
    custom_filter: Some("message_id = 'msg_12345'"),
    ..Default::default()
};

let lineage = tracing_client.query_traces(query).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="2-performance-analysis"><a class="header" href="#2-performance-analysis">2. Performance Analysis</a></h3>
<p>Identify bottlenecks in your data processing pipeline:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Query for slow data transfers
let slow_transfers = TraceQuery {
    event_types: Some(vec![TraceEventType::DataFlow { 
        to_actor: "*".to_string(), 
        to_port: "*".to_string() 
    }]),
    performance_filter: Some("execution_time_ns &gt; 10000000"), // &gt; 10ms
    time_range: Some((Utc::now() - Duration::hours(1), Utc::now())),
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h3 id="3-system-dependency-mapping"><a class="header" href="#3-system-dependency-mapping">3. System Dependency Mapping</a></h3>
<p>Understand which actors depend on which data sources:</p>
<pre><code class="language-sql">-- Find most active data flows
SELECT 
    source_actor,
    destination_actor,
    COUNT(*) as message_count,
    AVG(execution_time_ns) as avg_transfer_time,
    SUM(size_bytes) as total_bytes
FROM data_flow_events 
WHERE timestamp &gt; NOW() - INTERVAL '1 hour'
GROUP BY source_actor, destination_actor
ORDER BY message_count DESC;
</code></pre>
<h3 id="4-real-time-monitoring"><a class="header" href="#4-real-time-monitoring">4. Real-time Monitoring</a></h3>
<p>Monitor data flow in real-time for operational awareness:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Subscribe to data flow events for specific actors
let filters = SubscriptionFilters {
    actor_ids: Some(vec!["critical_processor".to_string()]),
    event_types: Some(vec![TraceEventType::DataFlow { 
        to_actor: "*".to_string(), 
        to_port: "*".to_string() 
    }]),
    ..Default::default()
};

tracing_client.subscribe(filters).await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="configuration-2"><a class="header" href="#configuration-2">Configuration</a></h2>
<h3 id="enabling-data-flow-tracing"><a class="header" href="#enabling-data-flow-tracing">Enabling Data Flow Tracing</a></h3>
<p>Data Flow Tracing is enabled automatically when you enable the observability framework:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let tracing_config = TracingConfig {
    server_url: "ws://localhost:8080".to_string(),
    enabled: true,                    // Enables all tracing including data flow
    batch_size: 50,                  // Batch size for data flow events
    batch_timeout: Duration::from_millis(1000),
    enable_compression: true,         // Recommended for data flow events
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h3 id="selective-tracing"><a class="header" href="#selective-tracing">Selective Tracing</a></h3>
<p>For high-throughput systems, you might want to selectively trace certain data flows:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Custom connector with selective tracing
impl SelectiveConnector {
    pub async fn send_message(&amp;self, message: Message) -&gt; Result&lt;()&gt; {
        self.channel.send(message.clone()).await?;
        
        // Only trace certain message types or conditions
        if should_trace_message(&amp;message) {
            if let Some(tracing) = global_tracing() {
                tracing.trace_data_flow(
                    &amp;self.from_actor, &amp;self.from_port,
                    &amp;self.to_actor, &amp;self.to_port,
                    message.type_name(), message.size_bytes()
                ).await?;
            }
        }
        
        Ok(())
    }
}

fn should_trace_message(message: &amp;Message) -&gt; bool {
    // Trace based on message type, size, or other criteria
    match message.type_name() {
        "CriticalAlert" =&gt; true,        // Always trace alerts
        "DebugInfo" =&gt; false,           // Never trace debug info
        "DataUpdate" if message.size_bytes() &gt; 1024 =&gt; true, // Large updates only
        _ =&gt; rand::random::&lt;f64&gt;() &lt; 0.1, // Sample 10% of other messages
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="sampling-configuration"><a class="header" href="#sampling-configuration">Sampling Configuration</a></h3>
<p>For extremely high-throughput scenarios, implement sampling:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct DataFlowSampler {
    sample_rate: f64,      // 0.0 to 1.0
    always_trace: Vec&lt;String&gt;, // Actor names to always trace
    never_trace: Vec&lt;String&gt;,  // Actor names to never trace
}

impl DataFlowSampler {
    pub fn should_trace(&amp;self, from_actor: &amp;str, to_actor: &amp;str) -&gt; bool {
        if self.never_trace.contains(&amp;from_actor.to_string()) ||
           self.never_trace.contains(&amp;to_actor.to_string()) {
            return false;
        }
        
        if self.always_trace.contains(&amp;from_actor.to_string()) ||
           self.always_trace.contains(&amp;to_actor.to_string()) {
            return true;
        }
        
        rand::random::&lt;f64&gt;() &lt; self.sample_rate
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="advanced-features-2"><a class="header" href="#advanced-features-2">Advanced Features</a></h2>
<h3 id="message-content-capture"><a class="header" href="#message-content-capture">Message Content Capture</a></h3>
<p>For debugging purposes, you can optionally capture message content:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let event = TraceEvent::data_flow_with_content(
    from_actor, from_port,
    to_actor, to_port,
    message_type, size_bytes,
    Some(message.serialize()?) // Optional content capture
);
<span class="boring">}</span></code></pre></pre>
<p>‚ö†Ô∏è <strong>Security Warning</strong>: Be careful when capturing message content in production. Ensure no sensitive data is included.</p>
<h3 id="custom-metadata"><a class="header" href="#custom-metadata">Custom Metadata</a></h3>
<p>Add custom metadata to data flow events:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Enhanced data flow tracing with custom metadata
pub async fn trace_enhanced_data_flow(
    tracing: &amp;TracingIntegration,
    from_actor: &amp;str, from_port: &amp;str,
    to_actor: &amp;str, to_port: &amp;str,
    message: &amp;Message,
    custom_metadata: HashMap&lt;String, serde_json::Value&gt;
) -&gt; Result&lt;()&gt; {
    let mut event = TraceEvent::data_flow(
        from_actor.to_string(), from_port.to_string(),
        to_actor.to_string(), to_port.to_string(),
        message.type_name(), message.size_bytes()
    );
    
    // Add custom metadata
    event.data.custom_attributes.extend(custom_metadata);
    
    // Add message-specific metadata
    event.data.custom_attributes.insert(
        "message_priority".to_string(), 
        json!(message.priority())
    );
    event.data.custom_attributes.insert(
        "message_correlation_id".to_string(), 
        json!(message.correlation_id())
    );
    
    tracing.record_event(event).await
}
<span class="boring">}</span></code></pre></pre>
<h3 id="causality-tracking"><a class="header" href="#causality-tracking">Causality Tracking</a></h3>
<p>Link data flow events to their triggering events:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub async fn trace_causally_linked_data_flow(
    tracing: &amp;TracingIntegration,
    triggering_event_id: EventId,
    from_actor: &amp;str, from_port: &amp;str,
    to_actor: &amp;str, to_port: &amp;str,
    message: &amp;Message
) -&gt; Result&lt;()&gt; {
    let mut event = TraceEvent::data_flow(
        from_actor.to_string(), from_port.to_string(),
        to_actor.to_string(), to_port.to_string(),
        message.type_name(), message.size_bytes()
    );
    
    // Link to triggering event
    event.causality.parent_event_id = Some(triggering_event_id);
    event.causality.dependency_chain.push(triggering_event_id);
    
    tracing.record_event(event).await
}
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-considerations-4"><a class="header" href="#performance-considerations-4">Performance Considerations</a></h2>
<h3 id="overhead-analysis"><a class="header" href="#overhead-analysis">Overhead Analysis</a></h3>
<p>Data Flow Tracing introduces minimal overhead:</p>
<ul>
<li><strong>Memory</strong>: ~200 bytes per event</li>
<li><strong>CPU</strong>: ~0.1ms per event (including serialization)</li>
<li><strong>Network</strong>: Batched transmission reduces network calls</li>
<li><strong>Storage</strong>: ~1KB per event when stored</li>
</ul>
<h3 id="optimization-strategies"><a class="header" href="#optimization-strategies">Optimization Strategies</a></h3>
<ol>
<li><strong>Batching</strong>: Use larger batch sizes for high-throughput scenarios</li>
<li><strong>Compression</strong>: Enable compression for network transmission</li>
<li><strong>Sampling</strong>: Sample events rather than capturing every one</li>
<li><strong>Filtering</strong>: Use selective tracing based on criticality</li>
<li><strong>Async Processing</strong>: All tracing operations are non-blocking</li>
</ol>
<h3 id="monitoring-performance-impact"><a class="header" href="#monitoring-performance-impact">Monitoring Performance Impact</a></h3>
<p>Monitor the tracing system's own performance:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Monitor tracing overhead
let tracing_metrics = global_tracing()
    .unwrap()
    .get_performance_metrics()
    .await?;

println!("Events per second: {}", tracing_metrics.events_per_second);
println!("Average latency: {}ms", tracing_metrics.avg_latency_ms);
println!("Memory usage: {}MB", tracing_metrics.memory_usage_mb);
<span class="boring">}</span></code></pre></pre>
<h2 id="visualization-and-analysis"><a class="header" href="#visualization-and-analysis">Visualization and Analysis</a></h2>
<h3 id="data-flow-diagrams"><a class="header" href="#data-flow-diagrams">Data Flow Diagrams</a></h3>
<p>Generate visual representations of your data flow:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Generate data flow graph for the last hour
let flow_data = tracing_client.query_data_flows(
    TraceQuery {
        time_range: Some((Utc::now() - Duration::hours(1), Utc::now())),
        ..Default::default()
    }
).await?;

let graph = DataFlowGraph::from_events(&amp;flow_data);
graph.render_to_file("data_flow_diagram.svg")?;
<span class="boring">}</span></code></pre></pre>
<h3 id="real-time-dashboard"><a class="header" href="#real-time-dashboard">Real-time Dashboard</a></h3>
<p>Build real-time monitoring dashboards:</p>
<pre><code class="language-javascript">// WebSocket connection for real-time data flow monitoring
const ws = new WebSocket('ws://tracing-server:8080');

ws.onmessage = (event) =&gt; {
    const traceEvent = JSON.parse(event.data);
    if (traceEvent.event_type.DataFlow) {
        updateDataFlowVisualization(traceEvent);
    }
};
</code></pre>
<h2 id="troubleshooting-4"><a class="header" href="#troubleshooting-4">Troubleshooting</a></h2>
<h3 id="common-issues-3"><a class="header" href="#common-issues-3">Common Issues</a></h3>
<p><strong>No Data Flow Events Appearing</strong>:</p>
<ul>
<li>Verify tracing is enabled: <code>enabled: true</code></li>
<li>Check that actors are connected via standard connectors</li>
<li>Ensure global tracing is initialized before network operations</li>
</ul>
<p><strong>Too Many Events</strong>:</p>
<ul>
<li>Implement sampling: reduce <code>sample_rate</code></li>
<li>Use selective tracing for specific actors only</li>
<li>Increase <code>batch_size</code> to reduce network overhead</li>
</ul>
<p><strong>Performance Impact</strong>:</p>
<ul>
<li>Enable compression: <code>enable_compression: true</code></li>
<li>Use PostgreSQL backend for better concurrent performance</li>
<li>Consider async event processing</li>
</ul>
<h3 id="debugging-data-flow-issues"><a class="header" href="#debugging-data-flow-issues">Debugging Data Flow Issues</a></h3>
<p>Use data flow tracing to debug connectivity and performance issues:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Debug missing data flows
let missing_flows = TraceQuery {
    actor_filter: Some("source_actor".to_string()),
    event_types: Some(vec![TraceEventType::MessageSent]),
    time_range: Some((start_time, end_time)),
    ..Default::default()
};

let sent_messages = tracing_client.query_traces(missing_flows).await?;

// Check if corresponding DataFlow events exist
for sent_event in sent_messages {
    let corresponding_flow = find_data_flow_for_message(&amp;sent_event).await?;
    if corresponding_flow.is_none() {
        println!("Missing data flow for message: {:?}", sent_event);
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-7"><a class="header" href="#best-practices-7">Best Practices</a></h2>
<ol>
<li><strong>Start Simple</strong>: Begin with default settings and tune based on your needs</li>
<li><strong>Monitor Overhead</strong>: Keep an eye on the performance impact of tracing</li>
<li><strong>Use Sampling</strong>: For high-throughput systems, sample rather than trace everything</li>
<li><strong>Secure Sensitive Data</strong>: Never trace sensitive message content</li>
<li><strong>Regular Cleanup</strong>: Set up automatic cleanup of old trace data</li>
<li><strong>Correlate Events</strong>: Use causality tracking to link related events</li>
<li><strong>Custom Metadata</strong>: Add domain-specific metadata for better insights</li>
</ol>
<p>Data Flow Tracing provides unprecedented visibility into your actor network's communication patterns. Use it to understand, debug, and optimize your distributed systems with confidence.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="configuration-3"><a class="header" href="#configuration-3">Configuration</a></h1>
<p>Reflow's observability framework provides flexible configuration options to suit different deployment scenarios and performance requirements.</p>
<h2 id="basic-configuration"><a class="header" href="#basic-configuration">Basic Configuration</a></h2>
<h3 id="tracingconfig-structure"><a class="header" href="#tracingconfig-structure">TracingConfig Structure</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::tracing::TracingConfig;
use std::time::Duration;

let config = TracingConfig {
    server_url: "ws://localhost:8080".to_string(),
    batch_size: 50,
    batch_timeout: Duration::from_millis(1000),
    enable_compression: true,
    enabled: true,
    retry_config: RetryConfig {
        max_retries: 3,
        initial_delay: Duration::from_millis(500),
        max_delay: Duration::from_secs(5),
        backoff_multiplier: 2.0,
    },
};
<span class="boring">}</span></code></pre></pre>
<h3 id="configuration-parameters"><a class="header" href="#configuration-parameters">Configuration Parameters</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Parameter</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>server_url</code></td><td>String</td><td><code>"ws://localhost:8080"</code></td><td>WebSocket URL of the tracing server</td></tr>
<tr><td><code>batch_size</code></td><td>usize</td><td><code>50</code></td><td>Number of events to batch before sending</td></tr>
<tr><td><code>batch_timeout</code></td><td>Duration</td><td><code>1000ms</code></td><td>Maximum time to wait before sending incomplete batch</td></tr>
<tr><td><code>enable_compression</code></td><td>bool</td><td><code>true</code></td><td>Enable gzip compression for network transmission</td></tr>
<tr><td><code>enabled</code></td><td>bool</td><td><code>true</code></td><td>Global enable/disable switch for tracing</td></tr>
<tr><td><code>retry_config</code></td><td>RetryConfig</td><td>See below</td><td>Configuration for retry logic</td></tr>
</tbody></table>
</div>
<h3 id="retry-configuration"><a class="header" href="#retry-configuration">Retry Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct RetryConfig {
    pub max_retries: u32,           // Maximum retry attempts
    pub initial_delay: Duration,    // Initial delay before first retry
    pub max_delay: Duration,        // Maximum delay between retries
    pub backoff_multiplier: f64,    // Exponential backoff multiplier
}
<span class="boring">}</span></code></pre></pre>
<h2 id="environment-based-configuration"><a class="header" href="#environment-based-configuration">Environment-Based Configuration</a></h2>
<h3 id="using-environment-variables"><a class="header" href="#using-environment-variables">Using Environment Variables</a></h3>
<pre><code class="language-bash"># Basic tracing configuration
export REFLOW_TRACING_ENABLED=true
export REFLOW_TRACING_SERVER_URL="ws://tracing-server:8080"
export REFLOW_TRACING_BATCH_SIZE=100
export REFLOW_TRACING_BATCH_TIMEOUT_MS=2000

# Compression and retry settings
export REFLOW_TRACING_COMPRESSION=true
export REFLOW_TRACING_MAX_RETRIES=5
export REFLOW_TRACING_INITIAL_DELAY_MS=1000
export REFLOW_TRACING_MAX_DELAY_MS=30000
</code></pre>
<h3 id="configuration-from-environment"><a class="header" href="#configuration-from-environment">Configuration from Environment</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::tracing::TracingConfig;

let config = TracingConfig::from_env().unwrap_or_default();
<span class="boring">}</span></code></pre></pre>
<h2 id="file-based-configuration"><a class="header" href="#file-based-configuration">File-Based Configuration</a></h2>
<h3 id="toml-configuration"><a class="header" href="#toml-configuration">TOML Configuration</a></h3>
<pre><code class="language-toml"># tracing.toml
[tracing]
enabled = true
server_url = "ws://localhost:8080"
batch_size = 50
batch_timeout_ms = 1000
enable_compression = true

[tracing.retry]
max_retries = 3
initial_delay_ms = 500
max_delay_ms = 5000
backoff_multiplier = 2.0

[tracing.filters]
# Optional: Configure event filtering
actor_patterns = ["sensor_*", "processor_*"]
exclude_actors = ["debug_*", "test_*"]
event_types = ["ActorCreated", "DataFlow", "ActorFailed"]
</code></pre>
<h3 id="loading-from-file"><a class="header" href="#loading-from-file">Loading from File</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::tracing::TracingConfig;

let config = TracingConfig::from_file("tracing.toml")?;
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-tuning"><a class="header" href="#performance-tuning">Performance Tuning</a></h2>
<h3 id="high-throughput-scenarios"><a class="header" href="#high-throughput-scenarios">High-Throughput Scenarios</a></h3>
<p>For systems with high message throughput:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = TracingConfig {
    batch_size: 200,                // Larger batches
    batch_timeout: Duration::from_millis(5000), // Longer timeout
    enable_compression: true,       // Reduce network overhead
    retry_config: RetryConfig {
        max_retries: 5,            // More resilient
        initial_delay: Duration::from_millis(100),
        max_delay: Duration::from_secs(30),
        backoff_multiplier: 1.5,   // Gentler backoff
    },
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h3 id="low-latency-requirements"><a class="header" href="#low-latency-requirements">Low-Latency Requirements</a></h3>
<p>For real-time monitoring needs:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = TracingConfig {
    batch_size: 1,                  // Send immediately
    batch_timeout: Duration::from_millis(10), // Very short timeout
    enable_compression: false,      // Reduce CPU overhead
    retry_config: RetryConfig {
        max_retries: 1,            // Fast failure
        initial_delay: Duration::from_millis(50),
        max_delay: Duration::from_millis(500),
        backoff_multiplier: 2.0,
    },
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h3 id="memory-constrained-environments"><a class="header" href="#memory-constrained-environments">Memory-Constrained Environments</a></h3>
<p>For embedded or resource-limited deployments:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = TracingConfig {
    batch_size: 10,                 // Small batches
    batch_timeout: Duration::from_millis(500),
    enable_compression: true,       // Save memory in transit
    retry_config: RetryConfig {
        max_retries: 2,            // Limit retry overhead
        initial_delay: Duration::from_millis(1000),
        max_delay: Duration::from_secs(10),
        backoff_multiplier: 2.0,
    },
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h2 id="event-filtering-1"><a class="header" href="#event-filtering-1">Event Filtering</a></h2>
<h3 id="actor-based-filtering"><a class="header" href="#actor-based-filtering">Actor-Based Filtering</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::tracing::{TracingConfig, EventFilter};

let filter = EventFilter::new()
    .include_actors(&amp;["critical_*", "payment_*"])
    .exclude_actors(&amp;["debug_*", "test_*"])
    .include_event_types(&amp;[
        TraceEventType::ActorCreated,
        TraceEventType::ActorFailed,
        TraceEventType::DataFlow { to_actor: "*".to_string(), to_port: "*".to_string() }
    ]);

let config = TracingConfig::default()
    .with_filter(filter);
<span class="boring">}</span></code></pre></pre>
<h3 id="sampling-configuration-1"><a class="header" href="#sampling-configuration-1">Sampling Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::tracing::SamplingStrategy;

// Sample 10% of all events
let config = TracingConfig::default()
    .with_sampling(SamplingStrategy::Percentage(10.0));

// Sample every 5th event
let config = TracingConfig::default()
    .with_sampling(SamplingStrategy::EveryNth(5));

// Adaptive sampling based on load
let config = TracingConfig::default()
    .with_sampling(SamplingStrategy::Adaptive {
        base_rate: 10.0,
        max_rate: 100.0,
        load_threshold: 0.8,
    });
<span class="boring">}</span></code></pre></pre>
<h2 id="security-configuration"><a class="header" href="#security-configuration">Security Configuration</a></h2>
<h3 id="tlsssl-configuration"><a class="header" href="#tlsssl-configuration">TLS/SSL Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::tracing::{TracingConfig, TlsConfig};

let tls_config = TlsConfig {
    ca_cert_path: Some("ca-cert.pem".to_string()),
    client_cert_path: Some("client-cert.pem".to_string()),
    client_key_path: Some("client-key.pem".to_string()),
    verify_hostname: true,
};

let config = TracingConfig {
    server_url: "wss://secure-tracing-server:8443".to_string(),
    tls_config: Some(tls_config),
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h3 id="authentication-1"><a class="header" href="#authentication-1">Authentication</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::tracing::AuthConfig;

let auth_config = AuthConfig::ApiKey {
    key: "your-api-key".to_string(),
    header: "X-API-Key".to_string(),
};

let config = TracingConfig {
    auth_config: Some(auth_config),
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h2 id="dynamic-configuration"><a class="header" href="#dynamic-configuration">Dynamic Configuration</a></h2>
<h3 id="runtime-configuration-updates"><a class="header" href="#runtime-configuration-updates">Runtime Configuration Updates</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::tracing;

// Get current global configuration
let current_config = tracing::get_global_config();

// Update configuration at runtime
let updated_config = current_config
    .with_batch_size(100)
    .with_compression(false);

tracing::update_global_config(updated_config)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="configuration-monitoring"><a class="header" href="#configuration-monitoring">Configuration Monitoring</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::tracing::ConfigWatcher;

// Watch for configuration file changes
let watcher = ConfigWatcher::new("tracing.toml")?;
watcher.on_change(|new_config| {
    println!("Configuration updated: {:?}", new_config);
    tracing::update_global_config(new_config)
})?;
<span class="boring">}</span></code></pre></pre>
<h2 id="validation-and-testing"><a class="header" href="#validation-and-testing">Validation and Testing</a></h2>
<h3 id="configuration-validation"><a class="header" href="#configuration-validation">Configuration Validation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::tracing::TracingConfig;

let config = TracingConfig::default();

// Validate configuration
if let Err(e) = config.validate() {
    eprintln!("Invalid configuration: {}", e);
    return Err(e);
}

// Test connection
if config.test_connection().await.is_err() {
    eprintln!("Cannot connect to tracing server");
}
<span class="boring">}</span></code></pre></pre>
<h3 id="configuration-examples"><a class="header" href="#configuration-examples">Configuration Examples</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Development configuration
let dev_config = TracingConfig {
    server_url: "ws://localhost:8080".to_string(),
    batch_size: 10,
    batch_timeout: Duration::from_millis(100),
    enable_compression: false,
    enabled: true,
    ..Default::default()
};

// Production configuration
let prod_config = TracingConfig {
    server_url: "wss://tracing.prod.company.com:443".to_string(),
    batch_size: 100,
    batch_timeout: Duration::from_millis(2000),
    enable_compression: true,
    enabled: true,
    tls_config: Some(TlsConfig::default()),
    auth_config: Some(AuthConfig::from_env()?),
    ..Default::default()
};

// Testing configuration (disabled)
let test_config = TracingConfig {
    enabled: false,
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-8"><a class="header" href="#best-practices-8">Best Practices</a></h2>
<ol>
<li>
<p><strong>Start Conservative</strong>: Begin with small batch sizes and short timeouts, then tune based on observed performance.</p>
</li>
<li>
<p><strong>Monitor Overhead</strong>: Track the performance impact of tracing and adjust configuration accordingly.</p>
</li>
<li>
<p><strong>Use Environment Variables</strong>: Make configuration environment-specific without code changes.</p>
</li>
<li>
<p><strong>Enable Compression</strong>: For network-constrained environments, compression typically provides significant benefits.</p>
</li>
<li>
<p><strong>Configure Retries</strong>: Set appropriate retry parameters based on your network reliability.</p>
</li>
<li>
<p><strong>Filter Strategically</strong>: Use event filtering to reduce overhead while maintaining necessary observability.</p>
</li>
<li>
<p><strong>Secure Connections</strong>: Always use TLS in production environments.</p>
</li>
<li>
<p><strong>Test Configuration</strong>: Validate configuration in development and staging environments.</p>
</li>
<li>
<p><strong>Document Settings</strong>: Maintain clear documentation of configuration choices and their rationale.</p>
</li>
<li>
<p><strong>Version Configuration</strong>: Track configuration changes alongside code changes.</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="storage-backends"><a class="header" href="#storage-backends">Storage Backends</a></h1>
<p>Reflow's observability framework supports multiple storage backends to accommodate different operational requirements, from development and testing to large-scale production deployments.</p>
<h2 id="overview-4"><a class="header" href="#overview-4">Overview</a></h2>
<p>The tracing system provides a pluggable storage architecture that allows you to choose the most appropriate backend for your needs:</p>
<ul>
<li><strong>Memory Storage</strong>: Fast, ephemeral storage for development and testing</li>
<li><strong>SQLite Storage</strong>: Lightweight, embedded database for small to medium deployments</li>
<li><strong>PostgreSQL Storage</strong>: Robust, scalable database for production environments</li>
<li><strong>ClickHouse Storage</strong>: High-performance analytical database for massive scale</li>
<li><strong>Custom Storage</strong>: Implement your own storage adapter</li>
</ul>
<h2 id="memory-storage"><a class="header" href="#memory-storage">Memory Storage</a></h2>
<h3 id="when-to-use"><a class="header" href="#when-to-use">When to Use</a></h3>
<ul>
<li>Development and testing environments</li>
<li>Temporary trace analysis</li>
<li>Systems with limited persistence requirements</li>
<li>Quick prototyping and debugging</li>
</ul>
<h3 id="configuration-4"><a class="header" href="#configuration-4">Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_tracing::storage::MemoryStorage;

let storage = MemoryStorage::new();
<span class="boring">}</span></code></pre></pre>
<h3 id="features"><a class="header" href="#features">Features</a></h3>
<ul>
<li><strong>Ultra-fast</strong>: No disk I/O overhead</li>
<li><strong>Zero configuration</strong>: Works out of the box</li>
<li><strong>Bounded capacity</strong>: Configurable memory limits</li>
<li><strong>Automatic cleanup</strong>: LRU eviction when capacity is reached</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_tracing::storage::{MemoryStorage, MemoryConfig};

let config = MemoryConfig {
    max_traces: 10_000,
    max_events_per_trace: 1_000,
    max_memory_mb: 256,
    eviction_policy: EvictionPolicy::LRU,
};

let storage = MemoryStorage::with_config(config);
<span class="boring">}</span></code></pre></pre>
<h3 id="limitations"><a class="header" href="#limitations">Limitations</a></h3>
<ul>
<li><strong>No persistence</strong>: Data lost on restart</li>
<li><strong>Memory bound</strong>: Limited by available RAM</li>
<li><strong>Single process</strong>: No sharing between instances</li>
<li><strong>No complex queries</strong>: Basic filtering only</li>
</ul>
<h2 id="sqlite-storage"><a class="header" href="#sqlite-storage">SQLite Storage</a></h2>
<h3 id="when-to-use-1"><a class="header" href="#when-to-use-1">When to Use</a></h3>
<ul>
<li>Small to medium production deployments</li>
<li>Single-node applications</li>
<li>Applications requiring persistence without database administration</li>
<li>Development environments with persistence needs</li>
</ul>
<h3 id="configuration-5"><a class="header" href="#configuration-5">Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_tracing::storage::SqliteStorage;

let storage = SqliteStorage::new("traces.db").await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="features-1"><a class="header" href="#features-1">Features</a></h3>
<ul>
<li><strong>Persistent</strong>: Data survives restarts</li>
<li><strong>ACID transactions</strong>: Data integrity guarantees</li>
<li><strong>Full SQL support</strong>: Complex queries and analysis</li>
<li><strong>Embedded</strong>: No separate database server required</li>
<li><strong>Backup friendly</strong>: Single file for easy backups</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_tracing::storage::{SqliteStorage, SqliteConfig};

let config = SqliteConfig {
    database_path: "traces.db".to_string(),
    journal_mode: JournalMode::WAL,
    synchronous: SynchronousMode::Normal,
    cache_size_mb: 64,
    busy_timeout_ms: 5000,
    max_connections: 10,
};

let storage = SqliteStorage::with_config(config).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="performance-tuning-1"><a class="header" href="#performance-tuning-1">Performance Tuning</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Optimize for write performance
let fast_config = SqliteConfig {
    journal_mode: JournalMode::WAL,      // Write-Ahead Logging
    synchronous: SynchronousMode::Normal, // Balanced durability/speed
    cache_size_mb: 128,                  // Larger cache
    busy_timeout_ms: 10000,              // Handle contention
    ..Default::default()
};

// Optimize for read performance
let read_config = SqliteConfig {
    cache_size_mb: 256,                  // Very large cache
    temp_store: TempStore::Memory,       // In-memory temp tables
    mmap_size_mb: 512,                   // Memory-mapped I/O
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h3 id="limitations-1"><a class="header" href="#limitations-1">Limitations</a></h3>
<ul>
<li><strong>Single writer</strong>: Write concurrency limited</li>
<li><strong>File size</strong>: Large databases can become unwieldy</li>
<li><strong>Network access</strong>: No remote access without additional tools</li>
</ul>
<h2 id="postgresql-storage"><a class="header" href="#postgresql-storage">PostgreSQL Storage</a></h2>
<h3 id="when-to-use-2"><a class="header" href="#when-to-use-2">When to Use</a></h3>
<ul>
<li>Production environments with multiple instances</li>
<li>High-concurrency applications</li>
<li>Applications requiring advanced SQL features</li>
<li>Distributed systems</li>
<li>Long-term data retention requirements</li>
</ul>
<h3 id="configuration-6"><a class="header" href="#configuration-6">Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_tracing::storage::PostgresStorage;

let storage = PostgresStorage::new("postgresql://user:pass@localhost/traces").await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="features-2"><a class="header" href="#features-2">Features</a></h3>
<ul>
<li><strong>High concurrency</strong>: Excellent multi-client performance</li>
<li><strong>ACID compliance</strong>: Strong consistency guarantees</li>
<li><strong>Advanced SQL</strong>: Window functions, CTEs, advanced analytics</li>
<li><strong>JSON support</strong>: Native support for trace event JSON</li>
<li><strong>Partitioning</strong>: Time-based table partitioning</li>
<li><strong>Replication</strong>: Built-in streaming replication</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_tracing::storage::{PostgresStorage, PostgresConfig};

let config = PostgresConfig {
    connection_url: "postgresql://user:pass@localhost/traces".to_string(),
    max_connections: 20,
    min_connections: 5,
    connection_timeout_ms: 5000,
    idle_timeout_ms: 600000,
    max_lifetime_ms: 1800000,
    schema_name: "tracing".to_string(),
    enable_partitioning: true,
    partition_interval: PartitionInterval::Daily,
};

let storage = PostgresStorage::with_config(config).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="schema-setup"><a class="header" href="#schema-setup">Schema Setup</a></h3>
<pre><code class="language-sql">-- Create dedicated schema
CREATE SCHEMA IF NOT EXISTS tracing;

-- Create partitioned tables
CREATE TABLE tracing.traces (
    trace_id UUID PRIMARY KEY,
    flow_id VARCHAR(255) NOT NULL,
    execution_id UUID NOT NULL,
    start_time TIMESTAMPTZ NOT NULL,
    end_time TIMESTAMPTZ,
    status VARCHAR(50) NOT NULL,
    metadata JSONB,
    created_at TIMESTAMPTZ DEFAULT NOW()
) PARTITION BY RANGE (start_time);

CREATE TABLE tracing.events (
    event_id UUID PRIMARY KEY,
    trace_id UUID NOT NULL REFERENCES tracing.traces(trace_id),
    timestamp TIMESTAMPTZ NOT NULL,
    event_type VARCHAR(100) NOT NULL,
    actor_id VARCHAR(255) NOT NULL,
    data JSONB NOT NULL,
    created_at TIMESTAMPTZ DEFAULT NOW()
) PARTITION BY RANGE (timestamp);

-- Create indexes for performance
CREATE INDEX idx_traces_flow_id ON tracing.traces(flow_id);
CREATE INDEX idx_traces_start_time ON tracing.traces(start_time);
CREATE INDEX idx_events_trace_id ON tracing.events(trace_id);
CREATE INDEX idx_events_timestamp ON tracing.events(timestamp);
CREATE INDEX idx_events_actor_id ON tracing.events(actor_id);
CREATE INDEX idx_events_type ON tracing.events(event_type);

-- GIN index for JSON queries
CREATE INDEX idx_events_data_gin ON tracing.events USING GIN(data);
</code></pre>
<h3 id="partitioning-management"><a class="header" href="#partitioning-management">Partitioning Management</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Automatic partition management
let config = PostgresConfig {
    enable_partitioning: true,
    partition_interval: PartitionInterval::Daily,
    partition_retention_days: 30,
    auto_create_partitions: true,
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h3 id="performance-optimization-2"><a class="header" href="#performance-optimization-2">Performance Optimization</a></h3>
<pre><code class="language-sql">-- Optimize PostgreSQL configuration
ALTER SYSTEM SET shared_buffers = '256MB';
ALTER SYSTEM SET effective_cache_size = '1GB';
ALTER SYSTEM SET maintenance_work_mem = '64MB';
ALTER SYSTEM SET checkpoint_completion_target = 0.9;
ALTER SYSTEM SET wal_buffers = '16MB';
ALTER SYSTEM SET default_statistics_target = 100;
SELECT pg_reload_conf();
</code></pre>
<h2 id="clickhouse-storage"><a class="header" href="#clickhouse-storage">ClickHouse Storage</a></h2>
<h3 id="when-to-use-3"><a class="header" href="#when-to-use-3">When to Use</a></h3>
<ul>
<li>Very high-volume trace data (millions of events per second)</li>
<li>Analytical workloads and reporting</li>
<li>Time-series analysis</li>
<li>Long-term data retention with compression</li>
<li>Real-time dashboards and monitoring</li>
</ul>
<h3 id="configuration-7"><a class="header" href="#configuration-7">Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_tracing::storage::ClickHouseStorage;

let storage = ClickHouseStorage::new("http://localhost:8123").await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="features-3"><a class="header" href="#features-3">Features</a></h3>
<ul>
<li><strong>Columnar storage</strong>: Excellent compression and analytical performance</li>
<li><strong>Distributed architecture</strong>: Horizontal scaling</li>
<li><strong>Real-time ingestion</strong>: Handle massive write loads</li>
<li><strong>Advanced analytics</strong>: Built-in analytical functions</li>
<li><strong>Time-series optimized</strong>: Purpose-built for time-ordered data</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_tracing::storage::{ClickHouseStorage, ClickHouseConfig};

let config = ClickHouseConfig {
    url: "http://clickhouse:8123".to_string(),
    database: "tracing".to_string(),
    cluster: Some("cluster".to_string()),
    username: Some("default".to_string()),
    password: None,
    compression: CompressionMethod::LZ4,
    batch_size: 10000,
    flush_interval_ms: 5000,
    max_memory_usage: 1_000_000_000, // 1GB
    max_execution_time_ms: 300_000,   // 5 minutes
};

let storage = ClickHouseStorage::with_config(config).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="schema-design"><a class="header" href="#schema-design">Schema Design</a></h3>
<pre><code class="language-sql">-- Optimized ClickHouse schema
CREATE TABLE tracing.events_local ON CLUSTER cluster (
    timestamp DateTime64(3),
    trace_id UUID,
    event_id UUID,
    flow_id String,
    execution_id UUID,
    event_type LowCardinality(String),
    actor_id String,
    port String,
    message_type String,
    message_size UInt32,
    execution_time_ns UInt64,
    memory_usage UInt64,
    cpu_usage Float32,
    data String -- JSON as string for flexibility
) ENGINE = ReplicatedMergeTree('/clickhouse/tables/{cluster}/{shard}/events', '{replica}')
PARTITION BY toYYYYMM(timestamp)
ORDER BY (timestamp, trace_id, event_id)
SETTINGS index_granularity = 8192;

-- Distributed table
CREATE TABLE tracing.events ON CLUSTER cluster AS tracing.events_local
ENGINE = Distributed(cluster, tracing, events_local, rand());

-- Materialized views for aggregations
CREATE MATERIALIZED VIEW tracing.event_metrics
ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(timestamp)
ORDER BY (timestamp, actor_id, event_type)
AS SELECT
    toStartOfMinute(timestamp) as timestamp,
    actor_id,
    event_type,
    count() as event_count,
    avg(execution_time_ns) as avg_execution_time,
    max(execution_time_ns) as max_execution_time,
    sum(message_size) as total_bytes
FROM tracing.events_local
GROUP BY timestamp, actor_id, event_type;
</code></pre>
<h3 id="performance-tuning-2"><a class="header" href="#performance-tuning-2">Performance Tuning</a></h3>
<pre><code class="language-xml">&lt;!-- ClickHouse configuration --&gt;
&lt;yandex&gt;
    &lt;profiles&gt;
        &lt;default&gt;
            &lt;max_memory_usage&gt;10000000000&lt;/max_memory_usage&gt;
            &lt;use_uncompressed_cache&gt;1&lt;/use_uncompressed_cache&gt;
            &lt;load_balancing&gt;random&lt;/load_balancing&gt;
        &lt;/default&gt;
    &lt;/profiles&gt;
    
    &lt;users&gt;
        &lt;default&gt;
            &lt;profile&gt;default&lt;/profile&gt;
            &lt;networks incl="networks" replace="replace"&gt;
                &lt;ip&gt;::/0&lt;/ip&gt;
            &lt;/networks&gt;
        &lt;/default&gt;
    &lt;/users&gt;
&lt;/yandex&gt;
</code></pre>
<h2 id="custom-storage-implementation"><a class="header" href="#custom-storage-implementation">Custom Storage Implementation</a></h2>
<h3 id="storage-trait"><a class="header" href="#storage-trait">Storage Trait</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use async_trait::async_trait;
use reflow_tracing::storage::{StorageBackend, StorageError};

#[async_trait]
pub trait StorageBackend: Send + Sync {
    async fn store_trace(&amp;self, trace: FlowTrace) -&gt; Result&lt;(), StorageError&gt;;
    async fn get_trace(&amp;self, trace_id: TraceId) -&gt; Result&lt;Option&lt;FlowTrace&gt;, StorageError&gt;;
    async fn query_traces(&amp;self, query: TraceQuery) -&gt; Result&lt;Vec&lt;FlowTrace&gt;, StorageError&gt;;
    async fn store_event(&amp;self, trace_id: TraceId, event: TraceEvent) -&gt; Result&lt;(), StorageError&gt;;
    async fn get_events(&amp;self, trace_id: TraceId) -&gt; Result&lt;Vec&lt;TraceEvent&gt;, StorageError&gt;;
    async fn health_check(&amp;self) -&gt; Result&lt;(), StorageError&gt;;
}
<span class="boring">}</span></code></pre></pre>
<h3 id="example-redis-storage"><a class="header" href="#example-redis-storage">Example: Redis Storage</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use redis::{Client, Connection};
use reflow_tracing::storage::{StorageBackend, StorageError};

pub struct RedisStorage {
    client: Client,
}

impl RedisStorage {
    pub fn new(url: &amp;str) -&gt; Result&lt;Self, StorageError&gt; {
        let client = Client::open(url)?;
        Ok(Self { client })
    }
}

#[async_trait]
impl StorageBackend for RedisStorage {
    async fn store_trace(&amp;self, trace: FlowTrace) -&gt; Result&lt;(), StorageError&gt; {
        let mut conn = self.client.get_connection()?;
        let key = format!("trace:{}", trace.trace_id);
        let value = serde_json::to_string(&amp;trace)?;
        
        redis::cmd("SET")
            .arg(&amp;key)
            .arg(&amp;value)
            .arg("EX")
            .arg(3600) // 1 hour TTL
            .query(&amp;mut conn)?;
            
        Ok(())
    }
    
    async fn get_trace(&amp;self, trace_id: TraceId) -&gt; Result&lt;Option&lt;FlowTrace&gt;, StorageError&gt; {
        let mut conn = self.client.get_connection()?;
        let key = format!("trace:{}", trace_id);
        
        let value: Option&lt;String&gt; = redis::cmd("GET")
            .arg(&amp;key)
            .query(&amp;mut conn)?;
            
        match value {
            Some(json) =&gt; Ok(Some(serde_json::from_str(&amp;json)?)),
            None =&gt; Ok(None),
        }
    }
    
    // Implement other methods...
}
<span class="boring">}</span></code></pre></pre>
<h2 id="storage-selection-guide"><a class="header" href="#storage-selection-guide">Storage Selection Guide</a></h2>
<h3 id="decision-matrix"><a class="header" href="#decision-matrix">Decision Matrix</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Feature</th><th>Memory</th><th>SQLite</th><th>PostgreSQL</th><th>ClickHouse</th><th>Custom</th></tr></thead><tbody>
<tr><td><strong>Persistence</strong></td><td>‚ùå</td><td>‚úÖ</td><td>‚úÖ</td><td>‚úÖ</td><td>Depends</td></tr>
<tr><td><strong>Concurrency</strong></td><td>Medium</td><td>Low</td><td>High</td><td>Very High</td><td>Depends</td></tr>
<tr><td><strong>Scale</strong></td><td>Small</td><td>Medium</td><td>Large</td><td>Massive</td><td>Depends</td></tr>
<tr><td><strong>Setup Complexity</strong></td><td>None</td><td>Low</td><td>Medium</td><td>High</td><td>Varies</td></tr>
<tr><td><strong>Query Flexibility</strong></td><td>Limited</td><td>High</td><td>Very High</td><td>High</td><td>Depends</td></tr>
<tr><td><strong>Analytics</strong></td><td>Basic</td><td>Good</td><td>Excellent</td><td>Outstanding</td><td>Depends</td></tr>
<tr><td><strong>Operational Overhead</strong></td><td>None</td><td>Low</td><td>Medium</td><td>High</td><td>Varies</td></tr>
</tbody></table>
</div>
<h3 id="recommendations"><a class="header" href="#recommendations">Recommendations</a></h3>
<p><strong>Development/Testing</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Quick start with memory storage
let storage = MemoryStorage::new();
<span class="boring">}</span></code></pre></pre>
<p><strong>Small Production</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// SQLite for simple deployments
let storage = SqliteStorage::new("traces.db").await?;
<span class="boring">}</span></code></pre></pre>
<p><strong>Medium Production</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// PostgreSQL for robust applications
let storage = PostgresStorage::new("postgresql://...").await?;
<span class="boring">}</span></code></pre></pre>
<p><strong>Large Scale/Analytics</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// ClickHouse for high-volume scenarios
let storage = ClickHouseStorage::new("http://clickhouse:8123").await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="migration-between-backends"><a class="header" href="#migration-between-backends">Migration Between Backends</a></h2>
<h3 id="exportimport-tool"><a class="header" href="#exportimport-tool">Export/Import Tool</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_tracing::migration::StorageMigrator;

// Migrate from SQLite to PostgreSQL
let migrator = StorageMigrator::new(
    SqliteStorage::new("traces.db").await?,
    PostgresStorage::new("postgresql://...").await?
);

migrator.migrate_all_traces().await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="backup-and-restore"><a class="header" href="#backup-and-restore">Backup and Restore</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Backup to file
let backup_path = "traces_backup.json";
storage.export_to_file(backup_path).await?;

// Restore from file
storage.import_from_file(backup_path).await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="monitoring-storage-performance"><a class="header" href="#monitoring-storage-performance">Monitoring Storage Performance</a></h2>
<h3 id="metrics-collection"><a class="header" href="#metrics-collection">Metrics Collection</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_tracing::storage::StorageMetrics;

let metrics = storage.get_metrics().await?;
println!("Storage performance:");
println!("  Write latency: {}ms", metrics.avg_write_latency_ms);
println!("  Read latency: {}ms", metrics.avg_read_latency_ms);
println!("  Storage size: {}MB", metrics.storage_size_mb);
println!("  Query performance: {}ms", metrics.avg_query_latency_ms);
<span class="boring">}</span></code></pre></pre>
<h3 id="health-monitoring"><a class="header" href="#health-monitoring">Health Monitoring</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Regular health checks
tokio::spawn(async move {
    loop {
        match storage.health_check().await {
            Ok(_) =&gt; println!("Storage healthy"),
            Err(e) =&gt; eprintln!("Storage unhealthy: {}", e),
        }
        tokio::time::sleep(Duration::from_secs(30)).await;
    }
});
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-9"><a class="header" href="#best-practices-9">Best Practices</a></h2>
<ol>
<li><strong>Choose Appropriate Backend</strong>: Match storage backend to your scale and requirements</li>
<li><strong>Plan for Growth</strong>: Start simple but design for scale</li>
<li><strong>Monitor Performance</strong>: Track storage metrics and query performance</li>
<li><strong>Regular Backups</strong>: Implement automated backup strategies</li>
<li><strong>Partition Large Tables</strong>: Use time-based partitioning for better performance</li>
<li><strong>Index Strategically</strong>: Create indexes for common query patterns</li>
<li><strong>Manage Retention</strong>: Implement data retention policies to control growth</li>
<li><strong>Test Disaster Recovery</strong>: Regularly test backup and restore procedures</li>
<li><strong>Optimize Queries</strong>: Use EXPLAIN to understand and optimize query performance</li>
<li><strong>Monitor Resources</strong>: Keep an eye on disk space, memory, and CPU usage</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="production-deployment"><a class="header" href="#production-deployment">Production Deployment</a></h1>
<p>This guide covers deploying Reflow's observability framework in production environments, including scalability considerations, security best practices, and operational procedures.</p>
<h2 id="architecture-overview-2"><a class="header" href="#architecture-overview-2">Architecture Overview</a></h2>
<h3 id="production-architecture"><a class="header" href="#production-architecture">Production Architecture</a></h3>
<pre><code class="language-mermaid">graph TB
    App1[Reflow App 1] --&gt; LB[Load Balancer]
    App2[Reflow App 2] --&gt; LB
    App3[Reflow App N] --&gt; LB
    
    LB --&gt; TS1[Tracing Server 1]
    LB --&gt; TS2[Tracing Server 2]
    
    TS1 --&gt; DB[(PostgreSQL Primary)]
    TS2 --&gt; DB
    
    DB --&gt; Replica[(PostgreSQL Replica)]
    
    TS1 --&gt; Cache[(Redis Cache)]
    TS2 --&gt; Cache
    
    Grafana[Grafana] --&gt; DB
    Grafana --&gt; Cache
    
    Monitor[Monitoring] --&gt; TS1
    Monitor --&gt; TS2
    Monitor --&gt; DB
</code></pre>
<h3 id="component-responsibilities"><a class="header" href="#component-responsibilities">Component Responsibilities</a></h3>
<ul>
<li><strong>Reflow Applications</strong>: Generate trace events</li>
<li><strong>Load Balancer</strong>: Distribute connections across tracing servers</li>
<li><strong>Tracing Servers</strong>: Receive, process, and store trace data</li>
<li><strong>PostgreSQL</strong>: Primary data storage with replication</li>
<li><strong>Redis</strong>: Caching and real-time data</li>
<li><strong>Grafana</strong>: Visualization and dashboards</li>
<li><strong>Monitoring</strong>: Health checks and alerting</li>
</ul>
<h2 id="infrastructure-requirements"><a class="header" href="#infrastructure-requirements">Infrastructure Requirements</a></h2>
<h3 id="minimum-production-setup"><a class="header" href="#minimum-production-setup">Minimum Production Setup</a></h3>
<p><strong>Tracing Server</strong>:</p>
<ul>
<li>CPU: 2 cores</li>
<li>Memory: 4GB RAM</li>
<li>Storage: 50GB SSD</li>
<li>Network: 1Gbps</li>
</ul>
<p><strong>Database (PostgreSQL)</strong>:</p>
<ul>
<li>CPU: 4 cores</li>
<li>Memory: 8GB RAM</li>
<li>Storage: 200GB SSD (for data) + 100GB (for WAL)</li>
<li>Network: 1Gbps</li>
</ul>
<p><strong>Cache (Redis)</strong>:</p>
<ul>
<li>CPU: 2 cores</li>
<li>Memory: 4GB RAM</li>
<li>Storage: 20GB SSD</li>
<li>Network: 1Gbps</li>
</ul>
<h3 id="high-scale-production-setup"><a class="header" href="#high-scale-production-setup">High-Scale Production Setup</a></h3>
<p><strong>Tracing Server Cluster</strong>:</p>
<ul>
<li>3+ instances</li>
<li>CPU: 8 cores each</li>
<li>Memory: 16GB RAM each</li>
<li>Storage: 100GB SSD each</li>
<li>Network: 10Gbps</li>
</ul>
<p><strong>Database Cluster</strong>:</p>
<ul>
<li>Primary + 2 replicas</li>
<li>CPU: 16 cores each</li>
<li>Memory: 64GB RAM each</li>
<li>Storage: 1TB NVMe SSD each</li>
<li>Network: 10Gbps</li>
</ul>
<p><strong>Cache Cluster</strong>:</p>
<ul>
<li>3 instance Redis cluster</li>
<li>CPU: 4 cores each</li>
<li>Memory: 16GB RAM each</li>
<li>Storage: 50GB SSD each</li>
<li>Network: 10Gbps</li>
</ul>
<h2 id="container-deployment"><a class="header" href="#container-deployment">Container Deployment</a></h2>
<h3 id="docker-compose"><a class="header" href="#docker-compose">Docker Compose</a></h3>
<pre><code class="language-yaml"># docker-compose.prod.yml
version: '3.8'

services:
  tracing-server:
    image: reflow/tracing-server:latest
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G
    environment:
      - RUST_LOG=info
      - TRACING_DATABASE_URL=postgresql://user:pass@postgres:5432/tracing
      - TRACING_REDIS_URL=redis://redis:6379
      - TRACING_BIND_ADDRESS=0.0.0.0:8080
      - TRACING_MAX_CONNECTIONS=1000
    ports:
      - "8080:8080"
    networks:
      - tracing-network
    depends_on:
      - postgres
      - redis
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  postgres:
    image: postgres:15
    environment:
      - POSTGRES_DB=tracing
      - POSTGRES_USER=tracing_user
      - POSTGRES_PASSWORD_FILE=/run/secrets/postgres_password
      - POSTGRES_INITDB_ARGS=--auth-host=scram-sha-256
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    networks:
      - tracing-network
    secrets:
      - postgres_password
    command: postgres -c shared_preload_libraries=pg_stat_statements
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U tracing_user -d tracing"]
      interval: 30s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - tracing-network
    command: redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 5s
      retries: 3

  nginx:
    image: nginx:alpine
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    ports:
      - "80:80"
      - "443:443"
    networks:
      - tracing-network
    depends_on:
      - tracing-server

volumes:
  postgres_data:
  redis_data:

networks:
  tracing-network:
    driver: overlay

secrets:
  postgres_password:
    external: true
</code></pre>
<h3 id="kubernetes-deployment"><a class="header" href="#kubernetes-deployment">Kubernetes Deployment</a></h3>
<pre><code class="language-yaml"># tracing-server-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tracing-server
  labels:
    app: tracing-server
spec:
  replicas: 3
  selector:
    matchLabels:
      app: tracing-server
  template:
    metadata:
      labels:
        app: tracing-server
    spec:
      containers:
      - name: tracing-server
        image: reflow/tracing-server:latest
        ports:
        - containerPort: 8080
        env:
        - name: RUST_LOG
          value: "info"
        - name: TRACING_DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: tracing-secrets
              key: database-url
        - name: TRACING_REDIS_URL
          value: "redis://redis:6379"
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: tracing-server
spec:
  selector:
    app: tracing-server
  ports:
  - protocol: TCP
    port: 8080
    targetPort: 8080
  type: ClusterIP

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: tracing-server-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
spec:
  tls:
  - hosts:
    - tracing.yourdomain.com
    secretName: tracing-tls
  rules:
  - host: tracing.yourdomain.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: tracing-server
            port:
              number: 8080
</code></pre>
<h3 id="postgresql-configuration"><a class="header" href="#postgresql-configuration">PostgreSQL Configuration</a></h3>
<pre><code class="language-yaml"># postgres-deployment.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
spec:
  serviceName: postgres
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:15
        env:
        - name: POSTGRES_DB
          value: tracing
        - name: POSTGRES_USER
          value: tracing_user
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-secrets
              key: password
        ports:
        - containerPort: 5432
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
        - name: postgres-config
          mountPath: /etc/postgresql/postgresql.conf
          subPath: postgresql.conf
        resources:
          requests:
            memory: "4Gi"
            cpu: "2000m"
          limits:
            memory: "8Gi"
            cpu: "4000m"
      volumes:
      - name: postgres-config
        configMap:
          name: postgres-config
  volumeClaimTemplates:
  - metadata:
      name: postgres-storage
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 200Gi
      storageClassName: fast-ssd
</code></pre>
<h2 id="configuration-management-1"><a class="header" href="#configuration-management-1">Configuration Management</a></h2>
<h3 id="environment-specific-configuration"><a class="header" href="#environment-specific-configuration">Environment-Specific Configuration</a></h3>
<pre><code class="language-toml"># config/production.toml
[server]
bind_address = "0.0.0.0:8080"
max_connections = 1000
worker_threads = 8
keep_alive_timeout = 30

[database]
url = "postgresql://user:pass@postgres-cluster:5432/tracing"
max_connections = 20
min_connections = 5
connection_timeout = 5000
statement_timeout = 30000

[redis]
url = "redis://redis-cluster:6379"
pool_size = 10
connection_timeout = 3000

[tracing]
batch_size = 100
batch_timeout_ms = 2000
max_event_size = 1048576  # 1MB
compression = true

[logging]
level = "info"
format = "json"
target = "stdout"

[metrics]
enabled = true
bind_address = "0.0.0.0:9090"
</code></pre>
<h3 id="secret-management"><a class="header" href="#secret-management">Secret Management</a></h3>
<pre><code class="language-bash"># Kubernetes secrets
kubectl create secret generic tracing-secrets \
  --from-literal=database-url="postgresql://user:pass@postgres:5432/tracing" \
  --from-literal=redis-url="redis://redis:6379" \
  --from-literal=jwt-secret="your-jwt-secret"

kubectl create secret generic postgres-secrets \
  --from-literal=password="secure-postgres-password"

# Docker secrets
echo "secure-postgres-password" | docker secret create postgres_password -
</code></pre>
<h2 id="security-configuration-1"><a class="header" href="#security-configuration-1">Security Configuration</a></h2>
<h3 id="tlsssl-setup"><a class="header" href="#tlsssl-setup">TLS/SSL Setup</a></h3>
<pre><code class="language-nginx"># nginx.conf
events {
    worker_connections 1024;
}

http {
    upstream tracing_backend {
        server tracing-server:8080;
        keepalive 32;
    }

    server {
        listen 80;
        return 301 https://$server_name$request_uri;
    }

    server {
        listen 443 ssl http2;
        server_name tracing.yourdomain.com;

        ssl_certificate /etc/ssl/certs/tracing.crt;
        ssl_certificate_key /etc/ssl/private/tracing.key;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512;

        location / {
            proxy_pass http://tracing_backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
    }
}
</code></pre>
<h3 id="authentication-configuration"><a class="header" href="#authentication-configuration">Authentication Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Server configuration with authentication
use reflow_tracing::auth::{AuthConfig, JwtAuth};

let auth_config = AuthConfig {
    jwt_secret: env::var("JWT_SECRET")?,
    token_expiry: Duration::from_hours(24),
    issuer: "reflow-tracing".to_string(),
    audience: "reflow-clients".to_string(),
};

let server_config = ServerConfig {
    auth: Some(auth_config),
    require_auth: true,
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h3 id="network-security-1"><a class="header" href="#network-security-1">Network Security</a></h3>
<pre><code class="language-yaml"># Network policies
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: tracing-network-policy
spec:
  podSelector:
    matchLabels:
      app: tracing-server
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: reflow-client
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: postgres
    ports:
    - protocol: TCP
      port: 5432
  - to:
    - podSelector:
        matchLabels:
          app: redis
    ports:
    - protocol: TCP
      port: 6379
</code></pre>
<h2 id="monitoring-and-observability-1"><a class="header" href="#monitoring-and-observability-1">Monitoring and Observability</a></h2>
<h3 id="prometheus-metrics"><a class="header" href="#prometheus-metrics">Prometheus Metrics</a></h3>
<pre><code class="language-yaml"># prometheus-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
    
    scrape_configs:
    - job_name: 'tracing-server'
      static_configs:
      - targets: ['tracing-server:9090']
      metrics_path: /metrics
      scrape_interval: 10s
    
    - job_name: 'postgres'
      static_configs:
      - targets: ['postgres-exporter:9187']
    
    - job_name: 'redis'
      static_configs:
      - targets: ['redis-exporter:9121']
</code></pre>
<h3 id="health-checks"><a class="header" href="#health-checks">Health Checks</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Health check endpoints
use warp::Filter;

let health = warp::path("health")
    .and(warp::get())
    .map(|| {
        // Check database connectivity
        // Check Redis connectivity
        // Check disk space
        warp::reply::json(&amp;json!({
            "status": "healthy",
            "timestamp": Utc::now(),
            "checks": {
                "database": "ok",
                "redis": "ok",
                "disk_space": "ok"
            }
        }))
    });

let ready = warp::path("ready")
    .and(warp::get())
    .map(|| {
        // Check if server is ready to accept traffic
        warp::reply::json(&amp;json!({
            "status": "ready",
            "timestamp": Utc::now()
        }))
    });
<span class="boring">}</span></code></pre></pre>
<h3 id="alerting-rules"><a class="header" href="#alerting-rules">Alerting Rules</a></h3>
<pre><code class="language-yaml"># alerting-rules.yaml
groups:
- name: tracing-server
  rules:
  - alert: TracingServerDown
    expr: up{job="tracing-server"} == 0
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Tracing server is down"
      description: "Tracing server {{ $labels.instance }} has been down for more than 5 minutes"

  - alert: HighLatency
    expr: tracing_request_duration_seconds{quantile="0.95"} &gt; 0.5
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "High latency detected"
      description: "95th percentile latency is {{ $value }}s"

  - alert: HighErrorRate
    expr: rate(tracing_requests_total{status="error"}[5m]) &gt; 0.1
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "High error rate"
      description: "Error rate is {{ $value }} requests/second"

  - alert: DatabaseConnectionsHigh
    expr: pg_stat_activity_count &gt; 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High number of database connections"
      description: "{{ $value }} active connections to PostgreSQL"
</code></pre>
<h2 id="performance-tuning-3"><a class="header" href="#performance-tuning-3">Performance Tuning</a></h2>
<h3 id="postgresql-optimization"><a class="header" href="#postgresql-optimization">PostgreSQL Optimization</a></h3>
<pre><code class="language-sql">-- postgresql.conf optimizations
shared_buffers = 2GB                    # 25% of RAM
effective_cache_size = 6GB              # 75% of RAM
maintenance_work_mem = 512MB
work_mem = 16MB
max_connections = 200
wal_buffers = 16MB
checkpoint_completion_target = 0.9
random_page_cost = 1.1                  # For SSDs
effective_io_concurrency = 200          # For SSDs

-- Enable query logging for optimization
log_min_duration_statement = 1000       # Log queries &gt; 1s
log_checkpoints = on
log_connections = on
log_disconnections = on
log_lock_waits = on
</code></pre>
<h3 id="redis-optimization"><a class="header" href="#redis-optimization">Redis Optimization</a></h3>
<pre><code class="language-conf"># redis.conf
maxmemory 4gb
maxmemory-policy allkeys-lru
save 900 1
save 300 10
save 60 10000
tcp-keepalive 300
tcp-backlog 511
</code></pre>
<h3 id="application-tuning"><a class="header" href="#application-tuning">Application Tuning</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Server configuration for high performance
let config = ServerConfig {
    worker_threads: num_cpus::get(),
    max_connections: 1000,
    connection_pool_size: 20,
    batch_size: 200,
    batch_timeout: Duration::from_millis(5000),
    compression: true,
    buffer_size: 65536,
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h2 id="backup-and-recovery"><a class="header" href="#backup-and-recovery">Backup and Recovery</a></h2>
<h3 id="database-backup"><a class="header" href="#database-backup">Database Backup</a></h3>
<pre><code class="language-bash">#!/bin/bash
# backup.sh
BACKUP_DIR="/backups"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
DB_NAME="tracing"

# Create backup
pg_dump -h postgres -U tracing_user -d $DB_NAME | gzip &gt; "$BACKUP_DIR/tracing_$TIMESTAMP.sql.gz"

# Upload to S3
aws s3 cp "$BACKUP_DIR/tracing_$TIMESTAMP.sql.gz" s3://your-backup-bucket/database/

# Cleanup old backups (keep 30 days)
find $BACKUP_DIR -name "tracing_*.sql.gz" -mtime +30 -delete
</code></pre>
<h3 id="automated-backup-with-cronjob"><a class="header" href="#automated-backup-with-cronjob">Automated Backup with CronJob</a></h3>
<pre><code class="language-yaml"># backup-cronjob.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: postgres-backup
spec:
  schedule: "0 2 * * *"  # Daily at 2 AM
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: postgres-backup
            image: postgres:15
            env:
            - name: PGPASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgres-secrets
                  key: password
            command:
            - /bin/bash
            - -c
            - |
              pg_dump -h postgres -U tracing_user tracing | gzip &gt; /backup/tracing_$(date +%Y%m%d_%H%M%S).sql.gz
              # Upload to cloud storage
              aws s3 cp /backup/tracing_*.sql.gz s3://backup-bucket/
            volumeMounts:
            - name: backup-storage
              mountPath: /backup
          volumes:
          - name: backup-storage
            persistentVolumeClaim:
              claimName: backup-pvc
          restartPolicy: OnFailure
</code></pre>
<h3 id="disaster-recovery"><a class="header" href="#disaster-recovery">Disaster Recovery</a></h3>
<pre><code class="language-bash">#!/bin/bash
# restore.sh
BACKUP_FILE=$1

if [ -z "$BACKUP_FILE" ]; then
    echo "Usage: $0 &lt;backup_file&gt;"
    exit 1
fi

# Download backup from S3
aws s3 cp "s3://your-backup-bucket/database/$BACKUP_FILE" ./

# Restore database
gunzip -c "$BACKUP_FILE" | psql -h postgres -U tracing_user -d tracing

echo "Database restored from $BACKUP_FILE"
</code></pre>
<h2 id="scaling-strategies"><a class="header" href="#scaling-strategies">Scaling Strategies</a></h2>
<h3 id="horizontal-scaling-1"><a class="header" href="#horizontal-scaling-1">Horizontal Scaling</a></h3>
<pre><code class="language-yaml"># hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: tracing-server-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: tracing-server
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
</code></pre>
<h3 id="database-scaling"><a class="header" href="#database-scaling">Database Scaling</a></h3>
<pre><code class="language-sql">-- Read replicas configuration
-- Primary server
ALTER SYSTEM SET wal_level = replica;
ALTER SYSTEM SET max_wal_senders = 3;
ALTER SYSTEM SET max_replication_slots = 3;
SELECT pg_reload_conf();

-- Create replication slot
SELECT pg_create_physical_replication_slot('replica_1');

-- Replica server setup
standby_mode = 'on'
primary_conninfo = 'host=postgres-primary port=5432 user=replicator'
</code></pre>
<h2 id="maintenance-procedures"><a class="header" href="#maintenance-procedures">Maintenance Procedures</a></h2>
<h3 id="rolling-updates"><a class="header" href="#rolling-updates">Rolling Updates</a></h3>
<pre><code class="language-bash">#!/bin/bash
# rolling-update.sh
kubectl set image deployment/tracing-server tracing-server=reflow/tracing-server:v2.0.0
kubectl rollout status deployment/tracing-server
kubectl rollout history deployment/tracing-server
</code></pre>
<h3 id="database-maintenance"><a class="header" href="#database-maintenance">Database Maintenance</a></h3>
<pre><code class="language-sql">-- Regular maintenance tasks
VACUUM ANALYZE tracing.events;
VACUUM ANALYZE tracing.traces;
REINDEX INDEX CONCURRENTLY idx_events_timestamp;

-- Partition maintenance
SELECT create_monthly_partitions('tracing.events', '2024-01-01'::date);
SELECT drop_old_partitions('tracing.events', interval '90 days');
</code></pre>
<h3 id="log-rotation"><a class="header" href="#log-rotation">Log Rotation</a></h3>
<pre><code class="language-yaml"># fluent-bit-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluent-bit-config
data:
  fluent-bit.conf: |
    [INPUT]
        Name tail
        Path /var/log/containers/*tracing-server*.log
        Parser docker
        Tag tracing.*
    
    [OUTPUT]
        Name es
        Match tracing.*
        Host elasticsearch.logging.svc.cluster.local
        Port 9200
        Index tracing-logs
        Type _doc
</code></pre>
<h2 id="troubleshooting-5"><a class="header" href="#troubleshooting-5">Troubleshooting</a></h2>
<h3 id="common-issues-4"><a class="header" href="#common-issues-4">Common Issues</a></h3>
<p><strong>High Memory Usage</strong>:</p>
<pre><code class="language-bash"># Check memory usage
kubectl top pods
kubectl describe pod tracing-server-xxx

# Adjust memory limits
kubectl patch deployment tracing-server -p '{"spec":{"template":{"spec":{"containers":[{"name":"tracing-server","resources":{"limits":{"memory":"8Gi"}}}]}}}}'
</code></pre>
<p><strong>Database Connection Issues</strong>:</p>
<pre><code class="language-sql">-- Check active connections
SELECT count(*) FROM pg_stat_activity;

-- Kill long-running queries
SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE state = 'active' AND query_start &lt; NOW() - INTERVAL '10 minutes';
</code></pre>
<p><strong>Performance Issues</strong>:</p>
<pre><code class="language-bash"># Check metrics
curl http://tracing-server:9090/metrics | grep -E "latency|throughput|errors"

# Scale up
kubectl scale deployment tracing-server --replicas=10
</code></pre>
<p>This production deployment guide provides a comprehensive foundation for running Reflow's observability framework at scale with proper security, monitoring, and operational procedures.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="creating-actors"><a class="header" href="#creating-actors">Creating Actors</a></h1>
<p>This guide covers how to create custom actors in Reflow using the correct implementation patterns. Learn everything from basic actors to advanced patterns with state management and error handling.</p>
<h2 id="creating-actors-two-approaches"><a class="header" href="#creating-actors-two-approaches">Creating Actors: Two Approaches</a></h2>
<p>Reflow provides two ways to create actors:</p>
<ol>
<li><strong>Actor Macro</strong> (Recommended): Use the <code>#[actor]</code> macro for simple, declarative actor creation</li>
<li><strong>Manual Implementation</strong>: Implement the <code>Actor</code> trait directly for maximum control</li>
</ol>
<h2 id="using-the-actor-macro"><a class="header" href="#using-the-actor-macro">Using the Actor Macro</a></h2>
<p>The <code>#[actor]</code> macro is the recommended way to create actors. It generates all the necessary boilerplate code including the Actor trait implementation, port management, and process creation.</p>
<h3 id="basic-actor"><a class="header" href="#basic-actor">Basic Actor</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::collections::HashMap;
use reflow_network::{
    actor::ActorContext,
    message::Message,
};
use actor_macro::actor;

#[actor(
    HelloActor,
    inports::&lt;100&gt;(input),
    outports::&lt;50&gt;(output)
)]
async fn hello_actor(context: ActorContext) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt; {
    let payload = context.get_payload();
    
    if let Some(Message::String(text)) = payload.get("input") {
        let response = format!("Hello, {}!", text);
        
        Ok([
            ("output".to_owned(), Message::string(response))
        ].into())
    } else {
        Err(anyhow::anyhow!("Expected string input"))
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="actor-with-multiple-inputs"><a class="header" href="#actor-with-multiple-inputs">Actor with Multiple Inputs</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[actor(
    GreeterActor,
    inports::&lt;100&gt;(name, age),
    outports::&lt;50&gt;(greeting),
    await_all_inports  // Wait for both inputs before processing
)]
async fn greeter_actor(context: ActorContext) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt; {
    let payload = context.get_payload();
    
    let name = match payload.get("name").expect("expected name") {
        Message::String(s) =&gt; s,
        _ =&gt; return Err(anyhow::anyhow!("Name must be a string")),
    };
    
    let age = match payload.get("age").expect("expected age") {
        Message::Integer(n) =&gt; *n,
        _ =&gt; return Err(anyhow::anyhow!("Age must be an integer")),
    };
    
    let greeting = format!("Hello {}, you are {} years old!", name, age);
    
    Ok([
        ("greeting".to_owned(), Message::string(greeting))
    ].into())
}
<span class="boring">}</span></code></pre></pre>
<h3 id="stateful-actor"><a class="header" href="#stateful-actor">Stateful Actor</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::actor::MemoryState;

#[actor(
    CounterActor,
    state(MemoryState),
    inports::&lt;100&gt;(increment, reset),
    outports::&lt;50&gt;(count, total)
)]
async fn counter_actor(context: ActorContext) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt; {
    let payload = context.get_payload();
    let state = context.get_state();
    
    let mut state_guard = state.lock();
    let memory_state = state_guard
        .as_mut_any()
        .downcast_mut::&lt;MemoryState&gt;()
        .expect("Expected MemoryState");
    
    // Initialize state if needed
    if !memory_state.contains_key("count") {
        memory_state.insert("count", serde_json::json!(0));
        memory_state.insert("total", serde_json::json!(0));
    }
    
    let current_count = memory_state.get("count")
        .and_then(|v| v.as_i64())
        .unwrap_or(0);
    
    let current_total = memory_state.get("total")
        .and_then(|v| v.as_i64())
        .unwrap_or(0);
    
    let (new_count, new_total) = if payload.contains_key("reset") {
        // Reset counter
        (0, current_total)
    } else if let Some(Message::Integer(amount)) = payload.get("increment") {
        // Increment by specific amount
        let new_count = current_count + amount;
        (new_count, current_total + amount)
    } else {
        // Default increment by 1
        let new_count = current_count + 1;
        (new_count, current_total + 1)
    };
    
    // Update state
    memory_state.insert("count", serde_json::json!(new_count));
    memory_state.insert("total", serde_json::json!(new_total));
    
    println!("Counter: {} (total: {})", new_count, new_total);
    
    Ok([
        ("count".to_owned(), Message::Integer(new_count)),
        ("total".to_owned(), Message::Integer(new_total)),
    ].into())
}
<span class="boring">}</span></code></pre></pre>
<h2 id="actor-macro-parameters"><a class="header" href="#actor-macro-parameters">Actor Macro Parameters</a></h2>
<h3 id="port-definitions"><a class="header" href="#port-definitions">Port Definitions</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Basic ports (unbounded channels)
inports(A, B, C)
outports(X, Y)

// Ports with capacity (bounded channels)
inports::&lt;100&gt;(A, B)      // Input ports with capacity 100
outports::&lt;50&gt;(X, Y)      // Output ports with capacity 50
<span class="boring">}</span></code></pre></pre>
<h3 id="state-management-2"><a class="header" href="#state-management-2">State Management</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Use built-in MemoryState
state(MemoryState)

// Custom state types can also be used
// (must implement ActorState trait)
<span class="boring">}</span></code></pre></pre>
<h3 id="input-synchronization"><a class="header" href="#input-synchronization">Input Synchronization</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Process inputs as they arrive (default)
#[actor(MyActor, inports(A, B), outports(C))]

// Wait for ALL inputs before processing
#[actor(MyActor, inports(A, B), outports(C), await_all_inports)]
<span class="boring">}</span></code></pre></pre>
<h2 id="practical-examples"><a class="header" href="#practical-examples">Practical Examples</a></h2>
<h3 id="data-processing-pipeline"><a class="header" href="#data-processing-pipeline">Data Processing Pipeline</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Sum Actor - adds numbers from multiple sources
#[actor(
    SumActor,
    inports::&lt;100&gt;(numbers),
    outports::&lt;50&gt;(sum, count)
)]
async fn sum_actor(context: ActorContext) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt; {
    let payload = context.get_payload();
    
    if let Some(Message::Array(numbers)) = payload.get("numbers") {
        let mut sum = 0i64;
        let mut count = 0usize;
        
        for num in numbers {
            if let Message::Integer(n) = num {
                sum += n;
                count += 1;
            }
        }
        
        println!("Sum Actor: {} numbers, sum = {}", count, sum);
        
        Ok([
            ("sum".to_owned(), Message::Integer(sum)),
            ("count".to_owned(), Message::Integer(count as i64)),
        ].into())
    } else {
        Err(anyhow::anyhow!("Expected array of numbers"))
    }
}

// Filter Actor - filters values based on condition
#[actor(
    FilterActor,
    inports::&lt;100&gt;(values, threshold),
    outports::&lt;50&gt;(passed, failed),
    await_all_inports
)]
async fn filter_actor(context: ActorContext) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt; {
    let payload = context.get_payload();
    
    let threshold = match payload.get("threshold").expect("expected threshold") {
        Message::Integer(t) =&gt; *t,
        _ =&gt; return Err(anyhow::anyhow!("Threshold must be integer")),
    };
    
    if let Some(Message::Array(values)) = payload.get("values") {
        let mut passed = Vec::new();
        let mut failed = Vec::new();
        
        for value in values {
            if let Message::Integer(n) = value {
                if *n &gt;= threshold {
                    passed.push(value.clone());
                } else {
                    failed.push(value.clone());
                }
            }
        }
        
        println!("Filter Actor: {} passed, {} failed (threshold: {})", 
                passed.len(), failed.len(), threshold);
        
        Ok([
            ("passed".to_owned(), Message::Array(passed)),
            ("failed".to_owned(), Message::Array(failed)),
        ].into())
    } else {
        Err(anyhow::anyhow!("Expected array of values"))
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="http-client-actor"><a class="header" href="#http-client-actor">HTTP Client Actor</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reqwest;

#[actor(
    HttpClientActor,
    inports::&lt;50&gt;(request),
    outports::&lt;25&gt;(response, error)
)]
async fn http_client_actor(context: ActorContext) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt; {
    let payload = context.get_payload();
    
    // Parse request
    let request = match payload.get("request") {
        Some(Message::Object(obj)) =&gt; obj,
        _ =&gt; return Err(anyhow::anyhow!("Expected request object")),
    };
    
    let url = match request.get("url") {
        Some(Message::String(s)) =&gt; s,
        _ =&gt; return Err(anyhow::anyhow!("Missing URL in request")),
    };
    
    let method = request.get("method")
        .and_then(|m| if let Message::String(s) = m { Some(s.as_str()) } else { None })
        .unwrap_or("GET");
    
    // Make HTTP request
    let client = reqwest::Client::new();
    
    let result = match method {
        "GET" =&gt; {
            match client.get(url).send().await {
                Ok(response) =&gt; {
                    let status = response.status().as_u16();
                    let text = response.text().await.unwrap_or_default();
                    
                    let response_obj = [
                        ("status".to_owned(), Message::Integer(status as i64)),
                        ("body".to_owned(), Message::String(text)),
                        ("url".to_owned(), Message::String(url.clone())),
                    ].into();
                    
                    [("response".to_owned(), Message::Object(response_obj))].into()
                },
                Err(e) =&gt; {
                    let error_obj = [
                        ("message".to_owned(), Message::String(e.to_string())),
                        ("url".to_owned(), Message::String(url.clone())),
                    ].into();
                    
                    [("error".to_owned(), Message::Object(error_obj))].into()
                }
            }
        },
        "POST" =&gt; {
            let body = request.get("body")
                .and_then(|b| if let Message::String(s) = b { Some(s) } else { None })
                .unwrap_or("");
            
            match client.post(url).body(body.to_string()).send().await {
                Ok(response) =&gt; {
                    let status = response.status().as_u16();
                    let text = response.text().await.unwrap_or_default();
                    
                    let response_obj = [
                        ("status".to_owned(), Message::Integer(status as i64)),
                        ("body".to_owned(), Message::String(text)),
                        ("url".to_owned(), Message::String(url.clone())),
                    ].into();
                    
                    [("response".to_owned(), Message::Object(response_obj))].into()
                },
                Err(e) =&gt; {
                    let error_obj = [
                        ("message".to_owned(), Message::String(e.to_string())),
                        ("url".to_owned(), Message::String(url.clone())),
                    ].into();
                    
                    [("error".to_owned(), Message::Object(error_obj))].into()
                }
            }
        },
        _ =&gt; {
            let error_obj = [
                ("message".to_owned(), Message::String(format!("Unsupported method: {}", method))),
            ].into();
            
            [("error".to_owned(), Message::Object(error_obj))].into()
        }
    };
    
    Ok(result)
}
<span class="boring">}</span></code></pre></pre>
<h3 id="batch-processing-actor"><a class="header" href="#batch-processing-actor">Batch Processing Actor</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[actor(
    BatchActor,
    state(MemoryState),
    inports::&lt;200&gt;(item, flush),
    outports::&lt;50&gt;(batch, count)
)]
async fn batch_actor(context: ActorContext) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt; {
    let payload = context.get_payload();
    let state = context.get_state();
    
    let mut state_guard = state.lock();
    let memory_state = state_guard
        .as_mut_any()
        .downcast_mut::&lt;MemoryState&gt;()
        .expect("Expected MemoryState");
    
    // Initialize batch storage
    if !memory_state.contains_key("batch") {
        memory_state.insert("batch", serde_json::json!([]));
        memory_state.insert("batch_size", serde_json::json!(10)); // Configurable batch size
    }
    
    let batch_size = memory_state.get("batch_size")
        .and_then(|v| v.as_u64())
        .unwrap_or(10) as usize;
    
    let mut current_batch: Vec&lt;serde_json::Value&gt; = memory_state.get("batch")
        .and_then(|v| v.as_array())
        .cloned()
        .unwrap_or_default();
    
    // Handle flush command
    if payload.contains_key("flush") {
        if !current_batch.is_empty() {
            let batch_messages: Vec&lt;Message&gt; = current_batch
                .into_iter()
                .map(|v| Message::from(v))
                .collect();
            
            // Clear batch
            memory_state.insert("batch", serde_json::json!([]));
            
            let count = batch_messages.len();
            println!("Batch Actor: Flushing {} items", count);
            
            return Ok([
                ("batch".to_owned(), Message::Array(batch_messages)),
                ("count".to_owned(), Message::Integer(count as i64)),
            ].into());
        } else {
            return Ok(HashMap::new()); // No items to flush
        }
    }
    
    // Handle new item
    if let Some(item) = payload.get("item") {
        current_batch.push(serde_json::json!(item));
        
        // Check if batch is full
        if current_batch.len() &gt;= batch_size {
            let batch_messages: Vec&lt;Message&gt; = current_batch
                .iter()
                .map(|v| Message::from(v.clone()))
                .collect();
            
            // Clear batch
            memory_state.insert("batch", serde_json::json!([]));
            
            let count = batch_messages.len();
            println!("Batch Actor: Full batch of {} items", count);
            
            Ok([
                ("batch".to_owned(), Message::Array(batch_messages)),
                ("count".to_owned(), Message::Integer(count as i64)),
            ].into())
        } else {
            // Update batch state
            memory_state.insert("batch", serde_json::json!(current_batch));
            
            // Return empty result (batch not ready yet)
            Ok(HashMap::new())
        }
    } else {
        Err(anyhow::anyhow!("Expected item or flush command"))
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="error-handling-patterns"><a class="header" href="#error-handling-patterns">Error Handling Patterns</a></h2>
<h3 id="graceful-error-handling"><a class="header" href="#graceful-error-handling">Graceful Error Handling</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[actor(
    ValidatorActor,
    inports::&lt;100&gt;(data),
    outports::&lt;50&gt;(valid, invalid, error)
)]
async fn validator_actor(context: ActorContext) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt; {
    let payload = context.get_payload();
    
    match payload.get("data") {
        Some(Message::Integer(n)) if *n &gt; 0 =&gt; {
            println!("Validator: Valid number {}", n);
            Ok([("valid".to_owned(), Message::Integer(*n))].into())
        },
        Some(Message::Integer(n)) =&gt; {
            println!("Validator: Invalid number {} (must be positive)", n);
            Ok([("invalid".to_owned(), Message::Integer(*n))].into())
        },
        Some(other) =&gt; {
            let error_msg = format!("Expected integer, got {:?}", other);
            println!("Validator: {}", error_msg);
            Ok([("error".to_owned(), Message::Error(error_msg))].into())
        },
        None =&gt; {
            Err(anyhow::anyhow!("Missing data field"))
        }
    }
}

// Retry Actor - implements retry logic with exponential backoff
#[actor(
    RetryActor,
    state(MemoryState),
    inports::&lt;50&gt;(task),
    outports::&lt;25&gt;(success, failure)
)]
async fn retry_actor(context: ActorContext) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt; {
    let payload = context.get_payload();
    let state = context.get_state();
    
    let task = payload.get("task")
        .ok_or_else(|| anyhow::anyhow!("Missing task"))?;
    
    let max_retries = 3;
    let base_delay_ms = 100;
    
    for attempt in 1..=max_retries {
        match simulate_task_processing(task).await {
            Ok(result) =&gt; {
                println!("Retry Actor: Task succeeded on attempt {}", attempt);
                return Ok([("success".to_owned(), result)].into());
            },
            Err(e) =&gt; {
                if attempt &lt; max_retries {
                    let delay = base_delay_ms * (2_u64.pow(attempt - 1));
                    println!("Retry Actor: Attempt {} failed, retrying in {}ms: {}", 
                            attempt, delay, e);
                    
                    tokio::time::sleep(tokio::time::Duration::from_millis(delay)).await;
                } else {
                    println!("Retry Actor: All {} attempts failed: {}", max_retries, e);
                    return Ok([
                        ("failure".to_owned(), Message::Error(format!("Failed after {} attempts: {}", max_retries, e)))
                    ].into());
                }
            }
        }
    }
    
    unreachable!()
}

async fn simulate_task_processing(task: &amp;Message) -&gt; Result&lt;Message, anyhow::Error&gt; {
    // Simulate processing that might fail
    use rand::Rng;
    let mut rng = rand::thread_rng();
    
    if rng.gen_bool(0.7) { // 70% success rate
        Ok(Message::String(format!("Processed: {:?}", task)))
    } else {
        Err(anyhow::anyhow!("Simulated task failure"))
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="using-actors-in-networks"><a class="header" href="#using-actors-in-networks">Using Actors in Networks</a></h2>
<h3 id="registration-and-instantiation"><a class="header" href="#registration-and-instantiation">Registration and Instantiation</a></h3>
<pre><pre class="playground"><code class="language-rust">use reflow_network::{Network, NetworkConfig};
use reflow_network::connector::{Connector, ConnectionPoint, InitialPacket};

#[tokio::main]
async fn main() -&gt; Result&lt;(), anyhow::Error&gt; {
    let mut network = Network::new(NetworkConfig::default());
    
    // Register actor types
    network.register_actor("hello_process", HelloActor::new())?;
    network.register_actor("counter_process", CounterActor::new())?;
    network.register_actor("validator_process", ValidatorActor::new())?;
    
    // Create actor instances
    network.add_node("hello1", "hello_process")?;
    network.add_node("counter1", "counter_process")?;
    network.add_node("validator1", "validator_process")?;
    
    // Connect actors
    network.add_connection(Connector {
        from: ConnectionPoint {
            actor: "hello1".to_owned(),
            port: "output".to_owned(),
            ..Default::default()
        },
        to: ConnectionPoint {
            actor: "validator1".to_owned(),
            port: "data".to_owned(),
            ..Default::default()
        },
    });
    
    // Send initial data
    network.add_initial(InitialPacket {
        to: ConnectionPoint {
            actor: "hello1".to_owned(),
            port: "input".to_owned(),
            initial_data: Some(Message::String("World".to_owned())),
        },
    });
    
    // Start the network
    network.start().await?;
    
    // Wait for processing
    tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;
    
    Ok(())
}</code></pre></pre>
<h2 id="testing-actors-1"><a class="header" href="#testing-actors-1">Testing Actors</a></h2>
<h3 id="unit-testing-actor-functions"><a class="header" href="#unit-testing-actor-functions">Unit Testing Actor Functions</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod tests {
    use super::*;
    use reflow_network::actor::{ActorContext, MemoryState, ActorLoad};
    use std::sync::Arc;
    use parking_lot::Mutex;
    
    fn create_test_context(payload: HashMap&lt;String, Message&gt;) -&gt; ActorContext {
        let (tx, _rx) = flume::unbounded();
        let state: Arc&lt;Mutex&lt;dyn reflow_network::actor::ActorState&gt;&gt; = 
            Arc::new(Mutex::new(MemoryState::default()));
        
        ActorContext::new(
            payload,
            (tx, _rx),
            state,
            HashMap::new(),
            Arc::new(Mutex::new(ActorLoad::new(0))),
        )
    }
    
    #[tokio::test]
    async fn test_hello_actor() {
        let payload = HashMap::from([
            ("input".to_string(), Message::String("Test".to_string()))
        ]);
        
        let context = create_test_context(payload);
        let result = hello_actor(context).await.unwrap();
        
        assert_eq!(
            result.get("output"),
            Some(&amp;Message::String("Hello, Test!".to_string()))
        );
    }
    
    #[tokio::test]
    async fn test_counter_actor_increment() {
        let payload = HashMap::from([
            ("increment".to_string(), Message::Integer(5))
        ]);
        
        let context = create_test_context(payload);
        let result = counter_actor(context).await.unwrap();
        
        assert_eq!(result.get("count"), Some(&amp;Message::Integer(5)));
        assert_eq!(result.get("total"), Some(&amp;Message::Integer(5)));
    }
    
    #[tokio::test]
    async fn test_greeter_actor() {
        let payload = HashMap::from([
            ("name".to_string(), Message::String("Alice".to_string())),
            ("age".to_string(), Message::Integer(30)),
        ]);
        
        let context = create_test_context(payload);
        let result = greeter_actor(context).await.unwrap();
        
        assert_eq!(
            result.get("greeting"),
            Some(&amp;Message::String("Hello Alice, you are 30 years old!".to_string()))
        );
    }
    
    #[tokio::test]
    async fn test_validator_actor_valid() {
        let payload = HashMap::from([
            ("data".to_string(), Message::Integer(42))
        ]);
        
        let context = create_test_context(payload);
        let result = validator_actor(context).await.unwrap();
        
        assert_eq!(result.get("valid"), Some(&amp;Message::Integer(42)));
        assert!(!result.contains_key("invalid"));
        assert!(!result.contains_key("error"));
    }
    
    #[tokio::test]
    async fn test_validator_actor_invalid() {
        let payload = HashMap::from([
            ("data".to_string(), Message::Integer(-5))
        ]);
        
        let context = create_test_context(payload);
        let result = validator_actor(context).await.unwrap();
        
        assert_eq!(result.get("invalid"), Some(&amp;Message::Integer(-5)));
        assert!(!result.contains_key("valid"));
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-10"><a class="header" href="#best-practices-10">Best Practices</a></h2>
<h3 id="actor-design-guidelines"><a class="header" href="#actor-design-guidelines">Actor Design Guidelines</a></h3>
<ol>
<li><strong>Single Responsibility</strong>: Each actor should have one clear purpose</li>
<li><strong>Idempotent Processing</strong>: Handle duplicate messages gracefully</li>
<li><strong>Error Propagation</strong>: Use both Result returns and error output ports</li>
<li><strong>State Minimal</strong>: Keep state minimal and well-defined</li>
<li><strong>Port Naming</strong>: Use descriptive port names</li>
</ol>
<h3 id="performance-tips"><a class="header" href="#performance-tips">Performance Tips</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Use appropriate channel capacities
inports::&lt;1000&gt;(high_volume_input)   // High throughput
inports::&lt;10&gt;(low_volume_input)      // Low throughput

// Batch processing for efficiency
#[actor(
    EfficientProcessor,
    inports::&lt;500&gt;(batch),
    outports::&lt;100&gt;(results)
)]
async fn efficient_processor(context: ActorContext) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt; {
    let payload = context.get_payload();
    
    if let Some(Message::Array(items)) = payload.get("batch") {
        // Process items in parallel
        use futures::stream::{self, StreamExt};
        
        let results: Vec&lt;Message&gt; = stream::iter(items.iter())
            .map(|item| async move {
                process_single_item(item).await
            })
            .buffer_unordered(10) // Process 10 items concurrently
            .collect()
            .await;
        
        Ok([("results".to_owned(), Message::Array(results))].into())
    } else {
        Err(anyhow::anyhow!("Expected batch of items"))
    }
}

async fn process_single_item(item: &amp;Message) -&gt; Message {
    // Simulate processing
    tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;
    item.clone()
}
<span class="boring">}</span></code></pre></pre>
<h3 id="memory-management-3"><a class="header" href="#memory-management-3">Memory Management</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Avoid cloning large data when possible
#[actor(
    MemoryEfficientActor,
    inports::&lt;100&gt;(data),
    outports::&lt;50&gt;(processed)
)]
async fn memory_efficient_actor(context: ActorContext) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt; {
    let payload = context.get_payload();
    
    // Process data in-place when possible
    if let Some(Message::Array(items)) = payload.get("data") {
        let count = items.len();
        
        // Instead of cloning all items, just extract what we need
        let summary = Message::Object([
            ("count".to_owned(), Message::Integer(count as i64)),
            ("first_item".to_owned(), items.first().cloned().unwrap_or(Message::None)),
            ("last_item".to_owned(), items.last().cloned().unwrap_or(Message::None)),
        ].into());
        
        Ok([("processed".to_owned(), summary)].into())
    } else {
        Err(anyhow::anyhow!("Expected array data"))
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="manual-actor-implementation"><a class="header" href="#manual-actor-implementation">Manual Actor Implementation</a></h2>
<p>For maximum control or when the macro limitations are insufficient, you can implement the Actor trait manually. This approach gives you complete control over the actor's behavior and lifecycle.</p>
<h3 id="basic-manual-actor"><a class="header" href="#basic-manual-actor">Basic Manual Actor</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::actor::{Actor, ActorBehavior, ActorContext, Port, MemoryState, ActorLoad};
use reflow_network::message::Message;
use std::collections::HashMap;
use std::sync::Arc;
use parking_lot::Mutex;
use std::pin::Pin;
use std::future::Future;

pub struct ManualActor {
    inports: Port,
    outports: Port,
    name: String,
    load: Arc&lt;Mutex&lt;ActorLoad&gt;&gt;,
}

impl ManualActor {
    pub fn new(name: String) -&gt; Self {
        Self {
            inports: flume::unbounded(),
            outports: flume::unbounded(),
            name,
            load: Arc::new(Mutex::new(ActorLoad::new(0))),
        }
    }
}

impl Actor for ManualActor {
    fn get_behavior(&amp;self) -&gt; ActorBehavior {
        let name = self.name.clone();
        
        Box::new(move |context: ActorContext| {
            let name = name.clone();
            
            Box::pin(async move {
                let payload = context.get_payload();
                
                if let Some(Message::String(text)) = payload.get("input") {
                    let response = format!("{}: Processing '{}'", name, text);
                    println!("{}", response);
                    
                    Ok([
                        ("output".to_owned(), Message::String(response))
                    ].into())
                } else {
                    Err(anyhow::anyhow!("Expected string input"))
                }
            })
        })
    }
    
    fn get_inports(&amp;self) -&gt; Port {
        self.inports.clone()
    }
    
    fn get_outports(&amp;self) -&gt; Port {
        self.outports.clone()
    }
    
    fn load_count(&amp;self) -&gt; Arc&lt;Mutex&lt;ActorLoad&gt;&gt; {
        self.load.clone()
    }
    
    fn create_process(&amp;self) -&gt; Pin&lt;Box&lt;dyn Future&lt;Output = ()&gt; + 'static + Send&gt;&gt; {
        let inports = self.get_inports();
        let behavior = self.get_behavior();
        let outports = self.get_outports();
        let state: Arc&lt;Mutex&lt;dyn reflow_network::actor::ActorState&gt;&gt; = 
            Arc::new(Mutex::new(MemoryState::default()));
        let load_count = self.load_count();
        
        Box::pin(async move {
            use futures::stream::StreamExt;
            
            loop {
                if let Some(payload) = inports.1.stream().next().await {
                    // Increment load count
                    {
                        let mut load = load_count.lock();
                        load.inc();
                    }
                    
                    let context = ActorContext::new(
                        payload,
                        outports.clone(),
                        state.clone(),
                        HashMap::new(),
                        load_count.clone(),
                    );
                    
                    match behavior(context).await {
                        Ok(result) =&gt; {
                            if !result.is_empty() {
                                let _ = outports.0.send(result);
                            }
                        },
                        Err(e) =&gt; {
                            eprintln!("Error in actor behavior: {:?}", e);
                        }
                    }
                    
                    // Decrement load count
                    {
                        let mut load = load_count.lock();
                        load.dec();
                    }
                }
            }
        })
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="stateful-manual-actor"><a class="header" href="#stateful-manual-actor">Stateful Manual Actor</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct CustomState {
    pub counter: i64,
    pub last_message: String,
    pub timestamps: Vec&lt;i64&gt;,
}

impl reflow_network::actor::ActorState for CustomState {
    fn as_mut_any(&amp;mut self) -&gt; &amp;mut dyn std::any::Any {
        self
    }
    
    fn as_any(&amp;self) -&gt; &amp;dyn std::any::Any {
        self
    }
}

pub struct StatefulManualActor {
    inports: Port,
    outports: Port,
    initial_state: CustomState,
    load: Arc&lt;Mutex&lt;ActorLoad&gt;&gt;,
}

impl StatefulManualActor {
    pub fn new(initial_state: CustomState) -&gt; Self {
        Self {
            inports: flume::unbounded(),
            outports: flume::unbounded(),
            initial_state,
            load: Arc::new(Mutex::new(ActorLoad::new(0))),
        }
    }
}

impl Actor for StatefulManualActor {
    fn get_behavior(&amp;self) -&gt; ActorBehavior {
        Box::new(|context: ActorContext| {
            Box::pin(async move {
                let payload = context.get_payload();
                let state = context.get_state();
                
                let mut state_guard = state.lock();
                let custom_state = state_guard
                    .as_mut_any()
                    .downcast_mut::&lt;CustomState&gt;()
                    .expect("Expected CustomState");
                
                // Update counter
                custom_state.counter += 1;
                
                // Record timestamp
                let now = chrono::Utc::now().timestamp_millis();
                custom_state.timestamps.push(now);
                
                // Keep only last 10 timestamps
                if custom_state.timestamps.len() &gt; 10 {
                    custom_state.timestamps.remove(0);
                }
                
                // Process message
                if let Some(Message::String(text)) = payload.get("message") {
                    custom_state.last_message = text.clone();
                    
                    let response = format!(
                        "Processed message #{}: '{}' (last 5 timestamps: {:?})",
                        custom_state.counter,
                        text,
                        custom_state.timestamps.iter().rev().take(5).collect::&lt;Vec&lt;_&gt;&gt;()
                    );
                    
                    Ok([
                        ("response".to_owned(), Message::String(response)),
                        ("counter".to_owned(), Message::Integer(custom_state.counter)),
                    ].into())
                } else {
                    Err(anyhow::anyhow!("Expected message field"))
                }
            })
        })
    }
    
    fn get_inports(&amp;self) -&gt; Port {
        self.inports.clone()
    }
    
    fn get_outports(&amp;self) -&gt; Port {
        self.outports.clone()
    }
    
    fn load_count(&amp;self) -&gt; Arc&lt;Mutex&lt;ActorLoad&gt;&gt; {
        self.load.clone()
    }
    
    fn create_process(&amp;self) -&gt; Pin&lt;Box&lt;dyn Future&lt;Output = ()&gt; + 'static + Send&gt;&gt; {
        let inports = self.get_inports();
        let behavior = self.get_behavior();
        let outports = self.get_outports();
        let state: Arc&lt;Mutex&lt;dyn reflow_network::actor::ActorState&gt;&gt; = 
            Arc::new(Mutex::new(self.initial_state.clone()));
        let load_count = self.load_count();
        
        Box::pin(async move {
            use futures::stream::StreamExt;
            
            loop {
                if let Some(payload) = inports.1.stream().next().await {
                    // Increment load count
                    {
                        let mut load = load_count.lock();
                        load.inc();
                    }
                    
                    let context = ActorContext::new(
                        payload,
                        outports.clone(),
                        state.clone(),
                        HashMap::new(),
                        load_count.clone(),
                    );
                    
                    match behavior(context).await {
                        Ok(result) =&gt; {
                            if !result.is_empty() {
                                let _ = outports.0.send(result);
                            }
                        },
                        Err(e) =&gt; {
                            eprintln!("Error in stateful actor behavior: {:?}", e);
                        }
                    }
                    
                    // Decrement load count
                    {
                        let mut load = load_count.lock();
                        load.dec();
                    }
                }
            }
        })
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="multi-input-manual-actor"><a class="header" href="#multi-input-manual-actor">Multi-Input Manual Actor</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct MultiInputActor {
    inports: Port,
    outports: Port,
    await_all_inputs: bool,
    input_ports: Vec&lt;String&gt;,
    load: Arc&lt;Mutex&lt;ActorLoad&gt;&gt;,
}

impl MultiInputActor {
    pub fn new(input_ports: Vec&lt;String&gt;, await_all_inputs: bool) -&gt; Self {
        Self {
            inports: flume::bounded(100),
            outports: flume::bounded(50),
            await_all_inputs,
            input_ports,
            load: Arc::new(Mutex::new(ActorLoad::new(0))),
        }
    }
}

impl Actor for MultiInputActor {
    fn get_behavior(&amp;self) -&gt; ActorBehavior {
        Box::new(|context: ActorContext| {
            Box::pin(async move {
                let payload = context.get_payload();
                
                // Collect all available data
                let mut results = HashMap::new();
                let mut total_value = 0i64;
                let mut value_count = 0;
                
                for (port, message) in &amp;payload {
                    if let Message::Integer(value) = message {
                        total_value += value;
                        value_count += 1;
                        
                        results.insert(
                            format!("processed_{}", port), 
                            Message::Integer(value * 2)
                        );
                    }
                }
                
                if value_count &gt; 0 {
                    results.insert("sum".to_owned(), Message::Integer(total_value));
                    results.insert("average".to_owned(), Message::Integer(total_value / value_count));
                    results.insert("count".to_owned(), Message::Integer(value_count));
                }
                
                println!("MultiInput Actor: processed {} values, sum = {}", value_count, total_value);
                
                Ok(results)
            })
        })
    }
    
    fn get_inports(&amp;self) -&gt; Port {
        self.inports.clone()
    }
    
    fn get_outports(&amp;self) -&gt; Port {
        self.outports.clone()
    }
    
    fn load_count(&amp;self) -&gt; Arc&lt;Mutex&lt;ActorLoad&gt;&gt; {
        self.load.clone()
    }
    
    fn create_process(&amp;self) -&gt; Pin&lt;Box&lt;dyn Future&lt;Output = ()&gt; + 'static + Send&gt;&gt; {
        let inports = self.get_inports();
        let behavior = self.get_behavior();
        let outports = self.get_outports();
        let state: Arc&lt;Mutex&lt;dyn reflow_network::actor::ActorState&gt;&gt; = 
            Arc::new(Mutex::new(MemoryState::default()));
        let load_count = self.load_count();
        let await_all_inputs = self.await_all_inputs;
        let input_ports_count = self.input_ports.len();
        
        Box::pin(async move {
            use futures::stream::StreamExt;
            let mut all_inputs: HashMap&lt;String, Message&gt; = HashMap::new();
            
            loop {
                if let Some(packet) = inports.1.stream().next().await {
                    // Increment load count
                    {
                        let mut load = load_count.lock();
                        load.inc();
                    }
                    
                    if await_all_inputs {
                        // Accumulate inputs until we have all expected ports
                        all_inputs.extend(packet);
                        
                        if all_inputs.len() &gt;= input_ports_count {
                            let context = ActorContext::new(
                                all_inputs.clone(),
                                outports.clone(),
                                state.clone(),
                                HashMap::new(),
                                load_count.clone(),
                            );
                            
                            match behavior(context).await {
                                Ok(result) =&gt; {
                                    if !result.is_empty() {
                                        let _ = outports.0.send(result);
                                    }
                                },
                                Err(e) =&gt; {
                                    eprintln!("Error in multi-input actor behavior: {:?}", e);
                                }
                            }
                            
                            all_inputs.clear();
                        } else {
                            // Continue without decrementing load count
                            {
                                let mut load = load_count.lock();
                                load.dec();
                            }
                            continue;
                        }
                    } else {
                        // Process immediately
                        let context = ActorContext::new(
                            packet,
                            outports.clone(),
                            state.clone(),
                            HashMap::new(),
                            load_count.clone(),
                        );
                        
                        match behavior(context).await {
                            Ok(result) =&gt; {
                                if !result.is_empty() {
                                    let _ = outports.0.send(result);
                                }
                            },
                            Err(e) =&gt; {
                                eprintln!("Error in multi-input actor behavior: {:?}", e);
                            }
                        }
                    }
                    
                    // Decrement load count
                    {
                        let mut load = load_count.lock();
                        load.dec();
                    }
                }
            }
        })
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="when-to-use-manual-implementation"><a class="header" href="#when-to-use-manual-implementation">When to Use Manual Implementation</a></h3>
<p><strong>Use manual implementation when:</strong></p>
<ol>
<li><strong>Complex State Requirements</strong>: You need custom state types or complex state initialization</li>
<li><strong>Custom Port Logic</strong>: You need dynamic port creation or complex routing logic</li>
<li><strong>Advanced Error Handling</strong>: You need sophisticated error recovery or circuit breaker patterns</li>
<li><strong>Performance Optimization</strong>: You need fine-grained control over message processing</li>
<li><strong>Integration Requirements</strong>: You need to integrate with external systems in specific ways</li>
</ol>
<p><strong>Example: Circuit Breaker Actor</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(Debug, Clone)]
enum CircuitState {
    Closed,   // Normal operation
    Open,     // Failing, rejecting requests
    HalfOpen, // Testing if service recovered
}

pub struct CircuitBreakerActor {
    inports: Port,
    outports: Port,
    failure_threshold: u32,
    timeout_ms: u64,
    load: Arc&lt;Mutex&lt;ActorLoad&gt;&gt;,
}

impl CircuitBreakerActor {
    pub fn new(failure_threshold: u32, timeout_ms: u64) -&gt; Self {
        Self {
            inports: flume::unbounded(),
            outports: flume::unbounded(),
            failure_threshold,
            timeout_ms,
            load: Arc::new(Mutex::new(ActorLoad::new(0))),
        }
    }
}

impl Actor for CircuitBreakerActor {
    fn get_behavior(&amp;self) -&gt; ActorBehavior {
        let failure_threshold = self.failure_threshold;
        let timeout_ms = self.timeout_ms;
        
        Box::new(move |context: ActorContext| {
            Box::pin(async move {
                let payload = context.get_payload();
                let state = context.get_state();
                
                let mut state_guard = state.lock();
                let memory_state = state_guard
                    .as_mut_any()
                    .downcast_mut::&lt;MemoryState&gt;()
                    .expect("Expected MemoryState");
                
                // Initialize circuit breaker state
                if !memory_state.contains_key("circuit_state") {
                    memory_state.insert("circuit_state", serde_json::json!("Closed"));
                    memory_state.insert("failure_count", serde_json::json!(0));
                    memory_state.insert("last_failure_time", serde_json::json!(0));
                }
                
                let circuit_state_str = memory_state.get("circuit_state")
                    .and_then(|v| v.as_str())
                    .unwrap_or("Closed");
                
                let failure_count = memory_state.get("failure_count")
                    .and_then(|v| v.as_u64())
                    .unwrap_or(0) as u32;
                
                let last_failure_time = memory_state.get("last_failure_time")
                    .and_then(|v| v.as_i64())
                    .unwrap_or(0);
                
                let circuit_state = match circuit_state_str {
                    "Open" =&gt; CircuitState::Open,
                    "HalfOpen" =&gt; CircuitState::HalfOpen,
                    _ =&gt; CircuitState::Closed,
                };
                
                let now = chrono::Utc::now().timestamp_millis();
                
                match circuit_state {
                    CircuitState::Open =&gt; {
                        // Check if timeout has passed
                        if now - last_failure_time &gt; timeout_ms as i64 {
                            memory_state.insert("circuit_state", serde_json::json!("HalfOpen"));
                            println!("Circuit breaker: Transitioning to HalfOpen");
                        } else {
                            return Ok([
                                ("rejected".to_owned(), 
                                 Message::Error("Circuit breaker is OPEN".to_string()))
                            ].into());
                        }
                    },
                    CircuitState::HalfOpen =&gt; {
                        // Process one request to test
                    },
                    CircuitState::Closed =&gt; {
                        // Normal operation
                    }
                }
                
                // Simulate processing the request
                if let Some(request) = payload.get("request") {
                    // Simulate success/failure (in real implementation, you'd call actual service)
                    let success = payload.get("simulate_success")
                        .and_then(|v| if let Message::Boolean(b) = v { Some(*b) } else { None })
                        .unwrap_or(true);
                    
                    if success {
                        // Success - reset failure count if in HalfOpen
                        if matches!(circuit_state, CircuitState::HalfOpen) {
                            memory_state.insert("circuit_state", serde_json::json!("Closed"));
                            memory_state.insert("failure_count", serde_json::json!(0));
                            println!("Circuit breaker: Transitioning to Closed");
                        }
                        
                        Ok([
                            ("success".to_owned(), Message::String("Request processed".to_string()))
                        ].into())
                    } else {
                        // Failure
                        let new_failure_count = failure_count + 1;
                        memory_state.insert("failure_count", serde_json::json!(new_failure_count));
                        memory_state.insert("last_failure_time", serde_json::json!(now));
                        
                        if new_failure_count &gt;= failure_threshold {
                            memory_state.insert("circuit_state", serde_json::json!("Open"));
                            println!("Circuit breaker: Transitioning to Open");
                        }
                        
                        Ok([
                            ("failure".to_owned(), 
                             Message::Error(format!("Request failed (failures: {})", new_failure_count)))
                        ].into())
                    }
                } else {
                    Err(anyhow::anyhow!("Missing request"))
                }
            })
        })
    }
    
    fn get_inports(&amp;self) -&gt; Port { self.inports.clone() }
    fn get_outports(&amp;self) -&gt; Port { self.outports.clone() }
    fn load_count(&amp;self) -&gt; Arc&lt;Mutex&lt;ActorLoad&gt;&gt; { self.load.clone() }
    
    fn create_process(&amp;self) -&gt; Pin&lt;Box&lt;dyn Future&lt;Output = ()&gt; + 'static + Send&gt;&gt; {
        let inports = self.get_inports();
        let behavior = self.get_behavior();
        let outports = self.get_outports();
        let state: Arc&lt;Mutex&lt;dyn reflow_network::actor::ActorState&gt;&gt; = 
            Arc::new(Mutex::new(MemoryState::default()));
        let load_count = self.load_count();
        
        Box::pin(async move {
            use futures::stream::StreamExt;
            
            loop {
                if let Some(payload) = inports.1.stream().next().await {
                    {
                        let mut load = load_count.lock();
                        load.inc();
                    }
                    
                    let context = ActorContext::new(
                        payload,
                        outports.clone(),
                        state.clone(),
                        HashMap::new(),
                        load_count.clone(),
                    );
                    
                    match behavior(context).await {
                        Ok(result) =&gt; {
                            if !result.is_empty() {
                                let _ = outports.0.send(result);
                            }
                        },
                        Err(e) =&gt; {
                            eprintln!("Error in circuit breaker: {:?}", e);
                        }
                    }
                    
                    {
                        let mut load = load_count.lock();
                        load.dec();
                    }
                }
            }
        })
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="testing-manual-actors"><a class="header" href="#testing-manual-actors">Testing Manual Actors</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod manual_actor_tests {
    use super::*;
    
    #[tokio::test]
    async fn test_manual_actor() {
        let actor = ManualActor::new("TestActor".to_string());
        let behavior = actor.get_behavior();
        
        let payload = HashMap::from([
            ("input".to_string(), Message::String("test".to_string()))
        ]);
        
        let (tx, _rx) = flume::unbounded();
        let state: Arc&lt;Mutex&lt;dyn reflow_network::actor::ActorState&gt;&gt; = 
            Arc::new(Mutex::new(MemoryState::default()));
        
        let context = ActorContext::new(
            payload,
            (tx, _rx),
            state,
            HashMap::new(),
            Arc::new(Mutex::new(ActorLoad::new(0))),
        );
        
        let result = behavior(context).await.unwrap();
        
        assert!(result.contains_key("output"));
        if let Some(Message::String(output)) = result.get("output") {
            assert!(output.contains("TestActor"));
            assert!(output.contains("test"));
        }
    }
    
    #[tokio::test]
    async fn test_stateful_manual_actor() {
        let initial_state = CustomState {
            counter: 0,
            last_message: String::new(),
            timestamps: Vec::new(),
        };
        
        let actor = StatefulManualActor::new(initial_state);
        let behavior = actor.get_behavior();
        
        let payload = HashMap::from([
            ("message".to_string(), Message::String("hello".to_string()))
        ]);
        
        let (tx, _rx) = flume::unbounded();
        let state: Arc&lt;Mutex&lt;dyn reflow_network::actor::ActorState&gt;&gt; = 
            Arc::new(Mutex::new(CustomState::default()));
        
        let context = ActorContext::new(
            payload,
            (tx, _rx),
            state,
            HashMap::new(),
            Arc::new(Mutex::new(ActorLoad::new(0))),
        );
        
        let result = behavior(context).await.unwrap();
        
        assert_eq!(result.get("counter"), Some(&amp;Message::Integer(1)));
        assert!(result.contains_key("response"));
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="choosing-between-macro-and-manual-implementation"><a class="header" href="#choosing-between-macro-and-manual-implementation">Choosing Between Macro and Manual Implementation</a></h2>
<h3 id="use-actor-macro-when"><a class="header" href="#use-actor-macro-when">Use Actor Macro When:</a></h3>
<ul>
<li>Simple, stateless processing</li>
<li>Standard input/output patterns</li>
<li>Rapid prototyping</li>
<li>Most common use cases</li>
</ul>
<h3 id="use-manual-implementation-when"><a class="header" href="#use-manual-implementation-when">Use Manual Implementation When:</a></h3>
<ul>
<li>Complex state management</li>
<li>Custom error handling strategies</li>
<li>Performance-critical applications</li>
<li>Integration with external systems</li>
<li>Advanced patterns (circuit breakers, rate limiting, etc.)</li>
</ul>
<h2 id="next-steps-13"><a class="header" href="#next-steps-13">Next Steps</a></h2>
<ul>
<li><strong>State Management</strong>: <a href="api/actors/../state/advanced-patterns.html">Advanced State Patterns</a></li>
<li><strong>Network Integration</strong>: <a href="api/actors/../network/workflows.html">Building Workflows</a></li>
<li><strong>Performance</strong>: <a href="api/actors/../performance/optimization.html">Actor Optimization</a></li>
<li><strong>Examples</strong>: <a href="api/actors/../../examples/README.html">Real-World Examples</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="actorconfig-system"><a class="header" href="#actorconfig-system">ActorConfig System</a></h1>
<p>The ActorConfig system provides a unified configuration framework for all actors in Reflow, enabling dynamic configuration, runtime parameter adjustment, and consistent actor behavior across different deployment environments.</p>
<h2 id="overview-5"><a class="header" href="#overview-5">Overview</a></h2>
<p>ActorConfig replaces the previous ad-hoc configuration approach with a structured, type-safe system that supports:</p>
<ul>
<li><strong>Type-Safe Configuration</strong>: Strongly typed configuration parameters with validation</li>
<li><strong>Dynamic Updates</strong>: Runtime configuration changes without actor restart</li>
<li><strong>Environment Variables</strong>: Automatic environment variable injection</li>
<li><strong>JSON/YAML Support</strong>: Flexible configuration file formats</li>
<li><strong>Validation &amp; Defaults</strong>: Built-in validation with sensible defaults</li>
<li><strong>Metadata Integration</strong>: Rich metadata for configuration documentation</li>
</ul>
<h2 id="basic-usage-1"><a class="header" href="#basic-usage-1">Basic Usage</a></h2>
<h3 id="simple-actor-configuration"><a class="header" href="#simple-actor-configuration">Simple Actor Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::actor::{Actor, ActorConfig, ActorContext};
use std::collections::HashMap;

#[derive(Debug)]
struct ProcessorActor {
    config: ActorConfig,
}

impl ProcessorActor {
    fn new() -&gt; Self {
        Self {
            config: ActorConfig::default(),
        }
    }
}

impl Actor for ProcessorActor {
    fn create_process(&amp;self, config: ActorConfig) -&gt; Pin&lt;Box&lt;dyn Future&lt;Output = ()&gt; + Send + 'static&gt;&gt; {
        // Extract configuration values
        let batch_size = config.get_number("batch_size").unwrap_or(10.0) as usize;
        let timeout_ms = config.get_number("timeout_ms").unwrap_or(5000.0) as u64;
        let enable_retry = config.get_boolean("enable_retry").unwrap_or(true);
        let processor_name = config.get_string("name").unwrap_or("default_processor".to_string().into());
        
        Box::pin(async move {
            println!("Processor {} starting with batch_size={}, timeout={}ms, retry={}", 
                processor_name, batch_size, timeout_ms, enable_retry);
            
            // Actor implementation using configuration...
        })
    }
    
    // ... other Actor trait methods
}
<span class="boring">}</span></code></pre></pre>
<h3 id="configuration-from-json"><a class="header" href="#configuration-from-json">Configuration from JSON</a></h3>
<pre><code class="language-json">{
  "name": "data_processor",
  "batch_size": 50,
  "timeout_ms": 10000,
  "enable_retry": true,
  "processing_mode": "parallel",
  "max_retries": 3,
  "retry_delay_ms": 1000
}
</code></pre>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Load configuration from JSON
let config_json = r#"
{
  "name": "data_processor",
  "batch_size": 50,
  "timeout_ms": 10000,
  "enable_retry": true,
  "processing_mode": "parallel"
}
"#;

let config = ActorConfig::from_json(config_json)?;
let actor = ProcessorActor::new();

// Use configuration when creating actor process
let process = actor.create_process(config);
tokio::spawn(process);
<span class="boring">}</span></code></pre></pre>
<h2 id="configuration-sources"><a class="header" href="#configuration-sources">Configuration Sources</a></h2>
<h3 id="environment-variables-1"><a class="header" href="#environment-variables-1">Environment Variables</a></h3>
<p>ActorConfig automatically reads from environment variables with configurable prefixes:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Environment variables:
// PROCESSOR_BATCH_SIZE=100
// PROCESSOR_TIMEOUT_MS=15000
// PROCESSOR_ENABLE_RETRY=false

let config = ActorConfig::from_env("PROCESSOR")?;

// Access values
let batch_size = config.get_number("batch_size").unwrap(); // 100.0
let timeout = config.get_number("timeout_ms").unwrap();   // 15000.0
let retry = config.get_boolean("enable_retry").unwrap();  // false
<span class="boring">}</span></code></pre></pre>
<h3 id="configuration-files"><a class="header" href="#configuration-files">Configuration Files</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From YAML file
let config = ActorConfig::from_yaml_file("configs/processor.yaml").await?;

// From JSON file
let config = ActorConfig::from_json_file("configs/processor.json").await?;

// From TOML file
let config = ActorConfig::from_toml_file("configs/processor.toml").await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="combined-sources-with-precedence"><a class="header" href="#combined-sources-with-precedence">Combined Sources with Precedence</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Build configuration with precedence: CLI args &gt; env vars &gt; config file &gt; defaults
let config = ActorConfig::builder()
    .from_file("configs/defaults.yaml").await?
    .from_env("PROCESSOR")?
    .from_args(std::env::args())?
    .build()?;
<span class="boring">}</span></code></pre></pre>
<h2 id="configuration-schema-and-validation"><a class="header" href="#configuration-schema-and-validation">Configuration Schema and Validation</a></h2>
<h3 id="defining-configuration-schema"><a class="header" href="#defining-configuration-schema">Defining Configuration Schema</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::actor::{ActorConfigSchema, ConfigField, ConfigType};
use serde::{Deserialize, Serialize};

#[derive(Debug, Serialize, Deserialize)]
struct ProcessorConfigSchema {
    #[serde(default = "default_batch_size")]
    batch_size: u32,
    
    #[serde(default = "default_timeout")]
    timeout_ms: u64,
    
    #[serde(default)]
    enable_retry: bool,
    
    #[serde(default = "default_name")]
    name: String,
    
    processing_mode: ProcessingMode,
}

#[derive(Debug, Serialize, Deserialize)]
enum ProcessingMode {
    Sequential,
    Parallel,
    Batch,
}

fn default_batch_size() -&gt; u32 { 10 }
fn default_timeout() -&gt; u64 { 5000 }
fn default_name() -&gt; String { "processor".to_string() }

impl ActorConfigSchema for ProcessorConfigSchema {
    fn schema() -&gt; Vec&lt;ConfigField&gt; {
        vec![
            ConfigField {
                name: "batch_size".to_string(),
                config_type: ConfigType::Number,
                required: false,
                default_value: Some(serde_json::Value::Number(10.into())),
                description: Some("Number of items to process in each batch".to_string()),
                validation: Some("Must be between 1 and 1000".to_string()),
            },
            ConfigField {
                name: "timeout_ms".to_string(),
                config_type: ConfigType::Number,
                required: false,
                default_value: Some(serde_json::Value::Number(5000.into())),
                description: Some("Processing timeout in milliseconds".to_string()),
                validation: Some("Must be positive".to_string()),
            },
            ConfigField {
                name: "enable_retry".to_string(),
                config_type: ConfigType::Boolean,
                required: false,
                default_value: Some(serde_json::Value::Bool(false)),
                description: Some("Enable automatic retry on failure".to_string()),
                validation: None,
            },
            ConfigField {
                name: "name".to_string(),
                config_type: ConfigType::String,
                required: false,
                default_value: Some(serde_json::Value::String("processor".to_string())),
                description: Some("Actor instance name".to_string()),
                validation: Some("Must be non-empty alphanumeric".to_string()),
            },
            ConfigField {
                name: "processing_mode".to_string(),
                config_type: ConfigType::String,
                required: true,
                default_value: None,
                description: Some("Processing execution mode".to_string()),
                validation: Some("Must be one of: sequential, parallel, batch".to_string()),
            },
        ]
    }
    
    fn validate(&amp;self) -&gt; Result&lt;(), String&gt; {
        if self.batch_size == 0 || self.batch_size &gt; 1000 {
            return Err("batch_size must be between 1 and 1000".to_string());
        }
        
        if self.timeout_ms == 0 {
            return Err("timeout_ms must be positive".to_string());
        }
        
        if self.name.is_empty() {
            return Err("name cannot be empty".to_string());
        }
        
        Ok(())
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="using-typed-configuration"><a class="header" href="#using-typed-configuration">Using Typed Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl Actor for ProcessorActor {
    fn create_process(&amp;self, config: ActorConfig) -&gt; Pin&lt;Box&lt;dyn Future&lt;Output = ()&gt; + Send + 'static&gt;&gt; {
        // Parse and validate configuration against schema
        let typed_config: ProcessorConfigSchema = config.parse_typed()?;
        
        // Configuration is now type-safe and validated
        let batch_size = typed_config.batch_size;
        let timeout = Duration::from_millis(typed_config.timeout_ms);
        let enable_retry = typed_config.enable_retry;
        let name = typed_config.name;
        let mode = typed_config.processing_mode;
        
        Box::pin(async move {
            match mode {
                ProcessingMode::Sequential =&gt; {
                    // Sequential processing logic
                },
                ProcessingMode::Parallel =&gt; {
                    // Parallel processing logic
                },
                ProcessingMode::Batch =&gt; {
                    // Batch processing logic
                },
            }
        })
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="dynamic-configuration-updates"><a class="header" href="#dynamic-configuration-updates">Dynamic Configuration Updates</a></h2>
<h3 id="runtime-configuration-changes"><a class="header" href="#runtime-configuration-changes">Runtime Configuration Changes</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tokio::sync::watch;

struct DynamicProcessorActor {
    config_receiver: watch::Receiver&lt;ActorConfig&gt;,
}

impl DynamicProcessorActor {
    fn new(config_receiver: watch::Receiver&lt;ActorConfig&gt;) -&gt; Self {
        Self { config_receiver }
    }
}

impl Actor for DynamicProcessorActor {
    fn create_process(&amp;self, initial_config: ActorConfig) -&gt; Pin&lt;Box&lt;dyn Future&lt;Output = ()&gt; + Send + 'static&gt;&gt; {
        let mut config_receiver = self.config_receiver.clone();
        
        Box::pin(async move {
            let mut current_config = initial_config;
            
            loop {
                // Check for configuration updates
                if config_receiver.has_changed().unwrap_or(false) {
                    current_config = config_receiver.borrow().clone();
                    println!("Configuration updated: {:?}", current_config);
                    
                    // Apply new configuration
                    let batch_size = current_config.get_number("batch_size").unwrap_or(10.0) as usize;
                    println!("New batch size: {}", batch_size);
                }
                
                // Process with current configuration
                // ... actor logic ...
                
                tokio::time::sleep(Duration::from_millis(100)).await;
            }
        })
    }
}

// Update configuration at runtime
async fn update_actor_config() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let (config_sender, config_receiver) = watch::channel(ActorConfig::default());
    
    let actor = DynamicProcessorActor::new(config_receiver);
    tokio::spawn(actor.create_process(ActorConfig::default()));
    
    // Update configuration after 5 seconds
    tokio::time::sleep(Duration::from_secs(5)).await;
    
    let new_config = ActorConfig::from_json(r#"
    {
        "batch_size": 100,
        "timeout_ms": 20000,
        "enable_retry": true
    }
    "#)?;
    
    config_sender.send(new_config)?;
    println!("Configuration updated!");
    
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h2 id="configuration-in-networks-and-graphs"><a class="header" href="#configuration-in-networks-and-graphs">Configuration in Networks and Graphs</a></h2>
<h3 id="network-level-configuration"><a class="header" href="#network-level-configuration">Network-Level Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::network::{Network, NetworkConfig};

// Configure network with global defaults
let network_config = NetworkConfig {
    default_actor_config: Some(ActorConfig::from_json(r#"
    {
        "default_timeout_ms": 10000,
        "enable_monitoring": true,
        "log_level": "info"
    }
    "#)?),
    // ... other network config
};

let mut network = Network::new(network_config);

// Add actor with specific configuration
let actor_config = ActorConfig::from_json(r#"
{
    "batch_size": 50,
    "timeout_ms": 15000,
    "name": "data_processor_1"
}
"#)?;

network.add_node_with_config("processor1", "DataProcessorActor", Some(actor_config))?;
<span class="boring">}</span></code></pre></pre>
<h3 id="graph-level-configuration"><a class="header" href="#graph-level-configuration">Graph-Level Configuration</a></h3>
<pre><code class="language-json">{
  "caseSensitive": false,
  "properties": {
    "name": "data_processing_pipeline"
  },
  "processes": {
    "collector": {
      "component": "DataCollectorActor",
      "metadata": {
        "config": {
          "source_url": "https://api.example.com/data",
          "poll_interval_ms": 5000,
          "batch_size": 100
        }
      }
    },
    "processor": {
      "component": "DataProcessorActor",
      "metadata": {
        "config": {
          "processing_mode": "parallel",
          "worker_count": 4,
          "timeout_ms": 30000
        }
      }
    },
    "validator": {
      "component": "DataValidatorActor",
      "metadata": {
        "config": {
          "strict_validation": true,
          "schema_file": "./schemas/data.json"
        }
      }
    }
  },
  "connections": [
    {
      "from": { "nodeId": "collector", "portId": "Output" },
      "to": { "nodeId": "processor", "portId": "Input" }
    },
    {
      "from": { "nodeId": "processor", "portId": "Output" },
      "to": { "nodeId": "validator", "portId": "Input" }
    }
  ]
}
</code></pre>
<h3 id="loading-graph-with-configurations"><a class="header" href="#loading-graph-with-configurations">Loading Graph with Configurations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::Graph;

// Load graph - configurations are automatically extracted from metadata
let graph = Graph::load_from_file("data_pipeline.graph.json").await?;

// Each actor will receive its specific configuration
// Network automatically extracts config from process metadata
let mut network = Network::new(NetworkConfig::default());
network.load_graph(graph).await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="environment-specific-configurations"><a class="header" href="#environment-specific-configurations">Environment-Specific Configurations</a></h2>
<h3 id="development-vs-production"><a class="header" href="#development-vs-production">Development vs Production</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Development configuration
let dev_config = ActorConfig::from_json(r#"
{
    "log_level": "debug",
    "enable_profiling": true,
    "timeout_ms": 60000,
    "batch_size": 5
}
"#)?;

// Production configuration
let prod_config = ActorConfig::from_json(r#"
{
    "log_level": "warn",
    "enable_profiling": false,
    "timeout_ms": 10000,
    "batch_size": 100
}
"#)?;

// Select configuration based on environment
let config = match std::env::var("ENVIRONMENT").as_deref() {
    Ok("production") =&gt; prod_config,
    Ok("staging") =&gt; prod_config, // Use prod config for staging
    _ =&gt; dev_config, // Default to dev config
};
<span class="boring">}</span></code></pre></pre>
<h3 id="configuration-profiles"><a class="header" href="#configuration-profiles">Configuration Profiles</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Base configuration
let base_config = ActorConfig::from_yaml_file("configs/base.yaml").await?;

// Environment-specific overrides
let env = std::env::var("ENVIRONMENT").unwrap_or_else(|_| "development".to_string());
let env_config_path = format!("configs/{}.yaml", env);

let final_config = if std::path::Path::new(&amp;env_config_path).exists() {
    base_config.merge_with(ActorConfig::from_yaml_file(&amp;env_config_path).await?)?
} else {
    base_config
};
<span class="boring">}</span></code></pre></pre>
<h2 id="configuration-migration"><a class="header" href="#configuration-migration">Configuration Migration</a></h2>
<h3 id="migrating-from-direct-hashmap"><a class="header" href="#migrating-from-direct-hashmap">Migrating from Direct HashMap</a></h3>
<p><strong>Before (Old Pattern):</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Old approach - direct HashMap usage
impl Actor for OldActor {
    fn set_config(&amp;mut self, config: HashMap&lt;String, serde_json::Value&gt;) {
        self.batch_size = config.get("batch_size")
            .and_then(|v| v.as_f64())
            .unwrap_or(10.0) as usize;
        
        self.timeout = Duration::from_millis(
            config.get("timeout_ms")
                .and_then(|v| v.as_f64())
                .unwrap_or(5000.0) as u64
        );
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>After (New Pattern):</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// New approach - ActorConfig
impl Actor for NewActor {
    fn create_process(&amp;self, config: ActorConfig) -&gt; Pin&lt;Box&lt;dyn Future&lt;Output = ()&gt; + Send + 'static&gt;&gt; {
        let batch_size = config.get_number("batch_size").unwrap_or(10.0) as usize;
        let timeout = Duration::from_millis(config.get_number("timeout_ms").unwrap_or(5000.0) as u64);
        
        Box::pin(async move {
            // Actor implementation with configuration
        })
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="migration-helper"><a class="header" href="#migration-helper">Migration Helper</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Helper function to migrate from old HashMap format
impl ActorConfig {
    pub fn from_legacy_hashmap(legacy: HashMap&lt;String, serde_json::Value&gt;) -&gt; Self {
        let mut config = ActorConfig::default();
        
        for (key, value) in legacy {
            config.set(&amp;key, value);
        }
        
        config
    }
}

// Usage in migration
let legacy_config = HashMap::from([
    ("batch_size".to_string(), serde_json::Value::Number(50.into())),
    ("timeout_ms".to_string(), serde_json::Value::Number(10000.into())),
]);

let actor_config = ActorConfig::from_legacy_hashmap(legacy_config);
<span class="boring">}</span></code></pre></pre>
<h2 id="advanced-features-3"><a class="header" href="#advanced-features-3">Advanced Features</a></h2>
<h3 id="conditional-configuration"><a class="header" href="#conditional-configuration">Conditional Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(Debug, Serialize, Deserialize)]
struct ConditionalConfig {
    #[serde(default)]
    enable_cache: bool,
    
    #[serde(skip_serializing_if = "Option::is_none")]
    cache_size_mb: Option&lt;u32&gt;,
    
    #[serde(skip_serializing_if = "Option::is_none")]
    cache_ttl_seconds: Option&lt;u64&gt;,
}

impl ActorConfigSchema for ConditionalConfig {
    fn validate(&amp;self) -&gt; Result&lt;(), String&gt; {
        if self.enable_cache {
            if self.cache_size_mb.is_none() {
                return Err("cache_size_mb is required when cache is enabled".to_string());
            }
            if self.cache_ttl_seconds.is_none() {
                return Err("cache_ttl_seconds is required when cache is enabled".to_string());
            }
        }
        Ok(())
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="configuration-inheritance"><a class="header" href="#configuration-inheritance">Configuration Inheritance</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Base actor configuration
let base_config = ActorConfig::from_json(r#"
{
    "timeout_ms": 10000,
    "enable_logging": true,
    "log_level": "info"
}
"#)?;

// Specialized configuration inheriting from base
let specialized_config = base_config.extend_with(ActorConfig::from_json(r#"
{
    "batch_size": 50,
    "processing_mode": "parallel",
    "timeout_ms": 20000
}
"#)?)?;

// Result combines both configs with specialized values taking precedence
// timeout_ms: 20000 (overridden)
// enable_logging: true (inherited)
// log_level: "info" (inherited)  
// batch_size: 50 (added)
// processing_mode: "parallel" (added)
<span class="boring">}</span></code></pre></pre>
<h3 id="secret-management-1"><a class="header" href="#secret-management-1">Secret Management</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::actor::SecretResolver;

// Configuration with secret references
let config_with_secrets = ActorConfig::from_json(r#"
{
    "database_url": "${secret:DATABASE_URL}",
    "api_key": "${secret:API_KEY}",
    "batch_size": 100
}
"#)?;

// Resolve secrets from environment or secret store
let secret_resolver = SecretResolver::new()
    .with_env_prefix("SECRET_")
    .with_vault_client(vault_client);

let resolved_config = secret_resolver.resolve(config_with_secrets).await?;

// Secrets are now resolved:
// database_url: "postgresql://user:password@localhost/db"  
// api_key: "sk-1234567890abcdef"
// batch_size: 100
<span class="boring">}</span></code></pre></pre>
<h2 id="testing-with-actorconfig"><a class="header" href="#testing-with-actorconfig">Testing with ActorConfig</a></h2>
<h3 id="test-configuration-helpers"><a class="header" href="#test-configuration-helpers">Test Configuration Helpers</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::actor::testing::TestActorConfig;

#[tokio::test]
async fn test_actor_with_config() {
    let test_config = TestActorConfig::builder()
        .with_number("batch_size", 10.0)
        .with_boolean("enable_retry", false)
        .with_string("name", "test_actor")
        .build();
    
    let actor = MyActor::new();
    let process = actor.create_process(test_config.into());
    
    // Test actor behavior with specific configuration
    // ...
}

#[tokio::test]
async fn test_actor_configuration_validation() {
    let invalid_config = ActorConfig::from_json(r#"
    {
        "batch_size": -1,
        "timeout_ms": 0
    }
    "#).unwrap();
    
    let schema = MyActorConfigSchema::default();
    assert!(schema.validate_config(&amp;invalid_config).is_err());
}
<span class="boring">}</span></code></pre></pre>
<h3 id="configuration-mocking"><a class="header" href="#configuration-mocking">Configuration Mocking</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Mock configuration for testing
struct MockConfigProvider {
    configs: HashMap&lt;String, ActorConfig&gt;,
}

impl MockConfigProvider {
    fn new() -&gt; Self {
        Self {
            configs: HashMap::new(),
        }
    }
    
    fn add_config(&amp;mut self, actor_id: &amp;str, config: ActorConfig) {
        self.configs.insert(actor_id.to_string(), config);
    }
}

impl ConfigProvider for MockConfigProvider {
    async fn get_config(&amp;self, actor_id: &amp;str) -&gt; Result&lt;ActorConfig, ConfigError&gt; {
        self.configs.get(actor_id)
            .cloned()
            .ok_or_else(|| ConfigError::NotFound(actor_id.to_string()))
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-11"><a class="header" href="#best-practices-11">Best Practices</a></h2>
<h3 id="configuration-organization"><a class="header" href="#configuration-organization">Configuration Organization</a></h3>
<ol>
<li><strong>Use Typed Schemas</strong>: Define strongly typed configuration schemas for validation</li>
<li><strong>Provide Sensible Defaults</strong>: Always provide reasonable default values</li>
<li><strong>Document Configuration</strong>: Include descriptions and validation rules</li>
<li><strong>Environment Separation</strong>: Use different configurations for different environments</li>
<li><strong>Secret Security</strong>: Never store secrets in plain text configuration files</li>
</ol>
<h3 id="performance-considerations-5"><a class="header" href="#performance-considerations-5">Performance Considerations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Cache parsed configuration for performance
use std::sync::Arc;
use once_cell::sync::OnceCell;

struct CachedConfigActor {
    cached_config: OnceCell&lt;Arc&lt;ProcessorConfigSchema&gt;&gt;,
}

impl Actor for CachedConfigActor {
    fn create_process(&amp;self, config: ActorConfig) -&gt; Pin&lt;Box&lt;dyn Future&lt;Output = ()&gt; + Send + 'static&gt;&gt; {
        // Parse configuration once and cache it
        let parsed_config = self.cached_config.get_or_init(|| {
            Arc::new(config.parse_typed().expect("Invalid configuration"))
        }).clone();
        
        Box::pin(async move {
            // Use cached configuration
            let batch_size = parsed_config.batch_size;
            // ...
        })
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="error-handling-9"><a class="header" href="#error-handling-9">Error Handling</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::actor::ConfigError;

impl Actor for RobustActor {
    fn create_process(&amp;self, config: ActorConfig) -&gt; Pin&lt;Box&lt;dyn Future&lt;Output = ()&gt; + Send + 'static&gt;&gt; {
        Box::pin(async move {
            // Graceful configuration error handling
            let batch_size = match config.get_number("batch_size") {
                Some(size) if size &gt; 0.0 =&gt; size as usize,
                Some(_) =&gt; {
                    eprintln!("Invalid batch_size, using default");
                    10
                },
                None =&gt; {
                    println!("No batch_size specified, using default");
                    10
                }
            };
            
            // Continue with actor logic
        })
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="next-steps-14"><a class="header" href="#next-steps-14">Next Steps</a></h2>
<ul>
<li><a href="api/actors/creating-actors.html">Actor Creation Guide</a> - Learn how to create actors that use ActorConfig</li>
<li><a href="api/actors/../../architecture/multi-graph-composition.html">Multi-Graph Composition</a> - Using ActorConfig in multi-graph setups</li>
<li><a href="api/actors/../../migration/actor-config-migration.html">ActorConfig Migration Guide</a> - Migrating existing actors</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="creating-and-managing-graphs"><a class="header" href="#creating-and-managing-graphs">Creating and Managing Graphs</a></h1>
<p>This guide covers the core APIs for creating, modifying, and managing Reflow graphs.</p>
<h2 id="graph-creation"><a class="header" href="#graph-creation">Graph Creation</a></h2>
<h3 id="basic-graph-creation"><a class="header" href="#basic-graph-creation">Basic Graph Creation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{Graph, PortType};
use std::collections::HashMap;
use serde_json::json;

// Create a new graph
let mut graph = Graph::new("MyWorkflow", false, None);

// Create with case sensitivity enabled
let mut case_sensitive_graph = Graph::new("CaseSensitive", true, None);

// Create with initial properties
let properties = HashMap::from([
    ("description".to_string(), json!("Data processing workflow")),
    ("version".to_string(), json!("1.0.0")),
    ("author".to_string(), json!("John Doe"))
]);
let mut graph_with_props = Graph::new("WorkflowV1", false, Some(properties));
<span class="boring">}</span></code></pre></pre>
<h3 id="graph-with-history-tracking"><a class="header" href="#graph-with-history-tracking">Graph with History Tracking</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create graph with unlimited history
let (mut graph, mut history) = Graph::with_history();

// Create graph with limited history (recommended for production)
let (mut graph, mut history) = Graph::with_history_and_limit(100);
<span class="boring">}</span></code></pre></pre>
<h2 id="node-management-1"><a class="header" href="#node-management-1">Node Management</a></h2>
<h3 id="adding-nodes"><a class="header" href="#adding-nodes">Adding Nodes</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Basic node addition
graph.add_node("data_source", "FileReader", None);

// Node with position metadata
let metadata = HashMap::from([
    ("x".to_string(), json!(100)),
    ("y".to_string(), json!(200))
]);
graph.add_node("processor", "DataProcessor", Some(metadata));

// Node with comprehensive metadata
let rich_metadata = HashMap::from([
    ("x".to_string(), json!(300)),
    ("y".to_string(), json!(150)),
    ("label".to_string(), json!("CSV Parser")),
    ("color".to_string(), json!("#3498db")),
    ("estimated_time".to_string(), json!(2.5)),
    ("resources".to_string(), json!({
        "memory": 128,
        "cpu": 0.5
    })),
    ("configuration".to_string(), json!({
        "delimiter": ",",
        "has_header": true
    }))
]);
graph.add_node("csv_parser", "CSVParser", Some(rich_metadata));
<span class="boring">}</span></code></pre></pre>
<h3 id="node-retrieval"><a class="header" href="#node-retrieval">Node Retrieval</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Get node reference
if let Some(node) = graph.get_node("processor") {
    println!("Node component: {}", node.component);
    if let Some(metadata) = &amp;node.metadata {
        println!("Node metadata: {:?}", metadata);
    }
}

// Get mutable node reference
if let Some(node) = graph.get_node_mut("processor") {
    // Modify node directly (not recommended - use set_node_metadata instead)
}
<span class="boring">}</span></code></pre></pre>
<h3 id="updating-node-metadata"><a class="header" href="#updating-node-metadata">Updating Node Metadata</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Update metadata (merges with existing)
let updates = HashMap::from([
    ("color".to_string(), json!("#e74c3c")),
    ("priority".to_string(), json!("high"))
]);
graph.set_node_metadata("processor", updates);

// Clear specific metadata field by setting to null
let clear_color = HashMap::from([
    ("color".to_string(), json!(null))
]);
graph.set_node_metadata("processor", clear_color);
<span class="boring">}</span></code></pre></pre>
<h3 id="node-removal"><a class="header" href="#node-removal">Node Removal</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Remove node (automatically removes all connections)
graph.remove_node("old_processor");
<span class="boring">}</span></code></pre></pre>
<h3 id="node-renaming"><a class="header" href="#node-renaming">Node Renaming</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Rename node (updates all references)
graph.rename_node("old_name", "new_name");
<span class="boring">}</span></code></pre></pre>
<h2 id="connection-management-1"><a class="header" href="#connection-management-1">Connection Management</a></h2>
<h3 id="creating-connections"><a class="header" href="#creating-connections">Creating Connections</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Basic connection
graph.add_connection("source", "output", "processor", "input", None);

// Connection with metadata
let conn_metadata = HashMap::from([
    ("weight".to_string(), json!(0.8)),
    ("priority".to_string(), json!("high")),
    ("buffer_size".to_string(), json!(1024))
]);
graph.add_connection("processor", "output", "sink", "input", Some(conn_metadata));
<span class="boring">}</span></code></pre></pre>
<h3 id="connection-queries"><a class="header" href="#connection-queries">Connection Queries</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Get specific connection
if let Some(connection) = graph.get_connection("source", "output", "processor", "input") {
    println!("Connection metadata: {:?}", connection.metadata);
}

// Get all connections for a node
let incoming = graph.get_incoming_connections("processor");
for (source_node, source_port, connection) in incoming {
    println!("Input from {}:{}", source_node, source_port);
}

let outgoing = graph.get_outgoing_connections("processor");
for (target_node, target_port, connection) in outgoing {
    println!("Output to {}:{}", target_node, target_port);
}

// Get connections for specific port
let port_incoming = graph.get_incoming_connections_for_port("processor", "input");
let port_outgoing = graph.get_outgoing_connections_for_port("processor", "output");
<span class="boring">}</span></code></pre></pre>
<h3 id="connection-analysis"><a class="header" href="#connection-analysis">Connection Analysis</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Check if nodes are connected
if graph.are_nodes_connected("source", "processor") {
    println!("Nodes are connected");
}

// Check specific port connections
if graph.are_ports_connected("source", "output", "processor", "input") {
    println!("Ports are connected");
}

// Get connection degrees
let (in_degree, out_degree) = graph.get_connection_degree("processor");
println!("Node has {} inputs and {} outputs", in_degree, out_degree);

// Get port-specific degrees
let (port_in, port_out) = graph.get_port_connection_degree("processor", "data");
<span class="boring">}</span></code></pre></pre>
<h3 id="connection-updates"><a class="header" href="#connection-updates">Connection Updates</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Update connection metadata
let new_metadata = HashMap::from([
    ("bandwidth".to_string(), json!("high")),
    ("encrypted".to_string(), json!(true))
]);
graph.set_connection_metadata("source", "output", "processor", "input", new_metadata);
<span class="boring">}</span></code></pre></pre>
<h3 id="connection-removal"><a class="header" href="#connection-removal">Connection Removal</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Remove specific connection
graph.remove_connection("source", "output", "processor", "input");

// Remove all connections for a node (called automatically when removing node)
graph.remove_node_connections("isolated_node");
<span class="boring">}</span></code></pre></pre>
<h2 id="graph-ports-inportsoutports"><a class="header" href="#graph-ports-inportsoutports">Graph Ports (Inports/Outports)</a></h2>
<p>Graph ports expose internal node ports as external interfaces, making subgraphs reusable.</p>
<h3 id="adding-input-ports"><a class="header" href="#adding-input-ports">Adding Input Ports</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Basic inport
graph.add_inport("data_input", "processor", "input", PortType::Any, None);

// Inport with metadata
let port_metadata = HashMap::from([
    ("description".to_string(), json!("Main data input stream")),
    ("required".to_string(), json!(true)),
    ("default_value".to_string(), json!(null))
]);
graph.add_inport("config", "processor", "config", PortType::Object("Config".to_string()), Some(port_metadata));
<span class="boring">}</span></code></pre></pre>
<h3 id="adding-output-ports"><a class="header" href="#adding-output-ports">Adding Output Ports</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Basic outport
graph.add_outport("processed_data", "processor", "output", PortType::Object("ProcessedData".to_string()), None);

// Outport with metadata
let out_metadata = HashMap::from([
    ("description".to_string(), json!("Processed data stream")),
    ("format".to_string(), json!("json"))
]);
graph.add_outport("results", "processor", "result", PortType::Array(Box::new(PortType::Object("Result".to_string()))), Some(out_metadata));
<span class="boring">}</span></code></pre></pre>
<h3 id="port-management"><a class="header" href="#port-management">Port Management</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Update port metadata
let port_updates = HashMap::from([
    ("required".to_string(), json!(false)),
    ("deprecated".to_string(), json!(true))
]);
graph.set_inport_metadata("data_input", port_updates);
graph.set_outport_metadata("results", port_updates);

// Rename ports
graph.rename_inport("old_input", "new_input");
graph.rename_outport("old_output", "new_output");

// Remove ports
graph.remove_inport("unused_input");
graph.remove_outport("unused_output");
<span class="boring">}</span></code></pre></pre>
<h2 id="initial-information-packets-iips-1"><a class="header" href="#initial-information-packets-iips-1">Initial Information Packets (IIPs)</a></h2>
<p>IIPs provide static data to nodes at startup.</p>
<h3 id="adding-iips"><a class="header" href="#adding-iips">Adding IIPs</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Basic IIP
graph.add_initial(
    json!("config.yaml"),
    "file_reader",
    "filename",
    None
);

// IIP with metadata
let iip_metadata = HashMap::from([
    ("source".to_string(), json!("configuration")),
    ("priority".to_string(), json!("high"))
]);
graph.add_initial(
    json!({"host": "localhost", "port": 8080}),
    "server",
    "config",
    Some(iip_metadata)
);

// IIP with array index
graph.add_initial_index(
    json!("file1.txt"),
    "multi_reader",
    "files",
    0,
    None
);
<span class="boring">}</span></code></pre></pre>
<h3 id="graph-level-iips"><a class="header" href="#graph-level-iips">Graph-level IIPs</a></h3>
<p>When using graph ports, you can add IIPs at the graph level:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Add IIP to graph inport
graph.add_graph_initial(
    json!({"mode": "production"}),
    "config_input",  // Graph inport name
    None
);

// Add indexed IIP to graph inport
graph.add_graph_initial_index(
    json!("primary.db"),
    "database_files",  // Graph inport name
    0,
    None
);
<span class="boring">}</span></code></pre></pre>
<h3 id="removing-iips"><a class="header" href="#removing-iips">Removing IIPs</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Remove node-level IIP
graph.remove_initial("file_reader", "filename");

// Remove graph-level IIP
graph.remove_graph_initial("config_input");
<span class="boring">}</span></code></pre></pre>
<h2 id="node-groups-1"><a class="header" href="#node-groups-1">Node Groups</a></h2>
<p>Groups provide logical organization of related nodes.</p>
<h3 id="creating-groups"><a class="header" href="#creating-groups">Creating Groups</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create basic group
graph.add_group("data_processing", vec!["parser".to_string(), "validator".to_string(), "transformer".to_string()], None);

// Group with metadata
let group_metadata = HashMap::from([
    ("color".to_string(), json!("#2ecc71")),
    ("description".to_string(), json!("Data processing pipeline")),
    ("collapsed".to_string(), json!(false))
]);
graph.add_group("preprocessing", vec!["cleaner".to_string(), "normalizer".to_string()], Some(group_metadata));
<span class="boring">}</span></code></pre></pre>
<h3 id="managing-group-membership"><a class="header" href="#managing-group-membership">Managing Group Membership</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Add node to existing group
graph.add_to_group("data_processing", "formatter");

// Remove node from group
graph.remove_from_group("data_processing", "formatter");
<span class="boring">}</span></code></pre></pre>
<h3 id="group-metadata"><a class="header" href="#group-metadata">Group Metadata</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Update group metadata
let group_updates = HashMap::from([
    ("collapsed".to_string(), json!(true)),
    ("priority".to_string(), json!("high"))
]);
graph.set_group_metadata("data_processing", group_updates);
<span class="boring">}</span></code></pre></pre>
<h3 id="removing-groups"><a class="header" href="#removing-groups">Removing Groups</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Remove entire group (nodes remain, just ungrouped)
graph.remove_group("old_group");
<span class="boring">}</span></code></pre></pre>
<h2 id="graph-properties"><a class="header" href="#graph-properties">Graph Properties</a></h2>
<h3 id="setting-properties"><a class="header" href="#setting-properties">Setting Properties</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Set multiple properties
let properties = HashMap::from([
    ("name".to_string(), json!("Updated Workflow")),
    ("version".to_string(), json!("2.0.0")),
    ("description".to_string(), json!("Enhanced data processing")),
    ("tags".to_string(), json!(["data", "processing", "etl"]))
]);
graph.set_properties(properties);
<span class="boring">}</span></code></pre></pre>
<h3 id="getting-properties"><a class="header" href="#getting-properties">Getting Properties</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Properties are accessible via graph.properties field
if let Some(name) = graph.properties.get("name") {
    println!("Graph name: {}", name);
}
<span class="boring">}</span></code></pre></pre>
<h2 id="event-handling"><a class="header" href="#event-handling">Event Handling</a></h2>
<h3 id="subscribing-to-events"><a class="header" href="#subscribing-to-events">Subscribing to Events</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::GraphEvents;

// Get event receiver
let event_receiver = graph.event_channel.1.clone();

// Handle events in a loop
std::thread::spawn(move || {
    while let Ok(event) = event_receiver.recv() {
        match event {
            GraphEvents::AddNode(data) =&gt; {
                println!("Node added: {:?}", data);
            }
            GraphEvents::RemoveNode(data) =&gt; {
                println!("Node removed: {:?}", data);
            }
            GraphEvents::AddConnection(data) =&gt; {
                println!("Connection added: {:?}", data);
            }
            GraphEvents::RemoveConnection(data) =&gt; {
                println!("Connection removed: {:?}", data);
            }
            GraphEvents::ChangeNode(data) =&gt; {
                println!("Node changed: {:?}", data);
            }
            // ... handle other events
            _ =&gt; {}
        }
    }
});
<span class="boring">}</span></code></pre></pre>
<h3 id="event-types-reference-1"><a class="header" href="#event-types-reference-1">Event Types Reference</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Event</th><th>Triggered When</th><th>Data</th></tr></thead><tbody>
<tr><td><code>AddNode</code></td><td>Node is added</td><td>Node data</td></tr>
<tr><td><code>RemoveNode</code></td><td>Node is removed</td><td>Node data</td></tr>
<tr><td><code>RenameNode</code></td><td>Node is renamed</td><td><code>{old, new}</code></td></tr>
<tr><td><code>ChangeNode</code></td><td>Node metadata changes</td><td><code>{node, old_metadata, new_metadata}</code></td></tr>
<tr><td><code>AddConnection</code></td><td>Connection is added</td><td>Connection data</td></tr>
<tr><td><code>RemoveConnection</code></td><td>Connection is removed</td><td>Connection data</td></tr>
<tr><td><code>ChangeConnection</code></td><td>Connection metadata changes</td><td><code>{connection, old_metadata, new_metadata}</code></td></tr>
<tr><td><code>AddInitial</code></td><td>IIP is added</td><td>IIP data</td></tr>
<tr><td><code>RemoveInitial</code></td><td>IIP is removed</td><td>IIP data</td></tr>
<tr><td><code>AddGroup</code></td><td>Group is created</td><td>Group data</td></tr>
<tr><td><code>RemoveGroup</code></td><td>Group is removed</td><td>Group data</td></tr>
<tr><td><code>RenameGroup</code></td><td>Group is renamed</td><td><code>{old, new}</code></td></tr>
<tr><td><code>ChangeGroup</code></td><td>Group metadata changes</td><td><code>{group, old_metadata, new_metadata}</code></td></tr>
<tr><td><code>AddInport</code></td><td>Inport is added</td><td><code>{id, port}</code></td></tr>
<tr><td><code>RemoveInport</code></td><td>Inport is removed</td><td><code>{id, port}</code></td></tr>
<tr><td><code>RenameInport</code></td><td>Inport is renamed</td><td><code>{old, new}</code></td></tr>
<tr><td><code>ChangeInport</code></td><td>Inport metadata changes</td><td><code>{name, port, old_metadata, new_metadata}</code></td></tr>
<tr><td><code>AddOutport</code></td><td>Outport is added</td><td><code>{id, port}</code></td></tr>
<tr><td><code>RemoveOutport</code></td><td>Outport is removed</td><td><code>{id, port}</code></td></tr>
<tr><td><code>RenameOutport</code></td><td>Outport is renamed</td><td><code>{old, new}</code></td></tr>
<tr><td><code>ChangeOutport</code></td><td>Outport metadata changes</td><td><code>{name, port, old_metadata, new_metadata}</code></td></tr>
<tr><td><code>ChangeProperties</code></td><td>Graph properties change</td><td><code>{new, before}</code></td></tr>
</tbody></table>
</div>
<h2 id="serialization-and-loading"><a class="header" href="#serialization-and-loading">Serialization and Loading</a></h2>
<h3 id="exporting-graphs"><a class="header" href="#exporting-graphs">Exporting Graphs</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Export to GraphExport format
let export = graph.export();

// Serialize to JSON
let json_string = serde_json::to_string_pretty(&amp;export)?;
std::fs::write("workflow.json", json_string)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="loading-graphs"><a class="header" href="#loading-graphs">Loading Graphs</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Load from JSON
let json_content = std::fs::read_to_string("workflow.json")?;
let export: GraphExport = serde_json::from_str(&amp;json_content)?;

// Create graph from export
let metadata = HashMap::from([
    ("loaded_at".to_string(), json!(chrono::Utc::now().to_rfc3339()))
]);
let loaded_graph = Graph::load(export, Some(metadata));
<span class="boring">}</span></code></pre></pre>
<h2 id="webassembly-api"><a class="header" href="#webassembly-api">WebAssembly API</a></h2>
<p>When using the graph system in a browser via WebAssembly:</p>
<h3 id="javascripttypescript-usage"><a class="header" href="#javascripttypescript-usage">JavaScript/TypeScript Usage</a></h3>
<pre><code class="language-javascript">import { Graph, PortType } from 'reflow-network';

// Create graph
const graph = new Graph("WebWorkflow", false, {
    description: "Browser-based workflow"
});

// Add nodes
graph.addNode("input", "InputNode", { x: 0, y: 0 });
graph.addNode("output", "OutputNode", { x: 200, y: 0 });

// Add connections
graph.addConnection("input", "out", "output", "in", {});

// Subscribe to events
graph.subscribe((event) =&gt; {
    console.log("Graph event:", event);
    // Update UI based on event
    updateUI(event);
});

// Export for persistence
const exported = graph.toJSON();
localStorage.setItem('workflow', JSON.stringify(exported));

// Load saved workflow
const saved = JSON.parse(localStorage.getItem('workflow'));
const restoredGraph = Graph.load(saved, {});
</code></pre>
<h2 id="error-handling-10"><a class="header" href="#error-handling-10">Error Handling</a></h2>
<h3 id="common-error-scenarios"><a class="header" href="#common-error-scenarios">Common Error Scenarios</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::GraphError;

// Handle node operations
match graph.add_node("duplicate", "TestNode", None) {
    Ok(_) =&gt; println!("Node added successfully"),
    Err(GraphError::DuplicateNode(id)) =&gt; println!("Node {} already exists", id),
    Err(e) =&gt; println!("Error: {}", e),
}

// Handle traversal errors
match graph.traverse_depth_first("nonexistent", |node| {
    println!("Visiting: {}", node.id);
}) {
    Ok(_) =&gt; println!("Traversal completed"),
    Err(GraphError::NodeNotFound(id)) =&gt; println!("Start node {} not found", id),
    Err(e) =&gt; println!("Traversal error: {}", e),
}
<span class="boring">}</span></code></pre></pre>
<h3 id="error-types"><a class="header" href="#error-types">Error Types</a></h3>
<ul>
<li><code>NodeNotFound(String)</code> - Referenced node doesn't exist</li>
<li><code>DuplicateNode(String)</code> - Node with same ID already exists</li>
<li><code>InvalidConnection { from: String, to: String }</code> - Connection cannot be created</li>
<li><code>CycleDetected</code> - Operation would create a cycle (if validation enabled)</li>
<li><code>InvalidOperation(String)</code> - Generic operation error</li>
</ul>
<h2 id="best-practices-12"><a class="header" href="#best-practices-12">Best Practices</a></h2>
<h3 id="performance-tips-1"><a class="header" href="#performance-tips-1">Performance Tips</a></h3>
<ol>
<li>
<p><strong>Batch Operations</strong>: Group related changes to minimize events</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Instead of individual operations, batch them
graph.add_node("n1", "Node1", None);
graph.add_node("n2", "Node2", None);
graph.add_connection("n1", "out", "n2", "in", None);
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p><strong>Use Appropriate Data Structures</strong>: Store frequently accessed metadata efficiently</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: structured metadata
let metadata = HashMap::from([
    ("config".to_string(), json!({
        "retries": 3,
        "timeout": 30
    }))
]);

// Avoid: flat key-value for complex data
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p><strong>Validate Incrementally</strong>: Use targeted validation instead of full graph validation</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Check specific aspects instead of full validation
if let Some(cycle) = graph.detect_cycles() {
    // Handle cycle
}
<span class="boring">}</span></code></pre></pre>
</li>
</ol>
<h3 id="memory-management-4"><a class="header" href="#memory-management-4">Memory Management</a></h3>
<ol>
<li>
<p><strong>Limit History</strong>: Use bounded history for production systems</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let (graph, history) = Graph::with_history_and_limit(50);
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p><strong>Clean Up Events</strong>: Ensure event listeners are properly disposed</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Store receiver handle to drop when done
let receiver = graph.event_channel.1.clone();
// ... use receiver
drop(receiver); // Clean up
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p><strong>Efficient Metadata</strong>: Avoid storing large objects in metadata</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: reference to external data
let metadata = HashMap::from([
    ("data_ref".to_string(), json!("storage://large-dataset-id"))
]);

// Avoid: embedding large data
<span class="boring">}</span></code></pre></pre>
</li>
</ol>
<h2 id="next-steps-15"><a class="header" href="#next-steps-15">Next Steps</a></h2>
<ul>
<li><a href="api/graph/analysis.html">Graph Analysis</a> - Validation and performance analysis</li>
<li><a href="api/graph/layout.html">Layout System</a> - Positioning and visualization</li>
<li><a href="api/graph/advanced.html">Advanced Features</a> - History, subgraphs, and optimization</li>
<li><a href="api/graph/../../tutorials/building-visual-editor.html">Building Visual Editors</a> - Complete tutorial</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="graph-analysis-and-validation"><a class="header" href="#graph-analysis-and-validation">Graph Analysis and Validation</a></h1>
<p>Reflow's graph system provides extensive analysis capabilities for validation, performance optimization, and structural insights. This guide covers all analysis features available in the graph system.</p>
<h2 id="flow-validation"><a class="header" href="#flow-validation">Flow Validation</a></h2>
<h3 id="comprehensive-validation"><a class="header" href="#comprehensive-validation">Comprehensive Validation</a></h3>
<p>The <code>validate_flow</code> method performs a complete analysis of graph integrity:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{FlowValidation, PortMismatch};

// Perform full validation
let validation = graph.validate_flow()?;

// Check for issues
if !validation.cycles.is_empty() {
    for cycle in validation.cycles {
        println!("Cycle detected: {:?}", cycle);
    }
}

if !validation.orphaned_nodes.is_empty() {
    println!("Orphaned nodes: {:?}", validation.orphaned_nodes);
}

if !validation.port_mismatches.is_empty() {
    for mismatch in validation.port_mismatches {
        println!("Port type mismatch: {}", mismatch);
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="validation-results-structure"><a class="header" href="#validation-results-structure">Validation Results Structure</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct FlowValidation {
    pub cycles: Vec&lt;Vec&lt;String&gt;&gt;,           // Detected cycles
    pub orphaned_nodes: Vec&lt;String&gt;,        // Disconnected nodes
    pub port_mismatches: Vec&lt;PortMismatch&gt;, // Type incompatibilities
}

pub struct PortMismatch {
    pub from_node: String,
    pub from_port: String,
    pub from_type: PortType,
    pub to_node: String,
    pub to_port: String,
    pub to_type: PortType,
    pub reason: String,
}
<span class="boring">}</span></code></pre></pre>
<h2 id="cycle-detection-1"><a class="header" href="#cycle-detection-1">Cycle Detection</a></h2>
<h3 id="basic-cycle-detection"><a class="header" href="#basic-cycle-detection">Basic Cycle Detection</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Detect first cycle found
if let Some(cycle) = graph.detect_cycles() {
    println!("Cycle path: {:?}", cycle);
    // cycle is Vec&lt;String&gt; showing the path of the cycle
}

// Check if specific node is in a cycle
if graph.is_node_in_cycle("suspicious_node") {
    println!("Node is part of a cycle");
}
<span class="boring">}</span></code></pre></pre>
<h3 id="comprehensive-cycle-analysis"><a class="header" href="#comprehensive-cycle-analysis">Comprehensive Cycle Analysis</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::CycleAnalysis;

let cycle_analysis = graph.analyze_cycles();

println!("Total cycles found: {}", cycle_analysis.total_cycles);
println!("Cycle lengths: {:?}", cycle_analysis.cycle_lengths);
println!("Nodes involved in cycles: {:?}", cycle_analysis.nodes_in_cycles);

if let Some(longest) = cycle_analysis.longest_cycle {
    println!("Longest cycle: {:?} (length: {})", longest, longest.len());
}

if let Some(shortest) = cycle_analysis.shortest_cycle {
    println!("Shortest cycle: {:?} (length: {})", shortest, shortest.len());
}
<span class="boring">}</span></code></pre></pre>
<h3 id="all-cycles-detection"><a class="header" href="#all-cycles-detection">All Cycles Detection</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Find all cycles in the graph
let all_cycles = graph.detect_all_cycles();

for (i, cycle) in all_cycles.iter().enumerate() {
    println!("Cycle {}: {:?}", i + 1, cycle);
}
<span class="boring">}</span></code></pre></pre>
<h2 id="orphaned-node-analysis"><a class="header" href="#orphaned-node-analysis">Orphaned Node Analysis</a></h2>
<h3 id="basic-orphaned-node-detection"><a class="header" href="#basic-orphaned-node-detection">Basic Orphaned Node Detection</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Find all orphaned nodes
let orphaned = graph.find_orphaned_nodes();

for node in orphaned {
    println!("Orphaned node: {}", node);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="detailed-orphaned-analysis"><a class="header" href="#detailed-orphaned-analysis">Detailed Orphaned Analysis</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::OrphanedNodeAnalysis;

let orphan_analysis = graph.analyze_orphaned_nodes();

println!("Total orphaned nodes: {}", orphan_analysis.total_orphaned);

println!("Completely isolated nodes:");
for node in orphan_analysis.completely_isolated {
    println!("  - {}", node);
}

println!("Unreachable nodes (have connections but no path from entry points):");
for node in orphan_analysis.unreachable {
    println!("  - {}", node);
}

println!("Disconnected groups:");
for (i, group) in orphan_analysis.disconnected_groups.iter().enumerate() {
    println!("  Group {}: {:?}", i + 1, group);
}
<span class="boring">}</span></code></pre></pre>
<h2 id="port-type-validation"><a class="header" href="#port-type-validation">Port Type Validation</a></h2>
<h3 id="port-compatibility-checking"><a class="header" href="#port-compatibility-checking">Port Compatibility Checking</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Validate all port types in the graph
let port_mismatches = graph.validate_port_types();

for mismatch in port_mismatches {
    println!("Port mismatch: {} -&gt; {}", 
        format!("{}:{}", mismatch.from_node, mismatch.from_port),
        format!("{}:{}", mismatch.to_node, mismatch.to_port)
    );
    println!("  Types: {:?} -&gt; {:?}", mismatch.from_type, mismatch.to_type);
    println!("  Reason: {}", mismatch.reason);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="custom-type-compatibility"><a class="header" href="#custom-type-compatibility">Custom Type Compatibility</a></h3>
<p>The graph system includes built-in type compatibility rules:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Built-in compatibility rules:
// Any ‚Üî Any type (always compatible)
// Integer ‚Üí Float (automatic promotion)
// T ‚Üí Stream (streaming any type)
// T ‚Üí Option&lt;T&gt; (wrapping in option)
// Array&lt;T&gt; ‚Üí Array&lt;U&gt; (if T ‚Üí U)

// Example of compatible connections:
graph.add_connection("int_source", "out", "float_processor", "in", None);     // Integer ‚Üí Float ‚úì
graph.add_connection("data_source", "out", "stream_processor", "in", None);   // Any ‚Üí Stream ‚úì
graph.add_connection("value", "out", "optional_sink", "in", None);            // T ‚Üí Option&lt;T&gt; ‚úì
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-analysis-2"><a class="header" href="#performance-analysis-2">Performance Analysis</a></h2>
<h3 id="parallelism-analysis"><a class="header" href="#parallelism-analysis">Parallelism Analysis</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{ParallelismAnalysis, PipelineStage};

let parallelism = graph.analyze_parallelism();

println!("Maximum parallelism: {}", parallelism.max_parallelism);

// Parallel branches that can execute simultaneously
println!("Parallel branches:");
for (i, branch) in parallelism.parallel_branches.iter().enumerate() {
    println!("  Branch {}: {:?}", i + 1, branch.nodes);
    println!("    Entry points: {:?}", branch.entry_points);
    println!("    Exit points: {:?}", branch.exit_points);
}

// Pipeline stages for sequential execution
println!("Pipeline stages:");
for stage in parallelism.pipeline_stages {
    println!("  Stage {}: {:?}", stage.level, stage.nodes);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="bottleneck-detection"><a class="header" href="#bottleneck-detection">Bottleneck Detection</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::Bottleneck;

let bottlenecks = graph.detect_bottlenecks();

for bottleneck in bottlenecks {
    match bottleneck {
        Bottleneck::HighDegree(node) =&gt; {
            let (in_deg, out_deg) = graph.get_connection_degree(&amp;node);
            println!("High-degree bottleneck: {} ({} in, {} out)", node, in_deg, out_deg);
        }
        Bottleneck::SequentialChain(chain) =&gt; {
            println!("Sequential chain (could be parallelized): {:?}", chain);
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="high-degree-node-analysis"><a class="header" href="#high-degree-node-analysis">High-Degree Node Analysis</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Find nodes with unusually high connection counts
let high_degree_nodes = graph.find_high_degree_nodes();

for node in high_degree_nodes {
    let (incoming, outgoing) = graph.get_connection_degree(&amp;node);
    let total_degree = incoming + outgoing;
    
    println!("High-degree node: {} (total degree: {})", node, total_degree);
    println!("  Incoming: {}, Outgoing: {}", incoming, outgoing);
    
    // Analyze connected nodes
    let connected = graph.get_connected_nodes(&amp;node);
    println!("  Connected to {} other nodes", connected.len());
}
<span class="boring">}</span></code></pre></pre>
<h3 id="sequential-chain-analysis"><a class="header" href="#sequential-chain-analysis">Sequential Chain Analysis</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Find chains that could potentially be parallelized
let sequential_chains = graph.find_sequential_chains();

for (i, chain) in sequential_chains.iter().enumerate() {
    println!("Sequential chain {}: {:?}", i + 1, chain);
    println!("  Length: {} nodes", chain.len());
    
    // Analyze chain characteristics
    if chain.len() &gt;= 5 {
        println!("  ‚ö†Ô∏è  Long chain - consider breaking into parallel segments");
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="data-flow-analysis"><a class="header" href="#data-flow-analysis">Data Flow Analysis</a></h2>
<h3 id="flow-path-tracing"><a class="header" href="#flow-path-tracing">Flow Path Tracing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{DataFlowPath, DataTransform};

// Trace data flow from a starting node
let flow_paths = graph.trace_data_flow("input_node")?;

for (i, path) in flow_paths.iter().enumerate() {
    println!("Flow path {}:", i + 1);
    println!("  Nodes: {:?}", path.nodes);
    
    println!("  Transformations:");
    for transform in &amp;path.transforms {
        println!("    {} -&gt; {} ({}: {} -&gt; {})", 
            transform.node, 
            transform.operation,
            transform.node,
            transform.input_type, 
            transform.output_type
        );
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="execution-path-analysis"><a class="header" href="#execution-path-analysis">Execution Path Analysis</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::ExecutionPath;

// Find all possible execution paths
let execution_paths = graph.find_execution_paths();

for (i, path) in execution_paths.iter().enumerate() {
    println!("Execution path {}:", i + 1);
    println!("  Nodes: {:?}", path.nodes);
    println!("  Estimated time: {:.2}s", path.estimated_time);
    println!("  Resource requirements: {:?}", path.resource_requirements);
    
    // Check for parallel execution markers
    if path.resource_requirements.contains_key("parallel_branches") {
        let branches = path.resource_requirements["parallel_branches"];
        println!("  ‚ö° Contains {} parallel branches", branches);
    }
    
    if path.resource_requirements.contains_key("contains_cycle") {
        println!("  ‚ö†Ô∏è  Path contains cycles");
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="resource-requirements-analysis"><a class="header" href="#resource-requirements-analysis">Resource Requirements Analysis</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Analyze resource requirements for the entire graph
let resource_analysis = graph.analyze_resource_requirements();

println!("Graph resource requirements:");
for (resource, requirement) in resource_analysis {
    match resource.as_str() {
        "memory" =&gt; println!("  Memory: {:.1} MB", requirement),
        "cpu" =&gt; println!("  CPU cores: {:.1}", requirement),
        "disk" =&gt; println!("  Disk space: {:.1} GB", requirement),
        "network" =&gt; println!("  Network bandwidth: {:.1} Mbps", requirement),
        _ =&gt; println!("  {}: {:.2}", resource, requirement),
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="runtime-analysis"><a class="header" href="#runtime-analysis">Runtime Analysis</a></h2>
<h3 id="comprehensive-runtime-analysis"><a class="header" href="#comprehensive-runtime-analysis">Comprehensive Runtime Analysis</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{EnhancedGraphAnalysis, OptimizationSuggestion};

let runtime_analysis = graph.analyze_for_runtime();

println!("=== Runtime Analysis ===");
println!("Estimated execution time: {:.2}s", runtime_analysis.estimated_execution_time);
println!("Resource requirements: {:?}", runtime_analysis.resource_requirements);

// Parallelism opportunities
println!("\nParallelism analysis:");
println!("  Max parallelism: {}", runtime_analysis.parallelism.max_parallelism);
println!("  Parallel branches: {}", runtime_analysis.parallelism.parallel_branches.len());
println!("  Pipeline stages: {}", runtime_analysis.parallelism.pipeline_stages.len());

// Optimization suggestions
println!("\nOptimization suggestions:");
for suggestion in runtime_analysis.optimization_suggestions {
    match suggestion {
        OptimizationSuggestion::ParallelizableChain { nodes } =&gt; {
            println!("  ‚ö° Parallelize chain: {:?}", nodes);
        }
        OptimizationSuggestion::RedundantNode { node, reason } =&gt; {
            println!("  üóëÔ∏è  Remove redundant node '{}': {}", node, reason);
        }
        OptimizationSuggestion::ResourceBottleneck { resource, severity } =&gt; {
            println!("  ‚ö†Ô∏è  Resource bottleneck in '{}': {:.1}% usage", resource, severity * 100.0);
        }
        OptimizationSuggestion::DataTypeOptimization { from, to, suggestion } =&gt; {
            println!("  üîß Optimize types {} ‚Üí {}: {}", from, to, suggestion);
        }
    }
}

// Performance bottlenecks
println!("\nPerformance bottlenecks:");
for bottleneck in runtime_analysis.performance_bottlenecks {
    match bottleneck {
        Bottleneck::HighDegree(node) =&gt; {
            println!("  üî• High-degree node: {}", node);
        }
        Bottleneck::SequentialChain(chain) =&gt; {
            println!("  üêå Sequential bottleneck: {:?}", chain);
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="subgraph-analysis-1"><a class="header" href="#subgraph-analysis-1">Subgraph Analysis</a></h2>
<h3 id="extracting-subgraphs"><a class="header" href="#extracting-subgraphs">Extracting Subgraphs</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{Subgraph, SubgraphAnalysis};

// Get reachable subgraph from a node
if let Some(subgraph) = graph.get_reachable_subgraph("start_node") {
    println!("Subgraph from 'start_node':");
    println!("  Nodes: {:?}", subgraph.nodes);
    println!("  Entry points: {:?}", subgraph.entry_points);
    println!("  Exit points: {:?}", subgraph.exit_points);
    println!("  Internal connections: {}", subgraph.internal_connections.len());
    
    // Analyze subgraph characteristics
    let analysis = graph.analyze_subgraph(&amp;subgraph);
    println!("  Analysis:");
    println!("    Node count: {}", analysis.node_count);
    println!("    Connection count: {}", analysis.connection_count);
    println!("    Max depth: {}", analysis.max_depth);
    println!("    Is cyclic: {}", analysis.is_cyclic);
    println!("    Branching factor: {:.2}", analysis.branching_factor);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="independent-subgraph-detection"><a class="header" href="#independent-subgraph-detection">Independent Subgraph Detection</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Find all independent subgraphs
let subgraphs = graph.find_subgraphs();

println!("Found {} independent subgraphs:", subgraphs.len());
for (i, subgraph) in subgraphs.iter().enumerate() {
    println!("  Subgraph {}: {} nodes", i + 1, subgraph.nodes.len());
    
    let analysis = graph.analyze_subgraph(subgraph);
    if analysis.is_cyclic {
        println!("    ‚ö†Ô∏è  Contains cycles");
    }
    
    if subgraph.entry_points.len() &gt; 1 {
        println!("    ‚ö° Multiple entry points - potential for parallel input");
    }
    
    if subgraph.exit_points.len() &gt; 1 {
        println!("    üìä Multiple exit points - produces multiple outputs");
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="graph-traversal-analysis"><a class="header" href="#graph-traversal-analysis">Graph Traversal Analysis</a></h2>
<h3 id="traversal-with-analysis"><a class="header" href="#traversal-with-analysis">Traversal with Analysis</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::collections::HashSet;

// Depth-first traversal with custom analysis
let mut visited_order = Vec::new();
let mut max_depth = 0;
let mut current_depth = 0;

graph.traverse_depth_first("start_node", |node| {
    visited_order.push(node.id.clone());
    current_depth += 1;
    max_depth = max_depth.max(current_depth);
    
    println!("Visiting {} at depth {}", node.id, current_depth);
    
    // Analyze node characteristics
    if let Some(metadata) = &amp;node.metadata {
        if let Some(estimated_time) = metadata.get("estimated_time") {
            println!("  Estimated processing time: {:?}", estimated_time);
        }
    }
})?;

println!("Traversal completed:");
println!("  Visit order: {:?}", visited_order);
println!("  Maximum depth: {}", max_depth);
<span class="boring">}</span></code></pre></pre>
<h3 id="breadth-first-layer-analysis"><a class="header" href="#breadth-first-layer-analysis">Breadth-First Layer Analysis</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Breadth-first traversal to analyze layers
let mut layers: HashMap&lt;usize, Vec&lt;String&gt;&gt; = HashMap::new();
let mut current_layer = 0;

graph.traverse_breadth_first("start_node", |node| {
    // In a real implementation, you'd track depth
    layers.entry(current_layer)
        .or_insert_with(Vec::new)
        .push(node.id.clone());
    
    println!("Layer {}: {}", current_layer, node.id);
})?;

// Analyze layer characteristics
for (layer, nodes) in layers {
    println!("Layer {} has {} nodes: {:?}", layer, nodes.len(), nodes);
    
    if nodes.len() &gt; 1 {
        println!("  ‚ö° Layer {} can be parallelized", layer);
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="custom-analysis-functions"><a class="header" href="#custom-analysis-functions">Custom Analysis Functions</a></h2>
<h3 id="building-custom-analyzers"><a class="header" href="#building-custom-analyzers">Building Custom Analyzers</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Custom analyzer for finding critical paths
fn find_critical_path(graph: &amp;Graph, start: &amp;str, end: &amp;str) -&gt; Option&lt;Vec&lt;String&gt;&gt; {
    let mut longest_path = Vec::new();
    let mut max_weight = 0.0;
    
    // Use path tracing to find all paths
    if let Ok(paths) = graph.trace_data_flow(start) {
        for path in paths {
            if path.nodes.last() == Some(&amp;end.to_string()) {
                // Calculate path weight based on estimated times
                let mut path_weight = 0.0;
                
                for node_id in &amp;path.nodes {
                    if let Some(node) = graph.get_node(node_id) {
                        if let Some(metadata) = &amp;node.metadata {
                            if let Some(time) = metadata.get("estimated_time") {
                                if let Some(t) = time.as_f64() {
                                    path_weight += t;
                                }
                            }
                        }
                    }
                }
                
                if path_weight &gt; max_weight {
                    max_weight = path_weight;
                    longest_path = path.nodes;
                }
            }
        }
    }
    
    if longest_path.is_empty() {
        None
    } else {
        Some(longest_path)
    }
}

// Usage
if let Some(critical_path) = find_critical_path(&amp;graph, "input", "output") {
    println!("Critical path: {:?}", critical_path);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="performance-metrics-collection"><a class="header" href="#performance-metrics-collection">Performance Metrics Collection</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::time::Instant;

// Benchmark graph operations
fn benchmark_graph_operations(graph: &amp;Graph) {
    let start = Instant::now();
    
    // Benchmark cycle detection
    let cycle_start = Instant::now();
    let _cycles = graph.detect_all_cycles();
    let cycle_time = cycle_start.elapsed();
    
    // Benchmark validation
    let validation_start = Instant::now();
    let _validation = graph.validate_flow();
    let validation_time = validation_start.elapsed();
    
    // Benchmark parallelism analysis
    let parallelism_start = Instant::now();
    let _parallelism = graph.analyze_parallelism();
    let parallelism_time = parallelism_start.elapsed();
    
    let total_time = start.elapsed();
    
    println!("=== Performance Metrics ===");
    println!("Graph size: {} nodes, {} connections", 
        graph.nodes.len(), 
        graph.connections.len()
    );
    println!("Cycle detection: {:?}", cycle_time);
    println!("Flow validation: {:?}", validation_time);
    println!("Parallelism analysis: {:?}", parallelism_time);
    println!("Total analysis time: {:?}", total_time);
}
<span class="boring">}</span></code></pre></pre>
<h2 id="analysis-best-practices"><a class="header" href="#analysis-best-practices">Analysis Best Practices</a></h2>
<h3 id="incremental-analysis"><a class="header" href="#incremental-analysis">Incremental Analysis</a></h3>
<p>For large graphs, perform incremental analysis:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Instead of full validation on every change
let full_validation = graph.validate_flow()?; // Expensive

// Use targeted analysis
if let Some(cycle) = graph.detect_cycles() {
    // Handle cycles specifically
}

// Check only specific node connections
let node_issues = graph.find_orphaned_nodes()
    .into_iter()
    .filter(|n| recently_modified_nodes.contains(n))
    .collect::&lt;Vec&lt;_&gt;&gt;();
<span class="boring">}</span></code></pre></pre>
<h3 id="caching-analysis-results"><a class="header" href="#caching-analysis-results">Caching Analysis Results</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::cell::RefCell;

struct CachedAnalyzer {
    graph: Graph,
    cached_validation: RefCell&lt;Option&lt;FlowValidation&gt;&gt;,
    validation_dirty: RefCell&lt;bool&gt;,
}

impl CachedAnalyzer {
    fn get_validation(&amp;self) -&gt; Result&lt;FlowValidation, GraphError&gt; {
        if *self.validation_dirty.borrow() {
            let validation = self.graph.validate_flow()?;
            *self.cached_validation.borrow_mut() = Some(validation.clone());
            *self.validation_dirty.borrow_mut() = false;
            Ok(validation)
        } else {
            Ok(self.cached_validation.borrow().clone().unwrap())
        }
    }
    
    fn invalidate_cache(&amp;self) {
        *self.validation_dirty.borrow_mut() = true;
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="parallel-analysis"><a class="header" href="#parallel-analysis">Parallel Analysis</a></h3>
<p>For very large graphs, consider parallel analysis:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::thread;

// Analyze different aspects in parallel
let graph_clone = graph.clone();
let cycle_handle = thread::spawn(move || {
    graph_clone.detect_all_cycles()
});

let graph_clone2 = graph.clone();
let orphan_handle = thread::spawn(move || {
    graph_clone2.analyze_orphaned_nodes()
});

let graph_clone3 = graph.clone();
let parallelism_handle = thread::spawn(move || {
    graph_clone3.analyze_parallelism()
});

// Collect results
let cycles = cycle_handle.join().unwrap();
let orphan_analysis = orphan_handle.join().unwrap();
let parallelism_analysis = parallelism_handle.join().unwrap();

println!("Parallel analysis completed:");
println!("  Cycles: {}", cycles.len());
println!("  Orphaned: {}", orphan_analysis.total_orphaned);
println!("  Max parallelism: {}", parallelism_analysis.max_parallelism);
<span class="boring">}</span></code></pre></pre>
<h2 id="analysis-error-handling"><a class="header" href="#analysis-error-handling">Analysis Error Handling</a></h2>
<h3 id="robust-error-handling"><a class="header" href="#robust-error-handling">Robust Error Handling</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::GraphError;

fn safe_analysis(graph: &amp;Graph) -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Validate graph structure first
    match graph.validate_flow() {
        Ok(validation) =&gt; {
            if !validation.cycles.is_empty() {
                println!("‚ö†Ô∏è  Cycles detected - some analyses may not be reliable");
            }
        }
        Err(e) =&gt; {
            eprintln!("Validation failed: {}", e);
            return Err(Box::new(e));
        }
    }
    
    // Perform safe traversal
    match graph.traverse_depth_first("start", |node| {
        println!("Processing: {}", node.id);
    }) {
        Ok(_) =&gt; println!("Traversal completed successfully"),
        Err(GraphError::NodeNotFound(node)) =&gt; {
            eprintln!("Start node '{}' not found", node);
        }
        Err(e) =&gt; {
            eprintln!("Traversal error: {}", e);
            return Err(Box::new(e));
        }
    }
    
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h2 id="integration-with-visual-editors"><a class="header" href="#integration-with-visual-editors">Integration with Visual Editors</a></h2>
<h3 id="real-time-analysis-updates"><a class="header" href="#real-time-analysis-updates">Real-time Analysis Updates</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Update UI based on analysis results
fn update_editor_with_analysis(graph: &amp;Graph, ui: &amp;mut GraphEditor) {
    // Highlight cycles
    if let Some(cycle) = graph.detect_cycles() {
        for node in cycle {
            ui.highlight_node(&amp;node, "error");
        }
    }
    
    // Show bottlenecks
    let bottlenecks = graph.detect_bottlenecks();
    for bottleneck in bottlenecks {
        match bottleneck {
            Bottleneck::HighDegree(node) =&gt; {
                ui.highlight_node(&amp;node, "bottleneck");
            }
            Bottleneck::SequentialChain(chain) =&gt; {
                ui.highlight_chain(&amp;chain, "optimization-opportunity");
            }
        }
    }
    
    // Show parallel opportunities
    let parallelism = graph.analyze_parallelism();
    for branch in parallelism.parallel_branches {
        ui.group_nodes(&amp;branch.nodes, "parallel-group");
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="next-steps-16"><a class="header" href="#next-steps-16">Next Steps</a></h2>
<ul>
<li><a href="api/graph/layout.html">Layout System</a> - Positioning and visualization</li>
<li><a href="api/graph/advanced.html">Advanced Features</a> - History, subgraphs, and optimization</li>
<li><a href="api/graph/creating-graphs.html">Creating Graphs</a> - Basic graph operations</li>
<li><a href="api/graph/../../tutorials/building-visual-editor.html">Building Visual Editors</a> - Complete tutorial</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="graph-layout-system"><a class="header" href="#graph-layout-system">Graph Layout System</a></h1>
<p>Reflow's layout system provides intelligent automatic positioning and manual positioning capabilities for graph nodes. The system supports multiple layout algorithms, custom positioning, and integration with visual editors.</p>
<h2 id="automatic-layout-1"><a class="header" href="#automatic-layout-1">Automatic Layout</a></h2>
<h3 id="basic-auto-layout"><a class="header" href="#basic-auto-layout">Basic Auto-Layout</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::Position;

// Calculate optimal positions using default algorithm
let positions = graph.calculate_layout();

for (node_id, position) in positions {
    println!("Node {}: x={:.1}, y={:.1}", node_id, position.x, position.y);
}

// Apply calculated layout to graph metadata
graph.auto_layout()?;
<span class="boring">}</span></code></pre></pre>
<h3 id="layout-algorithms"><a class="header" href="#layout-algorithms">Layout Algorithms</a></h3>
<p>The system supports multiple layout algorithms optimized for different graph types:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{LayoutAlgorithm, LayoutConfig};

// Hierarchical layout for DAGs (default)
let hierarchical_config = LayoutConfig {
    algorithm: LayoutAlgorithm::Hierarchical,
    node_spacing: 120.0,
    layer_spacing: 80.0,
    edge_spacing: 40.0,
    ..Default::default()
};

let positions = graph.calculate_layout_with_config(&amp;hierarchical_config);

// Force-directed layout for general graphs
let force_config = LayoutConfig {
    algorithm: LayoutAlgorithm::ForceDirected,
    iterations: 100,
    spring_strength: 0.5,
    repulsion_strength: 1000.0,
    ..Default::default()
};

let positions = graph.calculate_layout_with_config(&amp;force_config);

// Grid layout for structured workflows
let grid_config = LayoutConfig {
    algorithm: LayoutAlgorithm::Grid,
    grid_size: 150.0,
    columns: 5,
    align_to_grid: true,
    ..Default::default()
};

let positions = graph.calculate_layout_with_config(&amp;grid_config);
<span class="boring">}</span></code></pre></pre>
<h3 id="hierarchical-layout"><a class="header" href="#hierarchical-layout">Hierarchical Layout</a></h3>
<p>Best for directed acyclic graphs (DAGs) and workflow diagrams:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::HierarchicalConfig;

let hierarchical = HierarchicalConfig {
    direction: LayoutDirection::TopToBottom,
    layer_spacing: 100.0,
    node_spacing: 80.0,
    edge_routing: EdgeRouting::Orthogonal,
    minimize_crossings: true,
    balance_nodes: true,
};

let positions = graph.hierarchical_layout(&amp;hierarchical);

// Apply with automatic layer detection
graph.auto_layout_hierarchical()?;
<span class="boring">}</span></code></pre></pre>
<h3 id="force-directed-layout"><a class="header" href="#force-directed-layout">Force-Directed Layout</a></h3>
<p>Ideal for general graphs with cycles and complex interconnections:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::ForceDirectedConfig;

let force_config = ForceDirectedConfig {
    iterations: 150,
    cooling_factor: 0.95,
    initial_temperature: 100.0,
    spring_strength: 0.3,
    spring_length: 100.0,
    repulsion_strength: 800.0,
    gravity_strength: 0.1,
    node_charge: -30.0,
};

let positions = graph.force_directed_layout(&amp;force_config);
<span class="boring">}</span></code></pre></pre>
<h3 id="organic-layout"><a class="header" href="#organic-layout">Organic Layout</a></h3>
<p>Creates natural, flowing layouts:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::OrganicConfig;

let organic_config = OrganicConfig {
    preferred_edge_length: 120.0,
    edge_length_cost_factor: 0.0001,
    node_distribution_cost_factor: 20000.0,
    edge_crossing_cost_factor: 6000.0,
    edge_distance_cost_factor: 15000.0,
    border_line_cost_factor: 100.0,
    max_iterations: 200,
};

let positions = graph.organic_layout(&amp;organic_config);
<span class="boring">}</span></code></pre></pre>
<h2 id="manual-positioning-1"><a class="header" href="#manual-positioning-1">Manual Positioning</a></h2>
<h3 id="setting-node-positions"><a class="header" href="#setting-node-positions">Setting Node Positions</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::Position;

// Set specific position
graph.set_node_position("input_node", 0.0, 0.0)?;
graph.set_node_position("processor", 200.0, 100.0)?;
graph.set_node_position("output_node", 400.0, 0.0)?;

// Set position with custom anchor point
let position = Position {
    x: 150.0,
    y: 75.0,
    anchor: Some(Anchor { x: 0.5, y: 0.5 }), // Center anchor
};
graph.set_node_position_with_anchor("centered_node", position)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="position-metadata-structure"><a class="header" href="#position-metadata-structure">Position Metadata Structure</a></h3>
<p>Positions are stored in node metadata following this convention:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use serde_json::json;
use std::collections::HashMap;

// Standard position metadata
let position_metadata = HashMap::from([
    ("x".to_string(), json!(100)),
    ("y".to_string(), json!(150)),
    ("width".to_string(), json!(120)),
    ("height".to_string(), json!(80)),
    ("anchor".to_string(), json!({
        "x": 0.5,  // Horizontal anchor (0.0 = left, 0.5 = center, 1.0 = right)
        "y": 0.5   // Vertical anchor (0.0 = top, 0.5 = middle, 1.0 = bottom)
    }))
]);

graph.set_node_metadata("positioned_node", position_metadata);
<span class="boring">}</span></code></pre></pre>
<h3 id="retrieving-positions"><a class="header" href="#retrieving-positions">Retrieving Positions</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Get position for a specific node
if let Some(position) = graph.get_node_position("processor") {
    println!("Node position: ({}, {})", position.x, position.y);
}

// Get all node positions
let all_positions = graph.get_all_positions();
for (node_id, position) in all_positions {
    println!("{}: ({:.1}, {:.1})", node_id, position.x, position.y);
}

// Get positions within a bounding box
let bbox = BoundingBox {
    min_x: 0.0,
    min_y: 0.0,
    max_x: 500.0,
    max_y: 300.0,
};
let nodes_in_area = graph.get_nodes_in_area(bbox);
<span class="boring">}</span></code></pre></pre>
<h2 id="layout-constraints"><a class="header" href="#layout-constraints">Layout Constraints</a></h2>
<h3 id="alignment-constraints"><a class="header" href="#alignment-constraints">Alignment Constraints</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{AlignmentConstraint, ConstraintType};

// Horizontal alignment
let horizontal_alignment = AlignmentConstraint {
    nodes: vec!["node1".to_string(), "node2".to_string(), "node3".to_string()],
    constraint_type: ConstraintType::HorizontalAlignment,
    offset: 0.0,
};

// Vertical alignment
let vertical_alignment = AlignmentConstraint {
    nodes: vec!["input1".to_string(), "input2".to_string()],
    constraint_type: ConstraintType::VerticalAlignment,
    offset: 50.0, // 50 pixels apart
};

// Apply constraints during layout
let config = LayoutConfig {
    algorithm: LayoutAlgorithm::Hierarchical,
    constraints: vec![horizontal_alignment, vertical_alignment],
    ..Default::default()
};

graph.apply_layout_with_constraints(&amp;config)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="distance-constraints"><a class="header" href="#distance-constraints">Distance Constraints</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{DistanceConstraint, DistanceType};

// Minimum distance constraint
let min_distance = DistanceConstraint {
    from_node: "source".to_string(),
    to_node: "sink".to_string(),
    distance_type: DistanceType::Minimum,
    distance: 200.0,
};

// Maximum distance constraint
let max_distance = DistanceConstraint {
    from_node: "processor1".to_string(),
    to_node: "processor2".to_string(),
    distance_type: DistanceType::Maximum,
    distance: 300.0,
};

// Fixed distance constraint
let fixed_distance = DistanceConstraint {
    from_node: "controller".to_string(),
    to_node: "display".to_string(),
    distance_type: DistanceType::Fixed,
    distance: 150.0,
};
<span class="boring">}</span></code></pre></pre>
<h3 id="boundary-constraints"><a class="header" href="#boundary-constraints">Boundary Constraints</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::BoundaryConstraint;

// Keep nodes within bounds
let boundary = BoundaryConstraint {
    min_x: 0.0,
    min_y: 0.0,
    max_x: 1000.0,
    max_y: 600.0,
    enforce_during_layout: true,
};

// Apply boundary constraint
graph.set_layout_boundary(boundary);
<span class="boring">}</span></code></pre></pre>
<h2 id="layout-optimization"><a class="header" href="#layout-optimization">Layout Optimization</a></h2>
<h3 id="minimize-edge-crossings"><a class="header" href="#minimize-edge-crossings">Minimize Edge Crossings</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Optimize layout to reduce edge crossings
let optimized_positions = graph.minimize_edge_crossings()?;

// Apply optimization with maximum iterations
let crossings_config = EdgeCrossingConfig {
    max_iterations: 50,
    improvement_threshold: 0.01,
    use_barycenter_heuristic: true,
};

graph.optimize_edge_crossings(&amp;crossings_config)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="edge-bundling"><a class="header" href="#edge-bundling">Edge Bundling</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::EdgeBundling;

// Enable edge bundling for cleaner layouts
let bundling_config = EdgeBundling {
    enable: true,
    strength: 0.8,
    step_size: 0.1,
    iterations: 60,
    min_distance: 10.0,
};

graph.apply_edge_bundling(&amp;bundling_config)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="compact-layout"><a class="header" href="#compact-layout">Compact Layout</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create compact layout by minimizing overall area
let compact_config = CompactLayoutConfig {
    preserve_aspect_ratio: true,
    min_node_spacing: 20.0,
    pack_components: true,
};

graph.create_compact_layout(&amp;compact_config)?;
<span class="boring">}</span></code></pre></pre>
<h2 id="layer-based-layout"><a class="header" href="#layer-based-layout">Layer-Based Layout</a></h2>
<h3 id="automatic-layer-detection"><a class="header" href="#automatic-layer-detection">Automatic Layer Detection</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{LayerAnalysis, LayerDirection};

// Detect natural layers in the graph
let layer_analysis = graph.analyze_layers();

println!("Detected {} layers:", layer_analysis.layers.len());
for (level, nodes) in layer_analysis.layers.iter().enumerate() {
    println!("  Layer {}: {:?}", level, nodes);
}

// Apply layer-based layout
let layer_config = LayerLayoutConfig {
    direction: LayerDirection::LeftToRight,
    layer_spacing: 150.0,
    node_spacing: 100.0,
    center_nodes_in_layer: true,
};

graph.apply_layer_layout(&amp;layer_config)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="manual-layer-assignment"><a class="header" href="#manual-layer-assignment">Manual Layer Assignment</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Manually assign nodes to layers
let layer_assignments = HashMap::from([
    ("input1".to_string(), 0),
    ("input2".to_string(), 0),
    ("processor1".to_string(), 1),
    ("processor2".to_string(), 1),
    ("output".to_string(), 2),
]);

graph.set_layer_assignments(layer_assignments);
graph.apply_layer_layout(&amp;layer_config)?;
<span class="boring">}</span></code></pre></pre>
<h2 id="group-based-layout"><a class="header" href="#group-based-layout">Group-Based Layout</a></h2>
<h3 id="layout-node-groups"><a class="header" href="#layout-node-groups">Layout Node Groups</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::GroupLayoutConfig;

// Layout nodes within groups
let group_config = GroupLayoutConfig {
    group_spacing: 200.0,
    internal_spacing: 50.0,
    group_padding: 20.0,
    layout_algorithm: LayoutAlgorithm::Grid,
};

// Apply group-aware layout
graph.layout_groups(&amp;group_config)?;

// Layout specific group
graph.layout_group("data_processing", &amp;group_config)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="group-boundaries"><a class="header" href="#group-boundaries">Group Boundaries</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Calculate group boundaries
let group_bounds = graph.calculate_group_bounds("data_processing");
if let Some(bounds) = group_bounds {
    println!("Group bounds: ({}, {}) to ({}, {})", 
        bounds.min_x, bounds.min_y, bounds.max_x, bounds.max_y);
}

// Set custom group boundary
let custom_bounds = BoundingBox {
    min_x: 100.0,
    min_y: 50.0,
    max_x: 400.0,
    max_y: 250.0,
};
graph.set_group_bounds("data_processing", custom_bounds);
<span class="boring">}</span></code></pre></pre>
<h2 id="advanced-layout-features"><a class="header" href="#advanced-layout-features">Advanced Layout Features</a></h2>
<h3 id="multi-level-layout"><a class="header" href="#multi-level-layout">Multi-Level Layout</a></h3>
<p>For very large graphs, use multi-level layout:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::MultiLevelConfig;

let multilevel_config = MultiLevelConfig {
    coarsening_factor: 0.7,
    max_levels: 5,
    uncoarsening_iterations: 10,
    finest_level_iterations: 20,
};

let positions = graph.multilevel_layout(&amp;multilevel_config)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="incremental-layout"><a class="header" href="#incremental-layout">Incremental Layout</a></h3>
<p>Update layout incrementally when nodes are added/removed:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Add node with incremental layout update
graph.add_node("new_processor", "DataProcessor", None);
graph.add_connection("source", "out", "new_processor", "in", None);

// Update layout incrementally
let incremental_config = IncrementalLayoutConfig {
    stabilization_iterations: 10,
    affected_nodes_only: true,
    preserve_existing_positions: true,
};

graph.incremental_layout_update(&amp;incremental_config)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="layout-animation-support"><a class="header" href="#layout-animation-support">Layout Animation Support</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{LayoutAnimation, AnimationFrame};

// Generate animation frames for smooth transitions
let from_positions = graph.get_all_positions();
let to_positions = graph.calculate_layout();

let animation = LayoutAnimation::new(from_positions, to_positions, 30); // 30 frames

// Get animation frames
for (frame_idx, frame) in animation.frames().enumerate() {
    println!("Frame {}: {} position updates", frame_idx, frame.positions.len());
    
    // Apply frame in UI
    for (node_id, position) in frame.positions {
        // Update UI node position
        ui.set_node_position(&amp;node_id, position.x, position.y);
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="layout-quality-metrics"><a class="header" href="#layout-quality-metrics">Layout Quality Metrics</a></h2>
<h3 id="measuring-layout-quality"><a class="header" href="#measuring-layout-quality">Measuring Layout Quality</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{LayoutMetrics, LayoutQuality};

let metrics = graph.calculate_layout_metrics();

println!("Layout Quality Metrics:");
println!("  Edge crossings: {}", metrics.edge_crossings);
println!("  Average edge length: {:.2}", metrics.average_edge_length);
println!("  Node distribution score: {:.2}", metrics.node_distribution_score);
println!("  Aspect ratio: {:.2}", metrics.aspect_ratio);
println!("  Overall score: {:.2}", metrics.overall_quality_score);

// Detailed metrics
println!("\nDetailed Metrics:");
println!("  Minimum edge length: {:.2}", metrics.min_edge_length);
println!("  Maximum edge length: {:.2}", metrics.max_edge_length);
println!("  Edge length variance: {:.2}", metrics.edge_length_variance);
println!("  Node overlap count: {}", metrics.node_overlaps);
println!("  Angular resolution: {:.2}¬∞", metrics.angular_resolution);
<span class="boring">}</span></code></pre></pre>
<h3 id="layout-comparison"><a class="header" href="#layout-comparison">Layout Comparison</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Compare different layout algorithms
let algorithms = vec![
    LayoutAlgorithm::Hierarchical,
    LayoutAlgorithm::ForceDirected,
    LayoutAlgorithm::Organic,
];

let mut best_layout = None;
let mut best_score = 0.0;

for algorithm in algorithms {
    let config = LayoutConfig {
        algorithm: algorithm.clone(),
        ..Default::default()
    };
    
    let positions = graph.calculate_layout_with_config(&amp;config);
    graph.apply_positions(positions);
    
    let metrics = graph.calculate_layout_metrics();
    let score = metrics.overall_quality_score;
    
    println!("{:?}: score {:.2}", algorithm, score);
    
    if score &gt; best_score {
        best_score = score;
        best_layout = Some(algorithm);
    }
}

if let Some(best) = best_layout {
    println!("Best layout algorithm: {:?} (score: {:.2})", best, best_score);
}
<span class="boring">}</span></code></pre></pre>
<h2 id="custom-layout-algorithms"><a class="header" href="#custom-layout-algorithms">Custom Layout Algorithms</a></h2>
<h3 id="implementing-custom-layout"><a class="header" href="#implementing-custom-layout">Implementing Custom Layout</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{CustomLayout, LayoutContext};

struct CircularLayout {
    radius: f64,
    start_angle: f64,
}

impl CustomLayout for CircularLayout {
    fn calculate_positions(&amp;self, context: &amp;LayoutContext) -&gt; HashMap&lt;String, Position&gt; {
        let mut positions = HashMap::new();
        let node_count = context.nodes.len();
        let angle_step = 2.0 * std::f64::consts::PI / node_count as f64;
        
        for (i, node_id) in context.nodes.iter().enumerate() {
            let angle = self.start_angle + i as f64 * angle_step;
            let x = self.radius * angle.cos();
            let y = self.radius * angle.sin();
            
            positions.insert(node_id.clone(), Position { x, y, anchor: None });
        }
        
        positions
    }
}

// Use custom layout
let circular = CircularLayout {
    radius: 200.0,
    start_angle: 0.0,
};

let positions = graph.apply_custom_layout(&amp;circular)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="layout-plugins"><a class="header" href="#layout-plugins">Layout Plugins</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Register layout plugin
graph.register_layout_plugin("spiral", Box::new(SpiralLayout::new()));

// Use registered plugin
let config = LayoutConfig {
    algorithm: LayoutAlgorithm::Custom("spiral".to_string()),
    ..Default::default()
};

graph.calculate_layout_with_config(&amp;config);
<span class="boring">}</span></code></pre></pre>
<h2 id="layout-events"><a class="header" href="#layout-events">Layout Events</a></h2>
<h3 id="listening-to-layout-changes"><a class="header" href="#listening-to-layout-changes">Listening to Layout Changes</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::LayoutEvents;

// Subscribe to layout events
let layout_receiver = graph.layout_event_channel.1.clone();

std::thread::spawn(move || {
    while let Ok(event) = layout_receiver.recv() {
        match event {
            LayoutEvents::LayoutStarted { algorithm } =&gt; {
                println!("Layout started: {:?}", algorithm);
            }
            LayoutEvents::LayoutCompleted { algorithm, duration } =&gt; {
                println!("Layout completed: {:?} in {:?}", algorithm, duration);
            }
            LayoutEvents::NodePositionChanged { node_id, old_pos, new_pos } =&gt; {
                println!("Node {} moved: ({:.1}, {:.1}) -&gt; ({:.1}, {:.1})", 
                    node_id, old_pos.x, old_pos.y, new_pos.x, new_pos.y);
            }
            LayoutEvents::LayoutProgress { progress } =&gt; {
                println!("Layout progress: {:.1}%", progress * 100.0);
            }
        }
    }
});
<span class="boring">}</span></code></pre></pre>
<h2 id="webassembly-layout-api"><a class="header" href="#webassembly-layout-api">WebAssembly Layout API</a></h2>
<h3 id="javascript-integration"><a class="header" href="#javascript-integration">JavaScript Integration</a></h3>
<pre><code class="language-javascript">import { Graph, LayoutAlgorithm } from 'reflow-network';

const graph = new Graph("LayoutDemo", false, {});

// Add nodes and connections
graph.addNode("input", "InputNode", {});
graph.addNode("processor", "ProcessorNode", {});
graph.addNode("output", "OutputNode", {});
graph.addConnection("input", "out", "processor", "in", {});
graph.addConnection("processor", "out", "output", "in", {});

// Apply automatic layout
const positions = graph.calculateLayout({
    algorithm: LayoutAlgorithm.Hierarchical,
    nodeSpacing: 120,
    layerSpacing: 80
});

// Update UI with calculated positions
for (const [nodeId, position] of positions) {
    const nodeElement = document.getElementById(nodeId);
    nodeElement.style.left = `${position.x}px`;
    nodeElement.style.top = `${position.y}px`;
}

// Manual positioning
graph.setNodePosition("processor", 200, 100);

// Listen for layout events
graph.onLayoutChange((event) =&gt; {
    if (event.type === 'position_changed') {
        updateNodeElement(event.nodeId, event.newPosition);
    }
});
</code></pre>
<h2 id="layout-best-practices"><a class="header" href="#layout-best-practices">Layout Best Practices</a></h2>
<h3 id="performance-optimization-3"><a class="header" href="#performance-optimization-3">Performance Optimization</a></h3>
<ol>
<li><strong>Use appropriate algorithms</strong>: Choose the right algorithm for your graph type</li>
<li><strong>Limit iterations</strong>: Set reasonable iteration limits for force-directed layouts</li>
<li><strong>Cache layouts</strong>: Store calculated positions to avoid recalculation</li>
<li><strong>Incremental updates</strong>: Use incremental layout for small changes</li>
</ol>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Incremental update for small changes
graph.add_node("new_node", "Component", None);
graph.incremental_layout_update(&amp;incremental_config)?;

// Avoid: Full recalculation for small changes
graph.auto_layout()?; // Expensive for large graphs
<span class="boring">}</span></code></pre></pre>
<h3 id="visual-quality"><a class="header" href="#visual-quality">Visual Quality</a></h3>
<ol>
<li><strong>Minimize crossings</strong>: Use algorithms that reduce edge crossings</li>
<li><strong>Consistent spacing</strong>: Maintain uniform spacing between nodes</li>
<li><strong>Respect hierarchy</strong>: Use hierarchical layout for workflow graphs</li>
<li><strong>Group related nodes</strong>: Use group layouts for related components</li>
</ol>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Group-aware layout
let group_config = GroupLayoutConfig {
    group_spacing: 200.0,
    internal_spacing: 50.0,
    group_padding: 20.0,
    layout_algorithm: LayoutAlgorithm::Grid,
};
graph.layout_groups(&amp;group_config)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="user-experience"><a class="header" href="#user-experience">User Experience</a></h3>
<ol>
<li><strong>Smooth transitions</strong>: Use animation between layout changes</li>
<li><strong>Preserve user positioning</strong>: Respect manually positioned nodes</li>
<li><strong>Provide layout options</strong>: Allow users to choose layout algorithms</li>
<li><strong>Show progress</strong>: Display progress for long-running layout calculations</li>
</ol>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Preserve manual positions
let manual_positions = graph.get_manually_positioned_nodes();
let config = LayoutConfig {
    preserve_positions: manual_positions,
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h2 id="troubleshooting-6"><a class="header" href="#troubleshooting-6">Troubleshooting</a></h2>
<h3 id="common-layout-issues"><a class="header" href="#common-layout-issues">Common Layout Issues</a></h3>
<ol>
<li><strong>Overlapping nodes</strong>: Increase node spacing or use different algorithm</li>
<li><strong>Poor aspect ratio</strong>: Adjust layout bounds or use compact layout</li>
<li><strong>Too many crossings</strong>: Use hierarchical layout or enable crossing minimization</li>
<li><strong>Unstable force layout</strong>: Reduce spring strength or increase damping</li>
</ol>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Fix overlapping nodes
let config = LayoutConfig {
    node_spacing: 150.0, // Increase spacing
    collision_detection: true,
    ..Default::default()
};

// Fix unstable force layout
let force_config = ForceDirectedConfig {
    spring_strength: 0.1, // Reduce from default 0.3
    damping: 0.8,         // Add damping
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h2 id="next-steps-17"><a class="header" href="#next-steps-17">Next Steps</a></h2>
<ul>
<li><a href="api/graph/advanced.html">Advanced Features</a> - History, subgraphs, and optimization</li>
<li><a href="api/graph/creating-graphs.html">Creating Graphs</a> - Basic graph operations</li>
<li><a href="api/graph/analysis.html">Graph Analysis</a> - Validation and performance analysis</li>
<li><a href="api/graph/../../tutorials/building-visual-editor.html">Building Visual Editors</a> - Complete tutorial</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="advanced-graph-features"><a class="header" href="#advanced-graph-features">Advanced Graph Features</a></h1>
<p>This guide covers advanced features of Reflow's graph system including history management, subgraph operations, optimization techniques, and performance tuning.</p>
<h2 id="history-management"><a class="header" href="#history-management">History Management</a></h2>
<h3 id="basic-history-operations"><a class="header" href="#basic-history-operations">Basic History Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{Graph, GraphHistory};

// Create graph with history tracking
let (mut graph, mut history) = Graph::with_history();

// Make some changes
graph.add_node("input", "InputNode", None);
graph.add_node("output", "OutputNode", None);
graph.add_connection("input", "out", "output", "in", None);

// Undo last operation
if let Some(operation) = history.undo() {
    history.apply_inverse(&amp;mut graph, operation)?;
    println!("Undid: {:?}", operation);
}

// Redo operation
if let Some(operation) = history.redo() {
    history.apply_operation(&amp;mut graph, operation)?;
    println!("Redid: {:?}", operation);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="advanced-history-configuration"><a class="header" href="#advanced-history-configuration">Advanced History Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{HistoryConfig, HistoryLimit};

// Create history with custom configuration
let history_config = HistoryConfig {
    limit: HistoryLimit::Operations(100),  // Limit to 100 operations
    compress_threshold: 50,                // Compress after 50 operations
    auto_cleanup: true,                    // Clean up old entries automatically
    track_metadata_changes: true,          // Track metadata changes
};

let (mut graph, mut history) = Graph::with_history_config(history_config);

// Alternative: Limit by memory usage
let memory_config = HistoryConfig {
    limit: HistoryLimit::Memory(10 * 1024 * 1024), // 10 MB limit
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h3 id="history-compression"><a class="header" href="#history-compression">History Compression</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Manually compress history
history.compress()?;

// Get compression statistics
let stats = history.compression_stats();
println!("Compressed {} operations into {} snapshots", 
    stats.original_operations, stats.compressed_snapshots);
println!("Memory saved: {:.1} MB", stats.memory_saved / 1024.0 / 1024.0);

// Force full compression
history.force_compress_all()?;
<span class="boring">}</span></code></pre></pre>
<h3 id="history-snapshots"><a class="header" href="#history-snapshots">History Snapshots</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::Snapshot;

// Create named snapshot
let snapshot_id = history.create_snapshot("before_major_changes")?;

// Make changes...
graph.add_node("processor1", "DataProcessor", None);
graph.add_node("processor2", "DataProcessor", None);

// Restore to snapshot
history.restore_snapshot(&amp;mut graph, &amp;snapshot_id)?;

// List all snapshots
let snapshots = history.list_snapshots();
for snapshot in snapshots {
    println!("Snapshot: {} (created: {})", snapshot.name, snapshot.timestamp);
}

// Delete old snapshots
history.delete_snapshot("old_snapshot")?;
<span class="boring">}</span></code></pre></pre>
<h3 id="branching-history"><a class="header" href="#branching-history">Branching History</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::HistoryBranch;

// Create branch from current state
let branch_id = history.create_branch("experimental_feature")?;

// Switch to branch
history.switch_branch(&amp;mut graph, &amp;branch_id)?;

// Make experimental changes
graph.add_node("experimental", "ExperimentalNode", None);

// Switch back to main branch
history.switch_branch(&amp;mut graph, "main")?;

// Merge branch if satisfied with changes
history.merge_branch(&amp;mut graph, &amp;branch_id, "main")?;
<span class="boring">}</span></code></pre></pre>
<h3 id="history-events"><a class="header" href="#history-events">History Events</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::HistoryEvents;

// Subscribe to history events
let history_receiver = history.event_channel().1.clone();

std::thread::spawn(move || {
    while let Ok(event) = history_receiver.recv() {
        match event {
            HistoryEvents::OperationAdded { operation, index } =&gt; {
                println!("Added operation {}: {:?}", index, operation);
            }
            HistoryEvents::Undo { operation } =&gt; {
                println!("Undid operation: {:?}", operation);
            }
            HistoryEvents::Redo { operation } =&gt; {
                println!("Redid operation: {:?}", operation);
            }
            HistoryEvents::SnapshotCreated { name, timestamp } =&gt; {
                println!("Created snapshot '{}' at {}", name, timestamp);
            }
            HistoryEvents::HistoryCompressed { before_size, after_size } =&gt; {
                println!("Compressed history: {} -&gt; {} operations", before_size, after_size);
            }
        }
    }
});
<span class="boring">}</span></code></pre></pre>
<h2 id="subgraph-operations"><a class="header" href="#subgraph-operations">Subgraph Operations</a></h2>
<h3 id="creating-subgraphs"><a class="header" href="#creating-subgraphs">Creating Subgraphs</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{Subgraph, SubgraphConfig};

// Extract subgraph by node selection
let selected_nodes = vec!["processor1", "processor2", "connector"];
let subgraph = graph.extract_subgraph(&amp;selected_nodes)?;

println!("Extracted subgraph:");
println!("  Nodes: {:?}", subgraph.nodes);
println!("  Internal connections: {}", subgraph.internal_connections.len());
println!("  External connections: {}", subgraph.external_connections.len());

// Create subgraph with configuration
let config = SubgraphConfig {
    include_metadata: true,
    preserve_external_connections: true,
    auto_add_ports: true,
};

let configured_subgraph = graph.extract_subgraph_with_config(&amp;selected_nodes, &amp;config)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="subgraph-analysis-2"><a class="header" href="#subgraph-analysis-2">Subgraph Analysis</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::SubgraphAnalysis;

let analysis = graph.analyze_subgraph(&amp;subgraph);

println!("Subgraph Analysis:");
println!("  Node count: {}", analysis.node_count);
println!("  Connection count: {}", analysis.connection_count);
println!("  Max depth: {}", analysis.max_depth);
println!("  Is cyclic: {}", analysis.is_cyclic);
println!("  Branching factor: {:.2}", analysis.branching_factor);
println!("  Complexity score: {:.2}", analysis.complexity_score);

// Detailed connectivity analysis
println!("  Entry points: {:?}", analysis.entry_points);
println!("  Exit points: {:?}", analysis.exit_points);
println!("  Internal clusters: {}", analysis.internal_clusters);
<span class="boring">}</span></code></pre></pre>
<h3 id="subgraph-operations-1"><a class="header" href="#subgraph-operations-1">Subgraph Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Clone subgraph
let cloned_subgraph = subgraph.clone();

// Merge subgraphs
let merged = Subgraph::merge(vec![subgraph1, subgraph2, subgraph3])?;

// Subtract subgraph (remove nodes)
let remainder = graph.subtract_subgraph(&amp;subgraph)?;

// Replace subgraph with optimized version
let optimized = optimize_subgraph(&amp;subgraph)?;
graph.replace_subgraph(&amp;subgraph, &amp;optimized)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="subgraph-templates"><a class="header" href="#subgraph-templates">Subgraph Templates</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{SubgraphTemplate, TemplateParameter};

// Create reusable subgraph template
let template = SubgraphTemplate {
    name: "data_processing_pipeline".to_string(),
    description: "Standard data processing pipeline".to_string(),
    nodes: subgraph.nodes.clone(),
    connections: subgraph.internal_connections.clone(),
    parameters: vec![
        TemplateParameter {
            name: "buffer_size".to_string(),
            param_type: "integer".to_string(),
            default_value: Some(json!(1024)),
            description: "Buffer size for data processing".to_string(),
        }
    ],
};

// Instantiate template with parameters
let instance_params = HashMap::from([
    ("buffer_size".to_string(), json!(2048))
]);

let instance = template.instantiate("pipeline_1", instance_params)?;
graph.add_subgraph_instance(instance)?;
<span class="boring">}</span></code></pre></pre>
<h2 id="graph-optimization"><a class="header" href="#graph-optimization">Graph Optimization</a></h2>
<h3 id="automatic-optimization"><a class="header" href="#automatic-optimization">Automatic Optimization</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{OptimizationConfig, OptimizationLevel};

// Basic optimization
let optimized_graph = graph.optimize()?;

// Advanced optimization with configuration
let optimization_config = OptimizationConfig {
    level: OptimizationLevel::Aggressive,
    remove_redundant_nodes: true,
    merge_compatible_nodes: true,
    optimize_connection_paths: true,
    reorder_for_cache_locality: true,
    minimize_communication_cost: true,
};

let optimized = graph.optimize_with_config(&amp;optimization_config)?;

// Apply optimizations in-place
graph.apply_optimizations(&amp;optimization_config)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="redundancy-elimination"><a class="header" href="#redundancy-elimination">Redundancy Elimination</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::RedundancyAnalysis;

// Find redundant nodes
let redundancy = graph.analyze_redundancy();

println!("Redundancy Analysis:");
for redundant in redundancy.redundant_nodes {
    println!("  Node '{}': {}", redundant.node, redundant.reason);
    
    match redundant.redundancy_type {
        RedundancyType::DuplicateFunction =&gt; {
            println!("    Can be merged with: {:?}", redundant.merge_candidates);
        }
        RedundancyType::NoOperation =&gt; {
            println!("    Performs no operation - can be removed");
        }
        RedundancyType::BypassableTransform =&gt; {
            println!("    Transform can be bypassed");
        }
    }
}

// Automatically remove redundant nodes
graph.remove_redundant_nodes()?;
<span class="boring">}</span></code></pre></pre>
<h3 id="node-fusion"><a class="header" href="#node-fusion">Node Fusion</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::FusionCandidate;

// Find nodes that can be fused together
let fusion_candidates = graph.find_fusion_candidates();

for candidate in fusion_candidates {
    println!("Fusion opportunity: {:?}", candidate.nodes);
    println!("  Estimated speedup: {:.1}x", candidate.estimated_speedup);
    println!("  Memory savings: {:.1} MB", candidate.memory_savings);
    
    // Apply fusion if beneficial
    if candidate.estimated_speedup &gt; 1.5 {
        graph.fuse_nodes(&amp;candidate.nodes, &amp;candidate.fusion_strategy)?;
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="connection-optimization"><a class="header" href="#connection-optimization">Connection Optimization</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::ConnectionOptimization;

// Optimize connection routing
let connection_opt = ConnectionOptimization {
    minimize_wire_length: true,
    reduce_crossings: true,
    bundle_parallel_connections: true,
    use_hierarchical_routing: true,
};

graph.optimize_connections(&amp;connection_opt)?;

// Find and eliminate unnecessary intermediate nodes
let bypass_candidates = graph.find_bypass_candidates();
for candidate in bypass_candidates {
    if candidate.is_safe_to_bypass() {
        graph.bypass_node(&amp;candidate.node)?;
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-tuning-4"><a class="header" href="#performance-tuning-4">Performance Tuning</a></h2>
<h3 id="memory-optimization"><a class="header" href="#memory-optimization">Memory Optimization</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{MemoryConfig, MemoryOptimization};

// Configure memory usage
let memory_config = MemoryConfig {
    node_pool_size: 1000,
    connection_pool_size: 5000,
    metadata_cache_size: 10 * 1024 * 1024, // 10 MB
    enable_lazy_loading: true,
    compress_metadata: true,
};

graph.configure_memory(&amp;memory_config)?;

// Apply memory optimizations
let memory_opt = MemoryOptimization {
    compact_node_storage: true,
    use_interned_strings: true,
    enable_copy_on_write: true,
    garbage_collect_threshold: 0.8,
};

graph.apply_memory_optimization(&amp;memory_opt)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="index-optimization"><a class="header" href="#index-optimization">Index Optimization</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::IndexConfig;

// Optimize internal indices for better performance
let index_config = IndexConfig {
    connection_index_type: IndexType::HashMap, // Fast lookups
    node_index_type: IndexType::BTreeMap,      // Ordered iteration
    spatial_index_enabled: true,               // For layout operations
    cache_frequently_accessed: true,
};

graph.rebuild_indices(&amp;index_config)?;

// Enable adaptive indexing
graph.enable_adaptive_indexing(true);
<span class="boring">}</span></code></pre></pre>
<h3 id="parallel-processing-setup"><a class="header" href="#parallel-processing-setup">Parallel Processing Setup</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{ParallelConfig, ThreadingModel};

// Configure parallel processing
let parallel_config = ParallelConfig {
    max_threads: num_cpus::get(),
    threading_model: ThreadingModel::WorkStealing,
    enable_parallel_analysis: true,
    parallel_layout_threshold: 100, // Use parallel layout for &gt;100 nodes
    chunk_size: 50,
};

graph.configure_parallel_processing(&amp;parallel_config)?;

// Enable parallel operations
graph.enable_parallel_operations(true);
<span class="boring">}</span></code></pre></pre>
<h3 id="benchmarking-and-profiling"><a class="header" href="#benchmarking-and-profiling">Benchmarking and Profiling</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{Benchmark, ProfileConfig};
use std::time::Instant;

// Benchmark graph operations
let benchmark = Benchmark::new(&amp;graph);

let results = benchmark.run_full_suite()?;
println!("Benchmark Results:");
println!("  Node addition: {:.2}Œºs", results.node_addition_time.as_micros());
println!("  Connection creation: {:.2}Œºs", results.connection_time.as_micros());
println!("  Cycle detection: {:.2}ms", results.cycle_detection_time.as_millis());
println!("  Layout calculation: {:.2}ms", results.layout_time.as_millis());
println!("  Validation: {:.2}ms", results.validation_time.as_millis());

// Profile specific operations
let profile_config = ProfileConfig {
    sample_rate: 1000, // Sample every 1000 operations
    track_memory: true,
    track_time: true,
    output_format: OutputFormat::Json,
};

let profiler = graph.create_profiler(&amp;profile_config)?;
profiler.start();

// Perform operations...
graph.add_node("test", "TestNode", None);
// ... more operations

let profile_results = profiler.stop_and_collect();
profile_results.save_to_file("graph_profile.json")?;
<span class="boring">}</span></code></pre></pre>
<h2 id="large-graph-handling"><a class="header" href="#large-graph-handling">Large Graph Handling</a></h2>
<h3 id="streaming-operations"><a class="header" href="#streaming-operations">Streaming Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{StreamingConfig, GraphStream};

// Handle very large graphs with streaming
let streaming_config = StreamingConfig {
    chunk_size: 1000,
    memory_limit: 100 * 1024 * 1024, // 100 MB
    enable_disk_spillover: true,
    compression_level: 6,
};

let graph_stream = GraphStream::new(streaming_config);

// Process graph in chunks
for chunk in graph_stream.process_in_chunks(&amp;large_graph) {
    let chunk_result = process_graph_chunk(chunk)?;
    graph_stream.accumulate_result(chunk_result);
}

let final_result = graph_stream.finalize()?;
<span class="boring">}</span></code></pre></pre>
<h3 id="lazy-loading"><a class="header" href="#lazy-loading">Lazy Loading</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::LazyGraph;

// Create lazy-loading graph for very large datasets
let lazy_graph = LazyGraph::from_file("massive_graph.json")?;

// Nodes and connections are loaded on demand
if let Some(node) = lazy_graph.get_node("some_node")? {
    // Node is loaded into memory only when accessed
    println!("Node component: {}", node.component);
}

// Preload specific subgraphs for better performance
lazy_graph.preload_subgraph(&amp;["critical_node_1", "critical_node_2"])?;
<span class="boring">}</span></code></pre></pre>
<h3 id="distributed-graph-processing"><a class="header" href="#distributed-graph-processing">Distributed Graph Processing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{DistributedGraph, NodePartition};

// Partition graph across multiple nodes
let partitions = graph.create_partitions(4)?; // 4 partitions

for (i, partition) in partitions.iter().enumerate() {
    println!("Partition {}: {} nodes", i, partition.nodes.len());
    
    // Deploy partition to worker node
    let worker_id = format!("worker_{}", i);
    deploy_partition_to_worker(&amp;worker_id, partition)?;
}

// Coordinate distributed operations
let distributed_graph = DistributedGraph::new(partitions);
let distributed_result = distributed_graph.execute_distributed_analysis().await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="advanced-analysis"><a class="header" href="#advanced-analysis">Advanced Analysis</a></h2>
<h3 id="machine-learning-integration"><a class="header" href="#machine-learning-integration">Machine Learning Integration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{MLFeatures, GraphEmbedding};

// Extract features for machine learning
let features = graph.extract_ml_features();

println!("Graph ML Features:");
println!("  Node features: {} dimensions", features.node_features.len());
println!("  Edge features: {} dimensions", features.edge_features.len());
println!("  Global features: {} dimensions", features.global_features.len());

// Generate graph embeddings
let embedding_config = EmbeddingConfig {
    embedding_size: 128,
    walk_length: 10,
    num_walks: 100,
    context_size: 5,
};

let embeddings = graph.generate_embeddings(&amp;embedding_config)?;

// Use embeddings for similarity analysis
let similar_nodes = embeddings.find_similar_nodes("reference_node", 5)?;
for (node, similarity) in similar_nodes {
    println!("Similar node: {} (similarity: {:.3})", node, similarity);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="pattern-mining"><a class="header" href="#pattern-mining">Pattern Mining</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{PatternMiner, FrequentPattern};

// Mine frequent subgraph patterns
let miner = PatternMiner::new();
let patterns = miner.mine_frequent_patterns(&amp;graph, 0.1)?; // 10% minimum support

for pattern in patterns {
    println!("Frequent pattern (support: {:.1}%):", pattern.support * 100.0);
    println!("  Nodes: {:?}", pattern.nodes);
    println!("  Connections: {:?}", pattern.connections);
    
    // Find all instances of this pattern
    let instances = graph.find_pattern_instances(&amp;pattern)?;
    println!("  Found in {} locations", instances.len());
}
<span class="boring">}</span></code></pre></pre>
<h3 id="anomaly-detection"><a class="header" href="#anomaly-detection">Anomaly Detection</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{AnomalyDetector, AnomalyType};

// Detect structural anomalies
let detector = AnomalyDetector::new();
let anomalies = detector.detect_anomalies(&amp;graph)?;

for anomaly in anomalies {
    match anomaly.anomaly_type {
        AnomalyType::UnusualDegree =&gt; {
            println!("Node '{}' has unusual connectivity: {} connections", 
                anomaly.node, anomaly.score);
        }
        AnomalyType::IsolatedCluster =&gt; {
            println!("Isolated cluster detected around node '{}'", anomaly.node);
        }
        AnomalyType::UnexpectedPattern =&gt; {
            println!("Unexpected pattern at node '{}' (novelty: {:.2})", 
                anomaly.node, anomaly.score);
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="graph-transformation"><a class="header" href="#graph-transformation">Graph Transformation</a></h2>
<h3 id="rule-based-transformations"><a class="header" href="#rule-based-transformations">Rule-Based Transformations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{TransformationRule, RuleEngine};

// Define transformation rules
let rule = TransformationRule {
    name: "optimize_serial_processors".to_string(),
    pattern: GraphPattern::parse("A -&gt; B -&gt; C where A.type == B.type == 'Processor'")?,
    replacement: GraphReplacement::parse("A+B+C -&gt; OptimizedProcessor")?,
    condition: |nodes| {
        // Custom condition logic
        nodes.iter().all(|n| n.metadata.get("parallelizable") == Some(&amp;json!(true)))
    },
};

// Apply transformation rules
let rule_engine = RuleEngine::new();
rule_engine.add_rule(rule);

let transformed_graph = rule_engine.apply_rules(&amp;graph)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="graph-morphing"><a class="header" href="#graph-morphing">Graph Morphing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{MorphingConfig, MorphingStrategy};

// Gradually transform graph structure
let morphing_config = MorphingConfig {
    strategy: MorphingStrategy::Gradual,
    steps: 10,
    preserve_semantics: true,
    target_layout: Some(target_positions),
};

let morphing_steps = graph.create_morphing_sequence(&amp;target_graph, &amp;morphing_config)?;

for (step, intermediate_graph) in morphing_steps.enumerate() {
    println!("Morphing step {}/{}", step + 1, morphing_config.steps);
    
    // Apply intermediate graph state
    apply_graph_state(&amp;intermediate_graph);
    
    // Optional: pause for animation
    std::thread::sleep(std::time::Duration::from_millis(100));
}
<span class="boring">}</span></code></pre></pre>
<h2 id="custom-extensions"><a class="header" href="#custom-extensions">Custom Extensions</a></h2>
<h3 id="plugin-system"><a class="header" href="#plugin-system">Plugin System</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{GraphPlugin, PluginConfig};

// Create custom graph plugin
struct MyCustomPlugin {
    config: PluginConfig,
}

impl GraphPlugin for MyCustomPlugin {
    fn initialize(&amp;mut self, graph: &amp;mut Graph) -&gt; Result&lt;(), GraphError&gt; {
        // Plugin initialization logic
        println!("Initializing custom plugin for graph: {}", graph.name);
        Ok(())
    }
    
    fn on_node_added(&amp;mut self, graph: &amp;Graph, node: &amp;GraphNode) {
        // Custom logic when nodes are added
        println!("Plugin: Node added: {}", node.id);
    }
    
    fn on_connection_added(&amp;mut self, graph: &amp;Graph, connection: &amp;GraphConnection) {
        // Custom logic when connections are added
        println!("Plugin: Connection added");
    }
    
    fn custom_analysis(&amp;self, graph: &amp;Graph) -&gt; CustomAnalysisResult {
        // Custom analysis implementation
        CustomAnalysisResult::new()
    }
}

// Register and use plugin
graph.register_plugin("my_plugin", Box::new(MyCustomPlugin::new()))?;
graph.enable_plugin("my_plugin")?;

// Call custom analysis
let custom_result = graph.call_plugin_analysis("my_plugin")?;
<span class="boring">}</span></code></pre></pre>
<h3 id="event-hooks"><a class="header" href="#event-hooks">Event Hooks</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{EventHook, HookPriority};

// Create custom event hook
let custom_hook = EventHook::new()
    .on_node_added(|graph, node| {
        println!("Custom hook: Node {} added to graph {}", node.id, graph.name);
    })
    .on_connection_added(|graph, connection| {
        println!("Custom hook: Connection added");
    })
    .with_priority(HookPriority::High);

// Register hook
graph.register_hook("custom_logger", custom_hook)?;

// Temporary hooks for specific operations
graph.with_temporary_hook("validation_hook", |graph| {
    // This hook only applies during this operation
    let validation = graph.validate_flow()?;
    Ok(validation)
})?;
<span class="boring">}</span></code></pre></pre>
<h2 id="error-recovery"><a class="header" href="#error-recovery">Error Recovery</a></h2>
<h3 id="automatic-error-recovery"><a class="header" href="#automatic-error-recovery">Automatic Error Recovery</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{ErrorRecovery, RecoveryStrategy};

// Configure automatic error recovery
let recovery_config = ErrorRecovery {
    strategy: RecoveryStrategy::Rollback,
    max_retries: 3,
    backup_frequency: 10, // Create backup every 10 operations
    auto_fix_common_issues: true,
};

graph.configure_error_recovery(&amp;recovery_config)?;

// Operations are automatically protected
match graph.add_connection("nonexistent", "out", "target", "in", None) {
    Err(e) =&gt; {
        // Graph automatically attempts recovery
        println!("Error occurred but graph recovered: {}", e);
    }
    Ok(_) =&gt; println!("Operation succeeded"),
}
<span class="boring">}</span></code></pre></pre>
<h3 id="manual-recovery-operations"><a class="header" href="#manual-recovery-operations">Manual Recovery Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create manual checkpoint
let checkpoint = graph.create_checkpoint("before_risky_operation")?;

// Perform risky operations
match risky_graph_operation(&amp;mut graph) {
    Ok(result) =&gt; {
        // Success - commit changes
        graph.commit_checkpoint(&amp;checkpoint)?;
        Ok(result)
    }
    Err(e) =&gt; {
        // Failure - rollback to checkpoint
        graph.rollback_to_checkpoint(&amp;checkpoint)?;
        Err(e)
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="integration-patterns-1"><a class="header" href="#integration-patterns-1">Integration Patterns</a></h2>
<h3 id="event-sourcing"><a class="header" href="#event-sourcing">Event Sourcing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{EventStore, GraphEvent};

// Set up event sourcing
let event_store = EventStore::new("graph_events.log")?;
graph.enable_event_sourcing(&amp;event_store)?;

// All graph changes are automatically logged
graph.add_node("event_sourced", "EventNode", None);
// Event is automatically persisted

// Replay events to reconstruct graph state
let events = event_store.read_events_from(timestamp)?;
let reconstructed_graph = Graph::replay_events(events)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="cqrs-pattern"><a class="header" href="#cqrs-pattern">CQRS Pattern</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::graph::{CommandHandler, QueryHandler};

// Separate command and query responsibilities
let command_handler = CommandHandler::new(&amp;mut graph);
let query_handler = QueryHandler::new(&amp;graph);

// Commands modify state
command_handler.execute(AddNodeCommand {
    id: "cmd_node".to_string(),
    component: "CommandNode".to_string(),
    metadata: None,
})?;

// Queries read state (potentially from optimized read models)
let node_info = query_handler.get_node_info("cmd_node")?;
let analysis = query_handler.analyze_connectivity("cmd_node")?;
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-summary"><a class="header" href="#best-practices-summary">Best Practices Summary</a></h2>
<h3 id="performance-best-practices"><a class="header" href="#performance-best-practices">Performance Best Practices</a></h3>
<ol>
<li><strong>Use appropriate data structures</strong>: Choose indices based on access patterns</li>
<li><strong>Enable lazy loading</strong>: For large graphs, load data on demand</li>
<li><strong>Configure memory limits</strong>: Prevent memory exhaustion</li>
<li><strong>Use parallel processing</strong>: Enable for CPU-intensive operations</li>
<li><strong>Cache analysis results</strong>: Store expensive computations</li>
</ol>
<h3 id="scalability-best-practices"><a class="header" href="#scalability-best-practices">Scalability Best Practices</a></h3>
<ol>
<li><strong>Partition large graphs</strong>: Distribute across multiple nodes</li>
<li><strong>Stream large operations</strong>: Process data in chunks</li>
<li><strong>Use compression</strong>: Reduce memory and storage requirements</li>
<li><strong>Implement backpressure</strong>: Control data flow rates</li>
<li><strong>Monitor resource usage</strong>: Track memory and CPU consumption</li>
</ol>
<h3 id="maintainability-best-practices"><a class="header" href="#maintainability-best-practices">Maintainability Best Practices</a></h3>
<ol>
<li><strong>Use version control</strong>: Track graph schema changes</li>
<li><strong>Implement proper error handling</strong>: Handle edge cases gracefully</li>
<li><strong>Document custom extensions</strong>: Maintain clear plugin documentation</li>
<li><strong>Use consistent naming</strong>: Follow naming conventions</li>
<li><strong>Implement comprehensive testing</strong>: Test all graph operations</li>
</ol>
<h2 id="next-steps-18"><a class="header" href="#next-steps-18">Next Steps</a></h2>
<ul>
<li><a href="api/graph/../../tutorials/building-visual-editor.html">Building Visual Editors</a> - Complete tutorial</li>
<li><a href="api/graph/../../tutorials/performance-optimization.html">Performance Optimization</a> - Advanced optimization techniques</li>
<li><a href="api/graph/creating-graphs.html">Creating Graph</a> - Basic operations</li>
<li><a href="api/graph/analysis.html">Graph Analysis</a> - Validation and analysis</li>
<li><a href="api/graph/layout.html">Layout System</a> - Positioning and visualization</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="workspace-discovery"><a class="header" href="#workspace-discovery">Workspace Discovery</a></h1>
<p>Learn how to automatically discover and load graph files in multi-graph workspaces.</p>
<h2 id="overview-6"><a class="header" href="#overview-6">Overview</a></h2>
<p>Workspace discovery enables:</p>
<ul>
<li><strong>Automatic graph discovery</strong>: Find all <code>*.graph.json</code> and <code>*.graph.yaml</code> files recursively</li>
<li><strong>Folder-based namespacing</strong>: Use directory structure as natural namespaces</li>
<li><strong>Clean instantiation</strong>: Load discovered graphs into memory with proper isolation</li>
<li><strong>Rich metadata</strong>: Inject discovery information and workspace context</li>
<li><strong>Flexible configuration</strong>: Control discovery patterns and exclusions</li>
</ul>
<h2 id="basic-discovery"><a class="header" href="#basic-discovery">Basic Discovery</a></h2>
<h3 id="simple-workspace-discovery-1"><a class="header" href="#simple-workspace-discovery-1">Simple Workspace Discovery</a></h3>
<p>Discover all graphs in a workspace directory:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::workspace::{WorkspaceDiscovery, WorkspaceConfig};

// Basic workspace discovery
let config = WorkspaceConfig::default();
let discovery = WorkspaceDiscovery::new(config);

// Discover all graphs in current directory
let workspace = discovery.discover_workspace().await?;

println!("üéâ Discovered {} graphs across {} namespaces", 
    workspace.graphs.len(), 
    workspace.namespaces.len()
);

// Print discovered graphs
for graph_meta in &amp;workspace.graphs {
    let graph_name = graph_meta.graph.properties
        .get("name")
        .and_then(|v| v.as_str())
        .unwrap_or("unnamed");
    
    println!("üìà Graph: {} (namespace: {})", 
        graph_name,
        graph_meta.discovered_namespace
    );
}
<span class="boring">}</span></code></pre></pre>
<h3 id="custom-discovery-configuration"><a class="header" href="#custom-discovery-configuration">Custom Discovery Configuration</a></h3>
<p>Configure discovery behavior for your needs:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::path::PathBuf;

let workspace_config = WorkspaceConfig {
    root_path: PathBuf::from("./my_workspace"),
    graph_patterns: vec![
        "**/*.graph.json".to_string(),
        "**/*.graph.yaml".to_string(),
        "**/*.graph.yml".to_string(),
    ],
    excluded_paths: vec![
        "**/node_modules/**".to_string(),
        "**/target/**".to_string(),
        "**/.git/**".to_string(),
        "**/test/**".to_string(),
        "**/.*/**".to_string(),
    ],
    max_depth: Some(8),
    namespace_strategy: NamespaceStrategy::FolderStructure,
};

let discovery = WorkspaceDiscovery::new(workspace_config);
let workspace = discovery.discover_workspace().await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="namespace-strategies"><a class="header" href="#namespace-strategies">Namespace Strategies</a></h2>
<h3 id="1-folder-structure-default"><a class="header" href="#1-folder-structure-default">1. Folder Structure (Default)</a></h3>
<p>Use directory structure as hierarchical namespaces:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = WorkspaceConfig {
    namespace_strategy: NamespaceStrategy::FolderStructure,
    ..Default::default()
};

// Example structure:
// data/ingestion/collector.graph.json    ‚Üí namespace: "data/ingestion"
// data/processing/transformer.graph.json ‚Üí namespace: "data/processing"  
// ml/training/trainer.graph.json         ‚Üí namespace: "ml/training"
// ml/inference/predictor.graph.json      ‚Üí namespace: "ml/inference"
<span class="boring">}</span></code></pre></pre>
<h3 id="2-flattened-namespace"><a class="header" href="#2-flattened-namespace">2. Flattened Namespace</a></h3>
<p>Put all graphs in the root namespace:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = WorkspaceConfig {
    namespace_strategy: NamespaceStrategy::Flatten,
    ..Default::default()
};

// All graphs get namespace: "" (root)
<span class="boring">}</span></code></pre></pre>
<h3 id="3-file-based-prefixes"><a class="header" href="#3-file-based-prefixes">3. File-Based Prefixes</a></h3>
<p>Use filename prefixes as namespaces:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = WorkspaceConfig {
    namespace_strategy: NamespaceStrategy::FileBasedPrefix,
    ..Default::default()
};

// Examples:
// ml_trainer.graph.json     ‚Üí namespace: "ml"
// data_processor.graph.json ‚Üí namespace: "data"
// auth_service.graph.json   ‚Üí namespace: "auth"
<span class="boring">}</span></code></pre></pre>
<h3 id="4-custom-namespace-functions"><a class="header" href="#4-custom-namespace-functions">4. Custom Namespace Functions</a></h3>
<p>Define custom namespacing logic:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::workspace::NamespaceStrategy;

// Semantic-based namespacing
let config = WorkspaceConfig {
    namespace_strategy: NamespaceStrategy::custom(
        "semantic_based",
        Some(serde_json::json!({
            "rules": {
                "ml": ["model", "train", "predict"],
                "data": ["ingest", "process", "transform"],
                "api": ["service", "endpoint", "rest"]
            }
        }))
    )?,
    ..Default::default()
};

// Graphs are organized by semantic content
<span class="boring">}</span></code></pre></pre>
<h2 id="discovery-results"><a class="header" href="#discovery-results">Discovery Results</a></h2>
<h3 id="workspace-collection-structure"><a class="header" href="#workspace-collection-structure">Workspace Collection Structure</a></h3>
<p>The discovery process returns a comprehensive workspace collection:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(Debug)]
pub struct WorkspaceCollection {
    pub graphs: Vec&lt;GraphWithMetadata&gt;,
    pub namespaces: HashMap&lt;String, NamespaceInfo&gt;,
    pub dependency_analysis: DependencyAnalysis,
    pub workspace_root: PathBuf,
}

// Access discovered information
let workspace = discovery.discover_workspace().await?;

// Individual graphs with metadata
for graph_meta in &amp;workspace.graphs {
    println!("Graph: {}", graph_meta.file_info.graph_name);
    println!("  Path: {}", graph_meta.file_info.path.display());
    println!("  Namespace: {}", graph_meta.discovered_namespace);
    println!("  Size: {} bytes", graph_meta.file_info.size_bytes);
    println!("  Modified: {:?}", graph_meta.file_info.modified);
}

// Namespace organization
for (namespace, info) in &amp;workspace.namespaces {
    println!("üìÅ Namespace: {} ({} graphs)", namespace, info.graph_count);
    for graph_name in &amp;info.graphs {
        println!("  üìà {}", graph_name);
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="graph-metadata-enhancement"><a class="header" href="#graph-metadata-enhancement">Graph Metadata Enhancement</a></h3>
<p>Discovery automatically enhances graphs with workspace metadata:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Original graph properties are preserved and enhanced
let enhanced_graph = &amp;workspace.graphs[0].graph;

// Injected workspace metadata
let workspace_namespace = enhanced_graph.properties
    .get("workspace_namespace")
    .and_then(|v| v.as_str());

let workspace_path = enhanced_graph.properties
    .get("workspace_path")
    .and_then(|v| v.as_str());

let discovery_timestamp = enhanced_graph.properties
    .get("discovery_timestamp")
    .and_then(|v| v.as_str());

println!("Discovered at: {}", discovery_timestamp.unwrap_or("unknown"));
<span class="boring">}</span></code></pre></pre>
<h2 id="advanced-discovery"><a class="header" href="#advanced-discovery">Advanced Discovery</a></h2>
<h3 id="filtered-discovery"><a class="header" href="#filtered-discovery">Filtered Discovery</a></h3>
<p>Discover specific types of graphs:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::workspace::DiscoveryFilter;

let filter = DiscoveryFilter {
    name_patterns: vec!["*processor*".to_string(), "*trainer*".to_string()],
    capability_requirements: vec!["ml_training".to_string(), "data_processing".to_string()],
    min_file_size: Some(1024), // At least 1KB
    max_file_age_days: Some(30), // Modified within 30 days
};

let filtered_workspace = discovery.discover_workspace_with_filter(filter).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="incremental-discovery"><a class="header" href="#incremental-discovery">Incremental Discovery</a></h3>
<p>Update workspace with only changed files:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Initial discovery
let workspace = discovery.discover_workspace().await?;

// Later, discover only changes
let changes = discovery.discover_changes_since(&amp;workspace).await?;

println!("üìä Changes since last discovery:");
println!("  Added: {} graphs", changes.added.len());
println!("  Modified: {} graphs", changes.modified.len());
println!("  Removed: {} graphs", changes.removed.len());

// Apply changes to workspace
let updated_workspace = discovery.apply_changes(workspace, changes).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="parallel-discovery"><a class="header" href="#parallel-discovery">Parallel Discovery</a></h3>
<p>Speed up discovery with parallel processing:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = WorkspaceConfig {
    parallel_discovery: true,
    max_concurrent_loads: 8,
    ..Default::default()
};

let discovery = WorkspaceDiscovery::new(config);

// Discovery happens in parallel across multiple threads
let workspace = discovery.discover_workspace().await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="dependency-analysis"><a class="header" href="#dependency-analysis">Dependency Analysis</a></h2>
<h3 id="automatic-dependency-detection"><a class="header" href="#automatic-dependency-detection">Automatic Dependency Detection</a></h3>
<p>Discovery analyzes dependencies between graphs:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let workspace = discovery.discover_workspace().await?;
let analysis = &amp;workspace.dependency_analysis;

// View dependency relationships
for dep in &amp;analysis.dependencies {
    println!("üîó {} depends on {} ({})", 
        dep.dependent_graph,
        dep.dependency_graph,
        if dep.required { "required" } else { "optional" }
    );
}

// Check for circular dependencies
if analysis.has_circular_dependencies() {
    println!("‚ö†Ô∏è  Circular dependencies detected!");
    for cycle in analysis.get_circular_dependencies() {
        println!("  üîÑ {}", cycle.join(" ‚Üí "));
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="interface-analysis"><a class="header" href="#interface-analysis">Interface Analysis</a></h3>
<p>Analyze provided and required interfaces:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Graphs that provide interfaces
for interface in &amp;analysis.provided_interfaces {
    println!("üì§ {} provides interface: {} ({})", 
        interface.graph_name,
        interface.interface_name,
        interface.interface_definition.description.as_ref().unwrap_or(&amp;"No description".to_string())
    );
}

// Graphs that require interfaces
for interface in &amp;analysis.required_interfaces {
    println!("üì• {} requires interface: {} ({})", 
        interface.graph_name,
        interface.interface_name,
        interface.interface_definition.description.as_ref().unwrap_or(&amp;"No description".to_string())
    );
}

// Find interface compatibility
let compatibility_report = analysis.analyze_interface_compatibility();
for incompatibility in compatibility_report.mismatches {
    println!("‚ùå Interface mismatch: {} ‚Üí {}", 
        incompatibility.provider,
        incompatibility.consumer
    );
}
<span class="boring">}</span></code></pre></pre>
<h2 id="error-handling-11"><a class="header" href="#error-handling-11">Error Handling</a></h2>
<h3 id="discovery-errors-1"><a class="header" href="#discovery-errors-1">Discovery Errors</a></h3>
<p>Handle common discovery issues:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>match discovery.discover_workspace().await {
    Ok(workspace) =&gt; {
        println!("‚úÖ Discovery successful: {} graphs", workspace.graphs.len());
    },
    Err(e) =&gt; {
        match e {
            DiscoveryError::GlobError(pattern_err) =&gt; {
                eprintln!("‚ùå Invalid glob pattern: {}", pattern_err);
            },
            DiscoveryError::LoadError(path, reason) =&gt; {
                eprintln!("‚ùå Failed to load {}: {}", path.display(), reason);
            },
            DiscoveryError::UnsupportedFormat(path) =&gt; {
                eprintln!("‚ùå Unsupported file format: {}", path.display());
            },
            DiscoveryError::IoError(io_err) =&gt; {
                eprintln!("‚ùå IO error during discovery: {}", io_err);
            },
            _ =&gt; {
                eprintln!("‚ùå Discovery failed: {}", e);
            }
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="resilient-discovery"><a class="header" href="#resilient-discovery">Resilient Discovery</a></h3>
<p>Continue discovery even when some files fail to load:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = WorkspaceConfig {
    continue_on_load_error: true,
    max_load_errors: 5,
    ..Default::default()
};

let discovery = WorkspaceDiscovery::new(config);
let result = discovery.discover_workspace().await?;

// Check for partial failures
if !result.load_errors.is_empty() {
    println!("‚ö†Ô∏è  {} files failed to load:", result.load_errors.len());
    for error in &amp;result.load_errors {
        println!("  ‚ùå {}: {}", error.path.display(), error.reason);
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-optimization-4"><a class="header" href="#performance-optimization-4">Performance Optimization</a></h2>
<h3 id="caching-discovery-results"><a class="header" href="#caching-discovery-results">Caching Discovery Results</a></h3>
<p>Cache discovery results to speed up subsequent runs:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::workspace::DiscoveryCache;

let cache = DiscoveryCache::new("./workspace_cache");
let discovery = WorkspaceDiscovery::with_cache(config, cache);

// First run: Full discovery and cache
let workspace = discovery.discover_workspace().await?;

// Subsequent runs: Load from cache if nothing changed
let cached_workspace = discovery.discover_workspace().await?; // Much faster!
<span class="boring">}</span></code></pre></pre>
<h3 id="memory-management-5"><a class="header" href="#memory-management-5">Memory Management</a></h3>
<p>Configure memory usage for large workspaces:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = WorkspaceConfig {
    lazy_load_graphs: true,        // Load graph content on demand
    max_memory_usage_mb: 512,      // Limit memory usage
    graph_content_cache_size: 100, // Cache up to 100 graph contents
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h3 id="progress-monitoring"><a class="header" href="#progress-monitoring">Progress Monitoring</a></h3>
<p>Monitor discovery progress for large workspaces:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::workspace::DiscoveryProgress;

let (discovery, mut progress_rx) = WorkspaceDiscovery::with_progress(config);

// Start discovery in background
let workspace_future = discovery.discover_workspace();

// Monitor progress
tokio::spawn(async move {
    while let Some(progress) = progress_rx.recv().await {
        match progress {
            DiscoveryProgress::FilesFound(count) =&gt; {
                println!("üìÅ Found {} graph files", count);
            },
            DiscoveryProgress::LoadingFile(path) =&gt; {
                println!("üìà Loading {}", path.display());
            },
            DiscoveryProgress::NamespaceCreated(namespace, graph_count) =&gt; {
                println!("üìÇ Namespace '{}' with {} graphs", namespace, graph_count);
            },
            DiscoveryProgress::Complete(total_graphs) =&gt; {
                println!("‚úÖ Discovery complete: {} graphs", total_graphs);
                break;
            }
        }
    }
});

// Wait for completion
let workspace = workspace_future.await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="integration-examples-1"><a class="header" href="#integration-examples-1">Integration Examples</a></h2>
<h3 id="example-workspace-structure"><a class="header" href="#example-workspace-structure">Example Workspace Structure</a></h3>
<pre><code>my_workspace/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api_collector.graph.json      ‚Üí namespace: data/ingestion
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ file_reader.graph.yaml        ‚Üí namespace: data/ingestion
‚îÇ   ‚îú‚îÄ‚îÄ processing/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cleaner.graph.json            ‚Üí namespace: data/processing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transformer.graph.json        ‚Üí namespace: data/processing
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ validator.graph.yaml          ‚Üí namespace: data/processing
‚îÇ   ‚îî‚îÄ‚îÄ storage/
‚îÇ       ‚îú‚îÄ‚îÄ database_writer.graph.json    ‚Üí namespace: data/storage
‚îÇ       ‚îî‚îÄ‚îÄ cache_manager.graph.yaml      ‚Üí namespace: data/storage
‚îú‚îÄ‚îÄ ml/
‚îÇ   ‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_trainer.graph.json      ‚Üí namespace: ml/training
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ feature_engineer.graph.yaml   ‚Üí namespace: ml/training
‚îÇ   ‚îú‚îÄ‚îÄ inference/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predictor.graph.json          ‚Üí namespace: ml/inference
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ batch_scorer.graph.json       ‚Üí namespace: ml/inference
‚îÇ   ‚îî‚îÄ‚îÄ evaluation/
‚îÇ       ‚îî‚îÄ‚îÄ model_evaluator.graph.yaml    ‚Üí namespace: ml/evaluation
‚îú‚îÄ‚îÄ monitoring/
‚îÇ   ‚îú‚îÄ‚îÄ metrics.graph.json                ‚Üí namespace: monitoring
‚îÇ   ‚îú‚îÄ‚îÄ alerts.graph.yaml                 ‚Üí namespace: monitoring
‚îÇ   ‚îî‚îÄ‚îÄ dashboard.graph.json              ‚Üí namespace: monitoring
‚îî‚îÄ‚îÄ shared/
    ‚îú‚îÄ‚îÄ logging.graph.yaml                 ‚Üí namespace: shared
    ‚îú‚îÄ‚îÄ auth.graph.json                    ‚Üí namespace: shared
    ‚îî‚îÄ‚îÄ config.graph.json                  ‚Üí namespace: shared
</code></pre>
<h3 id="complete-discovery-example"><a class="header" href="#complete-discovery-example">Complete Discovery Example</a></h3>
<pre><pre class="playground"><code class="language-rust">use reflow_network::multi_graph::workspace::*;
use std::path::PathBuf;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Configure discovery
    let config = WorkspaceConfig {
        root_path: PathBuf::from("./my_workspace"),
        graph_patterns: vec![
            "**/*.graph.json".to_string(),
            "**/*.graph.yaml".to_string(),
        ],
        excluded_paths: vec![
            "**/test/**".to_string(),
            "**/.*/**".to_string(),
        ],
        max_depth: Some(6),
        namespace_strategy: NamespaceStrategy::FolderStructure,
    };
    
    // Perform discovery
    println!("üîç Starting workspace discovery...");
    let discovery = WorkspaceDiscovery::new(config);
    let workspace = discovery.discover_workspace().await?;
    
    // Print results
    println!("\nüìä Discovery Results");
    println!("================");
    println!("üìÅ Workspace root: {}", workspace.workspace_root.display());
    println!("üéØ Total graphs: {}", workspace.graphs.len());
    println!("üìÇ Namespaces: {}", workspace.namespaces.len());
    
    // Show namespace breakdown
    println!("\nüìÇ Namespace Organization:");
    for (namespace, info) in &amp;workspace.namespaces {
        println!("  üìÅ {} ({} graphs)", namespace, info.graphs.len());
        for graph_name in &amp;info.graphs {
            println!("    üìà {}", graph_name);
        }
    }
    
    // Show dependencies
    println!("\nüîó Dependencies:");
    for dep in &amp;workspace.dependency_analysis.dependencies {
        println!("  {} ‚Üí {} ({})", 
            dep.dependent_graph,
            dep.dependency_graph,
            if dep.required { "required" } else { "optional" }
        );
    }
    
    println!("\n‚úÖ Workspace discovery completed successfully!");
    
    Ok(())
}</code></pre></pre>
<h2 id="best-practices-13"><a class="header" href="#best-practices-13">Best Practices</a></h2>
<h3 id="1-organize-by-function"><a class="header" href="#1-organize-by-function">1. Organize by Function</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Functional organization
data/
  ingestion/     # Data collection graphs
  processing/    # Data transformation graphs  
  storage/       # Data persistence graphs
ml/
  training/      # ML training graphs
  inference/     # ML prediction graphs
  evaluation/    # ML validation graphs
<span class="boring">}</span></code></pre></pre>
<h3 id="2-consistent-naming"><a class="header" href="#2-consistent-naming">2. Consistent Naming</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Descriptive, consistent names
api_data_collector.graph.json
stream_data_processor.graph.json
ml_model_trainer.graph.json
postgres_storage_writer.graph.json

// Avoid: Generic names
collector.graph.json
processor.graph.json
trainer.graph.json
writer.graph.json
<span class="boring">}</span></code></pre></pre>
<h3 id="3-graph-documentation"><a class="header" href="#3-graph-documentation">3. Graph Documentation</a></h3>
<p>Include metadata in graph files for better discovery:</p>
<pre><code class="language-json">{
  "properties": {
    "name": "data_processor",
    "description": "Processes incoming data streams with validation and transformation",
    "version": "1.2.0",
    "tags": ["data", "processing", "validation"],
    "capabilities": ["stream_processing", "data_validation"],
    "dependencies": ["data_collector"]
  }
}
</code></pre>
<h2 id="next-steps-19"><a class="header" href="#next-steps-19">Next Steps</a></h2>
<ul>
<li><a href="api/multi-graph/graph-composition.html">Graph Composition</a> - Combine discovered graphs</li>
<li><a href="api/multi-graph/dependency-resolution.html">Dependency Resolution</a> - Handle graph dependencies</li>
<li><a href="api/multi-graph/../../tutorials/multi-graph-workspace.html">Tutorial: Multi-Graph Workspace</a></li>
</ul>
<h2 id="related-documentation"><a class="header" href="#related-documentation">Related Documentation</a></h2>
<ul>
<li><a href="api/multi-graph/../../architecture/multi-graph-composition.html">Architecture: Multi-Graph Composition</a></li>
<li><a href="api/multi-graph/../../architecture/graph-system.html">Graph System Overview</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="graph-composition"><a class="header" href="#graph-composition">Graph Composition</a></h1>
<p>Learn how to compose multiple discovered graphs into unified workflows.</p>
<h2 id="overview-7"><a class="header" href="#overview-7">Overview</a></h2>
<p>Graph composition allows you to:</p>
<ul>
<li><strong>Combine multiple graphs</strong>: Merge discovered graphs into a single executable network</li>
<li><strong>Create cross-graph connections</strong>: Connect processes across different graph namespaces</li>
<li><strong>Resolve dependencies</strong>: Handle inter-graph dependencies automatically</li>
<li><strong>Share resources</strong>: Create shared processes accessible by multiple graphs</li>
<li><strong>Build unified workflows</strong>: Transform modular graphs into cohesive pipelines</li>
</ul>
<h2 id="basic-composition"><a class="header" href="#basic-composition">Basic Composition</a></h2>
<h3 id="using-graphcomposer"><a class="header" href="#using-graphcomposer">Using GraphComposer</a></h3>
<p>The primary tool for composing graphs:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::{GraphComposer, GraphComposition, GraphSource};

// Create composer
let mut composer = GraphComposer::new();

// Define composition
let composition = GraphComposition {
    sources: vec![
        GraphSource::JsonFile("data/collector.graph.json".to_string()),
        GraphSource::JsonFile("data/processor.graph.json".to_string()),
        GraphSource::JsonFile("ml/trainer.graph.json".to_string()),
    ],
    connections: vec![
        // Cross-graph connections defined here
    ],
    shared_resources: vec![
        // Shared processes defined here
    ],
    properties: HashMap::from([
        ("name".to_string(), serde_json::json!("composed_workflow")),
        ("version".to_string(), serde_json::json!("1.0.0")),
    ]),
    case_sensitive: Some(false),
    metadata: None,
};

// Compose into unified graph
let composed_graph = composer.compose_graphs(composition).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="from-workspace-discovery"><a class="header" href="#from-workspace-discovery">From Workspace Discovery</a></h3>
<p>Compose directly from discovered workspaces:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::workspace::{WorkspaceDiscovery, WorkspaceConfig};

// Discover workspace
let discovery = WorkspaceDiscovery::new(WorkspaceConfig::default());
let workspace = discovery.discover_workspace().await?;

// Convert to composition sources
let sources: Vec&lt;GraphSource&gt; = workspace.graphs
    .into_iter()
    .map(|g| GraphSource::GraphExport(g.graph))
    .collect();

let composition = GraphComposition {
    sources,
    connections: vec![], // Will be populated
    shared_resources: vec![],
    properties: HashMap::from([
        ("name".to_string(), serde_json::json!("workspace_composition")),
    ]),
    case_sensitive: Some(false),
    metadata: None,
};

let composed_graph = composer.compose_graphs(composition).await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="cross-graph-connections"><a class="header" href="#cross-graph-connections">Cross-Graph Connections</a></h2>
<h3 id="manual-connection-definition"><a class="header" href="#manual-connection-definition">Manual Connection Definition</a></h3>
<p>Create explicit connections between graphs:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::{CompositionConnection, CompositionEndpoint};

let composition = GraphComposition {
    sources: vec![
        GraphSource::JsonFile("data/collector.graph.json".to_string()),
        GraphSource::JsonFile("ml/trainer.graph.json".to_string()),
    ],
    connections: vec![
        CompositionConnection {
            from: CompositionEndpoint {
                process: "data/collector".to_string(),  // Namespaced process name
                port: "Output".to_string(),
                index: None,
            },
            to: CompositionEndpoint {
                process: "ml/feature_engineer".to_string(),
                port: "Input".to_string(),
                index: None,
            },
            metadata: Some(HashMap::from([
                ("description".to_string(), serde_json::json!("Data pipeline to ML training")),
            ])),
        },
    ],
    // ... rest of composition
};
<span class="boring">}</span></code></pre></pre>
<h3 id="using-connection-builder"><a class="header" href="#using-connection-builder">Using Connection Builder</a></h3>
<p>Programmatically build connections:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::GraphConnectionBuilder;

// First, discover workspace to get graph information
let workspace = discovery.discover_workspace().await?;

// Create connection builder
let mut connection_builder = GraphConnectionBuilder::new(workspace);

// Build connections using fluent API
connection_builder
    .connect(
        "collector",       // from graph
        "data_collector", // from process
        "Output",         // from port
        "processor",      // to graph
        "data_cleaner",   // to process
        "Input"           // to port
    )?
    .connect(
        "processor",
        "data_transformer",
        "Output",
        "trainer",
        "feature_engineer",
        "Input"
    )?;

// Get connections for composition
let connections = connection_builder.build();

let composition = GraphComposition {
    sources: workspace.graphs.into_iter()
        .map(|g| GraphSource::GraphExport(g.graph))
        .collect(),
    connections,
    // ... rest of composition
};
<span class="boring">}</span></code></pre></pre>
<h3 id="interface-based-connections-1"><a class="header" href="#interface-based-connections-1">Interface-Based Connections</a></h3>
<p>Connect using declared interfaces:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Connect using interface definitions from graphs
connection_builder
    .connect_interface(
        "processor",           // from graph
        "clean_data_output",   // from interface
        "trainer",             // to graph
        "training_data_input"  // to interface
    )?
    .connect_interface(
        "trainer",
        "model_output",
        "predictor",
        "model_input"
    )?;

let connections = connection_builder.build();
<span class="boring">}</span></code></pre></pre>
<h2 id="shared-resources"><a class="header" href="#shared-resources">Shared Resources</a></h2>
<h3 id="defining-shared-processes"><a class="header" href="#defining-shared-processes">Defining Shared Processes</a></h3>
<p>Create processes accessible by multiple graphs:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::SharedResource;

let composition = GraphComposition {
    sources: vec![
        // Multiple graphs that need logging
        GraphSource::JsonFile("data/processor.graph.json".to_string()),
        GraphSource::JsonFile("ml/trainer.graph.json".to_string()),
        GraphSource::JsonFile("api/service.graph.json".to_string()),
    ],
    shared_resources: vec![
        SharedResource {
            name: "shared_logger".to_string(),
            component: "LoggerActor".to_string(),
            metadata: Some(HashMap::from([
                ("log_level".to_string(), serde_json::json!("info")),
                ("output_file".to_string(), serde_json::json!("workflow.log")),
            ])),
        },
        SharedResource {
            name: "config_manager".to_string(),
            component: "ConfigManagerActor".to_string(),
            metadata: Some(HashMap::from([
                ("config_file".to_string(), serde_json::json!("config.yaml")),
            ])),
        },
    ],
    connections: vec![
        // Connect graphs to shared resources
        CompositionConnection {
            from: CompositionEndpoint {
                process: "data/processor".to_string(),
                port: "LogOutput".to_string(),
                index: None,
            },
            to: CompositionEndpoint {
                process: "shared_logger".to_string(),
                port: "Input".to_string(),
                index: None,
            },
            metadata: None,
        },
        // More connections to shared logger...
    ],
    // ... rest of composition
};
<span class="boring">}</span></code></pre></pre>
<h3 id="resource-sharing-patterns"><a class="header" href="#resource-sharing-patterns">Resource Sharing Patterns</a></h3>
<p>Common patterns for shared resources:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// 1. Centralized Logging
let shared_logging = SharedResource {
    name: "central_logger".to_string(),
    component: "CentralLoggerActor".to_string(),
    metadata: Some(HashMap::from([
        ("aggregation".to_string(), serde_json::json!(true)),
        ("format".to_string(), serde_json::json!("json")),
    ])),
};

// 2. Configuration Management
let config_service = SharedResource {
    name: "config_service".to_string(),
    component: "ConfigServiceActor".to_string(),
    metadata: Some(HashMap::from([
        ("watch_changes".to_string(), serde_json::json!(true)),
    ])),
};

// 3. Metrics Collection
let metrics_collector = SharedResource {
    name: "metrics_collector".to_string(),
    component: "MetricsCollectorActor".to_string(),
    metadata: Some(HashMap::from([
        ("export_interval".to_string(), serde_json::json!(30)),
        ("export_format".to_string(), serde_json::json!("prometheus")),
    ])),
};

// 4. Authentication Service
let auth_service = SharedResource {
    name: "auth_service".to_string(),
    component: "AuthServiceActor".to_string(),
    metadata: Some(HashMap::from([
        ("token_expiry".to_string(), serde_json::json!(3600)),
        ("jwt_secret".to_string(), serde_json::json!("${JWT_SECRET}")),
    ])),
};
<span class="boring">}</span></code></pre></pre>
<h2 id="namespace-management-1"><a class="header" href="#namespace-management-1">Namespace Management</a></h2>
<h3 id="automatic-namespacing"><a class="header" href="#automatic-namespacing">Automatic Namespacing</a></h3>
<p>Graphs are automatically namespaced during composition:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Original process names in individual graphs:
// collector.graph.json: "data_collector"
// processor.graph.json: "data_processor"  
// trainer.graph.json: "model_trainer"

// After composition with namespace prefixes:
// "data/data_collector"     (from collector graph in data/ folder)
// "data/data_processor"     (from processor graph in data/ folder)
// "ml/model_trainer"        (from trainer graph in ml/ folder)

// Access in composed graph:
let composed_export = composed_graph.export();
assert!(composed_export.processes.contains_key("data/data_collector"));
assert!(composed_export.processes.contains_key("ml/model_trainer"));
<span class="boring">}</span></code></pre></pre>
<h3 id="custom-namespace-mapping"><a class="header" href="#custom-namespace-mapping">Custom Namespace Mapping</a></h3>
<p>Control how namespaces are applied:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::{NamespaceMapping, NamespaceStrategy};

let namespace_mapping = NamespaceMapping {
    graph_mappings: HashMap::from([
        ("collector".to_string(), "ingestion".to_string()),
        ("processor".to_string(), "processing".to_string()),
        ("trainer".to_string(), "machine_learning".to_string()),
    ]),
    strategy: NamespaceStrategy::CustomMapping,
    collision_resolution: CollisionResolution::Prefix,
};

let composer = GraphComposer::with_namespace_mapping(namespace_mapping);
<span class="boring">}</span></code></pre></pre>
<h2 id="advanced-composition"><a class="header" href="#advanced-composition">Advanced Composition</a></h2>
<h3 id="conditional-composition"><a class="header" href="#conditional-composition">Conditional Composition</a></h3>
<p>Compose graphs based on conditions:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::ConditionalComposition;

let conditional_composition = ConditionalComposition {
    base_sources: vec![
        GraphSource::JsonFile("core/processor.graph.json".to_string()),
    ],
    conditional_sources: vec![
        ConditionalSource {
            condition: Condition::EnvironmentVariable("ENABLE_ML".to_string()),
            sources: vec![
                GraphSource::JsonFile("ml/trainer.graph.json".to_string()),
                GraphSource::JsonFile("ml/predictor.graph.json".to_string()),
            ],
        },
        ConditionalSource {
            condition: Condition::ConfigValue("features.analytics".to_string()),
            sources: vec![
                GraphSource::JsonFile("analytics/collector.graph.json".to_string()),
            ],
        },
    ],
};

let composed_graph = composer.compose_conditional(conditional_composition).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="templated-composition"><a class="header" href="#templated-composition">Templated Composition</a></h3>
<p>Use templates for dynamic composition:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::CompositionTemplate;

let template = CompositionTemplate {
    template_file: "templates/data_pipeline.yaml".to_string(),
    parameters: HashMap::from([
        ("input_source".to_string(), serde_json::json!("kafka")),
        ("output_destination".to_string(), serde_json::json!("postgres")),
        ("enable_validation".to_string(), serde_json::json!(true)),
    ]),
};

let composition = composer.render_template(template).await?;
let composed_graph = composer.compose_graphs(composition).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="layered-composition"><a class="header" href="#layered-composition">Layered Composition</a></h3>
<p>Build compositions in layers:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Base layer: Core functionality
let base_composition = GraphComposition {
    sources: vec![
        GraphSource::JsonFile("core/base.graph.json".to_string()),
    ],
    // ... base configuration
};

// Feature layer: Additional features
let feature_layer = GraphComposition {
    sources: vec![
        GraphSource::JsonFile("features/analytics.graph.json".to_string()),
        GraphSource::JsonFile("features/monitoring.graph.json".to_string()),
    ],
    // ... feature connections
};

// Environment layer: Environment-specific configuration
let env_layer = GraphComposition {
    sources: vec![
        GraphSource::JsonFile("env/production.graph.json".to_string()),
    ],
    // ... environment-specific resources
};

// Compose layers
let base_graph = composer.compose_graphs(base_composition).await?;
let feature_graph = composer.compose_layers(base_graph, feature_layer).await?;
let final_graph = composer.compose_layers(feature_graph, env_layer).await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="validation-and-testing-1"><a class="header" href="#validation-and-testing-1">Validation and Testing</a></h2>
<h3 id="composition-validation"><a class="header" href="#composition-validation">Composition Validation</a></h3>
<p>Validate composed graphs before execution:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::CompositionValidator;

let validator = CompositionValidator::new();

// Validate composition structure
let validation_result = validator.validate_composition(&amp;composition).await?;

if !validation_result.is_valid() {
    println!("‚ùå Composition validation failed:");
    for error in &amp;validation_result.errors {
        println!("  - {}", error);
    }
    for warning in &amp;validation_result.warnings {
        println!("  ‚ö†Ô∏è  {}", warning);
    }
} else {
    println!("‚úÖ Composition validation passed");
}
<span class="boring">}</span></code></pre></pre>
<h3 id="testing-composed-graphs"><a class="header" href="#testing-composed-graphs">Testing Composed Graphs</a></h3>
<p>Test the composed graph before deployment:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::CompositionTester;

let tester = CompositionTester::new();

// Create test scenarios
let test_scenarios = vec![
    TestScenario {
        name: "data_flow_test".to_string(),
        inputs: HashMap::from([
            ("data/collector".to_string(), vec![
                Message::String("test_data".to_string())
            ]),
        ]),
        expected_outputs: HashMap::from([
            ("ml/predictor".to_string(), vec![
                Message::Object(serde_json::json!({"prediction": 0.95}))
            ]),
        ]),
        timeout_ms: 5000,
    },
];

// Run tests
let test_results = tester.run_tests(&amp;composed_graph, test_scenarios).await?;

for result in &amp;test_results {
    if result.passed {
        println!("‚úÖ Test '{}' passed", result.scenario_name);
    } else {
        println!("‚ùå Test '{}' failed: {}", result.scenario_name, result.error.as_ref().unwrap());
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-optimization-5"><a class="header" href="#performance-optimization-5">Performance Optimization</a></h2>
<h3 id="lazy-loading-1"><a class="header" href="#lazy-loading-1">Lazy Loading</a></h3>
<p>Only load necessary graphs:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = CompositionConfig {
    lazy_loading: true,
    load_on_demand: true,
    cache_loaded_graphs: true,
    max_concurrent_loads: 4,
};

let composer = GraphComposer::with_config(config);
<span class="boring">}</span></code></pre></pre>
<h3 id="parallel-composition"><a class="header" href="#parallel-composition">Parallel Composition</a></h3>
<p>Compose large numbers of graphs in parallel:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = CompositionConfig {
    parallel_composition: true,
    max_parallel_graphs: 8,
    composition_timeout_ms: 30000,
};

let composer = GraphComposer::with_config(config);
<span class="boring">}</span></code></pre></pre>
<h3 id="memory-management-6"><a class="header" href="#memory-management-6">Memory Management</a></h3>
<p>Control memory usage during composition:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = CompositionConfig {
    max_memory_usage_mb: 1024,
    cleanup_intermediate_results: true,
    stream_large_graphs: true,
};

let composer = GraphComposer::with_config(config);
<span class="boring">}</span></code></pre></pre>
<h2 id="real-world-examples"><a class="header" href="#real-world-examples">Real-World Examples</a></h2>
<h3 id="data-processing-pipeline-1"><a class="header" href="#data-processing-pipeline-1">Data Processing Pipeline</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Compose a complete data processing pipeline
async fn create_data_pipeline() -&gt; Result&lt;Graph, CompositionError&gt; {
    let mut composer = GraphComposer::new();
    
    let composition = GraphComposition {
        sources: vec![
            GraphSource::JsonFile("ingestion/api_collector.graph.json".to_string()),
            GraphSource::JsonFile("processing/data_cleaner.graph.json".to_string()),
            GraphSource::JsonFile("processing/transformer.graph.json".to_string()),
            GraphSource::JsonFile("storage/database_writer.graph.json".to_string()),
        ],
        connections: vec![
            CompositionConnection {
                from: CompositionEndpoint {
                    process: "ingestion/api_collector".to_string(),
                    port: "RawData".to_string(),
                    index: None,
                },
                to: CompositionEndpoint {
                    process: "processing/data_cleaner".to_string(),
                    port: "Input".to_string(),
                    index: None,
                },
                metadata: None,
            },
            CompositionConnection {
                from: CompositionEndpoint {
                    process: "processing/data_cleaner".to_string(),
                    port: "CleanedData".to_string(),
                    index: None,
                },
                to: CompositionEndpoint {
                    process: "processing/transformer".to_string(),
                    port: "Input".to_string(),
                    index: None,
                },
                metadata: None,
            },
            CompositionConnection {
                from: CompositionEndpoint {
                    process: "processing/transformer".to_string(),
                    port: "TransformedData".to_string(),
                    index: None,
                },
                to: CompositionEndpoint {
                    process: "storage/database_writer".to_string(),
                    port: "Input".to_string(),
                    index: None,
                },
                metadata: None,
            },
        ],
        shared_resources: vec![
            SharedResource {
                name: "logger".to_string(),
                component: "LoggerActor".to_string(),
                metadata: Some(HashMap::from([
                    ("level".to_string(), serde_json::json!("info")),
                ])),
            },
        ],
        properties: HashMap::from([
            ("name".to_string(), serde_json::json!("data_processing_pipeline")),
            ("version".to_string(), serde_json::json!("1.0.0")),
        ]),
        case_sensitive: Some(false),
        metadata: None,
    };
    
    composer.compose_graphs(composition).await
}
<span class="boring">}</span></code></pre></pre>
<h3 id="ml-training-pipeline"><a class="header" href="#ml-training-pipeline">ML Training Pipeline</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Compose ML training and inference pipeline
async fn create_ml_pipeline() -&gt; Result&lt;Graph, CompositionError&gt; {
    let workspace = WorkspaceDiscovery::new(WorkspaceConfig {
        root_path: PathBuf::from("./ml_workspace"),
        ..Default::default()
    }).discover_workspace().await?;
    
    let mut connection_builder = GraphConnectionBuilder::new(workspace);
    
    // Build ML pipeline connections
    connection_builder
        .connect_interface(
            "data_preprocessor",
            "processed_data_output",
            "feature_engineer",
            "raw_data_input"
        )?
        .connect_interface(
            "feature_engineer",
            "features_output",
            "model_trainer",
            "training_data_input"
        )?
        .connect_interface(
            "model_trainer",
            "trained_model_output",
            "model_evaluator",
            "model_input"
        )?
        .connect_interface(
            "model_trainer",
            "trained_model_output",
            "inference_service",
            "model_input"
        )?;
    
    let connections = connection_builder.build();
    
    let composition = GraphComposition {
        sources: workspace.graphs.into_iter()
            .map(|g| GraphSource::GraphExport(g.graph))
            .collect(),
        connections,
        shared_resources: vec![
            SharedResource {
                name: "model_registry".to_string(),
                component: "ModelRegistryActor".to_string(),
                metadata: Some(HashMap::from([
                    ("storage_backend".to_string(), serde_json::json!("s3")),
                ])),
            },
            SharedResource {
                name: "metrics_tracker".to_string(),
                component: "MetricsTrackerActor".to_string(),
                metadata: Some(HashMap::from([
                    ("export_interval".to_string(), serde_json::json!(60)),
                ])),
            },
        ],
        properties: HashMap::from([
            ("name".to_string(), serde_json::json!("ml_training_pipeline")),
            ("description".to_string(), serde_json::json!("Complete ML training and inference pipeline")),
        ]),
        case_sensitive: Some(false),
        metadata: None,
    };
    
    let mut composer = GraphComposer::new();
    composer.compose_graphs(composition).await
}
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-14"><a class="header" href="#best-practices-14">Best Practices</a></h2>
<h3 id="1-plan-your-composition"><a class="header" href="#1-plan-your-composition">1. Plan Your Composition</a></h3>
<ul>
<li>Design graph boundaries thoughtfully</li>
<li>Keep related functionality together</li>
<li>Plan for reusability across compositions</li>
</ul>
<h3 id="2-use-clear-naming"><a class="header" href="#2-use-clear-naming">2. Use Clear Naming</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Descriptive endpoint names
CompositionEndpoint {
    process: "data_ingestion/api_collector".to_string(),
    port: "ValidatedApiData".to_string(),
    index: None,
}

// Avoid: Generic names
CompositionEndpoint {
    process: "graph1/proc1".to_string(),
    port: "Output".to_string(),
    index: None,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="3-document-connections"><a class="header" href="#3-document-connections">3. Document Connections</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>CompositionConnection {
    from: CompositionEndpoint { /* ... */ },
    to: CompositionEndpoint { /* ... */ },
    metadata: Some(HashMap::from([
        ("description".to_string(), serde_json::json!("Cleaned data flows to ML feature engineering")),
        ("data_type".to_string(), serde_json::json!("CleanedDataRecord")),
        ("expected_rate".to_string(), serde_json::json!("1000 records/minute")),
    ])),
}
<span class="boring">}</span></code></pre></pre>
<h3 id="4-validate-early-and-often"><a class="header" href="#4-validate-early-and-often">4. Validate Early and Often</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Validate before composing
let validation_result = validator.validate_composition(&amp;composition).await?;
assert!(validation_result.is_valid());

// Test after composing
let test_results = tester.run_tests(&amp;composed_graph, test_scenarios).await?;
assert!(test_results.iter().all(|r| r.passed));
<span class="boring">}</span></code></pre></pre>
<h3 id="5-use-shared-resources-wisely"><a class="header" href="#5-use-shared-resources-wisely">5. Use Shared Resources Wisely</a></h3>
<ul>
<li>Share stateless services (logging, config)</li>
<li>Be cautious with stateful shared resources</li>
<li>Consider resource contention and bottlenecks</li>
</ul>
<h2 id="next-steps-20"><a class="header" href="#next-steps-20">Next Steps</a></h2>
<ul>
<li><a href="api/multi-graph/dependency-resolution.html">Dependency Resolution</a> - Handle complex dependencies</li>
<li><a href="api/multi-graph/workspace-discovery.html">Workspace Discovery</a> - Discover graphs to compose</li>
<li><a href="api/multi-graph/../../tutorials/multi-graph-workspace.html">Tutorial: Multi-Graph Workspace</a></li>
</ul>
<h2 id="related-documentation-1"><a class="header" href="#related-documentation-1">Related Documentation</a></h2>
<ul>
<li><a href="api/multi-graph/../../architecture/multi-graph-composition.html">Architecture: Multi-Graph Composition</a></li>
<li><a href="api/multi-graph/../../architecture/graph-system.html">Graph System Overview</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="dependency-resolution-1"><a class="header" href="#dependency-resolution-1">Dependency Resolution</a></h1>
<p>Learn how to handle complex dependencies between graphs in multi-graph compositions.</p>
<h2 id="overview-8"><a class="header" href="#overview-8">Overview</a></h2>
<p>Dependency resolution in multi-graph systems involves:</p>
<ul>
<li><strong>Automatic dependency detection</strong>: Analyze graph dependencies from metadata</li>
<li><strong>Topological ordering</strong>: Ensure graphs are loaded in dependency order</li>
<li><strong>Circular dependency detection</strong>: Identify and resolve circular dependencies</li>
<li><strong>Version constraints</strong>: Handle version compatibility between dependent graphs</li>
<li><strong>Interface matching</strong>: Verify compatible interfaces between graphs</li>
<li><strong>Missing dependency handling</strong>: Graceful handling of unresolved dependencies</li>
</ul>
<h2 id="basic-dependency-resolution"><a class="header" href="#basic-dependency-resolution">Basic Dependency Resolution</a></h2>
<h3 id="dependency-resolver"><a class="header" href="#dependency-resolver">Dependency Resolver</a></h3>
<p>The core component for handling graph dependencies:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::{DependencyResolver, DependencyError};

let resolver = DependencyResolver::new();

// Load graphs with dependencies
let graphs = vec![
    graph_export_a,  // depends on graph_b
    graph_export_b,  // no dependencies
    graph_export_c,  // depends on graph_a and graph_b
];

// Resolve dependency order
let ordered_graphs = resolver.resolve_dependencies(&amp;graphs)?;

// Graphs are now ordered: [graph_b, graph_a, graph_c]
for graph in &amp;ordered_graphs {
    let name = graph.properties.get("name").and_then(|v| v.as_str()).unwrap_or("unnamed");
    println!("Loading graph: {}", name);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="dependency-declaration"><a class="header" href="#dependency-declaration">Dependency Declaration</a></h3>
<p>Declare dependencies in graph metadata:</p>
<pre><code class="language-json">{
  "properties": {
    "name": "ml_trainer",
    "version": "1.2.0",
    "dependencies": [
      "data_processor",
      "feature_engineer"
    ]
  },
  "graph_dependencies": [
    {
      "graph_name": "data_processor",
      "namespace": "data/processing",
      "version_constraint": "&gt;=1.0.0",
      "required": true,
      "description": "Requires processed data for training"
    },
    {
      "graph_name": "feature_engineer",
      "namespace": "ml/features",
      "version_constraint": "^2.1.0",
      "required": true,
      "description": "Requires feature engineering pipeline"
    }
  ]
}
</code></pre>
<h2 id="advanced-dependency-resolution"><a class="header" href="#advanced-dependency-resolution">Advanced Dependency Resolution</a></h2>
<h3 id="version-constraints"><a class="header" href="#version-constraints">Version Constraints</a></h3>
<p>Handle version compatibility:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::{VersionConstraint, VersionResolver};

// Define version constraints
let constraints = vec![
    VersionConstraint {
        graph_name: "data_processor".to_string(),
        constraint: "&gt;=1.0.0".to_string(),
        required: true,
    },
    VersionConstraint {
        graph_name: "ml_core".to_string(),
        constraint: "^2.0.0".to_string(),  // Compatible with 2.x.x
        required: true,
    },
    VersionConstraint {
        graph_name: "analytics".to_string(),
        constraint: "~1.5.0".to_string(),  // Compatible with 1.5.x
        required: false,
    },
];

let version_resolver = VersionResolver::new();
let resolution_result = version_resolver.resolve_versions(&amp;graphs, &amp;constraints)?;

if resolution_result.has_conflicts() {
    println!("‚ùå Version conflicts detected:");
    for conflict in &amp;resolution_result.conflicts {
        println!("  {} requires {} but {} is available", 
            conflict.dependent, conflict.required_version, conflict.available_version);
    }
} else {
    println!("‚úÖ All version constraints satisfied");
}
<span class="boring">}</span></code></pre></pre>
<h3 id="interface-compatibility"><a class="header" href="#interface-compatibility">Interface Compatibility</a></h3>
<p>Verify interface compatibility between dependent graphs:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::{InterfaceResolver, InterfaceCompatibility};

let interface_resolver = InterfaceResolver::new();

// Analyze interface compatibility
let compatibility_result = interface_resolver.analyze_compatibility(&amp;ordered_graphs)?;

for incompatibility in &amp;compatibility_result.incompatibilities {
    match incompatibility.severity {
        Severity::Error =&gt; {
            println!("‚ùå Interface incompatibility: {} ‚Üí {}", 
                incompatibility.provider, incompatibility.consumer);
            println!("   Expected: {}", incompatibility.expected_signature);
            println!("   Actual: {}", incompatibility.actual_signature);
        },
        Severity::Warning =&gt; {
            println!("‚ö†Ô∏è  Interface warning: {} ‚Üí {}", 
                incompatibility.provider, incompatibility.consumer);
            println!("   {}", incompatibility.description);
        },
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="conditional-dependencies"><a class="header" href="#conditional-dependencies">Conditional Dependencies</a></h3>
<p>Handle dependencies that are only required under certain conditions:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::{ConditionalDependency, DependencyCondition};

// Define conditional dependencies in graph metadata
let conditional_deps = vec![
    ConditionalDependency {
        graph_name: "ml_trainer".to_string(),
        condition: DependencyCondition::EnvironmentVariable("ENABLE_ML".to_string()),
        version_constraint: Some("&gt;=2.0.0".to_string()),
        required: true,
    },
    ConditionalDependency {
        graph_name: "analytics_dashboard".to_string(),
        condition: DependencyCondition::ConfigValue("features.analytics".to_string()),
        version_constraint: None,
        required: false,
    },
];

// Resolve conditional dependencies
let resolution_context = ResolutionContext {
    environment_variables: HashMap::from([
        ("ENABLE_ML".to_string(), "true".to_string()),
    ]),
    config_values: HashMap::from([
        ("features.analytics".to_string(), serde_json::json!(true)),
    ]),
};

let resolved_deps = resolver.resolve_conditional_dependencies(
    &amp;conditional_deps, 
    &amp;resolution_context
)?;
<span class="boring">}</span></code></pre></pre>
<h2 id="circular-dependency-detection"><a class="header" href="#circular-dependency-detection">Circular Dependency Detection</a></h2>
<h3 id="identifying-cycles"><a class="header" href="#identifying-cycles">Identifying Cycles</a></h3>
<p>Detect and report circular dependencies:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::CircularDependencyDetector;

let cycle_detector = CircularDependencyDetector::new();
let cycle_result = cycle_detector.detect_cycles(&amp;graphs)?;

if cycle_result.has_cycles() {
    println!("‚ùå Circular dependencies detected:");
    for cycle in &amp;cycle_result.cycles {
        println!("  üîÑ {}", cycle.join(" ‚Üí "));
        
        // Suggest resolution strategies
        let suggestions = cycle_detector.suggest_resolutions(&amp;cycle)?;
        for suggestion in suggestions {
            println!("    üí° {}", suggestion);
        }
    }
} else {
    println!("‚úÖ No circular dependencies found");
}
<span class="boring">}</span></code></pre></pre>
<h3 id="cycle-resolution-strategies"><a class="header" href="#cycle-resolution-strategies">Cycle Resolution Strategies</a></h3>
<p>Automatic strategies for resolving circular dependencies:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::{CycleResolutionStrategy, DependencyBreaker};

let cycle_breaker = DependencyBreaker::new();

// Strategy 1: Optional dependency promotion
let resolution1 = cycle_breaker.resolve_by_optional_promotion(&amp;cycle)?;

// Strategy 2: Interface extraction
let resolution2 = cycle_breaker.resolve_by_interface_extraction(&amp;cycle)?;

// Strategy 3: Dependency inversion
let resolution3 = cycle_breaker.resolve_by_dependency_inversion(&amp;cycle)?;

// Apply the best resolution strategy
let best_resolution = cycle_breaker.select_best_resolution(vec![
    resolution1, resolution2, resolution3
])?;

println!("üîß Applying resolution: {}", best_resolution.description);
let resolved_graphs = cycle_breaker.apply_resolution(&amp;graphs, &amp;best_resolution)?;
<span class="boring">}</span></code></pre></pre>
<h2 id="missing-dependency-handling"><a class="header" href="#missing-dependency-handling">Missing Dependency Handling</a></h2>
<h3 id="graceful-degradation-1"><a class="header" href="#graceful-degradation-1">Graceful Degradation</a></h3>
<p>Handle missing dependencies gracefully:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::{MissingDependencyHandler, DegradationStrategy};

let missing_handler = MissingDependencyHandler::new();

// Configure degradation strategies
let strategies = HashMap::from([
    ("optional_dependencies".to_string(), DegradationStrategy::Skip),
    ("required_dependencies".to_string(), DegradationStrategy::Fail),
    ("soft_dependencies".to_string(), DegradationStrategy::Substitute),
]);

missing_handler.configure_strategies(strategies);

// Handle missing dependencies
let resolution_result = missing_handler.handle_missing_dependencies(
    &amp;graphs,
    &amp;missing_deps
)?;

for action in &amp;resolution_result.actions {
    match action {
        DegradationAction::Skipped(graph_name) =&gt; {
            println!("‚è≠Ô∏è  Skipped optional dependency: {}", graph_name);
        },
        DegradationAction::Substituted(original, substitute) =&gt; {
            println!("üîÑ Substituted {} with {}", original, substitute);
        },
        DegradationAction::Failed(graph_name, reason) =&gt; {
            println!("‚ùå Failed to resolve required dependency: {} ({})", graph_name, reason);
        },
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="dependency-substitution"><a class="header" href="#dependency-substitution">Dependency Substitution</a></h3>
<p>Provide alternatives for missing dependencies:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::DependencySubstitution;

let substitutions = vec![
    DependencySubstitution {
        original: "premium_ml_engine".to_string(),
        substitute: "basic_ml_engine".to_string(),
        compatibility_level: CompatibilityLevel::Partial,
        feature_differences: vec![
            "Advanced model optimization not available".to_string(),
            "Reduced prediction accuracy".to_string(),
        ],
    },
    DependencySubstitution {
        original: "enterprise_analytics".to_string(),
        substitute: "community_analytics".to_string(),
        compatibility_level: CompatibilityLevel::Full,
        feature_differences: vec![],
    },
];

missing_handler.register_substitutions(substitutions);

// Apply substitutions during resolution
let result = missing_handler.resolve_with_substitutions(&amp;graphs)?;
<span class="boring">}</span></code></pre></pre>
<h2 id="dependency-analysis-and-reporting"><a class="header" href="#dependency-analysis-and-reporting">Dependency Analysis and Reporting</a></h2>
<h3 id="dependency-graph-visualization"><a class="header" href="#dependency-graph-visualization">Dependency Graph Visualization</a></h3>
<p>Generate dependency graphs for analysis:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::{DependencyAnalyzer, DependencyGraph};

let analyzer = DependencyAnalyzer::new();

// Generate dependency graph
let dep_graph = analyzer.build_dependency_graph(&amp;graphs)?;

// Export to various formats
dep_graph.export_to_dot("dependencies.dot")?;         // Graphviz DOT
dep_graph.export_to_json("dependencies.json")?;       // JSON format
dep_graph.export_to_mermaid("dependencies.md")?;      // Mermaid diagram

// Analyze graph properties
let analysis = analyzer.analyze_dependency_structure(&amp;dep_graph)?;

println!("üìä Dependency Analysis:");
println!("  Graphs: {}", analysis.total_graphs);
println!("  Dependencies: {}", analysis.total_dependencies);
println!("  Max depth: {}", analysis.max_dependency_depth);
println!("  Strongly connected components: {}", analysis.scc_count);
<span class="boring">}</span></code></pre></pre>
<h3 id="impact-analysis"><a class="header" href="#impact-analysis">Impact Analysis</a></h3>
<p>Analyze the impact of dependency changes:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::ImpactAnalyzer;

let impact_analyzer = ImpactAnalyzer::new();

// Analyze impact of changing a graph
let impact = impact_analyzer.analyze_change_impact(
    &amp;dep_graph,
    "data_processor",  // Graph being changed
    "2.0.0"            // New version
)?;

println!("üéØ Impact Analysis for data_processor v2.0.0:");
println!("  Directly affected graphs: {}", impact.direct_dependents.len());
println!("  Transitively affected graphs: {}", impact.transitive_dependents.len());
println!("  Breaking changes detected: {}", impact.breaking_changes.len());

for change in &amp;impact.breaking_changes {
    println!("  ‚ö†Ô∏è  {}: {}", change.affected_graph, change.description);
}
<span class="boring">}</span></code></pre></pre>
<h2 id="real-world-examples-1"><a class="header" href="#real-world-examples-1">Real-World Examples</a></h2>
<h3 id="data-processing-pipeline-dependencies"><a class="header" href="#data-processing-pipeline-dependencies">Data Processing Pipeline Dependencies</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Example: Complex data processing pipeline with dependencies
async fn resolve_data_pipeline_dependencies() -&gt; Result&lt;Vec&lt;GraphExport&gt;, DependencyError&gt; {
    let graphs = vec![
        // Base data collector (no dependencies)
        load_graph("data/ingestion/api_collector.graph.json").await?,
        
        // Data processor (depends on collector)
        load_graph("data/processing/cleaner.graph.json").await?,
        
        // Feature engineer (depends on processor)
        load_graph("ml/features/engineer.graph.json").await?,
        
        // ML trainer (depends on feature engineer)
        load_graph("ml/training/trainer.graph.json").await?,
        
        // Model validator (depends on trainer)
        load_graph("ml/validation/validator.graph.json").await?,
        
        // Inference service (depends on trainer, but not validator)
        load_graph("ml/inference/predictor.graph.json").await?,
        
        // Analytics dashboard (depends on multiple components)
        load_graph("analytics/dashboard.graph.json").await?,
    ];
    
    let resolver = DependencyResolver::new();
    let ordered_graphs = resolver.resolve_dependencies(&amp;graphs)?;
    
    // Result order: collector ‚Üí cleaner ‚Üí engineer ‚Üí trainer ‚Üí [validator, predictor] ‚Üí dashboard
    
    Ok(ordered_graphs)
}
<span class="boring">}</span></code></pre></pre>
<h3 id="ml-pipeline-with-version-constraints"><a class="header" href="#ml-pipeline-with-version-constraints">ML Pipeline with Version Constraints</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Example: ML pipeline with strict version requirements
async fn resolve_ml_pipeline_with_versions() -&gt; Result&lt;Vec&lt;GraphExport&gt;, DependencyError&gt; {
    let graphs = load_ml_graphs().await?;
    
    let version_constraints = vec![
        VersionConstraint {
            graph_name: "tensorflow_runtime".to_string(),
            constraint: "&gt;=2.8.0".to_string(),
            required: true,
        },
        VersionConstraint {
            graph_name: "data_validator".to_string(),
            constraint: "^1.5.0".to_string(),
            required: true,
        },
        VersionConstraint {
            graph_name: "model_optimizer".to_string(),
            constraint: "~2.1.0".to_string(),
            required: false,
        },
    ];
    
    let resolver = DependencyResolver::with_version_constraints(version_constraints);
    
    // Resolve dependencies with version checking
    let resolution_result = resolver.resolve_with_versions(&amp;graphs)?;
    
    if resolution_result.has_conflicts() {
        // Handle version conflicts
        for conflict in &amp;resolution_result.conflicts {
            eprintln!("Version conflict: {} requires {} but {} is available",
                conflict.dependent, conflict.required_version, conflict.available_version);
        }
        return Err(DependencyError::VersionConflict(resolution_result.conflicts));
    }
    
    Ok(resolution_result.ordered_graphs)
}
<span class="boring">}</span></code></pre></pre>
<h3 id="handling-optional-dependencies"><a class="header" href="#handling-optional-dependencies">Handling Optional Dependencies</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Example: System with optional features and dependencies
async fn resolve_with_optional_features() -&gt; Result&lt;Vec&lt;GraphExport&gt;, DependencyError&gt; {
    let base_graphs = load_core_graphs().await?;
    let optional_graphs = load_optional_graphs().await?;
    
    let resolver = DependencyResolver::new();
    
    // Configure optional dependency handling
    let config = DependencyResolutionConfig {
        allow_missing_optional: true,
        substitute_missing: true,
        fail_on_missing_required: true,
    };
    
    resolver.configure(config);
    
    // Define substitutions for missing optional dependencies
    let substitutions = vec![
        DependencySubstitution {
            original: "premium_feature_a".to_string(),
            substitute: "basic_feature_a".to_string(),
            compatibility_level: CompatibilityLevel::Partial,
            feature_differences: vec![
                "Advanced analytics not available".to_string(),
            ],
        },
    ];
    
    resolver.register_substitutions(substitutions);
    
    // Resolve with graceful handling of missing optional dependencies
    let all_graphs = [base_graphs, optional_graphs].concat();
    let resolution_result = resolver.resolve_with_graceful_degradation(&amp;all_graphs)?;
    
    // Report what was included/excluded
    for action in &amp;resolution_result.degradation_actions {
        match action {
            DegradationAction::Skipped(graph) =&gt; {
                println!("‚è≠Ô∏è  Skipped optional feature: {}", graph);
            },
            DegradationAction::Substituted(original, substitute) =&gt; {
                println!("üîÑ Using {} instead of {}", substitute, original);
            },
        }
    }
    
    Ok(resolution_result.ordered_graphs)
}
<span class="boring">}</span></code></pre></pre>
<h2 id="testing-dependency-resolution"><a class="header" href="#testing-dependency-resolution">Testing Dependency Resolution</a></h2>
<h3 id="unit-testing-dependencies"><a class="header" href="#unit-testing-dependencies">Unit Testing Dependencies</a></h3>
<p>Test dependency resolution logic:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod tests {
    use super::*;
    
    #[tokio::test]
    async fn test_simple_dependency_resolution() {
        let graph_a = create_test_graph("graph_a", vec![]);
        let graph_b = create_test_graph("graph_b", vec!["graph_a"]);
        let graph_c = create_test_graph("graph_c", vec!["graph_b"]);
        
        let graphs = vec![graph_c, graph_a, graph_b]; // Intentionally unordered
        
        let resolver = DependencyResolver::new();
        let ordered = resolver.resolve_dependencies(&amp;graphs).unwrap();
        
        assert_eq!(get_graph_name(&amp;ordered[0]), "graph_a");
        assert_eq!(get_graph_name(&amp;ordered[1]), "graph_b");
        assert_eq!(get_graph_name(&amp;ordered[2]), "graph_c");
    }
    
    #[tokio::test]
    async fn test_circular_dependency_detection() {
        let graph_a = create_test_graph("graph_a", vec!["graph_b"]);
        let graph_b = create_test_graph("graph_b", vec!["graph_c"]);
        let graph_c = create_test_graph("graph_c", vec!["graph_a"]);
        
        let graphs = vec![graph_a, graph_b, graph_c];
        
        let resolver = DependencyResolver::new();
        let result = resolver.resolve_dependencies(&amp;graphs);
        
        assert!(matches!(result, Err(DependencyError::CircularDependency(_))));
    }
    
    #[tokio::test]
    async fn test_version_constraint_validation() {
        let graph_a = create_test_graph_with_version("graph_a", "1.0.0", vec![]);
        let graph_b = create_test_graph_with_version("graph_b", "2.0.0", vec![
            ("graph_a", "&gt;=1.5.0")
        ]);
        
        let graphs = vec![graph_a, graph_b];
        
        let resolver = DependencyResolver::new();
        let result = resolver.resolve_dependencies(&amp;graphs);
        
        assert!(matches!(result, Err(DependencyError::VersionConflict(_))));
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="integration-testing-2"><a class="header" href="#integration-testing-2">Integration Testing</a></h3>
<p>Test complete dependency resolution workflows:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[tokio::test]
async fn test_complete_workspace_dependency_resolution() {
    let workspace_path = "test_workspace";
    setup_test_workspace(workspace_path).await;
    
    let discovery = WorkspaceDiscovery::new(WorkspaceConfig {
        root_path: PathBuf::from(workspace_path),
        ..Default::default()
    });
    
    let workspace = discovery.discover_workspace().await.unwrap();
    
    let resolver = DependencyResolver::new();
    let ordered_graphs = resolver.resolve_dependencies(&amp;workspace.graphs).await.unwrap();
    
    // Verify correct ordering
    verify_dependency_order(&amp;ordered_graphs);
    
    // Verify all required dependencies are satisfied
    verify_all_dependencies_satisfied(&amp;ordered_graphs);
    
    cleanup_test_workspace(workspace_path).await;
}
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-15"><a class="header" href="#best-practices-15">Best Practices</a></h2>
<h3 id="1-explicit-dependency-declaration"><a class="header" href="#1-explicit-dependency-declaration">1. Explicit Dependency Declaration</a></h3>
<p>Always declare dependencies explicitly in graph metadata:</p>
<pre><code class="language-json">{
  "properties": {
    "name": "my_graph",
    "dependencies": ["required_graph_1", "required_graph_2"]
  },
  "graph_dependencies": [
    {
      "graph_name": "required_graph_1",
      "version_constraint": "&gt;=1.0.0",
      "required": true,
      "description": "Provides core data processing functionality"
    }
  ]
}
</code></pre>
<h3 id="2-use-semantic-versioning"><a class="header" href="#2-use-semantic-versioning">2. Use Semantic Versioning</a></h3>
<p>Follow semantic versioning for graph versions:</p>
<pre><code class="language-json">{
  "properties": {
    "version": "2.1.3"  // MAJOR.MINOR.PATCH
  },
  "graph_dependencies": [
    {
      "graph_name": "data_processor",
      "version_constraint": "^2.0.0"  // Compatible with 2.x.x
    }
  ]
}
</code></pre>
<h3 id="3-design-for-loose-coupling"><a class="header" href="#3-design-for-loose-coupling">3. Design for Loose Coupling</a></h3>
<p>Minimize dependencies between graphs:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Minimal, well-defined dependencies
let graph_deps = vec![
    GraphDependency {
        graph_name: "core_processor".to_string(),
        required: true,
        // Only depends on stable core functionality
    },
];

// Avoid: Tight coupling with many dependencies
let graph_deps = vec![
    // Too many dependencies make the graph fragile
    GraphDependency { graph_name: "helper1".to_string(), required: true },
    GraphDependency { graph_name: "helper2".to_string(), required: true },
    GraphDependency { graph_name: "helper3".to_string(), required: true },
    GraphDependency { graph_name: "helper4".to_string(), required: true },
];
<span class="boring">}</span></code></pre></pre>
<h3 id="4-test-dependency-changes"><a class="header" href="#4-test-dependency-changes">4. Test Dependency Changes</a></h3>
<p>Always test the impact of dependency changes:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Before making changes, analyze impact
let impact = analyzer.analyze_change_impact(&amp;dep_graph, "my_graph", "2.0.0")?;

if impact.has_breaking_changes() {
    println!("‚ö†Ô∏è  Breaking changes detected - review carefully");
    for change in &amp;impact.breaking_changes {
        println!("  - {}", change.description);
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="5-document-dependencies"><a class="header" href="#5-document-dependencies">5. Document Dependencies</a></h3>
<p>Document why dependencies exist and what they provide:</p>
<pre><code class="language-json">{
  "graph_dependencies": [
    {
      "graph_name": "ml_core",
      "version_constraint": "&gt;=2.0.0",
      "required": true,
      "description": "Provides tensor operations and model training infrastructure required for neural network training"
    }
  ]
}
</code></pre>
<h2 id="next-steps-21"><a class="header" href="#next-steps-21">Next Steps</a></h2>
<ul>
<li><a href="api/multi-graph/workspace-discovery.html">Workspace Discovery</a> - Discover graphs for dependency analysis</li>
<li><a href="api/multi-graph/graph-composition.html">Graph Composition</a> - Compose resolved graphs</li>
<li><a href="api/multi-graph/../../tutorials/multi-graph-workspace.html">Tutorial: Multi-Graph Workspace</a></li>
</ul>
<h2 id="related-documentation-2"><a class="header" href="#related-documentation-2">Related Documentation</a></h2>
<ul>
<li><a href="api/multi-graph/../../architecture/multi-graph-composition.html">Architecture: Multi-Graph Composition</a></li>
<li><a href="api/multi-graph/../../architecture/graph-system.html">Graph System Overview</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="setting-up-distributed-networks"><a class="header" href="#setting-up-distributed-networks">Setting Up Distributed Networks</a></h1>
<p>This guide covers how to set up and configure distributed Reflow networks for cross-network actor communication.</p>
<h2 id="overview-9"><a class="header" href="#overview-9">Overview</a></h2>
<p>Distributed networks allow multiple Reflow instances to communicate with each other, enabling:</p>
<ul>
<li><strong>Cross-network workflows</strong>: Actors in different networks can send messages to each other</li>
<li><strong>Resource sharing</strong>: Share computational resources across multiple machines</li>
<li><strong>Scalability</strong>: Scale workflows beyond a single machine's capabilities</li>
<li><strong>Fault tolerance</strong>: Continue operation even if some network nodes fail</li>
</ul>
<h2 id="basic-setup-1"><a class="header" href="#basic-setup-1">Basic Setup</a></h2>
<h3 id="1-server-network-configuration"><a class="header" href="#1-server-network-configuration">1. Server Network Configuration</a></h3>
<p>First, set up a server network that will accept connections:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::distributed_network::{DistributedNetwork, DistributedConfig};
use reflow_network::network::NetworkConfig;

let server_config = DistributedConfig {
    network_id: "main_server".to_string(),
    instance_id: "server_001".to_string(),
    bind_address: "0.0.0.0".to_string(),
    bind_port: 8080,
    discovery_endpoints: vec![],
    auth_token: Some("secure_token".to_string()),
    max_connections: 100,
    heartbeat_interval_ms: 30000,
    local_network_config: NetworkConfig::default(),
};

let mut server_network = DistributedNetwork::new(server_config).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="2-client-network-configuration"><a class="header" href="#2-client-network-configuration">2. Client Network Configuration</a></h3>
<p>Set up a client network that connects to the server:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let client_config = DistributedConfig {
    network_id: "client_worker".to_string(),
    instance_id: "client_001".to_string(),
    bind_address: "127.0.0.1".to_string(),
    bind_port: 8081,
    discovery_endpoints: vec!["http://discovery.example.com:3000".to_string()],
    auth_token: Some("secure_token".to_string()),
    max_connections: 10,
    heartbeat_interval_ms: 30000,
    local_network_config: NetworkConfig::default(),
};

let mut client_network = DistributedNetwork::new(client_config).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="3-start-networks"><a class="header" href="#3-start-networks">3. Start Networks</a></h3>
<p>Start both networks and establish connection:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Start server first
server_network.start().await?;
println!("‚úÖ Server network started on port 8080");

// Start client
client_network.start().await?;
println!("‚úÖ Client network started on port 8081");

// Connect client to server
client_network.connect_to_network("127.0.0.1:8080").await?;
println!("üîó Client connected to server");
<span class="boring">}</span></code></pre></pre>
<h2 id="configuration-options"><a class="header" href="#configuration-options">Configuration Options</a></h2>
<h3 id="distributedconfig-fields"><a class="header" href="#distributedconfig-fields">DistributedConfig Fields</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Example</th></tr></thead><tbody>
<tr><td><code>network_id</code></td><td><code>String</code></td><td>Unique identifier for this network</td><td><code>"data_processing_cluster"</code></td></tr>
<tr><td><code>instance_id</code></td><td><code>String</code></td><td>Unique identifier for this instance</td><td><code>"worker_001"</code></td></tr>
<tr><td><code>bind_address</code></td><td><code>String</code></td><td>IP address to bind server to</td><td><code>"0.0.0.0"</code> or <code>"127.0.0.1"</code></td></tr>
<tr><td><code>bind_port</code></td><td><code>u16</code></td><td>Port number for server</td><td><code>8080</code></td></tr>
<tr><td><code>discovery_endpoints</code></td><td><code>Vec&lt;String&gt;</code></td><td>URLs of discovery services</td><td><code>["http://discovery:3000"]</code></td></tr>
<tr><td><code>auth_token</code></td><td><code>Option&lt;String&gt;</code></td><td>Authentication token</td><td><code>Some("secret_token")</code></td></tr>
<tr><td><code>max_connections</code></td><td><code>usize</code></td><td>Maximum concurrent connections</td><td><code>100</code></td></tr>
<tr><td><code>heartbeat_interval_ms</code></td><td><code>u64</code></td><td>Heartbeat interval in milliseconds</td><td><code>30000</code></td></tr>
<tr><td><code>local_network_config</code></td><td><code>NetworkConfig</code></td><td>Local network configuration</td><td><code>NetworkConfig::default()</code></td></tr>
</tbody></table>
</div>
<h3 id="security-configuration-2"><a class="header" href="#security-configuration-2">Security Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let secure_config = DistributedConfig {
    // ... other fields
    auth_token: Some("your_secure_token_here".to_string()),
    max_connections: 50, // Limit connections for security
    heartbeat_interval_ms: 15000, // More frequent heartbeats
};
<span class="boring">}</span></code></pre></pre>
<h3 id="high-performance-configuration"><a class="header" href="#high-performance-configuration">High-Performance Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let performance_config = DistributedConfig {
    // ... other fields
    max_connections: 1000,
    heartbeat_interval_ms: 60000, // Less frequent heartbeats
    local_network_config: NetworkConfig {
        max_buffer_size: 1024 * 1024, // 1MB buffer
        enable_compression: true,
        // ... other performance settings
    },
};
<span class="boring">}</span></code></pre></pre>
<h2 id="network-topologies"><a class="header" href="#network-topologies">Network Topologies</a></h2>
<h3 id="star-topology-hub-and-spoke"><a class="header" href="#star-topology-hub-and-spoke">Star Topology (Hub and Spoke)</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Central hub
let hub_config = DistributedConfig {
    network_id: "central_hub".to_string(),
    bind_port: 8080,
    max_connections: 100,
    // ... other fields
};

// Multiple spokes connect to hub
let spoke_configs = vec![
    ("data_processor", 8081),
    ("ml_trainer", 8082),
    ("analytics", 8083),
];

for (name, port) in spoke_configs {
    let spoke_config = DistributedConfig {
        network_id: name.to_string(),
        bind_port: port,
        discovery_endpoints: vec!["http://hub:8080".to_string()],
        // ... other fields
    };
}
<span class="boring">}</span></code></pre></pre>
<h3 id="mesh-topology-peer-to-peer"><a class="header" href="#mesh-topology-peer-to-peer">Mesh Topology (Peer-to-Peer)</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Each node connects to multiple others
let mesh_discovery = vec![
    "http://node1:8080".to_string(),
    "http://node2:8081".to_string(),
    "http://node3:8082".to_string(),
];

let node_config = DistributedConfig {
    network_id: "mesh_node_1".to_string(),
    discovery_endpoints: mesh_discovery,
    // ... other fields
};
<span class="boring">}</span></code></pre></pre>
<h2 id="discovery-service-integration"><a class="header" href="#discovery-service-integration">Discovery Service Integration</a></h2>
<h3 id="using-external-discovery-service"><a class="header" href="#using-external-discovery-service">Using External Discovery Service</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config_with_discovery = DistributedConfig {
    network_id: "auto_discovery_client".to_string(),
    discovery_endpoints: vec![
        "http://consul.service.consul:8500".to_string(),
        "http://etcd.cluster.local:2379".to_string(),
    ],
    // ... other fields
};
<span class="boring">}</span></code></pre></pre>
<h3 id="built-in-discovery"><a class="header" href="#built-in-discovery">Built-in Discovery</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Server acts as discovery endpoint for others
let discovery_server_config = DistributedConfig {
    network_id: "discovery_server".to_string(),
    bind_port: 8080,
    discovery_endpoints: vec![], // Empty - this is the discovery server
    // ... other fields
};

// Clients use server for discovery
let discovery_client_config = DistributedConfig {
    network_id: "discovery_client".to_string(),
    discovery_endpoints: vec!["http://discovery_server:8080".to_string()],
    // ... other fields
};
<span class="boring">}</span></code></pre></pre>
<h2 id="error-handling-12"><a class="header" href="#error-handling-12">Error Handling</a></h2>
<h3 id="connection-errors"><a class="header" href="#connection-errors">Connection Errors</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>match client_network.connect_to_network("127.0.0.1:8080").await {
    Ok(_) =&gt; println!("‚úÖ Connected successfully"),
    Err(e) =&gt; {
        eprintln!("‚ùå Connection failed: {}", e);
        // Implement retry logic
        tokio::time::sleep(Duration::from_secs(5)).await;
        // Retry connection...
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="network-startup-errors"><a class="header" href="#network-startup-errors">Network Startup Errors</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>match server_network.start().await {
    Ok(_) =&gt; println!("‚úÖ Network started"),
    Err(e) =&gt; {
        eprintln!("‚ùå Failed to start network: {}", e);
        match e.to_string().as_str() {
            s if s.contains("Address already in use") =&gt; {
                eprintln!("Port {} is already in use", server_config.bind_port);
                // Try different port
            },
            s if s.contains("Permission denied") =&gt; {
                eprintln!("Permission denied - try running as administrator or use port &gt; 1024");
            },
            _ =&gt; eprintln!("Unknown error: {}", e),
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="monitoring-and-diagnostics"><a class="header" href="#monitoring-and-diagnostics">Monitoring and Diagnostics</a></h2>
<h3 id="network-status"><a class="header" href="#network-status">Network Status</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Check network configuration
let config = server_network.get_config();
println!("Network ID: {}", config.network_id);
println!("Listening on: {}:{}", config.bind_address, config.bind_port);

// Monitor connections (if available in future API)
// let connections = server_network.get_active_connections().await?;
// println!("Active connections: {}", connections.len());
<span class="boring">}</span></code></pre></pre>
<h3 id="health-checks-1"><a class="header" href="#health-checks-1">Health Checks</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Implement health check endpoint
async fn health_check(network: &amp;DistributedNetwork) -&gt; bool {
    // Check if network is responsive
    match network.ping_network("target_network").await {
        Ok(_) =&gt; true,
        Err(_) =&gt; false,
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-16"><a class="header" href="#best-practices-16">Best Practices</a></h2>
<h3 id="1-network-naming"><a class="header" href="#1-network-naming">1. Network Naming</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Descriptive, hierarchical names
"company.department.service"
"prod.ml.training"
"dev.data.processing"

// Avoid: Generic or conflicting names
"network"
"server"
"client"
<span class="boring">}</span></code></pre></pre>
<h3 id="2-security"><a class="header" href="#2-security">2. Security</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Use strong authentication tokens
let auth_token = generate_secure_token(); // Use proper token generation

// Limit connections based on expected load
max_connections: calculate_expected_connections(),

// Use appropriate heartbeat intervals
heartbeat_interval_ms: match environment {
    Environment::Local =&gt; 10000,     // Fast for development
    Environment::LAN =&gt; 30000,       // Normal for LAN
    Environment::WAN =&gt; 60000,       // Slower for WAN
},
<span class="boring">}</span></code></pre></pre>
<h3 id="3-resource-management"><a class="header" href="#3-resource-management">3. Resource Management</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Proper shutdown sequence
async fn shutdown_gracefully(mut network: DistributedNetwork) -&gt; Result&lt;(), anyhow::Error&gt; {
    // Stop accepting new connections
    network.stop_accepting_connections().await?;
    
    // Wait for existing operations to complete
    tokio::time::sleep(Duration::from_secs(5)).await;
    
    // Shutdown network
    network.shutdown().await?;
    
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h3 id="4-development-vs-production"><a class="header" href="#4-development-vs-production">4. Development vs Production</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Development configuration
let dev_config = DistributedConfig {
    bind_address: "127.0.0.1".to_string(), // Local only
    heartbeat_interval_ms: 10000,          // Fast heartbeats
    max_connections: 10,                   // Low limit
    auth_token: None,                      // No auth for dev
    // ...
};

// Production configuration
let prod_config = DistributedConfig {
    bind_address: "0.0.0.0".to_string(),   // Accept external connections
    heartbeat_interval_ms: 30000,          // Balanced heartbeats
    max_connections: 1000,                 // Higher limit
    auth_token: Some(env::var("AUTH_TOKEN")?), // Required auth
    // ...
};
<span class="boring">}</span></code></pre></pre>
<h2 id="troubleshooting-7"><a class="header" href="#troubleshooting-7">Troubleshooting</a></h2>
<h3 id="common-issues-5"><a class="header" href="#common-issues-5">Common Issues</a></h3>
<ol>
<li>
<p><strong>Port Already in Use</strong></p>
<pre><code class="language-bash"># Check what's using the port
lsof -i :8080
# Use different port or kill conflicting process
</code></pre>
</li>
<li>
<p><strong>Connection Refused</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Check firewall settings
// Verify correct IP/port combination
// Ensure server is started before client connects
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p><strong>Authentication Failures</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Verify auth_token matches between networks
// Check token is not None when required
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p><strong>High Memory Usage</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Reduce max_connections
// Increase heartbeat_interval_ms
// Monitor for connection leaks
<span class="boring">}</span></code></pre></pre>
</li>
</ol>
<h2 id="next-steps-22"><a class="header" href="#next-steps-22">Next Steps</a></h2>
<ul>
<li><a href="api/distributed/remote-actors.html">Remote Actors</a> - Learn how to register and use remote actors</li>
<li><a href="api/distributed/discovery-registration.html">Discovery &amp; Registration</a> - Advanced discovery patterns</li>
<li><a href="api/distributed/conflict-resolution.html">Conflict Resolution</a> - Handle actor name conflicts</li>
</ul>
<h2 id="related-documentation-3"><a class="header" href="#related-documentation-3">Related Documentation</a></h2>
<ul>
<li><a href="api/distributed/../../architecture/distributed-networks.html">Architecture: Distributed Networks</a></li>
<li><a href="api/distributed/../../tutorials/distributed-workflow-example.html">Tutorial: Distributed Workflow Example</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="remote-actors"><a class="header" href="#remote-actors">Remote Actors</a></h1>
<p>Learn how to register, manage, and interact with remote actors across distributed networks.</p>
<h2 id="overview-10"><a class="header" href="#overview-10">Overview</a></h2>
<p>Remote actors allow you to use actors from other Reflow networks as if they were local. This enables:</p>
<ul>
<li><strong>Cross-network workflows</strong>: Chain actors across multiple networks</li>
<li><strong>Resource distribution</strong>: Use specialized actors on different machines</li>
<li><strong>Load balancing</strong>: Distribute work across multiple network instances</li>
<li><strong>Service isolation</strong>: Keep different services in separate networks</li>
</ul>
<h2 id="basic-remote-actor-usage"><a class="header" href="#basic-remote-actor-usage">Basic Remote Actor Usage</a></h2>
<h3 id="1-register-remote-actors"><a class="header" href="#1-register-remote-actors">1. Register Remote Actors</a></h3>
<p>After establishing a network connection, register remote actors:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::distributed_network::DistributedNetwork;

// Assume networks are already connected
let mut client_network = DistributedNetwork::new(client_config).await?;
client_network.start().await?;
client_network.connect_to_network("server:8080").await?;

// Register a remote actor
client_network.register_remote_actor(
    "data_processor",      // Remote actor ID
    "server_network"       // Remote network ID
).await?;

println!("‚úÖ Remote actor registered as proxy");
<span class="boring">}</span></code></pre></pre>
<h3 id="2-use-remote-actors-in-workflows"><a class="header" href="#2-use-remote-actors-in-workflows">2. Use Remote Actors in Workflows</a></h3>
<p>Remote actors appear as proxy actors in your local network:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Get local network reference
let local_network = client_network.get_local_network();
let mut network = local_network.write();

// Add remote actor to workflow (appears as local)
network.add_node("remote_processor", "data_processor@server_network", None)?;

// Create workflow with local and remote actors
network.add_node("local_generator", "data_generator", None)?;

// Connect local actor to remote actor
network.add_connection(Connector {
    from: ConnectionPoint {
        actor: "local_generator".to_string(),
        port: "Output".to_string(),
        ..Default::default()
    },
    to: ConnectionPoint {
        actor: "remote_processor".to_string(),  // This is the remote actor!
        port: "Input".to_string(),
        ..Default::default()
    },
})?;
<span class="boring">}</span></code></pre></pre>
<h3 id="3-send-messages-to-remote-actors"><a class="header" href="#3-send-messages-to-remote-actors">3. Send Messages to Remote Actors</a></h3>
<p>Send messages directly to remote actors:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::message::Message;

// Send message to remote actor
client_network.send_to_remote_actor(
    "server_network",      // Target network
    "data_processor",      // Target actor
    "Input",               // Target port
    Message::String("Hello from client!".to_string().into())
).await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="advanced-registration"><a class="header" href="#advanced-registration">Advanced Registration</a></h2>
<h3 id="register-with-custom-local-names"><a class="header" href="#register-with-custom-local-names">Register with Custom Local Names</a></h3>
<p>Avoid naming conflicts by using custom local names:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Register with custom alias to avoid conflicts
let local_alias = client_network.register_remote_actor_with_alias(
    "server_data_processor",  // Custom local name
    "data_processor",         // Remote actor name
    "server_network"          // Remote network
).await?;

println!("Remote actor available as: {}", local_alias);
<span class="boring">}</span></code></pre></pre>
<h3 id="batch-registration"><a class="header" href="#batch-registration">Batch Registration</a></h3>
<p>Register multiple remote actors at once:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let remote_actors = vec![
    ("data_processor", "server_network"),
    ("validator", "server_network"),
    ("transformer", "processing_network"),
];

for (actor_id, network_id) in remote_actors {
    match client_network.register_remote_actor(actor_id, network_id).await {
        Ok(_) =&gt; println!("‚úÖ Registered {}/{}", network_id, actor_id),
        Err(e) =&gt; eprintln!("‚ùå Failed to register {}/{}: {}", network_id, actor_id, e),
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="conditional-registration"><a class="header" href="#conditional-registration">Conditional Registration</a></h3>
<p>Register actors based on availability:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Check if network is available before registering
if client_network.is_network_connected("server_network").await {
    client_network.register_remote_actor("data_processor", "server_network").await?;
} else {
    eprintln!("Server network not available, using local fallback");
    // Use local actor instead
}
<span class="boring">}</span></code></pre></pre>
<h2 id="remote-actor-lifecycle"><a class="header" href="#remote-actor-lifecycle">Remote Actor Lifecycle</a></h2>
<h3 id="1-registration-process"><a class="header" href="#1-registration-process">1. Registration Process</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// 1. Network connection must be established first
client_network.connect_to_network("server:8080").await?;

// 2. Register creates a local proxy actor
client_network.register_remote_actor("remote_actor", "server_network").await?;

// 3. Proxy actor is added to local network
let local_network = client_network.get_local_network();
let network = local_network.read();
assert!(network.has_actor("remote_actor@server_network"));
<span class="boring">}</span></code></pre></pre>
<h3 id="2-message-flow"><a class="header" href="#2-message-flow">2. Message Flow</a></h3>
<pre><code class="language-mermaid">sequenceDiagram
    participant LA as Local Actor
    participant P as Proxy Actor
    participant B as Network Bridge
    participant RN as Remote Network
    participant RA as Remote Actor

    LA-&gt;&gt;P: Send Message
    P-&gt;&gt;B: Forward Message
    B-&gt;&gt;RN: Network Transport
    RN-&gt;&gt;RA: Deliver Message
    RA-&gt;&gt;RN: Response (if any)
    RN-&gt;&gt;B: Network Transport
    B-&gt;&gt;P: Forward Response
    P-&gt;&gt;LA: Deliver Response
</code></pre>
<h3 id="3-cleanup-and-unregistration"><a class="header" href="#3-cleanup-and-unregistration">3. Cleanup and Unregistration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Unregister remote actor when no longer needed
client_network.unregister_remote_actor("data_processor@server_network").await?;

// Or unregister all actors from a network
client_network.unregister_all_from_network("server_network").await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="error-handling-13"><a class="header" href="#error-handling-13">Error Handling</a></h2>
<h3 id="registration-errors"><a class="header" href="#registration-errors">Registration Errors</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>match client_network.register_remote_actor("processor", "server").await {
    Ok(_) =&gt; println!("‚úÖ Registration successful"),
    Err(e) =&gt; {
        match e.to_string().as_str() {
            s if s.contains("Network not connected") =&gt; {
                eprintln!("‚ùå Must connect to network first");
                // Establish connection and retry
            },
            s if s.contains("Actor not found") =&gt; {
                eprintln!("‚ùå Remote actor 'processor' doesn't exist");
                // Check available actors or use different name
            },
            s if s.contains("Name conflict") =&gt; {
                eprintln!("‚ùå Actor name conflicts with local actor");
                // Use different alias or handle conflict
            },
            _ =&gt; eprintln!("‚ùå Registration failed: {}", e),
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="message-delivery-errors"><a class="header" href="#message-delivery-errors">Message Delivery Errors</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>match client_network.send_to_remote_actor("server", "processor", "Input", message).await {
    Ok(_) =&gt; println!("‚úÖ Message sent"),
    Err(e) =&gt; {
        match e.to_string().as_str() {
            s if s.contains("Network disconnected") =&gt; {
                eprintln!("‚ùå Connection lost, attempting reconnection...");
                // Implement reconnection logic
            },
            s if s.contains("Actor not available") =&gt; {
                eprintln!("‚ùå Remote actor is not responding");
                // Use fallback actor or retry later
            },
            s if s.contains("Timeout") =&gt; {
                eprintln!("‚ùå Message delivery timed out");
                // Implement retry logic
            },
            _ =&gt; eprintln!("‚ùå Message delivery failed: {}", e),
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-considerations-6"><a class="header" href="#performance-considerations-6">Performance Considerations</a></h2>
<h3 id="connection-pooling-1"><a class="header" href="#connection-pooling-1">Connection Pooling</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Configure connection pooling for better performance
let config = DistributedConfig {
    max_connections: 50,           // Pool multiple connections
    heartbeat_interval_ms: 30000,  // Balance between responsiveness and overhead
    // ... other settings
};
<span class="boring">}</span></code></pre></pre>
<h3 id="message-batching-2"><a class="header" href="#message-batching-2">Message Batching</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Send multiple messages efficiently
let messages = vec![
    ("Input", Message::String("msg1".to_string().into())),
    ("Input", Message::String("msg2".to_string().into())),
    ("Input", Message::String("msg3".to_string().into())),
];

// Batch send (if supported by future API)
// client_network.send_batch_to_remote_actor("server", "processor", messages).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="caching-and-local-fallbacks"><a class="header" href="#caching-and-local-fallbacks">Caching and Local Fallbacks</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Implement local caching for remote actor responses
struct CachedRemoteActor {
    network: Arc&lt;DistributedNetwork&gt;,
    cache: Arc&lt;RwLock&lt;HashMap&lt;String, Message&gt;&gt;&gt;,
    fallback_actor: Option&lt;String&gt;,
}

impl CachedRemoteActor {
    async fn send_with_fallback(&amp;self, message: Message) -&gt; Result&lt;Message, anyhow::Error&gt; {
        // Try remote actor first
        match self.network.send_to_remote_actor("server", "processor", "Input", message.clone()).await {
            Ok(response) =&gt; Ok(response),
            Err(_) =&gt; {
                // Fall back to local actor if available
                if let Some(fallback) = &amp;self.fallback_actor {
                    println!("‚ö†Ô∏è  Using local fallback actor: {}", fallback);
                    // Send to local actor instead
                    self.send_to_local_actor(fallback, message).await
                } else {
                    Err(anyhow::anyhow!("Remote actor unavailable and no fallback configured"))
                }
            }
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="remote-actor-discovery"><a class="header" href="#remote-actor-discovery">Remote Actor Discovery</a></h2>
<h3 id="automatic-discovery-1"><a class="header" href="#automatic-discovery-1">Automatic Discovery</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Discover all available actors on a remote network
let available_actors = client_network.discover_remote_actors("server_network").await?;

for actor_info in available_actors {
    println!("Available actor: {} (capabilities: {:?})", 
        actor_info.name, 
        actor_info.capabilities
    );
    
    // Register if it matches our needs
    if actor_info.capabilities.contains(&amp;"data_processing".to_string()) {
        client_network.register_remote_actor(&amp;actor_info.name, "server_network").await?;
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="selective-registration-by-capability"><a class="header" href="#selective-registration-by-capability">Selective Registration by Capability</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Register only actors with specific capabilities
let required_capabilities = vec!["ml_training", "gpu_compute"];

let actors = client_network.discover_remote_actors("ml_cluster").await?;
for actor in actors {
    let has_required_caps = required_capabilities.iter()
        .any(|cap| actor.capabilities.contains(&amp;cap.to_string()));
    
    if has_required_caps {
        client_network.register_remote_actor(&amp;actor.name, "ml_cluster").await?;
        println!("‚úÖ Registered ML actor: {}", actor.name);
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="monitoring-remote-actors"><a class="header" href="#monitoring-remote-actors">Monitoring Remote Actors</a></h2>
<h3 id="health-checking"><a class="header" href="#health-checking">Health Checking</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Check if remote actor is responsive
async fn check_remote_actor_health(
    network: &amp;DistributedNetwork,
    network_id: &amp;str,
    actor_id: &amp;str
) -&gt; bool {
    match network.ping_remote_actor(network_id, actor_id).await {
        Ok(_) =&gt; {
            println!("‚úÖ Remote actor {}/{} is healthy", network_id, actor_id);
            true
        },
        Err(e) =&gt; {
            eprintln!("‚ùå Remote actor {}/{} health check failed: {}", network_id, actor_id, e);
            false
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="performance-monitoring"><a class="header" href="#performance-monitoring">Performance Monitoring</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Monitor remote actor performance
struct RemoteActorMetrics {
    actor_id: String,
    network_id: String,
    total_messages: u64,
    successful_messages: u64,
    average_latency_ms: f64,
    last_response_time: Option&lt;chrono::DateTime&lt;chrono::Utc&gt;&gt;,
}

impl RemoteActorMetrics {
    async fn record_message_sent(&amp;mut self) {
        self.total_messages += 1;
        // Record timing for latency calculation
    }
    
    async fn record_response_received(&amp;mut self, latency: Duration) {
        self.successful_messages += 1;
        self.last_response_time = Some(chrono::Utc::now());
        
        // Update rolling average
        let latency_ms = latency.as_millis() as f64;
        self.average_latency_ms = (self.average_latency_ms + latency_ms) / 2.0;
    }
    
    fn success_rate(&amp;self) -&gt; f64 {
        if self.total_messages == 0 {
            0.0
        } else {
            (self.successful_messages as f64) / (self.total_messages as f64)
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-17"><a class="header" href="#best-practices-17">Best Practices</a></h2>
<h3 id="1-network-design"><a class="header" href="#1-network-design">1. Network Design</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Organize actors by function and location
"auth_service@auth_cluster"
"data_processor@processing_cluster"  
"ml_trainer@gpu_cluster"

// Avoid: Generic names that don't indicate purpose
"actor1@server"
"service@network"
<span class="boring">}</span></code></pre></pre>
<h3 id="2-error-resilience"><a class="header" href="#2-error-resilience">2. Error Resilience</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Implement circuit breaker pattern for remote actors
struct CircuitBreaker {
    failure_count: u32,
    failure_threshold: u32,
    timeout_duration: Duration,
    last_failure_time: Option&lt;Instant&gt;,
    state: CircuitState,
}

enum CircuitState {
    Closed,   // Normal operation
    Open,     // Failing, don't try
    HalfOpen, // Testing if service recovered
}

impl CircuitBreaker {
    async fn call_remote_actor(&amp;mut self, network: &amp;DistributedNetwork) -&gt; Result&lt;Message, anyhow::Error&gt; {
        match self.state {
            CircuitState::Open =&gt; {
                if self.should_attempt_reset() {
                    self.state = CircuitState::HalfOpen;
                } else {
                    return Err(anyhow::anyhow!("Circuit breaker is open"));
                }
            },
            _ =&gt; {}
        }
        
        match network.send_to_remote_actor("server", "actor", "Input", Message::String("test".to_string().into())).await {
            Ok(response) =&gt; {
                self.on_success();
                Ok(response)
            },
            Err(e) =&gt; {
                self.on_failure();
                Err(e)
            }
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="3-resource-management-1"><a class="header" href="#3-resource-management-1">3. Resource Management</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Properly clean up remote actor registrations
async fn cleanup_remote_actors(network: &amp;mut DistributedNetwork) -&gt; Result&lt;(), anyhow::Error&gt; {
    // Get list of registered remote actors
    let remote_actors = network.list_remote_actors().await?;
    
    // Unregister all remote actors
    for (actor_id, network_id) in remote_actors {
        network.unregister_remote_actor(&amp;format!("{}@{}", actor_id, network_id)).await?;
        println!("üßπ Unregistered remote actor: {}@{}", actor_id, network_id);
    }
    
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h2 id="troubleshooting-8"><a class="header" href="#troubleshooting-8">Troubleshooting</a></h2>
<h3 id="common-issues-6"><a class="header" href="#common-issues-6">Common Issues</a></h3>
<ol>
<li>
<p><strong>Remote Actor Not Found</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Verify actor exists on remote network
let actors = client_network.list_actors_on_network("server_network").await?;
println!("Available actors: {:?}", actors);
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p><strong>Registration Fails</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Check network connection status
if !client_network.is_connected_to("server_network").await {
    client_network.connect_to_network("server:8080").await?;
}
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p><strong>Messages Not Delivered</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Check message serialization
let message = Message::String("test".to_string().into());
match serde_json::to_string(&amp;message) {
    Ok(_) =&gt; println!("‚úÖ Message is serializable"),
    Err(e) =&gt; eprintln!("‚ùå Message serialization failed: {}", e),
}
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p><strong>High Latency</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Monitor network latency
let start = Instant::now();
client_network.ping_network("server_network").await?;
let latency = start.elapsed();
println!("Network latency: {:?}", latency);
<span class="boring">}</span></code></pre></pre>
</li>
</ol>
<h2 id="next-steps-23"><a class="header" href="#next-steps-23">Next Steps</a></h2>
<ul>
<li><a href="api/distributed/discovery-registration.html">Discovery &amp; Registration</a> - Advanced discovery patterns</li>
<li><a href="api/distributed/conflict-resolution.html">Conflict Resolution</a> - Handle actor name conflicts</li>
<li><a href="api/distributed/../../tutorials/distributed-workflow-example.html">Tutorial: Distributed Workflow Example</a></li>
</ul>
<h2 id="related-documentation-4"><a class="header" href="#related-documentation-4">Related Documentation</a></h2>
<ul>
<li><a href="api/distributed/setting-up-networks.html">Setting Up Distributed Networks</a></li>
<li><a href="api/distributed/../../architecture/distributed-networks.html">Architecture: Distributed Networks</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="discovery--registration"><a class="header" href="#discovery--registration">Discovery &amp; Registration</a></h1>
<p>Learn how to use network discovery services and automatic actor registration in distributed Reflow networks.</p>
<h2 id="overview-11"><a class="header" href="#overview-11">Overview</a></h2>
<p>Discovery and registration services enable:</p>
<ul>
<li><strong>Automatic network discovery</strong>: Find available networks without manual configuration</li>
<li><strong>Service registration</strong>: Advertise your network's capabilities to others</li>
<li><strong>Dynamic actor discovery</strong>: Automatically find and register remote actors</li>
<li><strong>Health monitoring</strong>: Track network and actor availability</li>
<li><strong>Load balancing</strong>: Distribute connections across available instances</li>
</ul>
<h2 id="discovery-service-types"><a class="header" href="#discovery-service-types">Discovery Service Types</a></h2>
<h3 id="1-built-in-discovery"><a class="header" href="#1-built-in-discovery">1. Built-in Discovery</a></h3>
<p>Use Reflow's built-in discovery where one network acts as a registry:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::distributed_network::{DistributedNetwork, DistributedConfig};

// Discovery server (registry)
let registry_config = DistributedConfig {
    network_id: "discovery_registry".to_string(),
    instance_id: "registry_001".to_string(),
    bind_address: "0.0.0.0".to_string(),
    bind_port: 8090,
    discovery_endpoints: vec![], // Empty - this IS the discovery server
    // ... other config
};

let mut registry_network = DistributedNetwork::new(registry_config).await?;
registry_network.start().await?;
println!("üîç Discovery registry started on port 8090");
<span class="boring">}</span></code></pre></pre>
<h3 id="2-client-networks-using-registry"><a class="header" href="#2-client-networks-using-registry">2. Client Networks Using Registry</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Client networks connect to registry for discovery
let client_config = DistributedConfig {
    network_id: "worker_network".to_string(),
    instance_id: "worker_001".to_string(),
    bind_address: "127.0.0.1".to_string(),
    bind_port: 8091,
    discovery_endpoints: vec!["http://registry:8090".to_string()],
    // ... other config
};

let mut client_network = DistributedNetwork::new(client_config).await?;
client_network.start().await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="3-external-discovery-services"><a class="header" href="#3-external-discovery-services">3. External Discovery Services</a></h3>
<p>Integrate with external service discovery systems:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Using Consul
let consul_config = DistributedConfig {
    network_id: "consul_client".to_string(),
    discovery_endpoints: vec![
        "http://consul.service.consul:8500/v1/agent/services".to_string()
    ],
    // ... other config
};

// Using etcd
let etcd_config = DistributedConfig {
    network_id: "etcd_client".to_string(),
    discovery_endpoints: vec![
        "http://etcd.cluster.local:2379/v2/keys/reflow/services".to_string()
    ],
    // ... other config
};

// Using Kubernetes DNS
let k8s_config = DistributedConfig {
    network_id: "k8s_service".to_string(),
    discovery_endpoints: vec![
        "http://reflow-discovery.default.svc.cluster.local:8080".to_string()
    ],
    // ... other config
};
<span class="boring">}</span></code></pre></pre>
<h2 id="network-registration"><a class="header" href="#network-registration">Network Registration</a></h2>
<h3 id="basic-registration"><a class="header" href="#basic-registration">Basic Registration</a></h3>
<p>Networks automatically register themselves when started:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let network_config = DistributedConfig {
    network_id: "ml_processing_cluster".to_string(),
    instance_id: "gpu_worker_001".to_string(),
    bind_address: "0.0.0.0".to_string(),
    bind_port: 8080,
    discovery_endpoints: vec!["http://discovery:8090".to_string()],
    // ... other config
};

let mut network = DistributedNetwork::new(network_config).await?;

// Registration happens automatically on start
network.start().await?;
// Network is now registered with discovery service
<span class="boring">}</span></code></pre></pre>
<h3 id="registration-with-metadata"><a class="header" href="#registration-with-metadata">Registration with Metadata</a></h3>
<p>Include additional metadata during registration:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Register with capabilities and metadata
let registration_metadata = serde_json::json!({
    "capabilities": ["ml_training", "gpu_compute", "data_processing"],
    "resources": {
        "cpu_cores": 32,
        "gpu_count": 4,
        "memory_gb": 128
    },
    "version": "1.2.0",
    "tags": ["ml", "gpu", "production"],
    "health_check_url": "http://worker:8080/health"
});

// This metadata is included in registration (implementation detail)
// The discovery service can use this for intelligent routing
<span class="boring">}</span></code></pre></pre>
<h3 id="manual-registration-control"><a class="header" href="#manual-registration-control">Manual Registration Control</a></h3>
<p>Control registration timing and behavior:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Start network without auto-registration
let mut network = DistributedNetwork::new(config).await?;
network.start().await?;

// Perform initialization
setup_local_actors(&amp;mut network).await?;
run_health_checks(&amp;network).await?;

// Register manually when ready
network.register_with_discovery().await?;
println!("‚úÖ Network registered and ready for connections");
<span class="boring">}</span></code></pre></pre>
<h2 id="network-discovery-1"><a class="header" href="#network-discovery-1">Network Discovery</a></h2>
<h3 id="discover-available-networks"><a class="header" href="#discover-available-networks">Discover Available Networks</a></h3>
<p>Find networks that are currently available:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Discover all available networks
let discovered_networks = client_network.discover_networks().await?;

for network_info in discovered_networks {
    println!("üåê Found network: {} ({})", 
        network_info.network_id, 
        network_info.endpoint
    );
    println!("   Capabilities: {:?}", network_info.capabilities);
    println!("   Last seen: {}", network_info.last_seen);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="filtered-discovery-1"><a class="header" href="#filtered-discovery-1">Filtered Discovery</a></h3>
<p>Find networks with specific capabilities:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Discover networks with ML capabilities
let ml_networks = client_network.discover_networks_with_capability("ml_training").await?;

for network in ml_networks {
    println!("üß† ML Network: {} at {}", network.network_id, network.endpoint);
    
    // Connect to ML networks
    client_network.connect_to_network(&amp;network.endpoint).await?;
}
<span class="boring">}</span></code></pre></pre>
<h3 id="discovery-by-tags"><a class="header" href="#discovery-by-tags">Discovery by Tags</a></h3>
<p>Find networks using tag-based filtering:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Discover production GPU networks
let gpu_networks = client_network.discover_networks_by_tags(vec!["gpu", "production"]).await?;

for network in gpu_networks {
    if network.is_healthy() {
        client_network.connect_to_network(&amp;network.endpoint).await?;
        println!("‚úÖ Connected to GPU network: {}", network.network_id);
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="automatic-actor-discovery"><a class="header" href="#automatic-actor-discovery">Automatic Actor Discovery</a></h2>
<h3 id="discover-actors-on-connected-networks"><a class="header" href="#discover-actors-on-connected-networks">Discover Actors on Connected Networks</a></h3>
<p>Once connected to a network, discover its available actors:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Connect to a network first
client_network.connect_to_network("ml_cluster:8080").await?;

// Discover actors on that network
let actors = client_network.discover_actors_on_network("ml_cluster").await?;

for actor in actors {
    println!("üé≠ Actor: {} ({})", actor.name, actor.component_type);
    println!("   Capabilities: {:?}", actor.capabilities);
    println!("   Ports: in={:?}, out={:?}", actor.inports, actor.outports);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="automatic-registration"><a class="header" href="#automatic-registration">Automatic Registration</a></h3>
<p>Register all discovered actors automatically:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Discover and register all compatible actors
let discovered_actors = client_network.discover_actors_on_network("data_cluster").await?;

for actor in discovered_actors {
    // Only register actors we can use
    if actor.capabilities.contains(&amp;"data_processing".to_string()) {
        match client_network.register_remote_actor(&amp;actor.name, "data_cluster").await {
            Ok(_) =&gt; println!("‚úÖ Registered actor: {}", actor.name),
            Err(e) =&gt; eprintln!("‚ùå Failed to register {}: {}", actor.name, e),
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="selective-auto-registration"><a class="header" href="#selective-auto-registration">Selective Auto-Registration</a></h3>
<p>Register actors based on complex criteria:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>async fn smart_actor_registration(
    network: &amp;mut DistributedNetwork,
    remote_network_id: &amp;str
) -&gt; Result&lt;Vec&lt;String&gt;, anyhow::Error&gt; {
    let actors = network.discover_actors_on_network(remote_network_id).await?;
    let mut registered_actors = Vec::new();
    
    for actor in actors {
        // Complex registration logic
        let should_register = match actor.component_type.as_str() {
            "DataProcessorActor" =&gt; {
                // Only register if we don't have local data processors
                !network.has_local_actor_of_type("DataProcessorActor").await
            },
            "MLTrainerActor" =&gt; {
                // Only register GPU trainers
                actor.capabilities.contains(&amp;"gpu_compute".to_string())
            },
            "DatabaseActor" =&gt; {
                // Register if it's a different database type than our local ones
                let local_dbs = network.get_local_database_types().await;
                !local_dbs.contains(&amp;actor.get_database_type())
            },
            _ =&gt; false, // Don't auto-register unknown types
        };
        
        if should_register {
            let alias = network.register_remote_actor(&amp;actor.name, remote_network_id).await?;
            registered_actors.push(alias);
            println!("ü§ñ Smart-registered: {} as {}", actor.name, alias);
        }
    }
    
    Ok(registered_actors)
}
<span class="boring">}</span></code></pre></pre>
<h2 id="health-monitoring-1"><a class="header" href="#health-monitoring-1">Health Monitoring</a></h2>
<h3 id="network-health-checks"><a class="header" href="#network-health-checks">Network Health Checks</a></h3>
<p>Monitor the health of discovered networks:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Periodic health monitoring
async fn monitor_network_health(network: &amp;DistributedNetwork) -&gt; Result&lt;(), anyhow::Error&gt; {
    let mut interval = tokio::time::interval(Duration::from_secs(30));
    
    loop {
        interval.tick().await;
        
        let connected_networks = network.get_connected_networks().await;
        for network_id in connected_networks {
            match network.ping_network(&amp;network_id).await {
                Ok(latency) =&gt; {
                    println!("‚úÖ Network {} healthy ({}ms)", network_id, latency.as_millis());
                },
                Err(e) =&gt; {
                    eprintln!("‚ùå Network {} unhealthy: {}", network_id, e);
                    
                    // Attempt reconnection
                    if let Ok(network_info) = network.get_network_info(&amp;network_id).await {
                        match network.reconnect_to_network(&amp;network_info.endpoint).await {
                            Ok(_) =&gt; println!("üîÑ Reconnected to {}", network_id),
                            Err(e) =&gt; eprintln!("üîå Reconnection failed: {}", e),
                        }
                    }
                }
            }
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="actor-health-monitoring"><a class="header" href="#actor-health-monitoring">Actor Health Monitoring</a></h3>
<p>Monitor remote actor availability:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>async fn monitor_remote_actors(network: &amp;DistributedNetwork) -&gt; Result&lt;(), anyhow::Error&gt; {
    let remote_actors = network.list_registered_remote_actors().await;
    
    for (actor_alias, actor_ref) in remote_actors {
        match network.ping_remote_actor(&amp;actor_ref.network_id, &amp;actor_ref.actor_id).await {
            Ok(_) =&gt; {
                println!("‚úÖ Remote actor {} is responsive", actor_alias);
            },
            Err(e) =&gt; {
                eprintln!("‚ùå Remote actor {} is unresponsive: {}", actor_alias, e);
                
                // Try to re-register the actor
                match network.refresh_remote_actor(&amp;actor_alias).await {
                    Ok(_) =&gt; println!("üîÑ Refreshed remote actor: {}", actor_alias),
                    Err(e) =&gt; {
                        eprintln!("üö´ Failed to refresh {}: {}", actor_alias, e);
                        // Consider removing the actor or marking it as unavailable
                    }
                }
            }
        }
    }
    
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h2 id="load-balancing-and-failover"><a class="header" href="#load-balancing-and-failover">Load Balancing and Failover</a></h2>
<h3 id="discover-multiple-instances"><a class="header" href="#discover-multiple-instances">Discover Multiple Instances</a></h3>
<p>Find multiple instances of the same service:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Find all instances of a specific service type
let data_processors = client_network.discover_networks_with_capability("data_processing").await?;

println!("Found {} data processing networks:", data_processors.len());
for (i, network) in data_processors.iter().enumerate() {
    println!("  {}. {} at {} (load: {}%)", 
        i + 1, 
        network.network_id, 
        network.endpoint,
        network.cpu_usage.unwrap_or(0.0)
    );
}
<span class="boring">}</span></code></pre></pre>
<h3 id="load-balanced-registration"><a class="header" href="#load-balanced-registration">Load-Balanced Registration</a></h3>
<p>Register actors from multiple networks for load balancing:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Register the same actor type from multiple networks
let processing_networks = vec!["cluster_1", "cluster_2", "cluster_3"];

for (i, network_id) in processing_networks.iter().enumerate() {
    if client_network.is_network_available(network_id).await {
        let alias = format!("data_processor_{}", i + 1);
        client_network.register_remote_actor_with_alias(
            &amp;alias,
            "data_processor", 
            network_id
        ).await?;
        println!("‚öñÔ∏è  Registered load-balanced actor: {}", alias);
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="failover-registration"><a class="header" href="#failover-registration">Failover Registration</a></h3>
<p>Implement failover with primary and backup actors:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct FailoverActorRegistry {
    network: Arc&lt;DistributedNetwork&gt;,
    primary_actors: HashMap&lt;String, String&gt;,    // service -&gt; primary actor alias
    backup_actors: HashMap&lt;String, Vec&lt;String&gt;&gt;, // service -&gt; backup actor aliases
}

impl FailoverActorRegistry {
    async fn register_with_failover(&amp;mut self, 
        service_name: &amp;str, 
        actor_type: &amp;str
    ) -&gt; Result&lt;(), anyhow::Error&gt; {
        let networks = self.network.discover_networks_with_capability(actor_type).await?;
        
        if networks.is_empty() {
            return Err(anyhow::anyhow!("No networks found with capability: {}", actor_type));
        }
        
        // Primary: Use the network with lowest load
        let primary_network = networks.iter()
            .min_by(|a, b| a.cpu_usage.partial_cmp(&amp;b.cpu_usage).unwrap())
            .unwrap();
        
        let primary_alias = format!("{}_primary", service_name);
        self.network.register_remote_actor_with_alias(
            &amp;primary_alias,
            actor_type,
            &amp;primary_network.network_id
        ).await?;
        
        self.primary_actors.insert(service_name.to_string(), primary_alias);
        
        // Backups: Register from other networks
        let mut backup_aliases = Vec::new();
        for (i, network) in networks.iter().skip(1).enumerate() {
            let backup_alias = format!("{}_backup_{}", service_name, i + 1);
            self.network.register_remote_actor_with_alias(
                &amp;backup_alias,
                actor_type,
                &amp;network.network_id
            ).await?;
            backup_aliases.push(backup_alias);
        }
        
        self.backup_actors.insert(service_name.to_string(), backup_aliases);
        
        println!("üõ°Ô∏è  Registered failover service: {} with {} backups", 
            service_name, backup_aliases.len());
        
        Ok(())
    }
    
    async fn handle_primary_failure(&amp;self, service_name: &amp;str) -&gt; Result&lt;String, anyhow::Error&gt; {
        if let Some(backups) = self.backup_actors.get(service_name) {
            if let Some(first_backup) = backups.first() {
                // Promote first backup to primary
                println!("üîÑ Promoting backup to primary for service: {}", service_name);
                return Ok(first_backup.clone());
            }
        }
        Err(anyhow::anyhow!("No backup available for service: {}", service_name))
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="configuration-management-2"><a class="header" href="#configuration-management-2">Configuration Management</a></h2>
<h3 id="discovery-service-configuration"><a class="header" href="#discovery-service-configuration">Discovery Service Configuration</a></h3>
<p>Configure discovery service behavior:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(Debug, Clone)]
pub struct DiscoveryConfig {
    pub refresh_interval_ms: u64,
    pub health_check_interval_ms: u64,
    pub max_discovery_retries: u32,
    pub discovery_timeout_ms: u64,
    pub enable_auto_registration: bool,
    pub registration_metadata: serde_json::Value,
}

impl Default for DiscoveryConfig {
    fn default() -&gt; Self {
        DiscoveryConfig {
            refresh_interval_ms: 30000,      // 30 seconds
            health_check_interval_ms: 15000, // 15 seconds
            max_discovery_retries: 3,
            discovery_timeout_ms: 5000,      // 5 seconds
            enable_auto_registration: true,
            registration_metadata: serde_json::json!({
                "version": "1.0.0",
                "capabilities": []
            }),
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="environment-specific-discovery"><a class="header" href="#environment-specific-discovery">Environment-Specific Discovery</a></h3>
<p>Configure discovery for different environments:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn create_discovery_config(environment: &amp;str) -&gt; DiscoveryConfig {
    match environment {
        "development" =&gt; DiscoveryConfig {
            refresh_interval_ms: 10000,  // Faster refresh for dev
            health_check_interval_ms: 5000,
            discovery_timeout_ms: 2000,  // Shorter timeout
            enable_auto_registration: true,
            registration_metadata: serde_json::json!({
                "environment": "development",
                "auto_discovery": true
            }),
            ..Default::default()
        },
        "production" =&gt; DiscoveryConfig {
            refresh_interval_ms: 60000,  // Slower refresh for prod
            health_check_interval_ms: 30000,
            discovery_timeout_ms: 10000, // Longer timeout
            enable_auto_registration: false, // Manual control
            registration_metadata: serde_json::json!({
                "environment": "production",
                "manual_registration": true
            }),
            ..Default::default()
        },
        _ =&gt; DiscoveryConfig::default(),
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="error-handling-14"><a class="header" href="#error-handling-14">Error Handling</a></h2>
<h3 id="discovery-errors-2"><a class="header" href="#discovery-errors-2">Discovery Errors</a></h3>
<p>Handle common discovery and registration errors:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>async fn robust_discovery(network: &amp;DistributedNetwork) -&gt; Result&lt;Vec&lt;NetworkInfo&gt;, anyhow::Error&gt; {
    let mut retries = 3;
    let mut last_error = None;
    
    while retries &gt; 0 {
        match network.discover_networks().await {
            Ok(networks) =&gt; {
                if networks.is_empty() {
                    println!("‚ö†Ô∏è  No networks discovered, retrying...");
                } else {
                    return Ok(networks);
                }
            },
            Err(e) =&gt; {
                eprintln!("‚ùå Discovery attempt failed: {}", e);
                last_error = Some(e);
                
                // Wait before retry
                tokio::time::sleep(Duration::from_secs(2)).await;
            }
        }
        
        retries -= 1;
    }
    
    Err(last_error.unwrap_or_else(|| anyhow::anyhow!("Discovery failed after retries")))
}
<span class="boring">}</span></code></pre></pre>
<h3 id="registration-conflicts"><a class="header" href="#registration-conflicts">Registration Conflicts</a></h3>
<p>Handle registration conflicts gracefully:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>async fn safe_actor_registration(
    network: &amp;mut DistributedNetwork,
    actor_name: &amp;str,
    remote_network: &amp;str
) -&gt; Result&lt;String, anyhow::Error&gt; {
    match network.register_remote_actor(actor_name, remote_network).await {
        Ok(alias) =&gt; Ok(alias),
        Err(e) if e.to_string().contains("name conflict") =&gt; {
            // Try with numbered suffix
            for i in 1..=10 {
                let attempt_name = format!("{}_{}", actor_name, i);
                match network.register_remote_actor_with_alias(
                    &amp;attempt_name, 
                    actor_name, 
                    remote_network
                ).await {
                    Ok(alias) =&gt; {
                        println!("‚úÖ Registered with conflict resolution: {}", alias);
                        return Ok(alias);
                    },
                    Err(_) =&gt; continue,
                }
            }
            Err(anyhow::anyhow!("Could not resolve naming conflict for: {}", actor_name))
        },
        Err(e) =&gt; Err(e),
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-18"><a class="header" href="#best-practices-18">Best Practices</a></h2>
<h3 id="1-discovery-strategy"><a class="header" href="#1-discovery-strategy">1. Discovery Strategy</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Use hierarchical discovery with fallbacks
let discovery_endpoints = vec![
    "http://local-discovery:8090",      // Local first
    "http://regional-discovery:8090",   // Regional second
    "http://global-discovery:8090",     // Global fallback
];

// Configure discovery timeouts appropriately
let config = DiscoveryConfig {
    discovery_timeout_ms: 5000,    // 5 seconds max
    max_discovery_retries: 3,      // Try 3 times
    refresh_interval_ms: 30000,    // Refresh every 30s
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h3 id="2-health-monitoring"><a class="header" href="#2-health-monitoring">2. Health Monitoring</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Implement comprehensive health monitoring
async fn comprehensive_health_check(network: &amp;DistributedNetwork) -&gt; HealthStatus {
    let mut status = HealthStatus::new();
    
    // Check discovery service connectivity
    status.discovery_healthy = network.ping_discovery_service().await.is_ok();
    
    // Check connected networks
    let networks = network.get_connected_networks().await;
    for network_id in networks {
        let network_healthy = network.ping_network(&amp;network_id).await.is_ok();
        status.network_health.insert(network_id, network_healthy);
    }
    
    // Check remote actors
    let actors = network.list_registered_remote_actors().await;
    for (alias, actor_ref) in actors {
        let actor_healthy = network.ping_remote_actor(
            &amp;actor_ref.network_id, 
            &amp;actor_ref.actor_id
        ).await.is_ok();
        status.actor_health.insert(alias, actor_healthy);
    }
    
    status
}
<span class="boring">}</span></code></pre></pre>
<h3 id="3-resource-cleanup"><a class="header" href="#3-resource-cleanup">3. Resource Cleanup</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Proper cleanup on shutdown
async fn graceful_shutdown(mut network: DistributedNetwork) -&gt; Result&lt;(), anyhow::Error&gt; {
    // Stop discovery refresh
    network.stop_discovery_refresh().await?;
    
    // Unregister from discovery service
    network.unregister_from_discovery().await?;
    
    // Clean up remote actor registrations
    let remote_actors = network.list_registered_remote_actors().await;
    for (alias, _) in remote_actors {
        network.unregister_remote_actor(&amp;alias).await?;
    }
    
    // Disconnect from all networks
    let connected = network.get_connected_networks().await;
    for network_id in connected {
        network.disconnect_from_network(&amp;network_id).await?;
    }
    
    // Finally shutdown the network
    network.shutdown().await?;
    
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h2 id="integration-examples-2"><a class="header" href="#integration-examples-2">Integration Examples</a></h2>
<h3 id="docker-swarm-integration"><a class="header" href="#docker-swarm-integration">Docker Swarm Integration</a></h3>
<pre><code class="language-yaml"># docker-compose.yml
version: '3.8'
services:
  reflow-discovery:
    image: reflow:latest
    command: --mode discovery --port 8090
    ports:
      - "8090:8090"
    deploy:
      replicas: 1
      
  reflow-worker:
    image: reflow:latest
    command: --mode worker --discovery http://reflow-discovery:8090
    deploy:
      replicas: 3
    depends_on:
      - reflow-discovery
</code></pre>
<h3 id="kubernetes-integration"><a class="header" href="#kubernetes-integration">Kubernetes Integration</a></h3>
<pre><code class="language-yaml"># reflow-discovery-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: reflow-discovery
spec:
  selector:
    app: reflow-discovery
  ports:
    - port: 8090
      targetPort: 8090
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: reflow-discovery
spec:
  replicas: 1
  selector:
    matchLabels:
      app: reflow-discovery
  template:
    metadata:
      labels:
        app: reflow-discovery
    spec:
      containers:
      - name: reflow
        image: reflow:latest
        args: ["--mode", "discovery", "--port", "8090"]
        ports:
        - containerPort: 8090
</code></pre>
<h2 id="next-steps-24"><a class="header" href="#next-steps-24">Next Steps</a></h2>
<ul>
<li><a href="api/distributed/conflict-resolution.html">Conflict Resolution</a> - Handle actor name conflicts</li>
<li><a href="api/distributed/setting-up-networks.html">Setting Up Distributed Networks</a> - Basic network setup</li>
<li><a href="api/distributed/remote-actors.html">Remote Actors</a> - Working with remote actors</li>
</ul>
<h2 id="related-documentation-5"><a class="header" href="#related-documentation-5">Related Documentation</a></h2>
<ul>
<li><a href="api/distributed/../../architecture/distributed-networks.html">Architecture: Distributed Networks</a></li>
<li><a href="api/distributed/../../tutorials/distributed-workflow-example.html">Tutorial: Distributed Workflow Example</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="conflict-resolution-2"><a class="header" href="#conflict-resolution-2">Conflict Resolution</a></h1>
<p>Learn how to handle actor name conflicts in distributed Reflow networks.</p>
<h2 id="overview-12"><a class="header" href="#overview-12">Overview</a></h2>
<p>Name conflicts occur when multiple networks have actors with identical names. This guide covers:</p>
<ul>
<li><strong>Understanding conflict types</strong>: Different scenarios that cause conflicts</li>
<li><strong>Resolution strategies</strong>: Automatic and manual approaches to resolve conflicts</li>
<li><strong>Prevention techniques</strong>: Best practices to avoid conflicts</li>
<li><strong>Hierarchical namespacing</strong>: Advanced organization patterns</li>
</ul>
<h2 id="conflict-types"><a class="header" href="#conflict-types">Conflict Types</a></h2>
<h3 id="1-local-remote-conflicts"><a class="header" href="#1-local-remote-conflicts">1. Local-Remote Conflicts</a></h3>
<p>Conflict between a local actor and a remote actor with the same name:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Local network has "data_processor"
network.register_local_actor("data_processor", DataProcessorActor::new())?;

// Trying to register remote actor with same name
match client_network.register_remote_actor("data_processor", "server_network").await {
    Err(e) if e.to_string().contains("name conflict") =&gt; {
        println!("‚ùå Conflict: local 'data_processor' vs remote 'data_processor'");
    },
    _ =&gt; {}
}
<span class="boring">}</span></code></pre></pre>
<h3 id="2-remote-remote-conflicts"><a class="header" href="#2-remote-remote-conflicts">2. Remote-Remote Conflicts</a></h3>
<p>Multiple remote networks have actors with the same name:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Both networks have "authentication_service"
client_network.register_remote_actor("authentication_service", "primary_auth").await?;

// This will conflict:
match client_network.register_remote_actor("authentication_service", "backup_auth").await {
    Err(e) =&gt; println!("‚ùå Conflict: primary_auth/authentication_service vs backup_auth/authentication_service"),
    _ =&gt; {}
}
<span class="boring">}</span></code></pre></pre>
<h3 id="3-alias-conflicts"><a class="header" href="#3-alias-conflicts">3. Alias Conflicts</a></h3>
<p>Custom aliases that conflict with existing names:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Register with alias that conflicts with local actor
match client_network.register_remote_actor_with_alias(
    "local_actor_name",  // This alias conflicts!
    "remote_actor",
    "remote_network"
).await {
    Err(e) =&gt; println!("‚ùå Alias conflicts with existing local actor"),
    _ =&gt; {}
}
<span class="boring">}</span></code></pre></pre>
<h2 id="resolution-strategies"><a class="header" href="#resolution-strategies">Resolution Strategies</a></h2>
<h3 id="1-automatic-aliasing"><a class="header" href="#1-automatic-aliasing">1. Automatic Aliasing</a></h3>
<p>Let the system automatically generate unique aliases:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::distributed_network::ConflictResolutionStrategy;

// Automatic resolution with numbered suffixes
let alias = client_network.register_remote_actor_with_strategy(
    "data_processor",
    "server_network", 
    ConflictResolutionStrategy::AutoAlias
).await?;

// Results in aliases like:
// - "data_processor" (if no conflict)
// - "data_processor_1" (first conflict)
// - "data_processor_2" (second conflict)

println!("‚úÖ Registered as: {}", alias);
<span class="boring">}</span></code></pre></pre>
<h3 id="2-network-prefixing"><a class="header" href="#2-network-prefixing">2. Network Prefixing</a></h3>
<p>Prefix remote actors with their network name:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let alias = client_network.register_remote_actor_with_strategy(
    "data_processor",
    "server_network",
    ConflictResolutionStrategy::NetworkPrefix
).await?;

// Results in: "server_network_data_processor"
println!("‚úÖ Network-prefixed actor: {}", alias);
<span class="boring">}</span></code></pre></pre>
<h3 id="3-fully-qualified-names"><a class="header" href="#3-fully-qualified-names">3. Fully Qualified Names</a></h3>
<p>Use complete network::actor notation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let alias = client_network.register_remote_actor_with_strategy(
    "data_processor", 
    "server_network",
    ConflictResolutionStrategy::FullyQualified
).await?;

// Results in: "server_network::data_processor"
println!("‚úÖ Fully qualified actor: {}", alias);
<span class="boring">}</span></code></pre></pre>
<h3 id="4-manual-aliases"><a class="header" href="#4-manual-aliases">4. Manual Aliases</a></h3>
<p>Provide explicit custom aliases:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let alias = client_network.register_remote_actor_with_strategy(
    "data_processor",
    "server_network", 
    ConflictResolutionStrategy::ManualAlias("server_data_proc".to_string())
).await?;

// Results in: "server_data_proc"
println!("‚úÖ Custom alias: {}", alias);
<span class="boring">}</span></code></pre></pre>
<h3 id="5-fail-on-conflict"><a class="header" href="#5-fail-on-conflict">5. Fail on Conflict</a></h3>
<p>Explicitly handle conflicts in application code:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>match client_network.register_remote_actor_with_strategy(
    "data_processor",
    "server_network",
    ConflictResolutionStrategy::Fail
).await {
    Ok(alias) =&gt; println!("‚úÖ No conflict, registered as: {}", alias),
    Err(e) =&gt; {
        println!("‚ùå Registration failed due to conflict: {}", e);
        // Handle conflict manually
        handle_naming_conflict(&amp;mut client_network, "data_processor", "server_network").await?;
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="advanced-conflict-resolution"><a class="header" href="#advanced-conflict-resolution">Advanced Conflict Resolution</a></h2>
<h3 id="intelligent-conflict-detection"><a class="header" href="#intelligent-conflict-detection">Intelligent Conflict Detection</a></h3>
<p>Detect and analyze conflicts before registration:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>async fn analyze_potential_conflicts(
    network: &amp;DistributedNetwork,
    actor_name: &amp;str,
    remote_network_id: &amp;str
) -&gt; Result&lt;ConflictAnalysis, anyhow::Error&gt; {
    let mut analysis = ConflictAnalysis::new();
    
    // Check local conflicts
    if network.has_local_actor(actor_name).await {
        analysis.local_conflicts.push(LocalConflict {
            actor_name: actor_name.to_string(),
            actor_type: network.get_local_actor_type(actor_name).await?,
        });
    }
    
    // Check remote conflicts
    let remote_actors = network.list_registered_remote_actors().await;
    for (alias, actor_ref) in remote_actors {
        if alias == actor_name {
            analysis.remote_conflicts.push(RemoteConflict {
                alias,
                actor_ref,
            });
        }
    }
    
    // Suggest resolutions
    analysis.suggested_resolutions = suggest_resolutions(&amp;analysis, actor_name, remote_network_id);
    
    Ok(analysis)
}

#[derive(Debug)]
struct ConflictAnalysis {
    local_conflicts: Vec&lt;LocalConflict&gt;,
    remote_conflicts: Vec&lt;RemoteConflict&gt;,
    suggested_resolutions: Vec&lt;SuggestedResolution&gt;,
}

#[derive(Debug)]
struct SuggestedResolution {
    strategy: ConflictResolutionStrategy,
    resulting_alias: String,
    confidence: f32,
    description: String,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="multi-network-batch-registration"><a class="header" href="#multi-network-batch-registration">Multi-Network Batch Registration</a></h3>
<p>Handle conflicts when registering actors from multiple networks:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>async fn batch_register_with_conflict_resolution(
    network: &amp;mut DistributedNetwork,
    registrations: Vec&lt;(String, String)&gt;  // (actor_name, network_id)
) -&gt; Result&lt;BatchRegistrationResult, anyhow::Error&gt; {
    let mut results = BatchRegistrationResult::new();
    let mut name_usage = HashMap::new();
    
    // Analyze all potential conflicts first
    for (actor_name, network_id) in &amp;registrations {
        name_usage.entry(actor_name.clone())
            .or_insert_with(Vec::new)
            .push(network_id.clone());
    }
    
    // Register with conflict resolution
    for (actor_name, network_id) in registrations {
        let strategy = if name_usage[&amp;actor_name].len() &gt; 1 {
            // Multiple networks have same actor name
            ConflictResolutionStrategy::NetworkPrefix
        } else if network.has_local_actor(&amp;actor_name).await {
            // Conflicts with local actor
            ConflictResolutionStrategy::FullyQualified
        } else {
            // No conflicts expected
            ConflictResolutionStrategy::AutoAlias
        };
        
        match network.register_remote_actor_with_strategy(&amp;actor_name, &amp;network_id, strategy).await {
            Ok(alias) =&gt; {
                results.successful.push(SuccessfulRegistration {
                    actor_name: actor_name.clone(),
                    network_id: network_id.clone(),
                    alias,
                    strategy_used: strategy,
                });
            },
            Err(e) =&gt; {
                results.failed.push(FailedRegistration {
                    actor_name,
                    network_id,
                    error: e.to_string(),
                });
            }
        }
    }
    
    Ok(results)
}
<span class="boring">}</span></code></pre></pre>
<h3 id="context-aware-resolution"><a class="header" href="#context-aware-resolution">Context-Aware Resolution</a></h3>
<p>Choose resolution strategies based on actor types and usage patterns:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>async fn smart_conflict_resolution(
    network: &amp;mut DistributedNetwork,
    actor_name: &amp;str,
    network_id: &amp;str,
    actor_metadata: &amp;ActorMetadata
) -&gt; Result&lt;String, anyhow::Error&gt; {
    // Analyze actor characteristics
    let strategy = match actor_metadata.actor_type.as_str() {
        "DatabaseActor" =&gt; {
            // For databases, use descriptive prefixes
            let db_type = actor_metadata.get_database_type().unwrap_or("db");
            ConflictResolutionStrategy::ManualAlias(
                format!("{}_{}", db_type, actor_name)
            )
        },
        "MLTrainerActor" =&gt; {
            // For ML trainers, include model type
            let model_type = actor_metadata.get_model_type().unwrap_or("model");
            ConflictResolutionStrategy::ManualAlias(
                format!("{}_trainer_{}", model_type, network_id)
            )
        },
        "AuthenticationActor" =&gt; {
            // For auth services, indicate primary/backup
            let is_primary = actor_metadata.is_primary_service().unwrap_or(false);
            let role = if is_primary { "primary" } else { "backup" };
            ConflictResolutionStrategy::ManualAlias(
                format!("auth_{}_{}", role, network_id)
            )
        },
        _ =&gt; {
            // Default strategy for other types
            if network.has_local_actor(actor_name).await {
                ConflictResolutionStrategy::NetworkPrefix
            } else {
                ConflictResolutionStrategy::AutoAlias
            }
        }
    };
    
    network.register_remote_actor_with_strategy(actor_name, network_id, strategy).await
}
<span class="boring">}</span></code></pre></pre>
<h2 id="hierarchical-namespacing"><a class="header" href="#hierarchical-namespacing">Hierarchical Namespacing</a></h2>
<h3 id="subgraph-organization"><a class="header" href="#subgraph-organization">Subgraph Organization</a></h3>
<p>Organize remote actors in hierarchical namespaces:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Instead of flat aliases, use hierarchical organization
let mount_config = SubgraphMountConfig {
    mount_point: "server".to_string(),
    network_id: "server_network".to_string(),
    include_patterns: vec!["*".to_string()],
    exclude_patterns: vec!["internal_*".to_string()],
};

// Mount entire network as subgraph
network.mount_network_as_subgraph(mount_config).await?;

// Actors are now accessible as:
// - "server/data_processor"
// - "server/validator" 
// - "server/transformer"

// Use in workflows
network.add_node("remote_proc", "server/data_processor", None)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="nested-organization"><a class="header" href="#nested-organization">Nested Organization</a></h3>
<p>Create deeply nested hierarchies for complex setups:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Mount multiple networks with organized structure
let mount_configs = vec![
    SubgraphMountConfig {
        mount_point: "ml/training".to_string(),
        network_id: "ml_training_cluster".to_string(),
        // ...
    },
    SubgraphMountConfig {
        mount_point: "ml/inference".to_string(), 
        network_id: "ml_inference_cluster".to_string(),
        // ...
    },
    SubgraphMountConfig {
        mount_point: "data/processing".to_string(),
        network_id: "data_processing_cluster".to_string(),
        // ...
    },
];

for config in mount_configs {
    network.mount_network_as_subgraph(config).await?;
}

// Result: Clean hierarchical structure
// ml/training/model_trainer
// ml/training/feature_engineer
// ml/inference/predictor
// ml/inference/batch_scorer
// data/processing/cleaner
// data/processing/transformer
<span class="boring">}</span></code></pre></pre>
<h2 id="conflict-prevention"><a class="header" href="#conflict-prevention">Conflict Prevention</a></h2>
<h3 id="1-naming-conventions"><a class="header" href="#1-naming-conventions">1. Naming Conventions</a></h3>
<p>Establish clear naming conventions to prevent conflicts:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Descriptive, domain-specific names
"user_authentication_service"
"payment_data_processor"
"ml_model_trainer_gpu"
"postgres_connection_pool"

// Avoid: Generic names likely to conflict
"processor"
"handler"
"service"
"actor"
"worker"
<span class="boring">}</span></code></pre></pre>
<h3 id="2-network-aware-registration"><a class="header" href="#2-network-aware-registration">2. Network-Aware Registration</a></h3>
<p>Include network identity in actor names during registration:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Register with network context
async fn register_with_network_context(
    network: &amp;mut DistributedNetwork,
    actor_name: &amp;str,
    remote_network_id: &amp;str
) -&gt; Result&lt;String, anyhow::Error&gt; {
    // Auto-generate context-aware names
    let network_context = remote_network_id.split('_').next().unwrap_or(remote_network_id);
    let contextual_name = format!("{}_{}", network_context, actor_name);
    
    network.register_remote_actor_with_alias(
        &amp;contextual_name,
        actor_name,
        remote_network_id
    ).await
}
<span class="boring">}</span></code></pre></pre>
<h3 id="3-capability-based-naming"><a class="header" href="#3-capability-based-naming">3. Capability-Based Naming</a></h3>
<p>Name actors based on their capabilities rather than generic terms:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Analyze actor capabilities and suggest names
async fn suggest_capability_based_name(
    actor_metadata: &amp;ActorMetadata
) -&gt; String {
    let capabilities = &amp;actor_metadata.capabilities;
    
    let primary_capability = capabilities.first().unwrap_or(&amp;"generic".to_string());
    let secondary_capability = capabilities.get(1);
    
    match (primary_capability.as_str(), secondary_capability) {
        ("ml_training", Some(sec)) if sec.contains("gpu") =&gt; "gpu_ml_trainer".to_string(),
        ("data_processing", Some(sec)) if sec.contains("stream") =&gt; "stream_data_processor".to_string(),
        ("database", Some(sec)) =&gt; format!("{}_database", sec),
        (primary, _) =&gt; format!("{}_service", primary),
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="error-handling-15"><a class="header" href="#error-handling-15">Error Handling</a></h2>
<h3 id="conflict-resolution-errors"><a class="header" href="#conflict-resolution-errors">Conflict Resolution Errors</a></h3>
<p>Handle errors during conflict resolution:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>async fn handle_conflict_resolution_error(
    error: &amp;anyhow::Error,
    actor_name: &amp;str,
    network_id: &amp;str
) -&gt; ConflictResolutionAction {
    if error.to_string().contains("maximum retries exceeded") {
        ConflictResolutionAction::UseFullyQualified
    } else if error.to_string().contains("invalid alias") {
        ConflictResolutionAction::GenerateAlternative
    } else if error.to_string().contains("network disconnected") {
        ConflictResolutionAction::RetryLater
    } else {
        ConflictResolutionAction::FailRegistration
    }
}

enum ConflictResolutionAction {
    UseFullyQualified,
    GenerateAlternative,
    RetryLater,
    FailRegistration,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="registration-rollback"><a class="header" href="#registration-rollback">Registration Rollback</a></h3>
<p>Implement rollback for failed batch registrations:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>async fn register_with_rollback(
    network: &amp;mut DistributedNetwork,
    registrations: Vec&lt;(String, String)&gt;
) -&gt; Result&lt;Vec&lt;String&gt;, anyhow::Error&gt; {
    let mut successful_aliases = Vec::new();
    
    for (actor_name, network_id) in registrations {
        match network.register_remote_actor(&amp;actor_name, &amp;network_id).await {
            Ok(alias) =&gt; {
                successful_aliases.push(alias);
            },
            Err(e) =&gt; {
                // Rollback previous registrations
                for alias in &amp;successful_aliases {
                    if let Err(rollback_err) = network.unregister_remote_actor(alias).await {
                        eprintln!("‚ö†Ô∏è  Rollback failed for {}: {}", alias, rollback_err);
                    }
                }
                return Err(e);
            }
        }
    }
    
    Ok(successful_aliases)
}
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-19"><a class="header" href="#best-practices-19">Best Practices</a></h2>
<h3 id="1-proactive-conflict-analysis"><a class="header" href="#1-proactive-conflict-analysis">1. Proactive Conflict Analysis</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Analyze potential conflicts before registration
async fn plan_registrations(
    network: &amp;DistributedNetwork,
    planned_registrations: &amp;[(String, String)]
) -&gt; RegistrationPlan {
    let mut plan = RegistrationPlan::new();
    
    for (actor_name, network_id) in planned_registrations {
        let analysis = analyze_potential_conflicts(network, actor_name, network_id).await.unwrap();
        
        if analysis.has_conflicts() {
            plan.add_with_resolution(actor_name, network_id, analysis.best_resolution());
        } else {
            plan.add_direct(actor_name, network_id);
        }
    }
    
    plan
}
<span class="boring">}</span></code></pre></pre>
<h3 id="2-documentation-and-tracking"><a class="header" href="#2-documentation-and-tracking">2. Documentation and Tracking</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Track and document conflict resolutions
struct ConflictResolutionLog {
    entries: Vec&lt;ConflictLogEntry&gt;,
}

struct ConflictLogEntry {
    timestamp: chrono::DateTime&lt;chrono::Utc&gt;,
    original_name: String,
    resolved_alias: String,
    strategy_used: ConflictResolutionStrategy,
    reason: String,
}

impl ConflictResolutionLog {
    fn log_resolution(&amp;mut self, 
        original_name: String, 
        resolved_alias: String, 
        strategy: ConflictResolutionStrategy,
        reason: String
    ) {
        self.entries.push(ConflictLogEntry {
            timestamp: chrono::Utc::now(),
            original_name,
            resolved_alias,
            strategy_used: strategy,
            reason,
        });
    }
    
    fn generate_report(&amp;self) -&gt; String {
        // Generate human-readable conflict resolution report
        format!("Conflict Resolution Report\n{:#?}", self.entries)
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="3-testing-conflict-scenarios"><a class="header" href="#3-testing-conflict-scenarios">3. Testing Conflict Scenarios</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod conflict_tests {
    use super::*;
    
    #[tokio::test]
    async fn test_local_remote_conflict_resolution() {
        let mut network = create_test_network().await;
        
        // Register local actor
        network.register_local_actor("processor", TestActor::new()).unwrap();
        
        // Try to register remote actor with same name
        let alias = network.register_remote_actor_with_strategy(
            "processor",
            "remote_network",
            ConflictResolutionStrategy::AutoAlias
        ).await.unwrap();
        
        assert_eq!(alias, "processor_1");
    }
    
    #[tokio::test] 
    async fn test_multiple_remote_conflicts() {
        let mut network = create_test_network().await;
        
        // Register multiple remote actors with same name
        let alias1 = network.register_remote_actor("auth", "network1").await.unwrap();
        let alias2 = network.register_remote_actor_with_strategy(
            "auth", 
            "network2",
            ConflictResolutionStrategy::NetworkPrefix
        ).await.unwrap();
        
        assert_eq!(alias1, "auth");
        assert_eq!(alias2, "network2_auth");
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="next-steps-25"><a class="header" href="#next-steps-25">Next Steps</a></h2>
<ul>
<li><a href="api/distributed/setting-up-networks.html">Setting Up Distributed Networks</a> - Basic network setup</li>
<li><a href="api/distributed/remote-actors.html">Remote Actors</a> - Working with remote actors</li>
<li><a href="api/distributed/discovery-registration.html">Discovery &amp; Registration</a> - Network discovery</li>
</ul>
<h2 id="related-documentation-6"><a class="header" href="#related-documentation-6">Related Documentation</a></h2>
<ul>
<li><a href="api/distributed/../../architecture/distributed-networks.html">Architecture: Distributed Networks</a></li>
<li><a href="api/distributed/../../tutorials/distributed-workflow-example.html">Tutorial: Distributed Workflow Example</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="webassembly-api---getting-started"><a class="header" href="#webassembly-api---getting-started">WebAssembly API - Getting Started</a></h1>
<p>Complete guide to using Reflow's WebAssembly bindings for browser-based workflow automation.</p>
<h2 id="overview-13"><a class="header" href="#overview-13">Overview</a></h2>
<p>Reflow's WebAssembly (WASM) bindings provide a complete JavaScript interface for running actor-based workflows in web browsers. The API maintains the same conceptual model as the native Rust implementation while offering browser-friendly interfaces.</p>
<h2 id="core-architecture"><a class="header" href="#core-architecture">Core Architecture</a></h2>
<pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 Browser Application                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ JavaScript Actor Classes                            ‚îÇ
‚îÇ ‚îú‚îÄ MyActor.run(context)                            ‚îÇ
‚îÇ ‚îú‚îÄ AnotherActor.run(context)                       ‚îÇ
‚îÇ ‚îî‚îÄ CustomActor.run(context)                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ WASM JavaScript Bindings                           ‚îÇ
‚îÇ ‚îú‚îÄ Graph, GraphNetwork, GraphHistory               ‚îÇ
‚îÇ ‚îú‚îÄ Network, MemoryState, ActorRunContext           ‚îÇ
‚îÇ ‚îî‚îÄ WasmActorContext, JsWasmActor                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ WebAssembly Runtime                                 ‚îÇ
‚îÇ ‚îú‚îÄ Rust Actor System (compiled to WASM)           ‚îÇ
‚îÇ ‚îú‚îÄ Graph Management &amp; Validation                   ‚îÇ
‚îÇ ‚îî‚îÄ Network Execution Engine                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre>
<h2 id="quick-start"><a class="header" href="#quick-start">Quick Start</a></h2>
<h3 id="1-installation--setup"><a class="header" href="#1-installation--setup">1. Installation &amp; Setup</a></h3>
<pre><code class="language-bash"># Clone the repository
git clone https://github.com/reflow-project/reflow
cd reflow

# Build WASM bindings
cd crates/reflow_network
wasm-pack build --target web --out-dir pkg
</code></pre>
<h3 id="2-basic-html-setup"><a class="header" href="#2-basic-html-setup">2. Basic HTML Setup</a></h3>
<pre><code class="language-html">&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
    &lt;meta charset="UTF-8"&gt;
    &lt;title&gt;Reflow WASM Example&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;h1&gt;Reflow WebAssembly Example&lt;/h1&gt;
    &lt;button id="runWorkflow"&gt;Run Workflow&lt;/button&gt;
    &lt;pre id="output"&gt;&lt;/pre&gt;

    &lt;script type="module"&gt;
        import init, { 
            Graph,
            GraphNetwork,
            MemoryState,
            init_panic_hook 
        } from './pkg/reflow_network.js';

        // Initialize WASM
        await init();
        init_panic_hook();

        console.log('‚úÖ Reflow WASM initialized successfully!');
    &lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<h3 id="3-your-first-actor"><a class="header" href="#3-your-first-actor">3. Your First Actor</a></h3>
<pre><code class="language-javascript">class HelloWorldActor {
    constructor() {
        this.inports = ["input"];
        this.outports = ["output"];
        this.state = null; // Managed by WASM
        this.config = { greeting: "Hello" };
    }

    /**
     * Actor execution method
     * @param {ActorRunContext} context - Execution context
     */
    run(context) {
        // Get input data
        const input = context.input.input;
        
        // Access state
        const count = context.state.get('count') || 0;
        context.state.set('count', count + 1);
        
        // Process and send output
        const greeting = `${this.config.greeting}, ${input}! (execution #${count + 1})`;
        context.send({ output: greeting });
        
        console.log(`HelloWorldActor: ${greeting}`);
    }
}
</code></pre>
<h3 id="4-create-and-run-a-graph"><a class="header" href="#4-create-and-run-a-graph">4. Create and Run a Graph</a></h3>
<pre><code class="language-javascript">async function createAndRunWorkflow() {
    // Create a graph
    const graph = new Graph("HelloWorkflow", true, {
        description: "A simple greeting workflow",
        version: "1.0.0"
    });

    // Add nodes
    graph.addNode("greeter", "HelloWorldActor", {
        x: 100, y: 100,
        description: "Greets the input"
    });

    // Add initial data
    graph.addInitial("World", "greeter", "input", {
        description: "Initial greeting target"
    });

    // Create network
    const network = new GraphNetwork(graph);
    
    // Register actor
    network.registerActor("HelloWorldActor", new HelloWorldActor());
    
    // Start and run
    await network.start();
    
    console.log("üöÄ Workflow started!");
}

// Run the workflow
document.getElementById('runWorkflow').addEventListener('click', createAndRunWorkflow);
</code></pre>
<h2 id="core-api-classes"><a class="header" href="#core-api-classes">Core API Classes</a></h2>
<h3 id="graph"><a class="header" href="#graph">Graph</a></h3>
<p>The <code>Graph</code> class represents a workflow definition with nodes, connections, and metadata.</p>
<pre><code class="language-javascript">// Create a new graph
const graph = new Graph(name, caseSensitive, properties);

// Basic operations
graph.addNode(nodeId, actorType, metadata);
graph.removeNode(nodeId);
graph.addConnection(fromNode, fromPort, toNode, toPort, metadata);
graph.removeConnection(fromNode, fromPort, toNode, toPort);

// Graph-level ports
graph.addInport(publicName, nodeId, portId, metadata);
graph.addOutport(publicName, nodeId, portId, metadata);

// Initial data
graph.addInitial(data, nodeId, portId, metadata);

// Export/Import
const graphData = graph.toJSON();
const loadedGraph = Graph.load(graphData, metadata);
</code></pre>
<h3 id="graphnetwork"><a class="header" href="#graphnetwork">GraphNetwork</a></h3>
<p>The <code>GraphNetwork</code> class executes graphs with registered actors.</p>
<pre><code class="language-javascript">// Create from graph
const network = new GraphNetwork(graph);

// Register actors
network.registerActor("ActorType", new ActorImplementation());

// Network lifecycle
await network.start();
network.shutdown();

// Monitoring
network.next((event) =&gt; {
    console.log("Network event:", event);
});

// Direct execution
const result = await network.executeActor("nodeId", inputData);
</code></pre>
<h3 id="memorystate"><a class="header" href="#memorystate">MemoryState</a></h3>
<p>The <code>MemoryState</code> class provides persistent state management across actor executions.</p>
<pre><code class="language-javascript">// Create state
const state = new MemoryState();

// Basic operations
state.set(key, value);
const value = state.get(key);
const exists = state.has(key);
state.remove(key);
state.clear();

// Bulk operations
const allData = state.getAll();
state.setAll(dataObject);

// Utilities
const size = state.size();
const keys = state.keys();
const values = state.values();
</code></pre>
<h3 id="actorruncontext"><a class="header" href="#actorruncontext">ActorRunContext</a></h3>
<p>The <code>ActorRunContext</code> provides actors with access to inputs, state, and output channels.</p>
<pre><code class="language-javascript">class MyActor {
    run(context) {
        // Access inputs
        const inputData = context.input.portName;
        
        // State management
        context.state.set('key', 'value');
        const value = context.state.get('key');
        
        // Send outputs
        context.send({
            outputPort: resultData
        });
        
        // Access configuration
        const config = this.config;
    }
}
</code></pre>
<h2 id="event-system-1"><a class="header" href="#event-system-1">Event System</a></h2>
<h3 id="network-events-1"><a class="header" href="#network-events-1">Network Events</a></h3>
<p>Monitor network execution with the event system:</p>
<pre><code class="language-javascript">network.next((event) =&gt; {
    switch (event._type) {
        case "FlowTrace":
            console.log(`Data flow: ${event.from.actorId}:${event.from.port} ‚Üí ${event.to.actorId}:${event.to.port}`);
            console.log("Data:", event.from.data);
            break;
            
        case "ActorStarted":
            console.log(`Actor started: ${event.actorId}`);
            break;
            
        case "ActorStopped":
            console.log(`Actor stopped: ${event.actorId}`);
            break;
            
        case "NetworkStarted":
            console.log("Network execution started");
            break;
            
        case "NetworkStopped":
            console.log("Network execution stopped");
            break;
            
        case "ProcessError":
            console.error(`Error in ${event.actorId}:`, event.error);
            break;
            
        default:
            console.log("Other event:", event);
    }
});
</code></pre>
<h3 id="graph-events"><a class="header" href="#graph-events">Graph Events</a></h3>
<p>Monitor graph modifications:</p>
<pre><code class="language-javascript">graph.subscribe((event) =&gt; {
    switch (event.type) {
        case "nodeAdded":
            console.log(`Node added: ${event.nodeId}`);
            break;
            
        case "nodeRemoved":
            console.log(`Node removed: ${event.nodeId}`);
            break;
            
        case "connectionAdded":
            console.log(`Connection: ${event.from} ‚Üí ${event.to}`);
            break;
            
        case "connectionRemoved":
            console.log(`Connection removed: ${event.from} ‚Üí ${event.to}`);
            break;
    }
});
</code></pre>
<h2 id="advanced-features-4"><a class="header" href="#advanced-features-4">Advanced Features</a></h2>
<h3 id="graph-history-with-undoredo"><a class="header" href="#graph-history-with-undoredo">Graph History with Undo/Redo</a></h3>
<pre><code class="language-javascript">// Create graph with history support
const [graph, history] = Graph.withHistoryAndLimit(50);

// Make changes
graph.addNode("processor", "ProcessorActor", { x: 200, y: 100 });
graph.addConnection("input", "output", "processor", "input");

// Update history
history.processEvents(graph);

// Check state
const state = history.getState();
console.log("Can undo:", state.can_undo);
console.log("Can redo:", state.can_redo);
console.log("Undo stack size:", state.undo_size);

// Perform operations
if (state.can_undo) {
    history.undo(graph);
}

if (history.getState().can_redo) {
    history.redo(graph);
}

// Clear history
history.clear();
</code></pre>
<h3 id="direct-actor-execution"><a class="header" href="#direct-actor-execution">Direct Actor Execution</a></h3>
<p>Test actors individually without full network setup:</p>
<pre><code class="language-javascript">// Execute actor directly
const actor = new MyActor();
const result = await network.executeActor("nodeId", {
    input: "test data",
    config: { mode: "debug" }
});

console.log("Direct execution result:", result);
</code></pre>
<h3 id="batch-graph-operations"><a class="header" href="#batch-graph-operations">Batch Graph Operations</a></h3>
<p>Efficiently modify graphs with multiple operations:</p>
<pre><code class="language-javascript">// Batch multiple operations
const operations = [
    () =&gt; graph.addNode("node1", "Actor1", { x: 100, y: 100 }),
    () =&gt; graph.addNode("node2", "Actor2", { x: 200, y: 100 }),
    () =&gt; graph.addConnection("node1", "output", "node2", "input"),
    () =&gt; graph.addInitial("start", "node1", "trigger")
];

// Execute all operations
operations.forEach(op =&gt; op());

// Process all changes at once
history.processEvents(graph);
</code></pre>
<h2 id="data-types-and-serialization"><a class="header" href="#data-types-and-serialization">Data Types and Serialization</a></h2>
<h3 id="supported-data-types"><a class="header" href="#supported-data-types">Supported Data Types</a></h3>
<p>The WASM bridge supports these JavaScript types:</p>
<pre><code class="language-javascript">// Primitive types
const stringData = "Hello World";
const numberData = 42;
const booleanData = true;
const nullData = null;

// Objects and arrays
const objectData = {
    id: 123,
    name: "Example",
    tags: ["tag1", "tag2"],
    metadata: {
        created: new Date().toISOString(),
        version: "1.0"
    }
};

const arrayData = [1, 2, 3, "mixed", { nested: true }];

// Send through actor context
context.send({
    output: {
        primitive: numberData,
        object: objectData,
        array: arrayData
    }
});
</code></pre>
<h3 id="serialization-best-practices"><a class="header" href="#serialization-best-practices">Serialization Best Practices</a></h3>
<pre><code class="language-javascript">// ‚úÖ Good: Structured data
const goodData = {
    type: "sensor_reading",
    value: 23.5,
    timestamp: Date.now(),
    metadata: {
        sensor_id: "temp_01",
        location: "warehouse_a"
    }
};

// ‚ùå Avoid: Large JSON strings
const badData = JSON.stringify(largeObject);

// ‚úÖ Good: Split large data
const chunkedData = {
    chunk_id: 1,
    total_chunks: 5,
    data: partialData
};
</code></pre>
<h2 id="error-handling-16"><a class="header" href="#error-handling-16">Error Handling</a></h2>
<h3 id="comprehensive-error-handling"><a class="header" href="#comprehensive-error-handling">Comprehensive Error Handling</a></h3>
<pre><code class="language-javascript">try {
    // Initialize WASM
    await init();
    init_panic_hook();
    
    // Create and start network
    const network = new GraphNetwork(graph);
    network.registerActor("MyActor", new MyActor());
    await network.start();
    
} catch (error) {
    console.error("Error during initialization:", error);
    
    // Handle specific error types
    if (error.message.includes("WASM")) {
        alert("Failed to load WebAssembly. Please check browser compatibility.");
    } else if (error.message.includes("Actor")) {
        alert("Actor registration failed. Please check actor implementation.");
    } else {
        alert("Unexpected error. Please refresh the page.");
    }
}

// Network-level error handling
network.next((event) =&gt; {
    if (event._type === "ProcessError") {
        console.error(`Actor ${event.actorId} failed:`, event.error);
        
        // Implement recovery logic
        handleActorError(event.actorId, event.error);
    }
});

function handleActorError(actorId, error) {
    // Log error details
    console.error(`Processing error in ${actorId}:`, error);
    
    // Attempt recovery
    if (error.includes("timeout")) {
        // Restart actor or increase timeout
    } else if (error.includes("validation")) {
        // Fix input data and retry
    }
}
</code></pre>
<h3 id="actor-error-handling"><a class="header" href="#actor-error-handling">Actor Error Handling</a></h3>
<pre><code class="language-javascript">class RobustActor {
    run(context) {
        try {
            // Main processing logic
            const input = context.input.input;
            const result = this.processData(input);
            context.send({ output: result });
            
        } catch (error) {
            console.error(`Error in ${this.constructor.name}:`, error);
            
            // Send error information
            context.send({
                error: {
                    message: error.message,
                    timestamp: Date.now(),
                    input: context.input
                }
            });
        }
    }
    
    processData(input) {
        // Validate input
        if (!input || typeof input !== 'object') {
            throw new Error("Invalid input: expected object");
        }
        
        // Process with error handling
        return {
            processed: true,
            data: input,
            timestamp: Date.now()
        };
    }
}
</code></pre>
<h2 id="performance-optimization-6"><a class="header" href="#performance-optimization-6">Performance Optimization</a></h2>
<h3 id="memory-management-7"><a class="header" href="#memory-management-7">Memory Management</a></h3>
<pre><code class="language-javascript">// Clean up resources properly
function cleanup() {
    // Shutdown network
    if (network) {
        network.shutdown();
    }
    
    // Clear state
    if (state) {
        state.clear();
    }
    
    // Remove event listeners
    if (unsubscribe) {
        unsubscribe();
    }
}

// Set up cleanup on page unload
window.addEventListener('beforeunload', cleanup);
</code></pre>
<h3 id="efficient-state-usage"><a class="header" href="#efficient-state-usage">Efficient State Usage</a></h3>
<pre><code class="language-javascript">class OptimizedActor {
    run(context) {
        // Read state once
        const state = context.state.getAll();
        
        // Modify locally
        state.counter = (state.counter || 0) + 1;
        state.lastUpdate = Date.now();
        
        // Write back once
        context.state.setAll(state);
        
        // Process and send output
        context.send({ output: state.counter });
    }
}
</code></pre>
<h3 id="batch-processing"><a class="header" href="#batch-processing">Batch Processing</a></h3>
<pre><code class="language-javascript">class BatchProcessor {
    constructor() {
        this.inports = ["input"];
        this.outports = ["output"];
        this.config = { batchSize: 10 };
    }
    
    run(context) {
        // Accumulate inputs
        const batch = context.state.get('batch') || [];
        batch.push(context.input.input);
        
        if (batch.length &gt;= this.config.batchSize) {
            // Process entire batch
            const results = batch.map(item =&gt; this.processItem(item));
            
            // Send batch results
            context.send({ output: results });
            
            // Clear batch
            context.state.set('batch', []);
        } else {
            // Store for next execution
            context.state.set('batch', batch);
        }
    }
    
    processItem(item) {
        return { processed: item, timestamp: Date.now() };
    }
}
</code></pre>
<h2 id="development-tools"><a class="header" href="#development-tools">Development Tools</a></h2>
<h3 id="debug-mode"><a class="header" href="#debug-mode">Debug Mode</a></h3>
<pre><code class="language-javascript">// Enable debug logging
function enableDebugMode(network) {
    let eventCount = 0;
    
    network.next((event) =&gt; {
        eventCount++;
        console.group(`Event #${eventCount}: ${event._type}`);
        console.log("Full event:", event);
        
        if (event._type === "FlowTrace") {
            console.log(`From: ${event.from.actorId}:${event.from.port}`);
            console.log(`To: ${event.to.actorId}:${event.to.port}`);
            console.log("Data:", event.from.data);
        }
        
        console.groupEnd();
    });
    
    // Network information
    console.log("Registered actors:", network.getActorNames());
    console.log("Active actors:", network.getActiveActors());
    console.log("Total actor count:", network.getActorCount());
}
</code></pre>
<h3 id="graph-inspection"><a class="header" href="#graph-inspection">Graph Inspection</a></h3>
<pre><code class="language-javascript">function inspectGraph(graph) {
    const data = graph.toJSON();
    
    console.group("Graph Inspection");
    console.log("Graph name:", data.properties?.name || "Unnamed");
    console.log("Case sensitive:", data.caseSensitive);
    console.log("Processes:", Object.keys(data.processes || {}));
    console.log("Connections:", data.connections?.length || 0);
    console.log("Inports:", Object.keys(data.inports || {}));
    console.log("Outports:", Object.keys(data.outports || {}));
    console.log("Initial data:", data.initializers?.length || 0);
    console.log("Full structure:", data);
    console.groupEnd();
}
</code></pre>
<h2 id="next-steps-26"><a class="header" href="#next-steps-26">Next Steps</a></h2>
<ul>
<li><strong><a href="api/wasm/actors-in-browser.html">Browser Actors</a></strong> - Creating actors for web environments</li>
<li><strong><a href="api/wasm/graphs-and-networks.html">Graph Management</a></strong> - Advanced graph operations</li>
<li><strong><a href="api/wasm/state-management.html">State Management</a></strong> - Persistent state handling</li>
<li><strong><a href="api/wasm/events-and-monitoring.html">Events &amp; Monitoring</a></strong> - Real-time event handling</li>
<li><strong><a href="api/wasm/../../tutorials/browser-workflow-editor.html">Browser Workflow Editor Tutorial</a></strong> - Building visual editors</li>
</ul>
<p>The WebAssembly API provides a powerful foundation for building browser-based workflow applications. Start with the examples above and explore the detailed API documentation for advanced usage patterns.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="browser-actors-guide"><a class="header" href="#browser-actors-guide">Browser Actors Guide</a></h1>
<p>Complete guide to creating and managing actors in browser environments using Reflow's WebAssembly bindings.</p>
<h2 id="overview-14"><a class="header" href="#overview-14">Overview</a></h2>
<p>Browser actors in Reflow follow the same conceptual model as native Rust actors but use a JavaScript interface optimized for web environments. They support stateful processing, real-time event handling, and seamless integration with web APIs.</p>
<h2 id="actor-lifecycle-in-browser"><a class="header" href="#actor-lifecycle-in-browser">Actor Lifecycle in Browser</a></h2>
<pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                Actor Lifecycle                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1. Construction                                     ‚îÇ
‚îÇ    ‚îú‚îÄ new MyActor()                                ‚îÇ
‚îÇ    ‚îú‚îÄ Define inports/outports                      ‚îÇ
‚îÇ    ‚îî‚îÄ Initialize configuration                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 2. Registration                                     ‚îÇ
‚îÇ    ‚îú‚îÄ network.registerActor("MyActor", instance)   ‚îÇ
‚îÇ    ‚îî‚îÄ WASM bridge creates wrapper                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 3. Execution                                        ‚îÇ
‚îÇ    ‚îú‚îÄ run(context) called with inputs              ‚îÇ
‚îÇ    ‚îú‚îÄ Access state through context.state           ‚îÇ
‚îÇ    ‚îú‚îÄ Process data with JavaScript logic           ‚îÇ
‚îÇ    ‚îî‚îÄ Send outputs via context.send()              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 4. State Persistence                               ‚îÇ
‚îÇ    ‚îú‚îÄ State stored in WASM memory                  ‚îÇ
‚îÇ    ‚îî‚îÄ Survives across multiple executions          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre>
<h2 id="basic-actor-structure"><a class="header" href="#basic-actor-structure">Basic Actor Structure</a></h2>
<h3 id="minimal-actor"><a class="header" href="#minimal-actor">Minimal Actor</a></h3>
<pre><code class="language-javascript">class MinimalActor {
    constructor() {
        // Required: Define input and output ports
        this.inports = ["input"];
        this.outports = ["output"];
        
        // Optional: Actor configuration
        this.config = {};
        
        // State is managed by WASM bridge
        this.state = null;
    }

    /**
     * Main execution method called by the runtime
     * @param {ActorRunContext} context - Execution context
     */
    run(context) {
        // Get input data
        const input = context.input.input;
        
        // Simple processing
        const output = `Processed: ${input}`;
        
        // Send result
        context.send({ output });
    }
}
</code></pre>
<h3 id="stateful-actor-1"><a class="header" href="#stateful-actor-1">Stateful Actor</a></h3>
<pre><code class="language-javascript">class CounterActor {
    constructor() {
        this.inports = ["increment", "reset"];
        this.outports = ["count", "status"];
        this.config = { 
            step: 1,
            maxCount: 100 
        };
    }

    run(context) {
        // Get current count from persistent state
        let count = context.state.get('count') || 0;
        
        // Handle different input ports
        if (context.input.increment !== undefined) {
            count += this.config.step;
            
            // Check bounds
            if (count &gt;= this.config.maxCount) {
                count = this.config.maxCount;
                context.send({ 
                    status: "Maximum count reached" 
                });
            }
            
            // Update state
            context.state.set('count', count);
            
            // Send current count
            context.send({ count });
        }
        
        if (context.input.reset !== undefined) {
            count = 0;
            context.state.set('count', count);
            context.send({ 
                count,
                status: "Counter reset"
            });
        }
    }
}
</code></pre>
<h3 id="configurable-actor"><a class="header" href="#configurable-actor">Configurable Actor</a></h3>
<pre><code class="language-javascript">class ConfigurableProcessor {
    constructor() {
        this.inports = ["data", "config"];
        this.outports = ["processed", "error"];
        
        // Default configuration
        this.config = {
            mode: "transform",
            batchSize: 1,
            timeout: 5000,
            filters: [],
            outputFormat: "json"
        };
    }

    run(context) {
        // Update configuration if provided
        if (context.input.config) {
            this.updateConfig(context.input.config);
        }
        
        // Process data
        if (context.input.data) {
            try {
                const result = this.processData(context.input.data, context);
                context.send({ processed: result });
            } catch (error) {
                context.send({ 
                    error: {
                        message: error.message,
                        input: context.input.data,
                        timestamp: Date.now()
                    }
                });
            }
        }
    }
    
    updateConfig(newConfig) {
        // Merge with existing configuration
        this.config = { ...this.config, ...newConfig };
        console.log("Updated configuration:", this.config);
    }
    
    processData(data, context) {
        switch (this.config.mode) {
            case "transform":
                return this.transformData(data);
            case "filter":
                return this.filterData(data);
            case "aggregate":
                return this.aggregateData(data, context);
            default:
                throw new Error(`Unknown processing mode: ${this.config.mode}`);
        }
    }
    
    transformData(data) {
        return {
            transformed: true,
            original: data,
            timestamp: Date.now(),
            format: this.config.outputFormat
        };
    }
    
    filterData(data) {
        if (!Array.isArray(data)) {
            data = [data];
        }
        
        return data.filter(item =&gt; {
            return this.config.filters.every(filter =&gt; 
                this.applyFilter(item, filter)
            );
        });
    }
    
    aggregateData(data, context) {
        // Get previous aggregated data from state
        const previous = context.state.get('aggregated') || [];
        const combined = previous.concat(Array.isArray(data) ? data : [data]);
        
        // Keep only recent data based on batchSize
        const recent = combined.slice(-this.config.batchSize);
        context.state.set('aggregated', recent);
        
        return {
            count: recent.length,
            sum: recent.reduce((acc, val) =&gt; acc + (typeof val === 'number' ? val : 0), 0),
            average: recent.length &gt; 0 ? recent.reduce((acc, val) =&gt; acc + (typeof val === 'number' ? val : 0), 0) / recent.length : 0,
            latest: recent[recent.length - 1]
        };
    }
    
    applyFilter(item, filter) {
        // Simple filter implementation
        if (filter.field &amp;&amp; filter.value) {
            return item[filter.field] === filter.value;
        }
        return true;
    }
}
</code></pre>
<h2 id="advanced-actor-patterns"><a class="header" href="#advanced-actor-patterns">Advanced Actor Patterns</a></h2>
<h3 id="asynchronous-web-api-actor"><a class="header" href="#asynchronous-web-api-actor">Asynchronous Web API Actor</a></h3>
<pre><code class="language-javascript">class WebAPIActor {
    constructor() {
        this.inports = ["url", "config"];
        this.outports = ["data", "error"];
        this.config = {
            method: "GET",
            timeout: 10000,
            retries: 3
        };
    }

    async run(context) {
        const url = context.input.url;
        const config = { ...this.config, ...context.input.config };
        
        if (!url) {
            context.send({ error: "URL is required" });
            return;
        }

        try {
            const data = await this.fetchWithRetry(url, config);
            context.send({ data });
        } catch (error) {
            context.send({ 
                error: {
                    message: error.message,
                    url,
                    timestamp: Date.now()
                }
            });
        }
    }

    async fetchWithRetry(url, config) {
        let lastError;
        
        for (let attempt = 1; attempt &lt;= config.retries; attempt++) {
            try {
                const controller = new AbortController();
                const timeoutId = setTimeout(() =&gt; controller.abort(), config.timeout);
                
                const response = await fetch(url, {
                    method: config.method,
                    headers: config.headers,
                    body: config.body,
                    signal: controller.signal
                });
                
                clearTimeout(timeoutId);
                
                if (!response.ok) {
                    throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                }
                
                return await response.json();
                
            } catch (error) {
                lastError = error;
                
                if (attempt &lt; config.retries) {
                    // Exponential backoff
                    const delay = Math.pow(2, attempt) * 1000;
                    await new Promise(resolve =&gt; setTimeout(resolve, delay));
                }
            }
        }
        
        throw lastError;
    }
}
</code></pre>
<h3 id="timer-actor"><a class="header" href="#timer-actor">Timer Actor</a></h3>
<pre><code class="language-javascript">class TimerActor {
    constructor() {
        this.inports = ["start", "stop", "interval"];
        this.outports = ["tick", "status"];
        this.config = { defaultInterval: 1000 };
        
        // Store timer reference
        this.timerId = null;
    }

    run(context) {
        if (context.input.start !== undefined) {
            this.startTimer(context);
        }
        
        if (context.input.stop !== undefined) {
            this.stopTimer(context);
        }
        
        if (context.input.interval !== undefined) {
            this.updateInterval(context.input.interval, context);
        }
    }
    
    startTimer(context) {
        // Stop existing timer if running
        this.stopTimer(context, false);
        
        const interval = context.state.get('interval') || this.config.defaultInterval;
        let tickCount = context.state.get('tickCount') || 0;
        
        this.timerId = setInterval(() =&gt; {
            tickCount++;
            context.state.set('tickCount', tickCount);
            
            // Send tick event
            context.send({
                tick: {
                    count: tickCount,
                    timestamp: Date.now(),
                    interval: interval
                }
            });
        }, interval);
        
        context.state.set('running', true);
        context.send({ status: `Timer started with ${interval}ms interval` });
    }
    
    stopTimer(context, sendStatus = true) {
        if (this.timerId) {
            clearInterval(this.timerId);
            this.timerId = null;
        }
        
        context.state.set('running', false);
        
        if (sendStatus) {
            const tickCount = context.state.get('tickCount') || 0;
            context.send({ 
                status: `Timer stopped after ${tickCount} ticks` 
            });
        }
    }
    
    updateInterval(newInterval, context) {
        context.state.set('interval', newInterval);
        
        // Restart timer with new interval if currently running
        if (context.state.get('running')) {
            this.startTimer(context);
        }
    }
}
</code></pre>
<h3 id="file-reader-actor-browser"><a class="header" href="#file-reader-actor-browser">File Reader Actor (Browser)</a></h3>
<pre><code class="language-javascript">class FileReaderActor {
    constructor() {
        this.inports = ["file", "options"];
        this.outports = ["content", "progress", "error"];
        this.config = {
            readAs: "text", // "text", "dataURL", "arrayBuffer"
            encoding: "utf-8",
            chunkSize: 64 * 1024 // 64KB chunks for progress
        };
    }

    run(context) {
        const file = context.input.file;
        const options = { ...this.config, ...context.input.options };
        
        if (!file || !file instanceof File) {
            context.send({ error: "Valid File object required" });
            return;
        }

        this.readFile(file, options, context);
    }

    readFile(file, options, context) {
        const reader = new FileReader();
        
        // Track progress
        reader.onprogress = (event) =&gt; {
            if (event.lengthComputable) {
                const progress = (event.loaded / event.total) * 100;
                context.send({ 
                    progress: {
                        loaded: event.loaded,
                        total: event.total,
                        percentage: progress
                    }
                });
            }
        };
        
        reader.onload = (event) =&gt; {
            const result = event.target.result;
            context.send({
                content: {
                    data: result,
                    filename: file.name,
                    size: file.size,
                    type: file.type,
                    lastModified: file.lastModified,
                    readAs: options.readAs
                }
            });
        };
        
        reader.onerror = (event) =&gt; {
            context.send({
                error: {
                    message: "Failed to read file",
                    filename: file.name,
                    error: event.target.error
                }
            });
        };

        // Choose reading method based on options
        switch (options.readAs) {
            case "text":
                reader.readAsText(file, options.encoding);
                break;
            case "dataURL":
                reader.readAsDataURL(file);
                break;
            case "arrayBuffer":
                reader.readAsArrayBuffer(file);
                break;
            default:
                context.send({ error: `Unsupported read method: ${options.readAs}` });
        }
    }
}
</code></pre>
<h2 id="state-management-patterns"><a class="header" href="#state-management-patterns">State Management Patterns</a></h2>
<h3 id="complex-state-actor"><a class="header" href="#complex-state-actor">Complex State Actor</a></h3>
<pre><code class="language-javascript">class StatefulProcessor {
    constructor() {
        this.inports = ["data", "command"];
        this.outports = ["result", "state", "error"];
        this.config = {};
    }

    run(context) {
        // Handle commands
        if (context.input.command) {
            this.handleCommand(context.input.command, context);
        }
        
        // Process data
        if (context.input.data) {
            this.processData(context.input.data, context);
        }
    }
    
    handleCommand(command, context) {
        switch (command.action) {
            case "get_state":
                context.send({ 
                    state: context.state.getAll() 
                });
                break;
                
            case "set_state":
                if (command.data) {
                    context.state.setAll(command.data);
                    context.send({ 
                        result: "State updated successfully" 
                    });
                }
                break;
                
            case "clear_state":
                context.state.clear();
                context.send({ 
                    result: "State cleared" 
                });
                break;
                
            case "get_stats":
                this.sendStatistics(context);
                break;
                
            default:
                context.send({ 
                    error: `Unknown command: ${command.action}` 
                });
        }
    }
    
    processData(data, context) {
        // Update processing statistics
        const stats = context.state.get('stats') || {
            processedCount: 0,
            totalSize: 0,
            lastProcessed: null,
            errors: 0
        };
        
        try {
            // Simulate processing
            const processed = this.transform(data);
            
            // Update statistics
            stats.processedCount++;
            stats.totalSize += JSON.stringify(data).length;
            stats.lastProcessed = Date.now();
            
            context.state.set('stats', stats);
            context.send({ result: processed });
            
        } catch (error) {
            stats.errors++;
            context.state.set('stats', stats);
            
            context.send({
                error: {
                    message: error.message,
                    data: data,
                    timestamp: Date.now()
                }
            });
        }
    }
    
    transform(data) {
        return {
            original: data,
            transformed: Array.isArray(data) ? data.map(x =&gt; x * 2) : data,
            timestamp: Date.now()
        };
    }
    
    sendStatistics(context) {
        const stats = context.state.get('stats') || {};
        const stateSize = context.state.size();
        
        context.send({
            state: {
                statistics: stats,
                stateSize: stateSize,
                stateKeys: context.state.keys(),
                uptime: Date.now() - (stats.firstProcessed || Date.now())
            }
        });
    }
}
</code></pre>
<h3 id="cache-actor"><a class="header" href="#cache-actor">Cache Actor</a></h3>
<pre><code class="language-javascript">class CacheActor {
    constructor() {
        this.inports = ["get", "set", "delete", "clear"];
        this.outports = ["value", "status", "stats"];
        this.config = {
            maxSize: 100,
            ttlMs: 300000 // 5 minutes
        };
    }

    run(context) {
        if (context.input.get) {
            this.getValue(context.input.get, context);
        }
        
        if (context.input.set) {
            this.setValue(context.input.set, context);
        }
        
        if (context.input.delete) {
            this.deleteValue(context.input.delete, context);
        }
        
        if (context.input.clear) {
            this.clearCache(context);
        }
    }
    
    getValue(request, context) {
        const cache = context.state.get('cache') || {};
        const entry = cache[request.key];
        
        if (!entry) {
            context.send({ 
                value: { 
                    key: request.key, 
                    found: false 
                } 
            });
            return;
        }
        
        // Check TTL
        if (entry.expires &amp;&amp; Date.now() &gt; entry.expires) {
            delete cache[request.key];
            context.state.set('cache', cache);
            
            context.send({ 
                value: { 
                    key: request.key, 
                    found: false, 
                    expired: true 
                } 
            });
            return;
        }
        
        // Update access time
        entry.lastAccessed = Date.now();
        context.state.set('cache', cache);
        
        context.send({
            value: {
                key: request.key,
                value: entry.value,
                found: true,
                created: entry.created,
                lastAccessed: entry.lastAccessed
            }
        });
    }
    
    setValue(request, context) {
        const cache = context.state.get('cache') || {};
        
        // Enforce size limit
        const keys = Object.keys(cache);
        if (keys.length &gt;= this.config.maxSize &amp;&amp; !cache[request.key]) {
            // Remove oldest entry
            const oldest = keys.reduce((min, key) =&gt; 
                (!min || cache[key].lastAccessed &lt; cache[min].lastAccessed) ? key : min
            );
            delete cache[oldest];
        }
        
        // Set new value
        const now = Date.now();
        cache[request.key] = {
            value: request.value,
            created: now,
            lastAccessed: now,
            expires: request.ttl ? now + request.ttl : now + this.config.ttlMs
        };
        
        context.state.set('cache', cache);
        
        context.send({
            status: {
                operation: "set",
                key: request.key,
                success: true,
                cacheSize: Object.keys(cache).length
            }
        });
    }
    
    deleteValue(request, context) {
        const cache = context.state.get('cache') || {};
        const existed = cache[request.key] !== undefined;
        
        delete cache[request.key];
        context.state.set('cache', cache);
        
        context.send({
            status: {
                operation: "delete",
                key: request.key,
                existed: existed,
                cacheSize: Object.keys(cache).length
            }
        });
    }
    
    clearCache(context) {
        const cache = context.state.get('cache') || {};
        const count = Object.keys(cache).length;
        
        context.state.set('cache', {});
        
        context.send({
            status: {
                operation: "clear",
                clearedCount: count,
                cacheSize: 0
            }
        });
    }
}
</code></pre>
<h2 id="integration-with-browser-apis"><a class="header" href="#integration-with-browser-apis">Integration with Browser APIs</a></h2>
<h3 id="geolocation-actor"><a class="header" href="#geolocation-actor">Geolocation Actor</a></h3>
<pre><code class="language-javascript">class GeolocationActor {
    constructor() {
        this.inports = ["getCurrentPosition", "watchPosition", "clearWatch"];
        this.outports = ["position", "error"];
        this.config = {
            enableHighAccuracy: false,
            timeout: 10000,
            maximumAge: 600000 // 10 minutes
        };
        
        this.watchId = null;
    }

    run(context) {
        if (!navigator.geolocation) {
            context.send({ error: "Geolocation is not supported" });
            return;
        }
        
        if (context.input.getCurrentPosition) {
            this.getCurrentPosition(context);
        }
        
        if (context.input.watchPosition) {
            this.startWatching(context);
        }
        
        if (context.input.clearWatch) {
            this.stopWatching(context);
        }
    }
    
    getCurrentPosition(context) {
        const options = { ...this.config, ...context.input.getCurrentPosition };
        
        navigator.geolocation.getCurrentPosition(
            (position) =&gt; {
                context.send({
                    position: {
                        latitude: position.coords.latitude,
                        longitude: position.coords.longitude,
                        accuracy: position.coords.accuracy,
                        altitude: position.coords.altitude,
                        heading: position.coords.heading,
                        speed: position.coords.speed,
                        timestamp: position.timestamp
                    }
                });
            },
            (error) =&gt; {
                context.send({
                    error: {
                        code: error.code,
                        message: error.message,
                        timestamp: Date.now()
                    }
                });
            },
            options
        );
    }
    
    startWatching(context) {
        this.stopWatching(context, false);
        
        const options = { ...this.config, ...context.input.watchPosition };
        
        this.watchId = navigator.geolocation.watchPosition(
            (position) =&gt; {
                context.send({
                    position: {
                        latitude: position.coords.latitude,
                        longitude: position.coords.longitude,
                        accuracy: position.coords.accuracy,
                        altitude: position.coords.altitude,
                        heading: position.coords.heading,
                        speed: position.coords.speed,
                        timestamp: position.timestamp,
                        isWatching: true
                    }
                });
            },
            (error) =&gt; {
                context.send({
                    error: {
                        code: error.code,
                        message: error.message,
                        timestamp: Date.now(),
                        isWatching: true
                    }
                });
            },
            options
        );
        
        context.state.set('watching', true);
    }
    
    stopWatching(context, sendConfirmation = true) {
        if (this.watchId !== null) {
            navigator.geolocation.clearWatch(this.watchId);
            this.watchId = null;
        }
        
        context.state.set('watching', false);
        
        if (sendConfirmation) {
            context.send({
                position: {
                    message: "Stopped watching position",
                    timestamp: Date.now(),
                    isWatching: false
                }
            });
        }
    }
}
</code></pre>
<h2 id="testing-and-debugging-actors"><a class="header" href="#testing-and-debugging-actors">Testing and Debugging Actors</a></h2>
<h3 id="test-helper-functions"><a class="header" href="#test-helper-functions">Test Helper Functions</a></h3>
<pre><code class="language-javascript">// Actor testing utilities
class ActorTester {
    constructor(ActorClass) {
        this.ActorClass = ActorClass;
        this.actor = new ActorClass();
        this.mockState = new Map();
        this.outputs = [];
    }
    
    // Create a mock context for testing
    createMockContext(inputs) {
        const self = this;
        
        return {
            input: inputs,
            state: {
                get: (key) =&gt; self.mockState.get(key),
                set: (key, value) =&gt; self.mockState.set(key, value),
                has: (key) =&gt; self.mockState.has(key),
                remove: (key) =&gt; self.mockState.delete(key),
                clear: () =&gt; self.mockState.clear(),
                getAll: () =&gt; Object.fromEntries(self.mockState),
                setAll: (obj) =&gt; {
                    self.mockState.clear();
                    Object.entries(obj).forEach(([k, v]) =&gt; self.mockState.set(k, v));
                },
                size: () =&gt; self.mockState.size,
                keys: () =&gt; Array.from(self.mockState.keys()),
                values: () =&gt; Array.from(self.mockState.values())
            },
            send: (outputs) =&gt; {
                self.outputs.push({
                    timestamp: Date.now(),
                    outputs: outputs
                });
            }
        };
    }
    
    // Test actor with given inputs
    test(inputs, expectedOutputs) {
        this.outputs = [];
        const context = this.createMockContext(inputs);
        
        // Run the actor
        const result = this.actor.run(context);
        
        // Handle async actors
        if (result instanceof Promise) {
            return result.then(() =&gt; this.verifyOutputs(expectedOutputs));
        } else {
            return this.verifyOutputs(expectedOutputs);
        }
    }
    
    verifyOutputs(expectedOutputs) {
        const results = {
            passed: true,
            outputs: this.outputs,
            state: Object.fromEntries(this.mockState),
            errors: []
        };
        
        if (expectedOutputs) {
            // Simple verification - can be enhanced
            if (this.outputs.length !== expectedOutputs.length) {
                results.passed = false;
                results.errors.push(`Expected ${expectedOutputs.length} outputs, got ${this.outputs.length}`);
            }
        }
        
        return results;
    }
}

// Example usage
async function testCounterActor() {
    const tester = new ActorTester(CounterActor);
    
    // Test increment
    const result1 = await tester.test({ increment: 1 });
    console.log("Increment test:", result1);
    
    // Test reset
    const result2 = await tester.test({ reset: true });
    console.log("Reset test:", result2);
}
</code></pre>
<h3 id="debug-actor-wrapper"><a class="header" href="#debug-actor-wrapper">Debug Actor Wrapper</a></h3>
<pre><code class="language-javascript">class DebugActorWrapper {
    constructor(actor, name) {
        this.actor = actor;
        this.name = name || actor.constructor.name;
        this.executionCount = 0;
        this.totalExecutionTime = 0;
    }
    
    get inports() { return this.actor.inports; }
    get outports() { return this.actor.outports; }
    get config() { return this.actor.config; }
    set config(value) { this.actor.config = value; }
    
    run(context) {
        this.executionCount++;
        const startTime = performance.now();
        
        console.group(`üé≠ ${this.name} #${this.executionCount}`);
        console.log("Inputs:", context.input);
        console.log("State before:", context.state.getAll());
        
        // Wrap the send method to log outputs
        const originalSend = context.send;
        context.send = (outputs) =&gt; {
            console.log("Outputs:", outputs);
            originalSend(outputs);
        };
        
        try {
            const result = this.actor.run(context);
            
            const endTime = performance.now();
            const executionTime = endTime - startTime;
            this.totalExecutionTime += executionTime;
            
            console.log("State after:", context.state.getAll());
            console.log(`Execution time: ${executionTime.toFixed(2)}ms`);
            console.log(`Average time: ${(this.totalExecutionTime / this.executionCount).toFixed(2)}ms`);
            console.groupEnd();
            
            return result;
            
        } catch (error) {
            console.error("Actor error:", error);
            console.groupEnd();
            throw error;
        }
    }
}

// Usage
const debugCounter = new DebugActorWrapper(new CounterActor(), "MyCounter");
network.registerActor("CounterActor", debugCounter);
</code></pre>
<h2 id="performance-optimization-7"><a class="header" href="#performance-optimization-7">Performance Optimization</a></h2>
<h3 id="efficient-actor-patterns"><a class="header" href="#efficient-actor-patterns">Efficient Actor Patterns</a></h3>
<pre><code class="language-javascript">// ‚úÖ Good: Minimal state operations
class EfficientActor {
    run(context) {
        // Read state once
        const state = context.state.getAll();
        
        // Modify locally
        state.counter = (state.counter || 0) + 1;
        state.lastUpdate = Date.now();
        
        // Write once
        context.state.setAll(state);
        
        context.send({ output: state.counter });
    }
}

// ‚ùå Avoid: Multiple state operations
class InefficientActor {
    run(context) {
        // Multiple gets/sets are slower
        const counter = context.state.get('counter') || 0;
        context.state.set('counter', counter + 1);
        
        const lastUpdate = Date.now();
        context.state.set('lastUpdate', lastUpdate);
        
        context.send({ output: counter + 1 });
    }
}

// ‚úÖ Good: Batch processing
class BatchActor {
    constructor() {
        this.inports = ["input"];
        this.outports = ["output"];
        this.config = { batchSize: 10 };
    }
    
    run(context) {
        const batch = context.state.get('batch') || [];
        batch.push(context.input.input);
        
        if (batch.length &gt;= this.config.batchSize) {
            // Process entire batch at once
            const results = this.processBatch(batch);
            context.send({ output: results });
            context.state.set('batch', []);
        } else {
            context.state.set('batch', batch);
        }
    }
    
    processBatch(items) {
        return items.map(item =&gt; ({ processed: item, timestamp: Date.now() }));
    }
}
</code></pre>
<h2 id="next-steps-27"><a class="header" href="#next-steps-27">Next Steps</a></h2>
<ul>
<li><strong><a href="api/wasm/graphs-and-networks.html">Graph Management</a></strong> - Creating and managing graphs in browser</li>
<li><strong><a href="api/wasm/state-management.html">State Management</a></strong> - Advanced state handling patterns</li>
<li><strong><a href="api/wasm/events-and-monitoring.html">Events &amp; Monitoring</a></strong> - Real-time event handling</li>
<li><strong><a href="api/wasm/../../tutorials/browser-workflow-editor.html">Browser Workflow Editor Tutorial</a></strong> - Building visual editors</li>
</ul>
<p>Browser actors provide a powerful way to create interactive, stateful workflows that run entirely in the browser. Use the patterns and examples above to build robust, performant actor-based applications.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="standard-library"><a class="header" href="#standard-library">Standard Library</a></h1>
<p>Reflow's standard library provides a collection of pre-built components for common workflow operations.</p>
<h2 id="overview-15"><a class="header" href="#overview-15">Overview</a></h2>
<p>The standard library includes components for:</p>
<ul>
<li><strong>Flow Control</strong>: Conditional logic, loops, and branching</li>
<li><strong>Data Operations</strong>: Transformations, aggregations, and validation</li>
<li><strong>Integration</strong>: External API connectivity and data sources</li>
<li><strong>Synchronization</strong>: Coordination and timing primitives</li>
<li><strong>Utility</strong>: Helper functions and common operations</li>
</ul>
<h2 id="flow-control-components"><a class="header" href="#flow-control-components">Flow Control Components</a></h2>
<h3 id="conditionalactor"><a class="header" href="#conditionalactor">ConditionalActor</a></h3>
<p>Routes messages based on conditions:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::flow_control::ConditionalActor;
use reflow_network::message::Message;

// Create conditional actor
let conditional = ConditionalActor::new(|payload| {
    if let Some(Message::Integer(n)) = payload.get("value") {
        *n &gt; 0
    } else {
        false
    }
});

// Usage in workflow
let mut network = Network::new();
network.add_actor("filter", Box::new(conditional)).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="switchactor"><a class="header" href="#switchactor">SwitchActor</a></h3>
<p>Multi-way routing based on message content:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::flow_control::SwitchActor;

let switch = SwitchActor::new()
    .route("user_event", |msg| {
        matches!(msg.get("type"), Some(Message::String(s)) if s == "user")
    })
    .route("system_event", |msg| {
        matches!(msg.get("type"), Some(Message::String(s)) if s == "system")
    })
    .default_route("unknown");
<span class="boring">}</span></code></pre></pre>
<h3 id="loopactor"><a class="header" href="#loopactor">LoopActor</a></h3>
<p>Iterative processing with configurable conditions:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::flow_control::LoopActor;

let loop_actor = LoopActor::new()
    .max_iterations(100)
    .condition(|payload, iteration| {
        // Continue looping while condition is true
        if let Some(Message::Array(items)) = payload.get("items") {
            !items.is_empty() &amp;&amp; iteration &lt; 50
        } else {
            false
        }
    });
<span class="boring">}</span></code></pre></pre>
<h2 id="data-operations"><a class="header" href="#data-operations">Data Operations</a></h2>
<h3 id="transformactor"><a class="header" href="#transformactor">TransformActor</a></h3>
<p>Applies transformations to input data:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::data_operations::TransformActor;
use reflow_network::{Network, NetworkConfig};

// Create network and add transform actor
let mut network = Network::new(NetworkConfig::default());
network.register_actor("transform", TransformActor::new())?;
network.add_node("transformer", "transform")?;

// Usage: Send data with optional transform function
let transform_request = HashMap::from([
    ("In".to_string(), Message::string("hello world".to_string())),
    ("Function".to_string(), Message::string("uppercase".to_string())),
]);

// Supported transformations:
// - "identity": No change
// - "uppercase": Convert string to uppercase
// - "lowercase": Convert string to lowercase  
// - "number_to_string": Convert numbers to strings
// - "parse_int": Parse string to integer
// - "parse_float": Parse string to float
// - "to_json": Convert to JSON string
// - "from_json": Parse JSON string
<span class="boring">}</span></code></pre></pre>
<h3 id="mapactor"><a class="header" href="#mapactor">MapActor</a></h3>
<p>Apply transformations to each item in a collection:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::data_operations::MapActor;

// Create map actor
let mut network = Network::new(NetworkConfig::default());
network.register_actor("map", MapActor::new())?;
network.add_node("mapper", "map")?;

// Usage: Transform each item in an array
let map_request = HashMap::from([
    ("Collection".to_string(), Message::array(vec![
        EncodableValue::from(serde_json::json!("hello")),
        EncodableValue::from(serde_json::json!("world")),
    ])),
    ("Function".to_string(), Message::string("uppercase".to_string())),
]);
// Result: ["HELLO", "WORLD"]
<span class="boring">}</span></code></pre></pre>
<h3 id="reduceactor"><a class="header" href="#reduceactor">ReduceActor</a></h3>
<p>Combine collection items into a single value:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::data_operations::ReduceActor;

// Create reduce actor
let mut network = Network::new(NetworkConfig::default());
network.register_actor("reduce", ReduceActor::new())?;
network.add_node("reducer", "reduce")?;

// Usage: Sum numbers in an array
let reduce_request = HashMap::from([
    ("Collection".to_string(), Message::array(vec![
        EncodableValue::from(serde_json::json!(1)),
        EncodableValue::from(serde_json::json!(2)),
        EncodableValue::from(serde_json::json!(3)),
    ])),
    ("Function".to_string(), Message::string("sum".to_string())),
]);
// Result: 6

// Supported operations:
// - "sum": Add all numbers or concatenate strings
// - "product": Multiply all numbers
// - "join": Join strings with separator
// - "max": Find maximum value
// - "min": Find minimum value
<span class="boring">}</span></code></pre></pre>
<h3 id="groupactor"><a class="header" href="#groupactor">GroupActor</a></h3>
<p>Group collection items by key or criteria:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::data_operations::GroupActor;

// Create group actor
let mut network = Network::new(NetworkConfig::default());
network.register_actor("group", GroupActor::new())?;
network.add_node("grouper", "group")?;

// Usage: Group objects by property
let group_request = HashMap::from([
    ("Collection".to_string(), Message::array(vec![
        EncodableValue::from(serde_json::json!({"type": "user", "name": "Alice"})),
        EncodableValue::from(serde_json::json!({"type": "admin", "name": "Bob"})),
        EncodableValue::from(serde_json::json!({"type": "user", "name": "Charlie"})),
    ])),
    ("Key".to_string(), Message::string("type".to_string())),
]);
// Result: {"user": [Alice, Charlie], "admin": [Bob]}
<span class="boring">}</span></code></pre></pre>
<h3 id="sortactor"><a class="header" href="#sortactor">SortActor</a></h3>
<p>Sort collection items by criteria:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::data_operations::SortActor;

// Create sort actor
let mut network = Network::new(NetworkConfig::default());
network.register_actor("sort", SortActor::new())?;
network.add_node("sorter", "sort")?;

// Usage: Sort numbers in descending order
let sort_request = HashMap::from([
    ("Collection".to_string(), Message::Array(vec![
        Message::Integer(3).into(),
        Message::Integer(1).into(),
        Message::Integer(2).into(),
    ])),
    ("Order".to_string(), Message::String("desc".to_string())),
]);
// Result: [3, 2, 1]

// Sort objects by property:
let sort_objects = HashMap::from([
    ("Collection".to_string(), Message::Array(vec![
        Message::Object(serde_json::json!({"age": 30, "name": "Alice"}).into()).into(),
        Message::Object(serde_json::json!({"age": 25, "name": "Bob"}).into()).into(),
    ])),
    ("Key".to_string(), Message::String("age".to_string())),
    ("Order".to_string(), Message::String("asc".to_string())),
]);
// Result: [Bob, Alice] (sorted by age)
<span class="boring">}</span></code></pre></pre>
<h2 id="integration-components"><a class="header" href="#integration-components">Integration Components</a></h2>
<h3 id="httprequestactor"><a class="header" href="#httprequestactor">HttpRequestActor</a></h3>
<p>Make HTTP requests:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::integration::HttpRequestActor;

let http_client = HttpRequestActor::new()
    .timeout(Duration::from_secs(30))
    .retry_count(3)
    .default_headers(vec![
        ("User-Agent".to_string(), "Reflow/1.0".to_string()),
        ("Accept".to_string(), "application/json".to_string()),
    ]);

// Usage: send message with url, method, headers, body
let request = HashMap::from([
    ("url".to_string(), Message::String("https://api.example.com/data".to_string())),
    ("method".to_string(), Message::String("GET".to_string())),
]);
<span class="boring">}</span></code></pre></pre>
<h3 id="databaseactor"><a class="header" href="#databaseactor">DatabaseActor</a></h3>
<p>Database connectivity:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::integration::DatabaseActor;

let db_actor = DatabaseActor::new("postgresql://user:pass@localhost/db")
    .pool_size(10)
    .connection_timeout(Duration::from_secs(5));

// Usage: send SQL queries
let query = HashMap::from([
    ("sql".to_string(), Message::String("SELECT * FROM users WHERE active = $1".to_string())),
    ("params".to_string(), Message::Array(vec![Message::Boolean(true)])),
]);
<span class="boring">}</span></code></pre></pre>
<h3 id="filesystemactor"><a class="header" href="#filesystemactor">FileSystemActor</a></h3>
<p>File operations:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::integration::FileSystemActor;

let fs_actor = FileSystemActor::new()
    .base_path("/data")
    .allowed_extensions(vec!["txt", "json", "csv"]);

// Read file
let read_request = HashMap::from([
    ("operation".to_string(), Message::String("read".to_string())),
    ("path".to_string(), Message::String("input.txt".to_string())),
]);

// Write file
let write_request = HashMap::from([
    ("operation".to_string(), Message::String("write".to_string())),
    ("path".to_string(), Message::String("output.txt".to_string())),
    ("content".to_string(), Message::String("Hello, World!".to_string())),
]);
<span class="boring">}</span></code></pre></pre>
<h2 id="synchronization-components"><a class="header" href="#synchronization-components">Synchronization Components</a></h2>
<h3 id="barrieractor"><a class="header" href="#barrieractor">BarrierActor</a></h3>
<p>Wait for multiple inputs before proceeding:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::synchronization::BarrierActor;

let barrier = BarrierActor::new()
    .input_count(3) // Wait for 3 inputs
    .timeout(Duration::from_secs(60)) // Max wait time
    .combine_strategy(CombineStrategy::Merge); // How to combine inputs

// Outputs combined message when all inputs received
<span class="boring">}</span></code></pre></pre>
<h3 id="throttleactor"><a class="header" href="#throttleactor">ThrottleActor</a></h3>
<p>Rate limiting:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::synchronization::ThrottleActor;

let throttle = ThrottleActor::new()
    .rate_limit(100) // Max 100 messages per second
    .burst_size(10)  // Allow burst of 10 messages
    .strategy(ThrottleStrategy::DropOldest);
<span class="boring">}</span></code></pre></pre>
<h3 id="delayactor"><a class="header" href="#delayactor">DelayActor</a></h3>
<p>Add delays to message processing:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::synchronization::DelayActor;

let delay = DelayActor::new()
    .fixed_delay(Duration::from_millis(500))
    .jitter_range(Duration::from_millis(100)); // Add random jitter
<span class="boring">}</span></code></pre></pre>
<h3 id="scheduleractor"><a class="header" href="#scheduleractor">SchedulerActor</a></h3>
<p>Time-based message generation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::synchronization::SchedulerActor;

let scheduler = SchedulerActor::new()
    .cron_schedule("0 0 * * *") // Daily at midnight
    .message_template(HashMap::from([
        ("event".to_string(), Message::String("daily_job".to_string())),
        ("timestamp".to_string(), Message::String("{{now}}".to_string())),
    ]));
<span class="boring">}</span></code></pre></pre>
<h2 id="utility-components"><a class="header" href="#utility-components">Utility Components</a></h2>
<h3 id="loggeractor"><a class="header" href="#loggeractor">LoggerActor</a></h3>
<p>Structured logging:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::utility::LoggerActor;

let logger = LoggerActor::new()
    .level(LogLevel::Info)
    .format(LogFormat::Json)
    .output(LogOutput::File("/var/log/reflow.log"));

// Usage: send messages to log
let log_message = HashMap::from([
    ("level".to_string(), Message::String("info".to_string())),
    ("message".to_string(), Message::String("Processing started".to_string())),
    ("context".to_string(), Message::Object(context_data)),
]);
<span class="boring">}</span></code></pre></pre>
<h3 id="metricsactor"><a class="header" href="#metricsactor">MetricsActor</a></h3>
<p>Collect and emit metrics:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::utility::MetricsActor;

let metrics = MetricsActor::new()
    .endpoint("http://prometheus:9090/metrics")
    .namespace("reflow")
    .labels(vec![
        ("environment".to_string(), "production".to_string()),
        ("service".to_string(), "workflow-engine".to_string()),
    ]);

// Usage: send metrics data
let metric = HashMap::from([
    ("type".to_string(), Message::String("counter".to_string())),
    ("name".to_string(), Message::String("messages_processed".to_string())),
    ("value".to_string(), Message::Integer(1)),
    ("tags".to_string(), Message::Object(tags)),
]);
<span class="boring">}</span></code></pre></pre>
<h3 id="cacheactor"><a class="header" href="#cacheactor">CacheActor</a></h3>
<p>In-memory caching:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::utility::CacheActor;

let cache = CacheActor::new()
    .max_size(1000)
    .ttl(Duration::from_hours(1))
    .eviction_strategy(EvictionStrategy::LRU);

// Get from cache
let get_request = HashMap::from([
    ("operation".to_string(), Message::String("get".to_string())),
    ("key".to_string(), Message::String("user:123".to_string())),
]);

// Set cache value
let set_request = HashMap::from([
    ("operation".to_string(), Message::String("set".to_string())),
    ("key".to_string(), Message::String("user:123".to_string())),
    ("value".to_string(), Message::Object(user_data)),
    ("ttl".to_string(), Message::Integer(3600)), // Optional custom TTL
]);
<span class="boring">}</span></code></pre></pre>
<h2 id="configuration-examples-1"><a class="header" href="#configuration-examples-1">Configuration Examples</a></h2>
<h3 id="building-a-data-pipeline"><a class="header" href="#building-a-data-pipeline">Building a Data Pipeline</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::Network;
use reflow_components::*;

async fn create_data_pipeline() -&gt; Result&lt;Network, Box&lt;dyn std::error::Error&gt;&gt; {
    let mut network = Network::new();
    
    // 1. HTTP source to fetch data
    let http_source = integration::HttpRequestActor::new()
        .timeout(Duration::from_secs(30));
    
    // 2. Validate incoming data
    let validator = data_operations::ValidatorActor::new()
        .add_rule("required_field", |v| !matches!(v, Message::Null));
    
    // 3. Transform data
    let transformer = data_operations::MapActor::new(|payload| {
        // Custom transformation logic
        transform_data(payload)
    });
    
    // 4. Filter based on criteria
    let filter = data_operations::FilterActor::new(|payload| {
        filter_criteria(payload)
    });
    
    // 5. Aggregate results
    let aggregator = data_operations::AggregateActor::new()
        .window_size(100)
        .timeout(Duration::from_secs(60));
    
    // 6. Store results
    let database = integration::DatabaseActor::new("postgresql://...")
        .pool_size(5);
    
    // 7. Log activity
    let logger = utility::LoggerActor::new()
        .level(LogLevel::Info);
    
    // Add actors to network
    network.add_actor("http_source", Box::new(http_source)).await?;
    network.add_actor("validator", Box::new(validator)).await?;
    network.add_actor("transformer", Box::new(transformer)).await?;
    network.add_actor("filter", Box::new(filter)).await?;
    network.add_actor("aggregator", Box::new(aggregator)).await?;
    network.add_actor("database", Box::new(database)).await?;
    network.add_actor("logger", Box::new(logger)).await?;
    
    // Connect the pipeline
    network.connect("http_source", "output", "validator", "input").await?;
    network.connect("validator", "valid", "transformer", "input").await?;
    network.connect("transformer", "output", "filter", "input").await?;
    network.connect("filter", "output", "aggregator", "input").await?;
    network.connect("aggregator", "output", "database", "input").await?;
    
    // Log all stages
    network.connect("validator", "output", "logger", "input").await?;
    network.connect("transformer", "output", "logger", "input").await?;
    network.connect("aggregator", "output", "logger", "input").await?;
    
    Ok(network)
}

fn transform_data(payload: &amp;HashMap&lt;String, Message&gt;) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt; {
    // Implementation details...
    Ok(HashMap::new())
}

fn filter_criteria(payload: &amp;HashMap&lt;String, Message&gt;) -&gt; bool {
    // Implementation details...
    true
}
<span class="boring">}</span></code></pre></pre>
<h3 id="real-time-processing-workflow"><a class="header" href="#real-time-processing-workflow">Real-time Processing Workflow</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>async fn create_realtime_workflow() -&gt; Result&lt;Network, Box&lt;dyn std::error::Error&gt;&gt; {
    let mut network = Network::new();
    
    // Stream processor with throttling
    let throttle = synchronization::ThrottleActor::new()
        .rate_limit(1000) // 1000 msgs/sec
        .burst_size(50);
    
    // Real-time analytics
    let analytics = data_operations::AggregateActor::new()
        .window_size(1000)
        .timeout(Duration::from_secs(5)) // 5-second windows
        .aggregation_fn(|messages| {
            let mut stats = HashMap::new();
            
            // Calculate real-time statistics
            let count = messages.len() as i64;
            let avg_processing_time = calculate_avg_time(&amp;messages);
            
            stats.insert("count".to_string(), Message::Integer(count));
            stats.insert("avg_time".to_string(), Message::Float(avg_processing_time));
            stats.insert("window_end".to_string(), 
                        Message::String(chrono::Utc::now().to_rfc3339()));
            
            stats
        });
    
    // Metrics collection
    let metrics = utility::MetricsActor::new()
        .namespace("realtime")
        .endpoint("http://prometheus:9090/metrics");
    
    // Alert on anomalies
    let anomaly_detector = flow_control::ConditionalActor::new(|payload| {
        if let Some(Message::Float(avg_time)) = payload.get("avg_time") {
            *avg_time &gt; 1000.0 // Alert if avg time &gt; 1 second
        } else {
            false
        }
    });
    
    // Add to network
    network.add_actor("throttle", Box::new(throttle)).await?;
    network.add_actor("analytics", Box::new(analytics)).await?;
    network.add_actor("metrics", Box::new(metrics)).await?;
    network.add_actor("anomaly_detector", Box::new(anomaly_detector)).await?;
    
    // Connect pipeline
    network.connect("throttle", "output", "analytics", "input").await?;
    network.connect("analytics", "output", "metrics", "input").await?;
    network.connect("analytics", "output", "anomaly_detector", "input").await?;
    
    Ok(network)
}

fn calculate_avg_time(messages: &amp;[HashMap&lt;String, Message&gt;]) -&gt; f64 {
    // Calculate average processing time
    0.0
}
<span class="boring">}</span></code></pre></pre>
<h2 id="custom-component-creation"><a class="header" href="#custom-component-creation">Custom Component Creation</a></h2>
<h3 id="creating-a-custom-component"><a class="header" href="#creating-a-custom-component">Creating a Custom Component</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::ComponentBuilder;

// Define component configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
struct CustomConfig {
    threshold: f64,
    operation: String,
}

// Create component using builder
let custom_component = ComponentBuilder::new("custom_processor")
    .description("Custom data processor")
    .input_ports(vec!["data", "control"])
    .output_ports(vec!["result", "error"])
    .config_schema(serde_json::to_value(CustomConfig::default())?)
    .behavior(|payload, config| {
        Box::pin(async move {
            let config: CustomConfig = serde_json::from_value(config)?;
            
            // Custom processing logic
            process_custom_logic(payload, &amp;config).await
        })
    })
    .build()?;
<span class="boring">}</span></code></pre></pre>
<h3 id="component-registration"><a class="header" href="#component-registration">Component Registration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::ComponentRegistry;

// Register custom components
let mut registry = ComponentRegistry::new();

registry.register("custom_processor", custom_component)?;
registry.register("special_filter", special_filter_component)?;

// Use in workflows
let component = registry.create("custom_processor", custom_config)?;
network.add_actor("processor", component).await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="error-handling-17"><a class="header" href="#error-handling-17">Error Handling</a></h2>
<h3 id="error-propagation-1"><a class="header" href="#error-propagation-1">Error Propagation</a></h3>
<p>Components follow consistent error handling patterns:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Components return structured errors
let error_result = HashMap::from([
    ("error".to_string(), Message::Error("Validation failed".to_string())),
    ("error_code".to_string(), Message::String("VALIDATION_ERROR".to_string())),
    ("details".to_string(), Message::Object(error_details)),
    ("timestamp".to_string(), Message::String(Utc::now().to_rfc3339())),
]);
<span class="boring">}</span></code></pre></pre>
<h3 id="error-recovery-1"><a class="header" href="#error-recovery-1">Error Recovery</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Use error handling components
let error_handler = flow_control::ConditionalActor::new(|payload| {
    payload.contains_key("error")
});

let retry_actor = utility::RetryActor::new()
    .max_attempts(3)
    .backoff_strategy(BackoffStrategy::Exponential);

// Connect for error recovery
network.connect("processor", "error", "error_handler", "input").await?;
network.connect("error_handler", "true", "retry_actor", "input").await?;
network.connect("retry_actor", "output", "processor", "input").await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-tuning-5"><a class="header" href="#performance-tuning-5">Performance Tuning</a></h2>
<h3 id="batching"><a class="header" href="#batching">Batching</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Use batching for high-throughput scenarios
let batch_processor = data_operations::MapActor::new(|payload| {
    if let Some(Message::Array(batch)) = payload.get("batch") {
        // Process entire batch at once
        process_batch(batch)
    } else {
        // Handle single message
        process_single(payload)
    }
});

let batcher = utility::BatchActor::new()
    .batch_size(100)
    .timeout(Duration::from_millis(100));
<span class="boring">}</span></code></pre></pre>
<h3 id="parallel-processing"><a class="header" href="#parallel-processing">Parallel Processing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Distribute work across multiple workers
let load_balancer = flow_control::LoadBalancerActor::new()
    .strategy(LoadBalanceStrategy::RoundRobin)
    .worker_count(4);

// Workers process in parallel
for i in 0..4 {
    let worker = data_operations::MapActor::new(process_function);
    network.add_actor(&amp;format!("worker_{}", i), Box::new(worker)).await?;
    network.connect("load_balancer", &amp;format!("output_{}", i), 
                   &amp;format!("worker_{}", i), "input").await?;
}
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-20"><a class="header" href="#best-practices-20">Best Practices</a></h2>
<h3 id="component-selection"><a class="header" href="#component-selection">Component Selection</a></h3>
<ol>
<li><strong>Use appropriate granularity</strong> - Not too fine, not too coarse</li>
<li><strong>Prefer composition</strong> - Combine simple components over complex ones</li>
<li><strong>Consider performance</strong> - Choose components based on throughput requirements</li>
<li><strong>Plan for errors</strong> - Include error handling components in workflows</li>
</ol>
<h3 id="configuration-8"><a class="header" href="#configuration-8">Configuration</a></h3>
<ol>
<li><strong>Validate configuration</strong> - Use schema validation</li>
<li><strong>Use environment variables</strong> - For deployment-specific settings</li>
<li><strong>Document requirements</strong> - Clear component dependencies</li>
<li><strong>Test configurations</strong> - Validate settings before deployment</li>
</ol>
<h3 id="monitoring"><a class="header" href="#monitoring">Monitoring</a></h3>
<ol>
<li><strong>Add logging</strong> - Include LoggerActor for observability</li>
<li><strong>Collect metrics</strong> - Use MetricsActor for performance monitoring</li>
<li><strong>Set up alerts</strong> - Use ConditionalActor for anomaly detection</li>
<li><strong>Monitor resource usage</strong> - Track memory and CPU usage</li>
</ol>
<h2 id="next-steps-28"><a class="header" href="#next-steps-28">Next Steps</a></h2>
<ul>
<li><a href="components/./custom-components.html">Creating Custom Components</a> - Build your own components</li>
<li><a href="components/./component-testing.html">Component Testing</a> - Testing strategies</li>
<li><a href="components/./performance-optimization.html">Performance Guide</a> - Optimization techniques</li>
<li><a href="components/../examples/README.html">Examples</a> - Real-world component usage</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="deno-runtime-1"><a class="header" href="#deno-runtime-1">Deno Runtime</a></h1>
<p>Reflow's Deno runtime enables JavaScript and TypeScript actors with secure, sandboxed execution.</p>
<h2 id="overview-16"><a class="header" href="#overview-16">Overview</a></h2>
<p>The Deno runtime provides:</p>
<ul>
<li><strong>Secure sandbox</strong> with configurable permissions</li>
<li><strong>TypeScript support</strong> out of the box</li>
<li><strong>NPM package</strong> ecosystem access</li>
<li><strong>Modern JavaScript</strong> features (ES2022+)</li>
<li><strong>Async/await</strong> support for non-blocking operations</li>
</ul>
<h2 id="basic-usage-2"><a class="header" href="#basic-usage-2">Basic Usage</a></h2>
<h3 id="creating-a-javascript-actor"><a class="header" href="#creating-a-javascript-actor">Creating a JavaScript Actor</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_script::{ScriptActor, LanguageEngine};
use reflow_network::{Network, NetworkConfig};
use reflow_network::connector::{Connector, ConnectionPoint, InitialPacket};
use reflow_network::message::Message;

// Create script actor with JavaScript/Deno engine
let script_content = r#"
function process(inputs, context) {
    const data = inputs.data;
    
    if (typeof data === 'string') {
        return {
            result: data.toUpperCase(),
            length: data.length,
            timestamp: new Date().toISOString()
        };
    }
    
    return { error: 'Expected string input' };
}
"#;

let actor = ScriptActor::new(LanguageEngine::JavaScript, script_content.to_string());

// Register and use in network
let mut network = Network::new(NetworkConfig::default());
network.register_actor("js_processor", actor)?;
network.add_node("script1", "js_processor")?;

// Connect to other actors
network.add_connection(Connector {
    from: ConnectionPoint {
        actor: "source_actor".to_owned(),
        port: "output".to_owned(),
        ..Default::default()
    },
    to: ConnectionPoint {
        actor: "script1".to_owned(),
        port: "data".to_owned(),
        ..Default::default()
    },
});
<span class="boring">}</span></code></pre></pre>
<h3 id="javascript-actor-script"><a class="header" href="#javascript-actor-script">JavaScript Actor Script</a></h3>
<pre><code class="language-javascript">// script.js - Simple transformation actor
function process(inputs, context) {
    const data = inputs.data;
    
    if (typeof data === 'string') {
        return {
            result: data.toUpperCase(),
            length: data.length,
            timestamp: new Date().toISOString()
        };
    }
    
    return { error: 'Expected string input' };
}

// Export for Reflow
exports.process = process;
</code></pre>
<h2 id="actor-function-signature"><a class="header" href="#actor-function-signature">Actor Function Signature</a></h2>
<h3 id="input-parameters"><a class="header" href="#input-parameters">Input Parameters</a></h3>
<pre><code class="language-javascript">function process(inputs, context) {
    // inputs: Object containing input port data
    // context: Actor execution context
}
</code></pre>
<h3 id="context-object"><a class="header" href="#context-object">Context Object</a></h3>
<pre><code class="language-javascript">const context = {
    // Actor configuration
    config: {
        // Custom configuration values
    },
    
    // Utility functions
    log: (level, message) =&gt; {},
    
    // State management
    getState: () =&gt; {},
    setState: (state) =&gt; {},
    
    // Metrics
    incrementCounter: (name) =&gt; {},
    recordTimer: (name, duration) =&gt; {},
};
</code></pre>
<h3 id="return-values"><a class="header" href="#return-values">Return Values</a></h3>
<pre><code class="language-javascript">// Success - return output object
return {
    output1: "value1",
    output2: 42,
    status: "success"
};

// Error - return error object
return {
    error: "Something went wrong",
    code: 500
};

// Async operations
async function process(inputs, context) {
    const result = await fetchData(inputs.url);
    return { data: result };
}
</code></pre>
<h2 id="data-types"><a class="header" href="#data-types">Data Types</a></h2>
<h3 id="supported-types"><a class="header" href="#supported-types">Supported Types</a></h3>
<pre><code class="language-javascript">// Primitive types
return {
    string: "hello",
    number: 42,
    boolean: true,
    null: null,
};

// Complex types
return {
    array: [1, 2, 3],
    object: { key: "value" },
    nested: {
        array: [{ id: 1 }, { id: 2 }],
        metadata: { timestamp: Date.now() }
    }
};

// Binary data
return {
    buffer: new Uint8Array([1, 2, 3, 4])
};
</code></pre>
<h2 id="state-management-3"><a class="header" href="#state-management-3">State Management</a></h2>
<h3 id="persistent-state"><a class="header" href="#persistent-state">Persistent State</a></h3>
<pre><code class="language-javascript">function process(inputs, context) {
    // Get current state
    const state = context.getState() || { counter: 0 };
    
    // Update state
    state.counter += 1;
    state.lastInput = inputs.data;
    
    // Save state
    context.setState(state);
    
    return {
        count: state.counter,
        data: state.lastInput
    };
}
</code></pre>
<h2 id="async-operations"><a class="header" href="#async-operations">Async Operations</a></h2>
<h3 id="http-requests"><a class="header" href="#http-requests">HTTP Requests</a></h3>
<pre><code class="language-javascript">async function process(inputs, context) {
    try {
        const response = await fetch(inputs.url, {
            method: 'GET',
            headers: {
                'Content-Type': 'application/json'
            }
        });
        
        if (!response.ok) {
            return { error: `HTTP ${response.status}` };
        }
        
        const data = await response.json();
        return { result: data };
        
    } catch (error) {
        return { error: error.message };
    }
}
</code></pre>
<h3 id="file-operations"><a class="header" href="#file-operations">File Operations</a></h3>
<pre><code class="language-javascript">async function process(inputs, context) {
    try {
        // Read file (requires --allow-read permission)
        const content = await Deno.readTextFile(inputs.filename);
        
        // Process content
        const lines = content.split('\n').length;
        
        return {
            content: content,
            lineCount: lines
        };
        
    } catch (error) {
        return { error: `File error: ${error.message}` };
    }
}
</code></pre>
<h2 id="npm-package-support"><a class="header" href="#npm-package-support">NPM Package Support</a></h2>
<h3 id="using-external-packages"><a class="header" href="#using-external-packages">Using External Packages</a></h3>
<pre><code class="language-javascript">// Import from NPM
import { format } from "https://deno.land/x/date_fns/index.js";
import _ from "https://cdn.skypack.dev/lodash";

function process(inputs, context) {
    const now = new Date();
    const formatted = format(now, 'yyyy-MM-dd HH:mm:ss');
    
    const processed = _.map(inputs.data, item =&gt; ({
        ...item,
        timestamp: formatted
    }));
    
    return { result: processed };
}
</code></pre>
<h3 id="package-configuration"><a class="header" href="#package-configuration">Package Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = ScriptConfig {
    environment: ScriptEnvironment::SYSTEM,
    runtime: ScriptRuntime::JavaScript,
    source: script_source,
    entry_point: "process".to_string(),
    packages: Some(vec![
        "https://deno.land/x/date_fns@v2.29.3/index.js".to_string(),
        "https://cdn.skypack.dev/lodash@4.17.21".to_string(),
    ]),
};
<span class="boring">}</span></code></pre></pre>
<h2 id="error-handling-18"><a class="header" href="#error-handling-18">Error Handling</a></h2>
<h3 id="error-patterns"><a class="header" href="#error-patterns">Error Patterns</a></h3>
<pre><code class="language-javascript">function process(inputs, context) {
    try {
        // Validate inputs
        if (!inputs.data) {
            return { error: "Missing required 'data' input" };
        }
        
        if (typeof inputs.data !== 'string') {
            return { 
                error: "Invalid input type",
                expected: "string",
                received: typeof inputs.data
            };
        }
        
        // Process data
        const result = inputs.data.toLowerCase();
        
        if (result.length === 0) {
            return { 
                error: "Empty result",
                warning: "Input data was empty after processing"
            };
        }
        
        return { result: result };
        
    } catch (error) {
        // Log error for debugging
        context.log('error', `Processing failed: ${error.message}`);
        
        return {
            error: error.message,
            stack: error.stack,
            timestamp: new Date().toISOString()
        };
    }
}
</code></pre>
<h2 id="security-and-permissions"><a class="header" href="#security-and-permissions">Security and Permissions</a></h2>
<h3 id="permission-configuration"><a class="header" href="#permission-configuration">Permission Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_script::PermissionConfig;

let config = ScriptConfig {
    // ... other fields
    permissions: Some(PermissionConfig {
        allow_net: vec!["https://api.example.com".to_string()],
        allow_read: vec!["/tmp/data".to_string()],
        allow_write: vec!["/tmp/output".to_string()],
        allow_run: false,
        allow_env: false,
    }),
};
<span class="boring">}</span></code></pre></pre>
<h3 id="safe-practices"><a class="header" href="#safe-practices">Safe Practices</a></h3>
<pre><code class="language-javascript">function process(inputs, context) {
    // Validate and sanitize inputs
    const sanitized = sanitizeInput(inputs.userInput);
    
    // Use try-catch for external operations
    try {
        return processData(sanitized);
    } catch (error) {
        // Don't expose internal details
        return { error: "Processing failed" };
    }
}

function sanitizeInput(input) {
    if (typeof input !== 'string') return '';
    
    // Remove potentially dangerous characters
    return input
        .replace(/[&lt;&gt;]/g, '')
        .trim()
        .substring(0, 1000); // Limit length
}
</code></pre>
<h2 id="performance-optimization-8"><a class="header" href="#performance-optimization-8">Performance Optimization</a></h2>
<h3 id="efficient-processing"><a class="header" href="#efficient-processing">Efficient Processing</a></h3>
<pre><code class="language-javascript">// Use streaming for large data
async function process(inputs, context) {
    const results = [];
    
    // Process in chunks to avoid memory issues
    const chunkSize = 100;
    const data = inputs.data || [];
    
    for (let i = 0; i &lt; data.length; i += chunkSize) {
        const chunk = data.slice(i, i + chunkSize);
        const processed = await processChunk(chunk);
        results.push(...processed);
        
        // Allow other actors to run
        if (i % 1000 === 0) {
            await new Promise(resolve =&gt; setTimeout(resolve, 0));
        }
    }
    
    return { results: results };
}

async function processChunk(chunk) {
    return chunk.map(item =&gt; ({
        ...item,
        processed: true,
        timestamp: Date.now()
    }));
}
</code></pre>
<h3 id="caching-1"><a class="header" href="#caching-1">Caching</a></h3>
<pre><code class="language-javascript">// Simple in-memory cache
const cache = new Map();

function process(inputs, context) {
    const key = inputs.cacheKey;
    
    // Check cache first
    if (cache.has(key)) {
        context.log('info', `Cache hit for key: ${key}`);
        return { result: cache.get(key), fromCache: true };
    }
    
    // Expensive computation
    const result = expensiveOperation(inputs.data);
    
    // Store in cache with TTL
    cache.set(key, result);
    setTimeout(() =&gt; cache.delete(key), 60000); // 1 minute TTL
    
    return { result: result, fromCache: false };
}
</code></pre>
<h2 id="testing-javascript-actors"><a class="header" href="#testing-javascript-actors">Testing JavaScript Actors</a></h2>
<h3 id="unit-testing-1"><a class="header" href="#unit-testing-1">Unit Testing</a></h3>
<pre><code class="language-javascript">// test_actor.js
import { assertEquals } from "https://deno.land/std/testing/asserts.ts";

// Import your actor function
import { process } from "./my_actor.js";

Deno.test("actor processes string input", () =&gt; {
    const inputs = { data: "hello world" };
    const context = { 
        log: () =&gt; {},
        getState: () =&gt; ({}),
        setState: () =&gt; {}
    };
    
    const result = process(inputs, context);
    
    assertEquals(result.result, "HELLO WORLD");
    assertEquals(result.length, 11);
});

Deno.test("actor handles missing input", () =&gt; {
    const inputs = {};
    const context = { log: () =&gt; {} };
    
    const result = process(inputs, context);
    
    assertEquals(result.error, "Expected string input");
});
</code></pre>
<h3 id="integration-testing-3"><a class="header" href="#integration-testing-3">Integration Testing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[tokio::test]
async fn test_javascript_actor_integration() {
    let script = include_str!("test_script.js");
    let config = ScriptConfig {
        environment: ScriptEnvironment::SYSTEM,
        runtime: ScriptRuntime::JavaScript,
        source: script.as_bytes().to_vec(),
        entry_point: "process".to_string(),
        packages: None,
    };
    
    let actor = ScriptActor::new(config);
    
    // Test actor behavior
    let inputs = HashMap::from([
        ("data".to_string(), Message::String("test".to_string()))
    ]);
    
    let result = test_actor_behavior(actor, inputs).await;
    assert!(result.is_ok());
}
<span class="boring">}</span></code></pre></pre>
<h2 id="examples"><a class="header" href="#examples">Examples</a></h2>
<h3 id="data-transformation"><a class="header" href="#data-transformation">Data Transformation</a></h3>
<pre><code class="language-javascript">// Transform JSON data
function process(inputs, context) {
    const data = inputs.json_data;
    
    if (!Array.isArray(data)) {
        return { error: "Expected array input" };
    }
    
    const transformed = data.map(item =&gt; ({
        id: item.id,
        name: item.name?.toUpperCase(),
        email: item.email?.toLowerCase(),
        createdAt: new Date(item.created_at).toISOString(),
        tags: item.tags?.map(tag =&gt; tag.toLowerCase()) || []
    }));
    
    return {
        data: transformed,
        count: transformed.length,
        processedAt: new Date().toISOString()
    };
}
</code></pre>
<h3 id="api-integration"><a class="header" href="#api-integration">API Integration</a></h3>
<pre><code class="language-javascript">async function process(inputs, context) {
    const { endpoint, payload, authToken } = inputs;
    
    try {
        const response = await fetch(endpoint, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${authToken}`
            },
            body: JSON.stringify(payload)
        });
        
        const result = await response.json();
        
        return {
            status: response.status,
            data: result,
            success: response.ok
        };
        
    } catch (error) {
        return {
            error: error.message,
            success: false
        };
    }
}
</code></pre>
<h2 id="best-practices-21"><a class="header" href="#best-practices-21">Best Practices</a></h2>
<h3 id="code-organization"><a class="header" href="#code-organization">Code Organization</a></h3>
<pre><code class="language-javascript">// Separate concerns into functions
function process(inputs, context) {
    try {
        const validated = validateInputs(inputs);
        const processed = processData(validated);
        const formatted = formatOutput(processed);
        
        return { result: formatted };
    } catch (error) {
        return handleError(error, context);
    }
}

function validateInputs(inputs) {
    if (!inputs.data) throw new Error("Missing data");
    return inputs;
}

function processData(inputs) {
    // Main processing logic
    return inputs.data.map(transform);
}

function formatOutput(data) {
    return {
        items: data,
        timestamp: new Date().toISOString()
    };
}

function handleError(error, context) {
    context.log('error', error.message);
    return { error: "Processing failed" };
}
</code></pre>
<h3 id="resource-management-1"><a class="header" href="#resource-management-1">Resource Management</a></h3>
<pre><code class="language-javascript">// Clean up resources
function process(inputs, context) {
    const resources = [];
    
    try {
        // Acquire resources
        const db = openDatabase(inputs.connectionString);
        resources.push(db);
        
        const file = openFile(inputs.filename);
        resources.push(file);
        
        // Use resources
        const result = processWithResources(db, file);
        
        return { result: result };
        
    } finally {
        // Always clean up
        resources.forEach(resource =&gt; {
            try {
                resource.close();
            } catch (e) {
                // Log but don't throw
                console.error("Cleanup error:", e);
            }
        });
    }
}
</code></pre>
<h2 id="next-steps-29"><a class="header" href="#next-steps-29">Next Steps</a></h2>
<ul>
<li><a href="scripting/javascript/../python/python-engine.html">Python Runtime</a> - Python scripting support</li>
<li><a href="scripting/javascript/../wasm/wasm-plugins.html">WebAssembly Runtime</a> - WASM plugin system</li>
<li><a href="scripting/javascript/./script-configuration.html">Script Configuration</a> - Advanced configuration</li>
<li><a href="scripting/javascript/../../api/actors/creating-actors.html">Creating Actors</a> - Actor development guide</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="building-a-visual-graph-editor"><a class="header" href="#building-a-visual-graph-editor">Building a Visual Graph Editor</a></h1>
<p>Complete tutorial for creating a visual graph editor using Reflow's WebAssembly APIs.</p>
<h2 id="overview-17"><a class="header" href="#overview-17">Overview</a></h2>
<p>This tutorial walks through building a complete visual graph editor that allows users to:</p>
<ul>
<li>Create and edit graphs visually</li>
<li>Add nodes by dragging from a component palette</li>
<li>Connect nodes with visual links</li>
<li>Configure node properties through forms</li>
<li>Execute workflows and see real-time results</li>
<li>Save and load graph files</li>
</ul>
<h2 id="prerequisites-4"><a class="header" href="#prerequisites-4">Prerequisites</a></h2>
<ul>
<li>Basic HTML, CSS, and JavaScript knowledge</li>
<li>Understanding of Reflow's graph concepts</li>
<li>Node.js and npm installed</li>
</ul>
<h2 id="project-setup"><a class="header" href="#project-setup">Project Setup</a></h2>
<h3 id="1-initialize-project"><a class="header" href="#1-initialize-project">1. Initialize Project</a></h3>
<pre><code class="language-bash">mkdir reflow-visual-editor
cd reflow-visual-editor
npm init -y
</code></pre>
<h3 id="2-install-dependencies"><a class="header" href="#2-install-dependencies">2. Install Dependencies</a></h3>
<pre><code class="language-bash"># Core dependencies
npm install reflow-network-wasm

# Development dependencies
npm install --save-dev webpack webpack-cli webpack-dev-server
npm install --save-dev html-webpack-plugin css-loader style-loader
npm install --save-dev @babel/core @babel/preset-env babel-loader
</code></pre>
<h3 id="3-project-structure"><a class="header" href="#3-project-structure">3. Project Structure</a></h3>
<pre><code>reflow-visual-editor/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ index.html
‚îÇ   ‚îú‚îÄ‚îÄ index.js
‚îÇ   ‚îú‚îÄ‚îÄ style.css
‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Graph.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Node.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Connection.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Palette.js
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ PropertyPanel.js
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ drag-drop.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ events.js
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ serialization.js
‚îÇ   ‚îî‚îÄ‚îÄ workers/
‚îÇ       ‚îî‚îÄ‚îÄ execution-worker.js
‚îú‚îÄ‚îÄ webpack.config.js
‚îî‚îÄ‚îÄ package.json
</code></pre>
<h2 id="core-implementation"><a class="header" href="#core-implementation">Core Implementation</a></h2>
<h3 id="1-basic-html-structure"><a class="header" href="#1-basic-html-structure">1. Basic HTML Structure</a></h3>
<pre><code class="language-html">&lt;!-- src/index.html --&gt;
&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
    &lt;meta charset="UTF-8"&gt;
    &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt;
    &lt;title&gt;Reflow Visual Editor&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;div id="app"&gt;
        &lt;header class="toolbar"&gt;
            &lt;div class="toolbar-group"&gt;
                &lt;button id="new-graph"&gt;New&lt;/button&gt;
                &lt;button id="open-graph"&gt;Open&lt;/button&gt;
                &lt;button id="save-graph"&gt;Save&lt;/button&gt;
            &lt;/div&gt;
            &lt;div class="toolbar-group"&gt;
                &lt;button id="run-graph"&gt;Run&lt;/button&gt;
                &lt;button id="stop-graph"&gt;Stop&lt;/button&gt;
                &lt;button id="validate-graph"&gt;Validate&lt;/button&gt;
            &lt;/div&gt;
            &lt;div class="toolbar-group"&gt;
                &lt;button id="auto-layout"&gt;Auto Layout&lt;/button&gt;
                &lt;button id="zoom-fit"&gt;Zoom to Fit&lt;/button&gt;
            &lt;/div&gt;
        &lt;/header&gt;
        
        &lt;div class="editor-container"&gt;
            &lt;div class="sidebar"&gt;
                &lt;div class="component-palette" id="palette"&gt;
                    &lt;h3&gt;Components&lt;/h3&gt;
                    &lt;div class="palette-category" data-category="data"&gt;
                        &lt;h4&gt;Data Operations&lt;/h4&gt;
                        &lt;div class="palette-items"&gt;
                            &lt;!-- Component items will be populated by JavaScript --&gt;
                        &lt;/div&gt;
                    &lt;/div&gt;
                    &lt;div class="palette-category" data-category="flow"&gt;
                        &lt;h4&gt;Flow Control&lt;/h4&gt;
                        &lt;div class="palette-items"&gt;
                            &lt;!-- Component items will be populated by JavaScript --&gt;
                        &lt;/div&gt;
                    &lt;/div&gt;
                    &lt;div class="palette-category" data-category="io"&gt;
                        &lt;h4&gt;Input/Output&lt;/h4&gt;
                        &lt;div class="palette-items"&gt;
                            &lt;!-- Component items will be populated by JavaScript --&gt;
                        &lt;/div&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            
            &lt;div class="graph-canvas-container"&gt;
                &lt;svg id="graph-canvas" class="graph-canvas"&gt;
                    &lt;defs&gt;
                        &lt;marker id="arrowhead" markerWidth="10" markerHeight="7" 
                                refX="10" refY="3.5" orient="auto"&gt;
                            &lt;polygon points="0 0, 10 3.5, 0 7" fill="#666" /&gt;
                        &lt;/marker&gt;
                    &lt;/defs&gt;
                    &lt;g id="connections-layer"&gt;&lt;/g&gt;
                    &lt;g id="nodes-layer"&gt;&lt;/g&gt;
                &lt;/svg&gt;
                
                &lt;div class="canvas-overlay"&gt;
                    &lt;div class="zoom-controls"&gt;
                        &lt;button id="zoom-in"&gt;+&lt;/button&gt;
                        &lt;button id="zoom-out"&gt;-&lt;/button&gt;
                        &lt;span id="zoom-level"&gt;100%&lt;/span&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            
            &lt;div class="properties-panel" id="properties-panel"&gt;
                &lt;h3&gt;Properties&lt;/h3&gt;
                &lt;div id="property-form"&gt;
                    &lt;p&gt;Select a node to edit properties&lt;/p&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        
        &lt;div class="status-bar"&gt;
            &lt;span id="status-text"&gt;Ready&lt;/span&gt;
            &lt;div class="status-indicators"&gt;
                &lt;span id="node-count"&gt;0 nodes&lt;/span&gt;
                &lt;span id="connection-count"&gt;0 connections&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<h3 id="2-main-application-class"><a class="header" href="#2-main-application-class">2. Main Application Class</a></h3>
<pre><code class="language-javascript">// src/index.js
import { Graph } from 'reflow-network-wasm';
import GraphEditor from './components/Graph.js';
import ComponentPalette from './components/Palette.js';
import PropertyPanel from './components/PropertyPanel.js';
import './style.css';

class VisualEditor {
    constructor() {
        this.graph = new Graph("VisualWorkflow", true, {});
        this.graphEditor = new GraphEditor(this.graph, '#graph-canvas');
        this.palette = new ComponentPalette('#palette');
        this.propertyPanel = new PropertyPanel('#properties-panel');
        
        this.selectedNode = null;
        this.isExecuting = false;
        
        this.initializeEventListeners();
        this.initializeComponents();
    }
    
    initializeEventListeners() {
        // Toolbar events
        document.getElementById('new-graph').addEventListener('click', () =&gt; this.newGraph());
        document.getElementById('open-graph').addEventListener('click', () =&gt; this.openGraph());
        document.getElementById('save-graph').addEventListener('click', () =&gt; this.saveGraph());
        document.getElementById('run-graph').addEventListener('click', () =&gt; this.runGraph());
        document.getElementById('stop-graph').addEventListener('click', () =&gt; this.stopGraph());
        document.getElementById('validate-graph').addEventListener('click', () =&gt; this.validateGraph());
        document.getElementById('auto-layout').addEventListener('click', () =&gt; this.autoLayout());
        document.getElementById('zoom-fit').addEventListener('click', () =&gt; this.zoomToFit());
        
        // Zoom controls
        document.getElementById('zoom-in').addEventListener('click', () =&gt; this.graphEditor.zoomIn());
        document.getElementById('zoom-out').addEventListener('click', () =&gt; this.graphEditor.zoomOut());
        
        // Graph events
        this.graphEditor.on('nodeSelected', (node) =&gt; this.selectNode(node));
        this.graphEditor.on('nodeDeselected', () =&gt; this.deselectNode());
        this.graphEditor.on('nodeAdded', (node) =&gt; this.updateStatus());
        this.graphEditor.on('nodeRemoved', (node) =&gt; this.updateStatus());
        this.graphEditor.on('connectionAdded', (connection) =&gt; this.updateStatus());
        this.graphEditor.on('connectionRemoved', (connection) =&gt; this.updateStatus());
        
        // Palette events
        this.palette.on('componentDragStart', (component) =&gt; this.handleComponentDrag(component));
        
        // Property panel events
        this.propertyPanel.on('propertyChanged', (property, value) =&gt; this.updateNodeProperty(property, value));
    }
    
    initializeComponents() {
        this.palette.loadComponents([
            // Data Operations
            { 
                name: 'Map', 
                category: 'data', 
                component: 'MapActor',
                description: 'Transform data using a function',
                icon: 'üîÑ',
                ports: {
                    input: [{ name: 'input', type: 'any' }],
                    output: [{ name: 'output', type: 'any' }]
                }
            },
            { 
                name: 'Filter', 
                category: 'data', 
                component: 'FilterActor',
                description: 'Filter data based on conditions',
                icon: 'üîç',
                ports: {
                    input: [{ name: 'input', type: 'any' }],
                    output: [{ name: 'output', type: 'any' }]
                }
            },
            { 
                name: 'Aggregate', 
                category: 'data', 
                component: 'AggregateActor',
                description: 'Aggregate multiple inputs',
                icon: 'üìä',
                ports: {
                    input: [{ name: 'input', type: 'any' }],
                    output: [{ name: 'output', type: 'any' }]
                }
            },
            
            // Flow Control
            { 
                name: 'Conditional', 
                category: 'flow', 
                component: 'ConditionalActor',
                description: 'Branch based on condition',
                icon: 'üîÄ',
                ports: {
                    input: [{ name: 'input', type: 'any' }],
                    output: [
                        { name: 'true', type: 'any' },
                        { name: 'false', type: 'any' }
                    ]
                }
            },
            { 
                name: 'Merge', 
                category: 'flow', 
                component: 'MergeActor',
                description: 'Merge multiple inputs',
                icon: 'üîó',
                ports: {
                    input: [
                        { name: 'input1', type: 'any' },
                        { name: 'input2', type: 'any' }
                    ],
                    output: [{ name: 'output', type: 'any' }]
                }
            },
            
            // Input/Output
            { 
                name: 'HTTP Request', 
                category: 'io', 
                component: 'HttpRequestActor',
                description: 'Make HTTP requests',
                icon: 'üåê',
                ports: {
                    input: [{ name: 'url', type: 'string' }],
                    output: [
                        { name: 'response', type: 'object' },
                        { name: 'error', type: 'object' }
                    ]
                }
            },
            { 
                name: 'Logger', 
                category: 'io', 
                component: 'LoggerActor',
                description: 'Log messages',
                icon: 'üìù',
                ports: {
                    input: [{ name: 'message', type: 'any' }],
                    output: []
                }
            }
        ]);
        
        this.updateStatus();
    }
    
    newGraph() {
        if (this.hasUnsavedChanges()) {
            if (!confirm('You have unsaved changes. Create a new graph anyway?')) {
                return;
            }
        }
        
        this.graph = new Graph("VisualWorkflow", true, {});
        this.graphEditor.setGraph(this.graph);
        this.deselectNode();
        this.updateStatus();
        this.setStatus('New graph created');
    }
    
    async openGraph() {
        const input = document.createElement('input');
        input.type = 'file';
        input.accept = '.json';
        input.onchange = async (e) =&gt; {
            const file = e.target.files[0];
            if (file) {
                try {
                    const text = await file.text();
                    const graphData = JSON.parse(text);
                    this.graph = Graph.fromJson(graphData);
                    this.graphEditor.setGraph(this.graph);
                    this.deselectNode();
                    this.updateStatus();
                    this.setStatus(`Opened: ${file.name}`);
                } catch (error) {
                    alert(`Error opening file: ${error.message}`);
                }
            }
        };
        input.click();
    }
    
    saveGraph() {
        try {
            const graphData = this.graph.toJson();
            const blob = new Blob([JSON.stringify(graphData, null, 2)], 
                                { type: 'application/json' });
            const url = URL.createObjectURL(blob);
            
            const a = document.createElement('a');
            a.href = url;
            a.download = `${this.graph.name || 'workflow'}.json`;
            a.click();
            
            URL.revokeObjectURL(url);
            this.setStatus('Graph saved');
        } catch (error) {
            alert(`Error saving graph: ${error.message}`);
        }
    }
    
    async runGraph() {
        try {
            this.setStatus('Validating graph...');
            const validation = this.graph.validate();
            
            if (!validation.isValid) {
                alert(`Graph validation failed:\n${validation.errors.join('\n')}`);
                return;
            }
            
            this.setStatus('Starting execution...');
            this.isExecuting = true;
            
            // Use Web Worker for graph execution
            if (!this.executionWorker) {
                this.executionWorker = new Worker('./workers/execution-worker.js');
                this.executionWorker.onmessage = (e) =&gt; this.handleExecutionMessage(e);
            }
            
            this.executionWorker.postMessage({
                type: 'execute',
                graph: this.graph.toJson()
            });
            
            this.updateToolbarState();
        } catch (error) {
            this.setStatus(`Execution error: ${error.message}`);
            this.isExecuting = false;
            this.updateToolbarState();
        }
    }
    
    stopGraph() {
        if (this.executionWorker) {
            this.executionWorker.postMessage({ type: 'stop' });
        }
        this.isExecuting = false;
        this.updateToolbarState();
        this.setStatus('Execution stopped');
    }
    
    validateGraph() {
        try {
            const validation = this.graph.validate();
            
            if (validation.isValid) {
                this.setStatus('Graph is valid');
                // Highlight valid state in UI
                this.graphEditor.highlightValidation(validation);
            } else {
                this.setStatus(`Validation failed: ${validation.errors.length} errors`);
                // Show validation errors in UI
                this.graphEditor.showValidationErrors(validation.errors);
                
                // Show detailed errors in console or modal
                console.log('Validation errors:', validation.errors);
            }
        } catch (error) {
            this.setStatus(`Validation error: ${error.message}`);
        }
    }
    
    autoLayout() {
        try {
            this.setStatus('Calculating layout...');
            const positions = this.graph.calculateLayout({
                algorithm: 'hierarchical',
                nodeSpacing: 120,
                layerSpacing: 80
            });
            
            this.graphEditor.animateToPositions(positions);
            this.setStatus('Layout applied');
        } catch (error) {
            this.setStatus(`Layout error: ${error.message}`);
        }
    }
    
    zoomToFit() {
        this.graphEditor.zoomToFit();
        this.setStatus('Zoomed to fit');
    }
    
    selectNode(node) {
        this.selectedNode = node;
        this.propertyPanel.showNodeProperties(node);
        this.graphEditor.highlightNode(node.id);
    }
    
    deselectNode() {
        this.selectedNode = null;
        this.propertyPanel.clear();
        this.graphEditor.clearHighlight();
    }
    
    updateNodeProperty(property, value) {
        if (this.selectedNode) {
            this.selectedNode.metadata[property] = value;
            this.graphEditor.updateNode(this.selectedNode);
            this.setStatus(`Updated ${property}`);
        }
    }
    
    handleComponentDrag(component) {
        this.graphEditor.enableDropZone(component);
    }
    
    handleExecutionMessage(e) {
        const { type, data } = e.data;
        
        switch (type) {
            case 'progress':
                this.setStatus(`Executing... ${data.progress}%`);
                this.graphEditor.updateExecutionProgress(data);
                break;
                
            case 'completed':
                this.setStatus('Execution completed successfully');
                this.isExecuting = false;
                this.updateToolbarState();
                this.graphEditor.showExecutionResults(data.results);
                break;
                
            case 'error':
                this.setStatus(`Execution failed: ${data.error}`);
                this.isExecuting = false;
                this.updateToolbarState();
                this.graphEditor.showExecutionError(data);
                break;
                
            case 'nodeExecuted':
                this.graphEditor.highlightExecutedNode(data.nodeId);
                break;
        }
    }
    
    updateStatus() {
        const nodeCount = this.graph.getNodes().length;
        const connectionCount = this.graph.getConnections().length;
        
        document.getElementById('node-count').textContent = `${nodeCount} nodes`;
        document.getElementById('connection-count').textContent = `${connectionCount} connections`;
    }
    
    updateToolbarState() {
        document.getElementById('run-graph').disabled = this.isExecuting;
        document.getElementById('stop-graph').disabled = !this.isExecuting;
    }
    
    setStatus(message) {
        document.getElementById('status-text').textContent = message;
        console.log(`Status: ${message}`);
    }
    
    hasUnsavedChanges() {
        // Implement change tracking logic
        return false;
    }
}

// Initialize application when DOM is ready
document.addEventListener('DOMContentLoaded', () =&gt; {
    new VisualEditor();
});
</code></pre>
<h3 id="3-graph-editor-component"><a class="header" href="#3-graph-editor-component">3. Graph Editor Component</a></h3>
<pre><code class="language-javascript">// src/components/Graph.js
import { EventEmitter } from '../utils/events.js';
import Node from './Node.js';
import Connection from './Connection.js';

class GraphEditor extends EventEmitter {
    constructor(graph, canvasSelector) {
        super();
        this.graph = graph;
        this.canvas = document.querySelector(canvasSelector);
        this.nodesLayer = this.canvas.querySelector('#nodes-layer');
        this.connectionsLayer = this.canvas.querySelector('#connections-layer');
        
        this.nodes = new Map();
        this.connections = new Map();
        this.scale = 1;
        this.panX = 0;
        this.panY = 0;
        
        this.dragState = null;
        this.connectionDragState = null;
        
        this.initializeEventListeners();
        this.updateView();
    }
    
    initializeEventListeners() {
        // Mouse events for panning and selection
        this.canvas.addEventListener('mousedown', (e) =&gt; this.handleMouseDown(e));
        this.canvas.addEventListener('mousemove', (e) =&gt; this.handleMouseMove(e));
        this.canvas.addEventListener('mouseup', (e) =&gt; this.handleMouseUp(e));
        this.canvas.addEventListener('wheel', (e) =&gt; this.handleWheel(e));
        
        // Drag and drop for components
        this.canvas.addEventListener('dragover', (e) =&gt; e.preventDefault());
        this.canvas.addEventListener('drop', (e) =&gt; this.handleDrop(e));
        
        // Keyboard events
        document.addEventListener('keydown', (e) =&gt; this.handleKeyDown(e));
    }
    
    setGraph(graph) {
        this.graph = graph;
        this.updateView();
    }
    
    updateView() {
        this.clearView();
        this.renderConnections();
        this.renderNodes();
    }
    
    clearView() {
        this.nodesLayer.innerHTML = '';
        this.connectionsLayer.innerHTML = '';
        this.nodes.clear();
        this.connections.clear();
    }
    
    renderNodes() {
        const graphNodes = this.graph.getNodes();
        
        graphNodes.forEach(nodeData =&gt; {
            const node = new Node(nodeData, this);
            this.nodes.set(nodeData.id, node);
            this.nodesLayer.appendChild(node.element);
        });
    }
    
    renderConnections() {
        const graphConnections = this.graph.getConnections();
        
        graphConnections.forEach(connectionData =&gt; {
            const connection = new Connection(connectionData, this);
            this.connections.set(connection.id, connection);
            this.connectionsLayer.appendChild(connection.element);
        });
    }
    
    addNode(componentType, position) {
        const nodeId = `node_${Date.now()}`;
        const nodeData = {
            id: nodeId,
            component: componentType.component,
            metadata: {
                x: position.x,
                y: position.y,
                label: componentType.name,
                ...componentType.defaultProperties
            }
        };
        
        this.graph.addNode(nodeId, componentType.component, nodeData.metadata);
        
        const node = new Node(nodeData, this);
        this.nodes.set(nodeId, node);
        this.nodesLayer.appendChild(node.element);
        
        this.emit('nodeAdded', nodeData);
        return node;
    }
    
    removeNode(nodeId) {
        const node = this.nodes.get(nodeId);
        if (node) {
            // Remove all connections to this node
            const connections = this.graph.getConnections()
                .filter(conn =&gt; conn.fromNode === nodeId || conn.toNode === nodeId);
            
            connections.forEach(conn =&gt; this.removeConnection(conn.id));
            
            // Remove node from graph
            this.graph.removeNode(nodeId);
            
            // Remove from UI
            node.element.remove();
            this.nodes.delete(nodeId);
            
            this.emit('nodeRemoved', { id: nodeId });
        }
    }
    
    addConnection(fromNode, fromPort, toNode, toPort) {
        try {
            const connectionId = this.graph.addConnection(fromNode, fromPort, toNode, toPort, {});
            
            const connectionData = {
                id: connectionId,
                fromNode,
                fromPort,
                toNode,
                toPort
            };
            
            const connection = new Connection(connectionData, this);
            this.connections.set(connectionId, connection);
            this.connectionsLayer.appendChild(connection.element);
            
            this.emit('connectionAdded', connectionData);
            return connection;
        } catch (error) {
            console.error('Failed to create connection:', error);
            throw error;
        }
    }
    
    removeConnection(connectionId) {
        const connection = this.connections.get(connectionId);
        if (connection) {
            this.graph.removeConnection(connectionId);
            connection.element.remove();
            this.connections.delete(connectionId);
            
            this.emit('connectionRemoved', { id: connectionId });
        }
    }
    
    getNodePosition(nodeId) {
        const node = this.nodes.get(nodeId);
        return node ? node.getPosition() : null;
    }
    
    updateNodePosition(nodeId, position) {
        const node = this.nodes.get(nodeId);
        if (node) {
            node.setPosition(position);
            this.updateConnectionsForNode(nodeId);
        }
    }
    
    updateConnectionsForNode(nodeId) {
        this.connections.forEach(connection =&gt; {
            if (connection.fromNode === nodeId || connection.toNode === nodeId) {
                connection.updatePath();
            }
        });
    }
    
    handleMouseDown(e) {
        if (e.target === this.canvas) {
            this.startPanning(e);
        }
    }
    
    handleMouseMove(e) {
        if (this.dragState?.type === 'pan') {
            this.updatePanning(e);
        } else if (this.connectionDragState) {
            this.updateConnectionDrag(e);
        }
    }
    
    handleMouseUp(e) {
        if (this.dragState?.type === 'pan') {
            this.endPanning();
        } else if (this.connectionDragState) {
            this.endConnectionDrag(e);
        }
    }
    
    handleWheel(e) {
        e.preventDefault();
        const delta = e.deltaY &gt; 0 ? 0.9 : 1.1;
        this.zoom(delta, { x: e.clientX, y: e.clientY });
    }
    
    handleDrop(e) {
        e.preventDefault();
        const componentData = JSON.parse(e.dataTransfer.getData('component'));
        const rect = this.canvas.getBoundingClientRect();
        const position = this.screenToWorld({
            x: e.clientX - rect.left,
            y: e.clientY - rect.top
        });
        
        this.addNode(componentData, position);
    }
    
    handleKeyDown(e) {
        if (e.key === 'Delete' &amp;&amp; this.selectedNode) {
            this.removeNode(this.selectedNode.id);
        }
    }
    
    startPanning(e) {
        this.dragState = {
            type: 'pan',
            startX: e.clientX,
            startY: e.clientY,
            initialPanX: this.panX,
            initialPanY: this.panY
        };
    }
    
    updatePanning(e) {
        if (this.dragState?.type === 'pan') {
            const dx = e.clientX - this.dragState.startX;
            const dy = e.clientY - this.dragState.startY;
            
            this.panX = this.dragState.initialPanX + dx;
            this.panY = this.dragState.initialPanY + dy;
            
            this.updateTransform();
        }
    }
    
    endPanning() {
        this.dragState = null;
    }
    
    startConnectionDrag(fromNode, fromPort, startPosition) {
        this.connectionDragState = {
            fromNode,
            fromPort,
            startPosition,
            currentPosition: startPosition
        };
        
        // Create temporary connection line
        this.createTempConnectionLine();
    }
    
    updateConnectionDrag(e) {
        if (this.connectionDragState) {
            const rect = this.canvas.getBoundingClientRect();
            this.connectionDragState.currentPosition = {
                x: e.clientX - rect.left,
                y: e.clientY - rect.top
            };
            
            this.updateTempConnectionLine();
        }
    }
    
    endConnectionDrag(e) {
        if (this.connectionDragState) {
            // Find target node and port
            const target = this.findConnectionTarget(e);
            
            if (target) {
                try {
                    this.addConnection(
                        this.connectionDragState.fromNode,
                        this.connectionDragState.fromPort,
                        target.nodeId,
                        target.portName
                    );
                } catch (error) {
                    console.error('Connection failed:', error);
                }
            }
            
            this.removeTempConnectionLine();
            this.connectionDragState = null;
        }
    }
    
    zoom(factor, center) {
        const newScale = Math.max(0.1, Math.min(3, this.scale * factor));
        
        if (center) {
            const worldCenter = this.screenToWorld(center);
            this.scale = newScale;
            const newScreenCenter = this.worldToScreen(worldCenter);
            
            this.panX += center.x - newScreenCenter.x;
            this.panY += center.y - newScreenCenter.y;
        } else {
            this.scale = newScale;
        }
        
        this.updateTransform();
        this.updateZoomDisplay();
    }
    
    zoomIn() {
        this.zoom(1.2);
    }
    
    zoomOut() {
        this.zoom(0.8);
    }
    
    zoomToFit() {
        if (this.nodes.size === 0) return;
        
        // Calculate bounding box of all nodes
        let minX = Infinity, minY = Infinity;
        let maxX = -Infinity, maxY = -Infinity;
        
        this.nodes.forEach(node =&gt; {
            const pos = node.getPosition();
            minX = Math.min(minX, pos.x);
            minY = Math.min(minY, pos.y);
            maxX = Math.max(maxX, pos.x + 120); // Node width
            maxY = Math.max(maxY, pos.y + 80);  // Node height
        });
        
        const padding = 50;
        const contentWidth = maxX - minX + 2 * padding;
        const contentHeight = maxY - minY + 2 * padding;
        
        const canvasRect = this.canvas.getBoundingClientRect();
        const scaleX = canvasRect.width / contentWidth;
        const scaleY = canvasRect.height / contentHeight;
        
        this.scale = Math.min(scaleX, scaleY, 1);
        this.panX = (canvasRect.width - contentWidth * this.scale) / 2 - (minX - padding) * this.scale;
        this.panY = (canvasRect.height - contentHeight * this.scale) / 2 - (minY - padding) * this.scale;
        
        this.updateTransform();
        this.updateZoomDisplay();
    }
    
    updateTransform() {
        const transform = `translate(${this.panX}px, ${this.panY}px) scale(${this.scale})`;
        this.nodesLayer.style.transform = transform;
        this.connectionsLayer.style.transform = transform;
    }
    
    updateZoomDisplay() {
        const zoomPercent = Math.round(this.scale * 100);
        document.getElementById('zoom-level').textContent = `${zoomPercent}%`;
    }
    
    screenToWorld(screenPos) {
        return {
            x: (screenPos.x - this.panX) / this.scale,
            y: (screenPos.y - this.panY) / this.scale
        };
    }
    
    worldToScreen(worldPos) {
        return {
            x: worldPos.x * this.scale + this.panX,
            y: worldPos.y * this.scale + this.panY
        };
    }
    
    // Additional methods for animations, validation display, etc.
    animateToPositions
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="building-a-reactflow-editor-with-reflow-engine-in-a-web-worker"><a class="header" href="#building-a-reactflow-editor-with-reflow-engine-in-a-web-worker">Building a ReactFlow Editor with Reflow Engine in a Web Worker</a></h1>
<p>This tutorial demonstrates how to build a modern visual workflow editor using <strong>ReactFlow</strong> for the user interface and <strong>Reflow engine</strong> running in a Web Worker for graph execution and state management.</p>
<h2 id="table-of-contents"><a class="header" href="#table-of-contents">Table of Contents</a></h2>
<ol>
<li><a href="tutorials/reactflow-reflow-integration.html#architecture-overview">Architecture Overview</a></li>
<li><a href="tutorials/reactflow-reflow-integration.html#project-setup">Project Setup</a></li>
<li><a href="tutorials/reactflow-reflow-integration.html#worker-integration">Worker Integration</a></li>
<li><a href="tutorials/reactflow-reflow-integration.html#reactflow-integration">ReactFlow Integration</a></li>
<li><a href="tutorials/reactflow-reflow-integration.html#custom-node-components">Custom Node Components</a></li>
<li><a href="tutorials/reactflow-reflow-integration.html#real-time-communication">Real-time Communication</a></li>
<li><a href="tutorials/reactflow-reflow-integration.html#advanced-features">Advanced Features</a></li>
<li><a href="tutorials/reactflow-reflow-integration.html#complete-example">Complete Example</a></li>
<li><a href="tutorials/reactflow-reflow-integration.html#performance-optimization">Performance Optimization</a></li>
</ol>
<h2 id="architecture-overview-3"><a class="header" href="#architecture-overview-3">Architecture Overview</a></h2>
<p>Our architecture separates concerns between the UI layer (ReactFlow) and the execution engine (Reflow WebAssembly):</p>
<pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    React Application                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ   ReactFlow     ‚îÇ  ‚îÇ  Component      ‚îÇ  ‚îÇ   Execution     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     Editor      ‚îÇ  ‚îÇ    Palette      ‚îÇ  ‚îÇ    Controls     ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ            ‚îÇ                    ‚îÇ                    ‚îÇ         ‚îÇ
‚îÇ            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ                                 ‚îÇ                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ PostMessage API
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Web Worker                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Reflow WebAssm  ‚îÇ  ‚îÇ  Graph State    ‚îÇ  ‚îÇ   Persistence   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     Engine      ‚îÇ  ‚îÇ   Management    ‚îÇ  ‚îÇ   (IndexedDB)   ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre>
<p><strong>Benefits:</strong></p>
<ul>
<li><strong>Performance</strong>: Heavy graph operations don't block the UI thread</li>
<li><strong>Scalability</strong>: Can handle large, complex workflows</li>
<li><strong>Persistence</strong>: Graph state maintained separately from UI state</li>
<li><strong>Modularity</strong>: Clear separation between presentation and logic</li>
</ul>
<h2 id="project-setup-1"><a class="header" href="#project-setup-1">Project Setup</a></h2>
<h3 id="prerequisites-5"><a class="header" href="#prerequisites-5">Prerequisites</a></h3>
<ul>
<li>Node.js 18+ and npm/yarn</li>
<li>Rust toolchain with <code>wasm-pack</code> installed</li>
<li>Basic knowledge of React and TypeScript</li>
</ul>
<h3 id="1-initialize-react-project"><a class="header" href="#1-initialize-react-project">1. Initialize React Project</a></h3>
<pre><code class="language-bash"># Create new React TypeScript project
npm create react-app@latest reflow-editor --template typescript
cd reflow-editor

# Install ReactFlow and dependencies
npm install reactflow
npm install @types/web
</code></pre>
<h3 id="2-install-reflow-webassembly-package"><a class="header" href="#2-install-reflow-webassembly-package">2. Install Reflow WebAssembly Package</a></h3>
<pre><code class="language-bash"># Build the Reflow WebAssembly package (from Reflow repo root)
cd crates/reflow_network
wasm-pack build --target web --out-dir pkg

# Copy the generated package to your React project
cp -r pkg/ /path/to/reflow-editor/src/reflow-wasm/
</code></pre>
<h3 id="3-project-structure-1"><a class="header" href="#3-project-structure-1">3. Project Structure</a></h3>
<pre><code>reflow-editor/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Editor/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ReactFlowEditor.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CustomNodes/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ CustomEdges/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Palette/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ComponentPalette.tsx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Controls/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ ExecutionControls.tsx
‚îÇ   ‚îú‚îÄ‚îÄ workers/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ reflow-worker.ts
‚îÇ   ‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useReflowWorker.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ useGraphSync.ts
‚îÇ   ‚îú‚îÄ‚îÄ types/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ reflow.ts
‚îÇ   ‚îú‚îÄ‚îÄ reflow-wasm/          # Copied from Reflow build
‚îÇ   ‚îî‚îÄ‚îÄ App.tsx
</code></pre>
<h2 id="worker-integration"><a class="header" href="#worker-integration">Worker Integration</a></h2>
<h3 id="1-create-the-reflow-worker"><a class="header" href="#1-create-the-reflow-worker">1. Create the Reflow Worker</a></h3>
<p>First, let's create the Web Worker that manages the Reflow engine:</p>
<pre><code class="language-typescript">// src/workers/reflow-worker.ts
import { Graph, GraphHistory, StorageManager, initSync } from '../reflow-wasm/reflow_network.js';

// Worker state
let graph: Graph | null = null;
let history: GraphHistory | null = null;
let storage: StorageManager | null = null;

// Message types for type safety
export interface WorkerMessage {
  type: 'INIT' | 'ADD_NODE' | 'ADD_EDGE' | 'UPDATE_NODE' | 'ADD_GROUP' | 'EXECUTE';
  payload?: any;
}

export interface WorkerResponse {
  type: 'READY' | 'GRAPH_LOADED' | 'NODE_ADDED' | 'EDGE_ADDED' | 'ERROR';
  payload?: any;
}

// Initialize WebAssembly
fetch('/reflow_network_bg.wasm').then(async (res) =&gt; {
  initSync(await res.arrayBuffer());
  self.postMessage({ type: 'READY' } as WorkerResponse);
});

// Auto-save functionality
let saveTimeout: NodeJS.Timeout;
const autoSave = () =&gt; {
  if (saveTimeout) clearTimeout(saveTimeout);
  saveTimeout = setTimeout(() =&gt; saveGraphState(), 1000);
};

// Message handler
self.addEventListener('message', async (event: MessageEvent&lt;WorkerMessage&gt;) =&gt; {
  const { type, payload } = event.data;

  try {
    switch (type) {
      case 'INIT':
        await initializeGraph(payload.name);
        break;

      case 'ADD_NODE':
        if (!graph) throw new Error('Graph not initialized');
        addNode(payload);
        break;

      case 'ADD_EDGE':
        if (!graph) throw new Error('Graph not initialized');
        addEdge(payload);
        break;

      case 'UPDATE_NODE':
        if (!graph) throw new Error('Graph not initialized');
        updateNode(payload);
        break;

      case 'ADD_GROUP':
        if (!graph) throw new Error('Graph not initialized');
        addGroup(payload);
        break;

      case 'EXECUTE':
        if (!graph) throw new Error('Graph not initialized');
        executeGraph();
        break;

      default:
        console.warn('Unknown message type:', type);
    }
  } catch (error) {
    self.postMessage({
      type: 'ERROR',
      payload: { message: error.message }
    } as WorkerResponse);
  }
});

// Initialize graph with persistence
async function initializeGraph(name: string) {
  [graph, history] = Graph.withHistory();
  storage = GraphHistory.createStorageManager(name, 'history');
  
  await storage.initDatabase();

  // Load existing state
  try {
    const snapshot = await storage.loadFromIndexedDB('latest');
    if (snapshot) {
      history = GraphHistory.loadFromSnapshot(snapshot, graph);
    }
  } catch (error) {
    console.warn('No previous state found:', error);
  }

  // Subscribe to graph events
  graph.subscribe((graphEvent) =&gt; {
    self.postMessage({
      type: 'GRAPH_EVENT',
      payload: graphEvent
    } as WorkerResponse);
  });

  self.postMessage({
    type: 'GRAPH_LOADED',
    payload: { graph: graph.toJSON() }
  } as WorkerResponse);
}

// Graph operation functions
function addNode(nodeData: any) {
  if (!graph || !history) return;

  graph.addNode(nodeData.id, nodeData.process, nodeData.metadata);
  history.processEvents(graph);
  autoSave();

  self.postMessage({
    type: 'NODE_ADDED',
    payload: nodeData
  } as WorkerResponse);
}

function addEdge(edgeData: any) {
  if (!graph || !history) return;

  const { from, to } = edgeData;
  
  // Add ports if they don't exist
  graph.addOutport(from.port.id, from.actor, from.port.name, true, from.port.metadata);
  graph.addInport(to.port.id, to.actor, to.port.name, true, to.port.metadata);
  
  // Add connection
  graph.addConnection(from.actor, from.port.id, to.actor, to.port.id, edgeData.metadata);
  
  history.processEvents(graph);
  autoSave();

  self.postMessage({
    type: 'EDGE_ADDED',
    payload: edgeData
  } as WorkerResponse);
}

function updateNode(nodeData: any) {
  if (!graph || !history) return;

  graph.setNodeMetadata(nodeData.id, nodeData.metadata);
  history.processEvents(graph);
  autoSave();
}

function addGroup(groupData: any) {
  if (!graph || !history) return;

  graph.addGroup(groupData.id, groupData.nodes, groupData.metadata);
  history.processEvents(graph);
  autoSave();
}

function executeGraph() {
  if (!graph) return;
  
  // Implement graph execution logic here
  console.log('Executing graph:', graph.toJSON());
}

// Save graph state
async function saveGraphState() {
  if (!graph || !history || !storage) return;

  try {
    await storage.saveToIndexedDB('latest', graph, history);
  } catch (error) {
    console.warn('Failed to save to IndexedDB:', error);
    try {
      storage.saveToLocalStorage('latest', graph, history);
    } catch (storageError) {
      console.error('Failed to save state:', storageError);
    }
  }
}
</code></pre>
<h3 id="2-create-worker-hook"><a class="header" href="#2-create-worker-hook">2. Create Worker Hook</a></h3>
<p>Create a React hook to manage the worker communication:</p>
<pre><code class="language-typescript">// src/hooks/useReflowWorker.ts
import { useEffect, useRef, useCallback, useState } from 'react';
import type { WorkerMessage, WorkerResponse } from '../workers/reflow-worker';

export interface ReflowWorkerHook {
  isReady: boolean;
  sendMessage: (message: WorkerMessage) =&gt; void;
  addEventListener: (listener: (event: WorkerResponse) =&gt; void) =&gt; void;
  removeEventListener: (listener: (event: WorkerResponse) =&gt; void) =&gt; void;
}

export function useReflowWorker(): ReflowWorkerHook {
  const workerRef = useRef&lt;Worker | null&gt;(null);
  const [isReady, setIsReady] = useState(false);
  const listenersRef = useRef&lt;Set&lt;(event: WorkerResponse) =&gt; void&gt;&gt;(new Set());

  useEffect(() =&gt; {
    // Create worker
    workerRef.current = new Worker('/src/workers/reflow-worker.ts', {
      type: 'module'
    });

    // Handle worker messages
    const handleMessage = (event: MessageEvent&lt;WorkerResponse&gt;) =&gt; {
      const message = event.data;
      
      if (message.type === 'READY') {
        setIsReady(true);
      }

      // Notify all listeners
      listenersRef.current.forEach(listener =&gt; listener(message));
    };

    workerRef.current.addEventListener('message', handleMessage);

    return () =&gt; {
      workerRef.current?.terminate();
    };
  }, []);

  const sendMessage = useCallback((message: WorkerMessage) =&gt; {
    if (workerRef.current &amp;&amp; isReady) {
      workerRef.current.postMessage(message);
    }
  }, [isReady]);

  const addEventListener = useCallback((listener: (event: WorkerResponse) =&gt; void) =&gt; {
    listenersRef.current.add(listener);
  }, []);

  const removeEventListener = useCallback((listener: (event: WorkerResponse) =&gt; void) =&gt; {
    listenersRef.current.delete(listener);
  }, []);

  return {
    isReady,
    sendMessage,
    addEventListener,
    removeEventListener
  };
}
</code></pre>
<h2 id="reactflow-integration"><a class="header" href="#reactflow-integration">ReactFlow Integration</a></h2>
<h3 id="1-main-editor-component"><a class="header" href="#1-main-editor-component">1. Main Editor Component</a></h3>
<pre><code class="language-typescript">// src/components/Editor/ReactFlowEditor.tsx
import React, { useCallback, useEffect, useState } from 'react';
import ReactFlow, {
  Node,
  Edge,
  addEdge,
  useNodesState,
  useEdgesState,
  Connection,
  ReactFlowProvider,
  Controls,
  Background,
  Panel,
} from 'reactflow';

import 'reactflow/dist/style.css';

import { useReflowWorker } from '../../hooks/useReflowWorker';
import { useGraphSync } from '../../hooks/useGraphSync';
import { ReflowNode } from './CustomNodes/ReflowNode';
import { ComponentPalette } from '../Palette/ComponentPalette';
import { ExecutionControls } from '../Controls/ExecutionControls';

// Custom node types
const nodeTypes = {
  reflow: ReflowNode,
};

export function ReactFlowEditor() {
  const [nodes, setNodes, onNodesChange] = useNodesState([]);
  const [edges, setEdges, onEdgesChange] = useEdgesState([]);
  const worker = useReflowWorker();

  // Sync ReactFlow state with Reflow worker
  const { syncToWorker, syncFromWorker } = useGraphSync(worker, setNodes, setEdges);

  useEffect(() =&gt; {
    if (worker.isReady) {
      // Initialize the graph in the worker
      worker.sendMessage({
        type: 'INIT',
        payload: { name: 'ReactFlow Graph' }
      });
    }
  }, [worker.isReady]);

  const onConnect = useCallback(
    (params: Edge | Connection) =&gt; {
      // Update ReactFlow state
      setEdges((eds) =&gt; addEdge(params, eds));
      
      // Sync to worker
      syncToWorker.addEdge({
        from: {
          actor: params.source,
          port: {
            id: `${params.source}-${params.sourceHandle}`,
            name: params.sourceHandle || 'output',
          }
        },
        to: {
          actor: params.target,
          port: {
            id: `${params.target}-${params.targetHandle}`,
            name: params.targetHandle || 'input',
          }
        }
      });
    },
    [setEdges, syncToWorker]
  );

  const onDrop = useCallback(
    (event: React.DragEvent) =&gt; {
      event.preventDefault();

      const reactFlowBounds = event.currentTarget.getBoundingClientRect();
      const type = event.dataTransfer.getData('application/reactflow');
      const position = {
        x: event.clientX - reactFlowBounds.left,
        y: event.clientY - reactFlowBounds.top,
      };

      const newNode: Node = {
        id: `${type}-${Date.now()}`,
        type: 'reflow',
        position,
        data: {
          label: type,
          process: type,
          inports: getDefaultInports(type),
          outports: getDefaultOutports(type),
        },
      };

      // Update ReactFlow state
      setNodes((nds) =&gt; nds.concat(newNode));
      
      // Sync to worker
      syncToWorker.addNode({
        id: newNode.id,
        process: type,
        metadata: {
          position,
          name: type,
          inports: newNode.data.inports,
          outports: newNode.data.outports,
        }
      });
    },
    [setNodes, syncToWorker]
  );

  const onDragOver = useCallback((event: React.DragEvent) =&gt; {
    event.preventDefault();
    event.dataTransfer.dropEffect = 'move';
  }, []);

  return (
    &lt;div style={{ width: '100vw', height: '100vh', display: 'flex' }}&gt;
      {/* Component Palette */}
      &lt;ComponentPalette /&gt;
      
      {/* Main ReactFlow Editor */}
      &lt;div style={{ flex: 1 }} onDrop={onDrop} onDragOver={onDragOver}&gt;
        &lt;ReactFlow
          nodes={nodes}
          edges={edges}
          onNodesChange={onNodesChange}
          onEdgesChange={onEdgesChange}
          onConnect={onConnect}
          nodeTypes={nodeTypes}
          fitView
        &gt;
          &lt;Controls /&gt;
          &lt;Background /&gt;
          
          {/* Execution Controls Panel */}
          &lt;Panel position="top-right"&gt;
            &lt;ExecutionControls 
              onExecute={() =&gt; worker.sendMessage({ type: 'EXECUTE' })}
              isReady={worker.isReady}
            /&gt;
          &lt;/Panel&gt;
        &lt;/ReactFlow&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  );
}

// Helper functions for default port configurations
function getDefaultInports(nodeType: string) {
  const configs = {
    'DataSource': [],
    'MapActor': [{ id: 'input', name: 'input', trait: 'data' }],
    'Logger': [{ id: 'input', name: 'input', trait: 'data' }],
    'FilterActor': [{ id: 'input', name: 'input', trait: 'data' }],
  };
  return configs[nodeType] || [{ id: 'input', name: 'input', trait: 'data' }];
}

function getDefaultOutports(nodeType: string) {
  const configs = {
    'DataSource': [{ id: 'output', name: 'output', trait: 'data' }],
    'MapActor': [{ id: 'output', name: 'output', trait: 'data' }],
    'Logger': [],
    'FilterActor': [{ id: 'output', name: 'output', trait: 'data' }],
  };
  return configs[nodeType] || [{ id: 'output', name: 'output', trait: 'data' }];
}
</code></pre>
<h2 id="custom-node-components"><a class="header" href="#custom-node-components">Custom Node Components</a></h2>
<h3 id="1-reflow-node-component"><a class="header" href="#1-reflow-node-component">1. Reflow Node Component</a></h3>
<pre><code class="language-typescript">// src/components/Editor/CustomNodes/ReflowNode.tsx
import React, { memo } from 'react';
import { Handle, Position } from 'reactflow';

interface ReflowNodeData {
  label: string;
  process: string;
  inports: Array&lt;{ id: string; name: string; trait: string }&gt;;
  outports: Array&lt;{ id: string; name: string; trait: string }&gt;;
}

interface ReflowNodeProps {
  data: ReflowNodeData;
  isConnectable: boolean;
}

export const ReflowNode = memo(({ data, isConnectable }: ReflowNodeProps) =&gt; {
  return (
    &lt;div className="reflow-node"&gt;
      {/* Input Handles */}
      {data.inports.map((port, index) =&gt; (
        &lt;Handle
          key={port.id}
          type="target"
          position={Position.Left}
          id={port.id}
          isConnectable={isConnectable}
          style={{
            top: `${20 + (index * 25)}px`,
            background: getPortColor(port.trait),
          }}
        /&gt;
      ))}

      {/* Node Content */}
      &lt;div className="node-content"&gt;
        &lt;div className="node-header"&gt;
          &lt;strong&gt;{data.label}&lt;/strong&gt;
        &lt;/div&gt;
        &lt;div className="node-type"&gt;
          {data.process}
        &lt;/div&gt;
        
        {/* Port Labels */}
        &lt;div className="port-labels"&gt;
          &lt;div className="input-labels"&gt;
            {data.inports.map((port) =&gt; (
              &lt;div key={port.id} className="port-label"&gt;
                {port.name}
              &lt;/div&gt;
            ))}
          &lt;/div&gt;
          &lt;div className="output-labels"&gt;
            {data.outports.map((port) =&gt; (
              &lt;div key={port.id} className="port-label"&gt;
                {port.name}
              &lt;/div&gt;
            ))}
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;

      {/* Output Handles */}
      {data.outports.map((port, index) =&gt; (
        &lt;Handle
          key={port.id}
          type="source"
          position={Position.Right}
          id={port.id}
          isConnectable={isConnectable}
          style={{
            top: `${20 + (index * 25)}px`,
            background: getPortColor(port.trait),
          }}
        /&gt;
      ))}
    &lt;/div&gt;
  );
});

// Utility function for port colors
function getPortColor(trait: string): string {
  const colors = {
    data: '#3b82f6',      // Blue for data
    control: '#ef4444',   // Red for control
    event: '#10b981',     // Green for events
    config: '#f59e0b',    // Yellow for configuration
  };
  return colors[trait] || '#6b7280'; // Gray as default
}
</code></pre>
<h3 id="2-node-styles"><a class="header" href="#2-node-styles">2. Node Styles</a></h3>
<pre><code class="language-css">/* src/components/Editor/CustomNodes/ReflowNode.css */
.reflow-node {
  background: #ffffff;
  border: 2px solid #e5e7eb;
  border-radius: 8px;
  padding: 10px;
  min-width: 150px;
  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
  position: relative;
}

.reflow-node:hover {
  border-color: #3b82f6;
}

.node-content {
  display: flex;
  flex-direction: column;
  gap: 8px;
}

.node-header {
  font-size: 14px;
  font-weight: bold;
  color: #1f2937;
}

.node-type {
  font-size: 12px;
  color: #6b7280;
  font-style: italic;
}

.port-labels {
  display: flex;
  justify-content: space-between;
  font-size: 10px;
  color: #9ca3af;
}

.input-labels,
.output-labels {
  display: flex;
  flex-direction: column;
  gap: 4px;
}

.port-label {
  line-height: 1.2;
}

/* ReactFlow handle overrides */
.react-flow__handle {
  width: 8px;
  height: 8px;
  border: 2px solid #ffffff;
}

.react-flow__handle-left {
  left: -6px;
}

.react-flow__handle-right {
  right: -6px;
}
</code></pre>
<h2 id="real-time-communication"><a class="header" href="#real-time-communication">Real-time Communication</a></h2>
<h3 id="1-graph-synchronization-hook"><a class="header" href="#1-graph-synchronization-hook">1. Graph Synchronization Hook</a></h3>
<pre><code class="language-typescript">// src/hooks/useGraphSync.ts
import { useCallback, useEffect } from 'react';
import { Node, Edge } from 'reactflow';
import type { ReflowWorkerHook } from './useReflowWorker';

export function useGraphSync(
  worker: ReflowWorkerHook,
  setNodes: React.Dispatch&lt;React.SetStateAction&lt;Node[]&gt;&gt;,
  setEdges: React.Dispatch&lt;React.SetStateAction&lt;Edge[]&gt;&gt;
) {
  
  // Listen to worker events and sync to ReactFlow
  useEffect(() =&gt; {
    const handleWorkerMessage = (message: any) =&gt; {
      switch (message.type) {
        case 'GRAPH_LOADED':
          syncGraphFromWorker(message.payload.graph);
          break;
          
        case 'NODE_ADDED':
          // Handle real-time node additions from other sources
          break;
          
        case 'EDGE_ADDED':
          // Handle real-time edge additions from other sources
          break;
          
        case 'GRAPH_EVENT':
          // Handle live graph execution events
          console.log('Graph event:', message.payload);
          break;
      }
    };

    worker.addEventListener(handleWorkerMessage);
    
    return () =&gt; {
      worker.removeEventListener(handleWorkerMessage);
    };
  }, [worker]);

  // Convert Reflow graph to ReactFlow format
  const syncGraphFromWorker = useCallback((reflowGraph: any) =&gt; {
    const reactFlowNodes: Node[] = [];
    const reactFlowEdges: Edge[] = [];

    // Convert Reflow processes to ReactFlow nodes
    if (reflowGraph.processes) {
      Array.from(reflowGraph.processes.values()).forEach((process: any) =&gt; {
        const metadata = Object.fromEntries(process.metadata);
        const position = Object.fromEntries(metadata.position || new Map());
        
        reactFlowNodes.push({
          id: process.id,
          type: 'reflow',
          position: position,
          data: {
            label: metadata.name || process.component,
            process: process.component,
            inports: metadata.inports || [],
            outports: metadata.outports || [],
          },
        });
      });
    }

    // Convert Reflow connections to ReactFlow edges
    if (reflowGraph.connections) {
      reflowGraph.connections.forEach((connection: any) =&gt; {
        reactFlowEdges.push({
          id: `${connection.from.node_id}-${connection.from.port_name}-to-${connection.to.node_id}-${connection.to.port_name}`,
          source: connection.from.node_id,
          target: connection.to.node_id,
          sourceHandle: connection.from.port_name,
          targetHandle: connection.to.port_name,
        });
      });
    }

    setNodes(reactFlowNodes);
    setEdges(reactFlowEdges);
  }, [setNodes, setEdges]);

  // Functions to sync ReactFlow changes to worker
  const syncToWorker = {
    addNode: useCallback((nodeData: any) =&gt; {
      worker.sendMessage({
        type: 'ADD_NODE',
        payload: nodeData
      });
    }, [worker]),

    addEdge: useCallback((edgeData: any) =&gt; {
      worker.sendMessage({
        type: 'ADD_EDGE',
        payload: edgeData
      });
    }, [worker]),

    updateNode: useCallback((nodeData: any) =&gt; {
      worker.sendMessage({
        type: 'UPDATE_NODE',
        payload: nodeData
      });
    }, [worker]),
  };

  return {
    syncToWorker,
    syncFromWorker: syncGraphFromWorker,
  };
}
</code></pre>
<h2 id="advanced-features-5"><a class="header" href="#advanced-features-5">Advanced Features</a></h2>
<h3 id="1-component-palette"><a class="header" href="#1-component-palette">1. Component Palette</a></h3>
<pre><code class="language-typescript">// src/components/Palette/ComponentPalette.tsx
import React from 'react';

const COMPONENT_CATEGORIES = {
  'Data Sources': [
    { type: 'DataSource', label: 'Data Source', description: 'Generate or load data' },
    { type: 'FileReader', label: 'File Reader', description: 'Read files from disk' },
    { type: 'APISource', label: 'API Source', description: 'Fetch data from REST APIs' },
  ],
  'Processors': [
    { type: 'MapActor', label: 'Map', description: 'Transform data elements' },
    { type: 'FilterActor', label: 'Filter', description: 'Filter data elements' },
    { type: 'ReduceActor', label: 'Reduce', description: 'Aggregate data' },
    { type: 'SortActor', label: 'Sort', description: 'Sort data elements' },
  ],
  'Outputs': [
    { type: 'Logger', label: 'Logger', description: 'Log data to console' },
    { type: 'FileWriter', label: 'File Writer', description: 'Write data to file' },
    { type: 'ChartDisplay', label: 'Chart Display', description: 'Visualize data' },
  ],
};

export function ComponentPalette() {
  const onDragStart = (event: React.DragEvent, nodeType: string) =&gt; {
    event.dataTransfer.setData('application/reactflow', nodeType);
    event.dataTransfer.effectAllowed = 'move';
  };

  return (
    &lt;div className="component-palette"&gt;
      &lt;div className="palette-header"&gt;
        &lt;h3&gt;Components&lt;/h3&gt;
      &lt;/div&gt;
      
      &lt;div className="palette-content"&gt;
        {Object.entries(COMPONENT_CATEGORIES).map(([category, components]) =&gt; (
          &lt;div key={category} className="component-category"&gt;
            &lt;h4&gt;{category}&lt;/h4&gt;
            &lt;div className="component-list"&gt;
              {components.map((component) =&gt; (
                &lt;div
                  key={component.type}
                  className="component-item"
                  draggable
                  onDragStart={(event) =&gt; onDragStart(event, component.type)}
                &gt;
                  &lt;div className="component-label"&gt;{component.label}&lt;/div&gt;
                  &lt;div className="component-description"&gt;{component.description}&lt;/div&gt;
                &lt;/div&gt;
              ))}
            &lt;/div&gt;
          &lt;/div&gt;
        ))}
      &lt;/div&gt;
    &lt;/div&gt;
  );
}
</code></pre>
<h3 id="2-execution-controls"><a class="header" href="#2-execution-controls">2. Execution Controls</a></h3>
<pre><code class="language-typescript">// src/components/Controls/ExecutionControls.tsx
import React, { useState } from 'react';

interface ExecutionControlsProps {
  onExecute: () =&gt; void;
  isReady: boolean;
}

export function ExecutionControls({ onExecute, isReady }: ExecutionControlsProps) {
  const [isExecuting, setIsExecuting] = useState(false);

  const handleExecute = async () =&gt; {
    setIsExecuting(true);
    try {
      onExecute();
      // You can add execution status monitoring here
      setTimeout(() =&gt; setIsExecuting(false), 2000); // Simulate execution time
    } catch (error) {
      console.error('Execution failed:', error);
      setIsExecuting(false);
    }
  };

  return (
    &lt;div className="execution-controls"&gt;
      &lt;button
        onClick={handleExecute}
        disabled={!isReady || isExecuting}
        className={`execute-button ${isExecuting ? 'executing' : ''}`}
      &gt;
        {isExecuting ? 'Executing...' : 'Execute Workflow'}
      &lt;/button&gt;
      
      &lt;div className="status-indicator"&gt;
        &lt;div className={`status-dot ${isReady ? 'ready' : 'not-ready'}`} /&gt;
        &lt;span&gt;{isReady ? 'Ready' : 'Initializing...'}&lt;/span&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  );
}
</code></pre>
<h2 id="complete-example"><a class="header" href="#complete-example">Complete Example</a></h2>
<h3 id="1-main-app-component"><a class="header" href="#1-main-app-component">1. Main App Component</a></h3>
<pre><code class="language-typescript">// src/App.tsx
import React from 'react';
import { ReactFlowProvider } from 'reactflow';
import { ReactFlowEditor } from './components/Editor/ReactFlowEditor';

import './App.css';

function App() {
  return (
    &lt;div className="App"&gt;
      &lt;ReactFlowProvider&gt;
        &lt;ReactFlowEditor /&gt;
      &lt;/ReactFlowProvider&gt;
    &lt;/div&gt;
  );
}

export default App;
</code></pre>
<h3 id="2-complete-styling"><a class="header" href="#2-complete-styling">2. Complete Styling</a></h3>
<pre><code class="language-css">/* src/App.css */
.App {
  height: 100vh;
  width: 100vw;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
}

/* Component Palette Styles */
.component-palette {
  width: 300px;
  height: 100vh;
  background: #f8f9fa;
  border-right: 1px solid #e9ecef;
  display: flex;
  flex-direction: column;
  overflow-y: auto;
}

.palette-header {
  padding: 16px;
  background: #ffffff;
  border-bottom: 1px solid #e9ecef;
  box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
}

.palette-header h3 {
  margin: 0;
  font-size: 18px;
  font-weight: 600;
  color: #495057;
}

.palette-content {
  flex: 1;
  padding: 16px;
}

.component-category {
  margin-bottom: 24px;
}

.component-category h4 {
  margin: 0 0 12px 0;
  font-size: 14px;
  font-weight: 600;
  color: #6c757d;
  text-transform: uppercase;
  letter-spacing: 0.5px;
}

.component-list {
  display: flex;
  flex-direction: column;
  gap: 8px;
}

.component-item {
  padding: 12px;
  background: #ffffff;
  border: 1px solid #e9ecef;
  border-radius: 8px;
  cursor: grab;
  transition: all 0.2s ease;
  user-select: none;
}

.component-item:hover {
  border-color: #3b82f6;
  box-shadow: 0 2px 8px rgba(59, 130, 246, 0.15);
  transform: translateY(-1px);
}

.component-item:active {
  cursor: grabbing;
  transform: translateY(0);
}

.component-label {
  font-weight: 600;
  color: #212529;
  margin-bottom: 4px;
}

.component-description {
  font-size: 12px;
  color: #6c757d;
  line-height: 1.4;
}

/* Execution Controls Styles */
.execution-controls {
  display: flex;
  flex-direction: column;
  gap: 12px;
  padding: 16px;
  background: #ffffff;
  border: 1px solid #e9ecef;
  border-radius: 8px;
  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
  min-width: 200px;
}

.execute-button {
  padding: 10px 16px;
  background: #10b981;
  color: white;
  border: none;
  border-radius: 6px;
  font-weight: 600;
  cursor: pointer;
  transition: all 0.2s ease;
}

.execute-button:hover:not(:disabled) {
  background: #059669;
  transform: translateY(-1px);
}

.execute-button:disabled {
  background: #9ca3af;
  cursor: not-allowed;
  transform: none;
}

.execute-button.executing {
  background: #f59e0b;
  animation: pulse 2s infinite;
}

@keyframes pulse {
  0%, 100% { opacity: 1; }
  50% { opacity: 0.7; }
}

.status-indicator {
  display: flex;
  align-items: center;
  gap: 8px;
  font-size: 14px;
  color: #6c757d;
}

.status-dot {
  width: 8px;
  height: 8px;
  border-radius: 50%;
  transition: background-color 0.3s ease;
}

.status-dot.ready {
  background: #10b981;
}

.status-dot.not-ready {
  background: #ef4444;
  animation: blink 1s infinite;
}

@keyframes blink {
  0%, 100% { opacity: 1; }
  50% { opacity: 0.3; }
}

/* ReactFlow Customizations */
.react-flow__node.react-flow__node-reflow {
  background: transparent;
  border: none;
}

.react-flow__edge-path {
  stroke: #3b82f6;
  stroke-width: 2;
}

.react-flow__edge:hover .react-flow__edge-path {
  stroke: #1d4ed8;
  stroke-width: 3;
}

.react-flow__controls {
  background: #ffffff;
  border: 1px solid #e9ecef;
  border-radius: 8px;
  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
}

.react-flow__controls button {
  background: #ffffff;
  border: none;
  border-bottom: 1px solid #e9ecef;
}

.react-flow__controls button:hover {
  background: #f8f9fa;
}
</code></pre>
<h3 id="3-typescript-type-definitions"><a class="header" href="#3-typescript-type-definitions">3. TypeScript Type Definitions</a></h3>
<pre><code class="language-typescript">// src/types/reflow.ts
export interface ReflowPort {
  id: string;
  name: string;
  trait: 'data' | 'control' | 'event' | 'config';
  position?: { x: number; y: number };
  metadata?: Record&lt;string, any&gt;;
}

export interface ReflowNodeMetadata {
  position: { x: number; y: number };
  name: string;
  inports: ReflowPort[];
  outports: ReflowPort[];
  [key: string]: any;
}

export interface ReflowConnectionPoint {
  actor: string;
  port: {
    id: string;
    name: string;
    metadata?: Record&lt;string, any&gt;;
  };
}

export interface ReflowConnection {
  from: ReflowConnectionPoint;
  to: ReflowConnectionPoint;
  metadata?: Record&lt;string, any&gt;;
}

export interface ReflowGraphEvent {
  type: 'node_added' | 'edge_added' | 'node_updated' | 'execution_started' | 'execution_completed';
  data: any;
  timestamp: number;
}
</code></pre>
<h3 id="4-packagejson-configuration"><a class="header" href="#4-packagejson-configuration">4. Package.json Configuration</a></h3>
<pre><code class="language-json">{
  "name": "reflow-editor",
  "version": "0.1.0",
  "private": true,
  "dependencies": {
    "@types/react": "^18.2.0",
    "@types/react-dom": "^18.2.0",
    "@types/web": "^0.0.99",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-scripts": "5.0.1",
    "reactflow": "^11.10.0",
    "typescript": "^4.9.0"
  },
  "scripts": {
    "start": "react-scripts start",
    "build": "react-scripts build",
    "test": "react-scripts test",
    "eject": "react-scripts eject"
  },
  "eslintConfig": {
    "extends": [
      "react-app",
      "react-app/jest"
    ]
  },
  "browserslist": {
    "production": [
      "&gt;0.2%",
      "not dead",
      "not op_mini all"
    ],
    "development": [
      "last 1 chrome version",
      "last 1 firefox version",
      "last 1 safari version"
    ]
  }
}
</code></pre>
<h2 id="performance-optimization-9"><a class="header" href="#performance-optimization-9">Performance Optimization</a></h2>
<h3 id="1-memory-management"><a class="header" href="#1-memory-management">1. Memory Management</a></h3>
<pre><code class="language-typescript">// Optimize large graphs with virtualization
import { useCallback, useMemo } from 'react';

function useOptimizedNodes(nodes: Node[], viewport: { x: number; y: number; zoom: number }) {
  const visibleNodes = useMemo(() =&gt; {
    // Only render nodes in viewport to improve performance
    const padding = 200; // Extra padding around viewport
    const viewportBounds = {
      left: -viewport.x - padding,
      top: -viewport.y - padding,
      right: (-viewport.x + window.innerWidth) / viewport.zoom + padding,
      bottom: (-viewport.y + window.innerHeight) / viewport.zoom + padding,
    };

    return nodes.filter(node =&gt; {
      return (
        node.position.x &gt;= viewportBounds.left &amp;&amp;
        node.position.x &lt;= viewportBounds.right &amp;&amp;
        node.position.y &gt;= viewportBounds.top &amp;&amp;
        node.position.y &lt;= viewportBounds.bottom
      );
    });
  }, [nodes, viewport]);

  return visibleNodes;
}
</code></pre>
<h3 id="2-worker-optimization"><a class="header" href="#2-worker-optimization">2. Worker Optimization</a></h3>
<pre><code class="language-typescript">// Batch worker messages to reduce overhead
class WorkerMessageBatcher {
  private batchedMessages: WorkerMessage[] = [];
  private batchTimeout: NodeJS.Timeout | null = null;
  private worker: Worker;

  constructor(worker: Worker) {
    this.worker = worker;
  }

  sendMessage(message: WorkerMessage) {
    this.batchedMessages.push(message);
    
    if (this.batchTimeout) {
      clearTimeout(this.batchTimeout);
    }

    this.batchTimeout = setTimeout(() =&gt; {
      this.flushBatch();
    }, 16); // Batch messages for ~60fps
  }

  private flushBatch() {
    if (this.batchedMessages.length &gt; 0) {
      this.worker.postMessage({
        type: 'BATCH',
        payload: this.batchedMessages
      });
      this.batchedMessages = [];
    }
    this.batchTimeout = null;
  }
}
</code></pre>
<h3 id="3-state-management-optimization"><a class="header" href="#3-state-management-optimization">3. State Management Optimization</a></h3>
<pre><code class="language-typescript">// Use React.memo and useMemo for expensive operations
import { memo, useMemo } from 'react';

export const OptimizedReflowNode = memo(({ data, isConnectable }: ReflowNodeProps) =&gt; {
  const portColors = useMemo(() =&gt; {
    return {
      inports: data.inports.map(port =&gt; getPortColor(port.trait)),
      outports: data.outports.map(port =&gt; getPortColor(port.trait))
    };
  }, [data.inports, data.outports]);

  return (
    &lt;div className="reflow-node"&gt;
      {/* Optimized rendering with memoized colors */}
    &lt;/div&gt;
  );
}, (prevProps, nextProps) =&gt; {
  // Custom comparison for better performance
  return (
    prevProps.data.label === nextProps.data.label &amp;&amp;
    prevProps.data.process === nextProps.data.process &amp;&amp;
    prevProps.isConnectable === nextProps.isConnectable &amp;&amp;
    JSON.stringify(prevProps.data.inports) === JSON.stringify(nextProps.data.inports) &amp;&amp;
    JSON.stringify(prevProps.data.outports) === JSON.stringify(nextProps.data.outports)
  );
});
</code></pre>
<h3 id="4-webassembly-loading-optimization"><a class="header" href="#4-webassembly-loading-optimization">4. WebAssembly Loading Optimization</a></h3>
<pre><code class="language-typescript">// Pre-load and cache WebAssembly modules
class WasmCache {
  private static instance: WasmCache;
  private wasmModule: WebAssembly.Module | null = null;
  private loading: Promise&lt;WebAssembly.Module&gt; | null = null;

  static getInstance() {
    if (!WasmCache.instance) {
      WasmCache.instance = new WasmCache();
    }
    return WasmCache.instance;
  }

  async getModule(): Promise&lt;WebAssembly.Module&gt; {
    if (this.wasmModule) {
      return this.wasmModule;
    }

    if (this.loading) {
      return this.loading;
    }

    this.loading = this.loadModule();
    this.wasmModule = await this.loading;
    return this.wasmModule;
  }

  private async loadModule(): Promise&lt;WebAssembly.Module&gt; {
    const response = await fetch('/reflow_network_bg.wasm');
    const bytes = await response.arrayBuffer();
    return WebAssembly.compile(bytes);
  }
}
</code></pre>
<h2 id="best-practices--tips"><a class="header" href="#best-practices--tips">Best Practices &amp; Tips</a></h2>
<h3 id="1-error-handling"><a class="header" href="#1-error-handling">1. Error Handling</a></h3>
<ul>
<li>Always wrap worker communication in try-catch blocks</li>
<li>Implement proper error boundaries in React components</li>
<li>Provide meaningful error messages to users</li>
<li>Log errors for debugging but don't expose sensitive information</li>
</ul>
<h3 id="2-state-synchronization"><a class="header" href="#2-state-synchronization">2. State Synchronization</a></h3>
<ul>
<li>Keep ReactFlow state as the source of truth for UI</li>
<li>Use the worker for business logic and persistence</li>
<li>Implement debouncing for frequent updates</li>
<li>Handle race conditions in async operations</li>
</ul>
<h3 id="3-performance"><a class="header" href="#3-performance">3. Performance</a></h3>
<ul>
<li>Use React.memo for components that render frequently</li>
<li>Implement virtualization for large graphs (&gt;1000 nodes)</li>
<li>Batch worker messages to reduce overhead</li>
<li>Optimize WebAssembly loading and initialization</li>
</ul>
<h3 id="4-user-experience"><a class="header" href="#4-user-experience">4. User Experience</a></h3>
<ul>
<li>Show loading states during initialization</li>
<li>Provide feedback for long-running operations</li>
<li>Implement undo/redo functionality</li>
<li>Add keyboard shortcuts for common operations</li>
</ul>
<h2 id="conclusion"><a class="header" href="#conclusion">Conclusion</a></h2>
<p>This tutorial demonstrated how to build a modern, high-performance visual workflow editor by combining ReactFlow's excellent UI capabilities with Reflow's powerful WebAssembly engine running in a Web Worker.</p>
<h3 id="key-benefits-achieved"><a class="header" href="#key-benefits-achieved">Key Benefits Achieved</a></h3>
<ul>
<li><strong>Performance</strong>: UI remains responsive during heavy graph operations</li>
<li><strong>Scalability</strong>: Can handle complex workflows with hundreds of nodes</li>
<li><strong>Persistence</strong>: Automatic saving and loading of graph state</li>
<li><strong>Type Safety</strong>: Full TypeScript integration for better development experience</li>
<li><strong>Modularity</strong>: Clean separation between UI and business logic</li>
</ul>
<h3 id="next-steps-30"><a class="header" href="#next-steps-30">Next Steps</a></h3>
<ul>
<li><strong>Custom Components</strong>: Extend the component palette with domain-specific actors</li>
<li><strong>Real-time Collaboration</strong>: Add WebSocket support for multi-user editing</li>
<li><strong>Advanced Debugging</strong>: Implement step-through execution and breakpoints</li>
<li><strong>Plugin System</strong>: Create an extensible architecture for custom functionality</li>
<li><strong>Cloud Integration</strong>: Add support for cloud storage and sharing</li>
</ul>
<p>The architecture presented here provides a solid foundation for building production-ready workflow editors that can scale to enterprise requirements while maintaining excellent user experience.</p>
<p>For more advanced topics and examples, explore the <a href="tutorials/../README.html">main Reflow documentation</a> and the <a href="tutorials/../../examples/audio-flow/">audio-flow example</a> which demonstrates many of these concepts in action.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="performance-optimization-guide"><a class="header" href="#performance-optimization-guide">Performance Optimization Guide</a></h1>
<p>Advanced techniques for optimizing Reflow workflows and applications.</p>
<h2 id="overview-18"><a class="header" href="#overview-18">Overview</a></h2>
<p>This guide covers comprehensive performance optimization strategies for Reflow applications, from basic configuration tweaks to advanced architectural patterns.</p>
<h2 id="performance-analysis-3"><a class="header" href="#performance-analysis-3">Performance Analysis</a></h2>
<h3 id="1-profiling-your-application"><a class="header" href="#1-profiling-your-application">1. Profiling Your Application</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::profiling::{ProfileConfig, Profiler, PerformanceMetrics};
use std::time::Instant;

// Enable comprehensive profiling
let profile_config = ProfileConfig {
    enable_memory_tracking: true,
    enable_cpu_profiling: true,
    enable_network_monitoring: true,
    sample_rate: 1000, // Sample every 1000 operations
    output_format: OutputFormat::Json,
};

let profiler = Profiler::new(profile_config);
profiler.start();

// Run your workflow
let start = Instant::now();
network.execute().await?;
let duration = start.elapsed();

// Collect profiling data
let metrics = profiler.stop_and_collect();
println!("Execution time: {:?}", duration);
println!("Memory peak: {:.2} MB", metrics.peak_memory_mb);
println!("CPU utilization: {:.1}%", metrics.avg_cpu_percent);

// Save detailed report
metrics.save_report("performance_report.json")?;
<span class="boring">}</span></code></pre></pre>
<h3 id="2-benchmarking-workflows"><a class="header" href="#2-benchmarking-workflows">2. Benchmarking Workflows</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use criterion::{black_box, criterion_group, criterion_main, Criterion, BenchmarkId};

fn benchmark_workflow_variants(c: &amp;mut Criterion) {
    let rt = tokio::runtime::Runtime::new().unwrap();
    
    let mut group = c.benchmark_group("workflow_comparison");
    
    // Test different configurations
    for batch_size in [10, 50, 100, 500].iter() {
        group.bench_with_input(
            BenchmarkId::new("batched_workflow", batch_size),
            batch_size,
            |b, &amp;batch_size| {
                b.iter(|| {
                    rt.block_on(async {
                        let network = create_batched_workflow(batch_size).await;
                        black_box(network.execute().await)
                    })
                })
            },
        );
    }
    
    group.finish();
}

criterion_group!(benches, benchmark_workflow_variants);
criterion_main!(benches);
<span class="boring">}</span></code></pre></pre>
<h2 id="memory-optimization-1"><a class="header" href="#memory-optimization-1">Memory Optimization</a></h2>
<h3 id="1-memory-pool-configuration"><a class="header" href="#1-memory-pool-configuration">1. Memory Pool Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::{MemoryPool, PoolConfig};

// Configure memory pools for different object types
let pool_config = PoolConfig {
    message_pool_size: 10000,
    node_pool_size: 1000, 
    connection_pool_size: 5000,
    enable_auto_scaling: true,
    max_pool_size: 50000,
    cleanup_threshold: 0.8,
};

let memory_pool = MemoryPool::new(pool_config);

// Use pooled objects
let network = Network::with_memory_pool(memory_pool);
<span class="boring">}</span></code></pre></pre>
<h3 id="2-message-optimization"><a class="header" href="#2-message-optimization">2. Message Optimization</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::{Message, MessageBuilder, CompactMessage};

// Use compact message format for large data
fn create_efficient_message(data: &amp;[u8]) -&gt; Message {
    if data.len() &gt; 1024 {
        // Use compressed format for large payloads
        MessageBuilder::new()
            .compress_payload(true)
            .use_binary_format(true)
            .build_from_bytes(data)
    } else {
        // Use standard format for small payloads
        Message::Binary(data.to_vec())
    }
}

// Implement message recycling
struct MessageCache {
    cache: Vec&lt;Message&gt;,
    max_size: usize,
}

impl MessageCache {
    fn get_or_create(&amp;mut self) -&gt; Message {
        self.cache.pop().unwrap_or_else(|| Message::Null)
    }
    
    fn return_message(&amp;mut self, mut msg: Message) {
        if self.cache.len() &lt; self.max_size {
            // Reset message and return to cache
            msg.clear();
            self.cache.push(msg);
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="3-zero-copy-optimizations"><a class="header" href="#3-zero-copy-optimizations">3. Zero-Copy Optimizations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::Arc;
use bytes::Bytes;

// Use reference counting for large shared data
#[derive(Clone)]
struct SharedData {
    inner: Arc&lt;Bytes&gt;,
}

impl SharedData {
    fn new(data: Vec&lt;u8&gt;) -&gt; Self {
        Self {
            inner: Arc::new(Bytes::from(data))
        }
    }
    
    fn as_slice(&amp;self) -&gt; &amp;[u8] {
        &amp;self.inner
    }
}

// Actor implementation with zero-copy semantics
impl Actor for OptimizedProcessor {
    fn process(&amp;mut self, inputs: HashMap&lt;String, Message&gt;) -&gt; Result&lt;HashMap&lt;String, Message&gt;, ActorError&gt; {
        let mut outputs = HashMap::new();
        
        if let Some(Message::Binary(data)) = inputs.get("input") {
            // Process without copying the data
            let shared_data = SharedData::new(data.clone());
            
            // Pass reference to multiple outputs
            outputs.insert("output1".to_string(), 
                          Message::Custom(Box::new(shared_data.clone())));
            outputs.insert("output2".to_string(), 
                          Message::Custom(Box::new(shared_data)));
        }
        
        Ok(outputs)
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="cpu-optimization"><a class="header" href="#cpu-optimization">CPU Optimization</a></h2>
<h3 id="1-parallel-processing"><a class="header" href="#1-parallel-processing">1. Parallel Processing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use rayon::prelude::*;
use tokio::task;

// Parallel data processing
impl Actor for ParallelProcessor {
    fn process(&amp;mut self, inputs: HashMap&lt;String, Message&gt;) -&gt; Result&lt;HashMap&lt;String, Message&gt;, ActorError&gt; {
        if let Some(Message::Array(items)) = inputs.get("input") {
            // Process items in parallel
            let results: Vec&lt;Message&gt; = items
                .par_iter()
                .map(|item| self.process_item(item))
                .collect();
            
            let mut outputs = HashMap::new();
            outputs.insert("output".to_string(), Message::Array(results));
            Ok(outputs)
        } else {
            Err(ActorError::InvalidInput)
        }
    }
}

// Async parallel processing
async fn process_batch_async(items: Vec&lt;Message&gt;) -&gt; Result&lt;Vec&lt;Message&gt;, ActorError&gt; {
    let tasks: Vec&lt;_&gt; = items.into_iter()
        .map(|item| task::spawn(async move { process_item_async(item).await }))
        .collect();
    
    let mut results = Vec::new();
    for task in tasks {
        results.push(task.await??);
    }
    
    Ok(results)
}
<span class="boring">}</span></code></pre></pre>
<h3 id="2-cpu-affinity-and-thread-management"><a class="header" href="#2-cpu-affinity-and-thread-management">2. CPU Affinity and Thread Management</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::{ThreadConfig, CpuAffinity};

// Configure thread affinity for specific actors
let thread_config = ThreadConfig {
    worker_threads: num_cpus::get(),
    enable_work_stealing: true,
    cpu_affinity: CpuAffinity::Balanced,
    thread_priority: ThreadPriority::High,
};

// Pin specific actors to dedicated threads
let high_priority_executor = ThreadPoolBuilder::new()
    .num_threads(2)
    .thread_name(|i| format!("high-priority-{}", i))
    .build()?;

network.set_actor_executor("critical_processor", high_priority_executor);
<span class="boring">}</span></code></pre></pre>
<h3 id="3-simd-optimizations"><a class="header" href="#3-simd-optimizations">3. SIMD Optimizations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::simd::{f32x8, SimdFloat};

// SIMD-optimized data processing
fn process_array_simd(data: &amp;mut [f32]) {
    let chunks = data.chunks_exact_mut(8);
    let remainder = chunks.remainder();
    
    for chunk in chunks {
        let vec = f32x8::from_slice(chunk);
        let processed = vec * f32x8::splat(2.0) + f32x8::splat(1.0);
        processed.copy_to_slice(chunk);
    }
    
    // Handle remainder
    for item in remainder {
        *item = *item * 2.0 + 1.0;
    }
}

impl Actor for SIMDProcessor {
    fn process(&amp;mut self, inputs: HashMap&lt;String, Message&gt;) -&gt; Result&lt;HashMap&lt;String, Message&gt;, ActorError&gt; {
        if let Some(Message::Array(items)) = inputs.get("input") {
            let mut float_data: Vec&lt;f32&gt; = items.iter()
                .filter_map(|item| {
                    if let Message::Float(f) = item {
                        Some(*f as f32)
                    } else {
                        None
                    }
                })
                .collect();
            
            process_array_simd(&amp;mut float_data);
            
            let results: Vec&lt;Message&gt; = float_data.into_iter()
                .map(|f| Message::Float(f as f64))
                .collect();
            
            let mut outputs = HashMap::new();
            outputs.insert("output".to_string(), Message::Array(results));
            Ok(outputs)
        } else {
            Err(ActorError::InvalidInput)
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="network-optimization"><a class="header" href="#network-optimization">Network Optimization</a></h2>
<h3 id="1-connection-pooling"><a class="header" href="#1-connection-pooling">1. Connection Pooling</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::{ConnectionPool, PooledConnection};

// HTTP client with connection pooling
struct OptimizedHttpClient {
    pool: ConnectionPool,
    config: HttpConfig,
}

impl OptimizedHttpClient {
    fn new() -&gt; Self {
        let pool = ConnectionPool::builder()
            .max_connections(100)
            .idle_timeout(Duration::from_secs(30))
            .connection_timeout(Duration::from_secs(5))
            .keepalive(true)
            .build();
            
        Self {
            pool,
            config: HttpConfig::default(),
        }
    }
    
    async fn request(&amp;self, url: &amp;str) -&gt; Result&lt;Response, HttpError&gt; {
        let connection = self.pool.get_connection(url).await?;
        let response = connection.request(url).await?;
        
        // Connection is automatically returned to pool
        Ok(response)
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="2-batch-network-operations"><a class="header" href="#2-batch-network-operations">2. Batch Network Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::integration::BatchHttpActor;

// Batch multiple HTTP requests
let batch_http = BatchHttpActor::new()
    .batch_size(10)
    .batch_timeout(Duration::from_millis(100))
    .max_concurrent_batches(5)
    .retry_config(RetryConfig {
        max_attempts: 3,
        backoff: BackoffStrategy::Exponential,
        ..Default::default()
    });

// Configure request batching
impl Actor for BatchHttpActor {
    fn process(&amp;mut self, inputs: HashMap&lt;String, Message&gt;) -&gt; Result&lt;HashMap&lt;String, Message&gt;, ActorError&gt; {
        if let Some(Message::Array(urls)) = inputs.get("urls") {
            // Batch requests automatically
            let batched_requests = self.create_batches(urls);
            let futures: Vec&lt;_&gt; = batched_requests.into_iter()
                .map(|batch| self.execute_batch(batch))
                .collect();
            
            // Execute batches concurrently
            let results = futures::future::join_all(futures).await;
            
            let mut outputs = HashMap::new();
            outputs.insert("responses".to_string(), Message::Array(results));
            Ok(outputs)
        } else {
            Err(ActorError::InvalidInput)
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="3-websocket-optimization"><a class="header" href="#3-websocket-optimization">3. WebSocket Optimization</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tokio_tungstenite::{WebSocketStream, MaybeTlsStream};

// Optimized WebSocket handling
struct OptimizedWebSocket {
    stream: WebSocketStream&lt;MaybeTlsStream&lt;TcpStream&gt;&gt;,
    send_buffer: VecDeque&lt;Message&gt;,
    batch_size: usize,
}

impl OptimizedWebSocket {
    async fn send_batched(&amp;mut self) -&gt; Result&lt;(), WebSocketError&gt; {
        if self.send_buffer.len() &gt;= self.batch_size {
            let batch: Vec&lt;_&gt; = self.send_buffer.drain(..).collect();
            let combined_message = self.combine_messages(batch);
            self.stream.send(combined_message).await?;
        }
        Ok(())
    }
    
    fn combine_messages(&amp;self, messages: Vec&lt;Message&gt;) -&gt; tungstenite::Message {
        // Combine multiple messages into a single frame
        let combined_data = messages.into_iter()
            .map(|msg| msg.to_bytes())
            .collect::&lt;Vec&lt;_&gt;&gt;()
            .concat();
        
        tungstenite::Message::Binary(combined_data)
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="io-optimization"><a class="header" href="#io-optimization">I/O Optimization</a></h2>
<h3 id="1-async-io-best-practices"><a class="header" href="#1-async-io-best-practices">1. Async I/O Best Practices</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tokio::fs::File;
use tokio::io::{AsyncReadExt, AsyncWriteExt, BufReader, BufWriter};

// Efficient file processing
async fn process_large_file(path: &amp;str) -&gt; Result&lt;(), std::io::Error&gt; {
    let file = File::open(path).await?;
    let mut reader = BufReader::with_capacity(64 * 1024, file); // 64KB buffer
    
    let output_file = File::create("output.txt").await?;
    let mut writer = BufWriter::with_capacity(64 * 1024, output_file);
    
    let mut buffer = vec![0; 8192]; // 8KB read buffer
    
    loop {
        let bytes_read = reader.read(&amp;mut buffer).await?;
        if bytes_read == 0 {
            break;
        }
        
        // Process data in chunks
        let processed = process_chunk(&amp;buffer[..bytes_read]).await;
        writer.write_all(&amp;processed).await?;
    }
    
    writer.flush().await?;
    Ok(())
}

// Parallel file processing
async fn process_files_parallel(file_paths: Vec&lt;String&gt;) -&gt; Result&lt;(), std::io::Error&gt; {
    let semaphore = Arc::new(Semaphore::new(10)); // Limit concurrent file operations
    
    let tasks: Vec&lt;_&gt; = file_paths.into_iter()
        .map(|path| {
            let sem = semaphore.clone();
            tokio::spawn(async move {
                let _permit = sem.acquire().await.unwrap();
                process_large_file(&amp;path).await
            })
        })
        .collect();
    
    futures::future::try_join_all(tasks).await?;
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h3 id="2-database-optimization"><a class="header" href="#2-database-optimization">2. Database Optimization</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use sqlx::{Pool, Postgres, Row};

// Optimized database operations
struct OptimizedDbActor {
    pool: Pool&lt;Postgres&gt;,
    prepared_statements: HashMap&lt;String, String&gt;,
}

impl OptimizedDbActor {
    async fn new(database_url: &amp;str) -&gt; Result&lt;Self, sqlx::Error&gt; {
        let pool = sqlx::postgres::PgPoolOptions::new()
            .max_connections(20)
            .min_connections(5)
            .acquire_timeout(Duration::from_secs(3))
            .idle_timeout(Duration::from_secs(600))
            .max_lifetime(Duration::from_secs(1800))
            .connect(database_url)
            .await?;
        
        Ok(Self {
            pool,
            prepared_statements: HashMap::new(),
        })
    }
    
    async fn batch_insert(&amp;self, records: Vec&lt;Record&gt;) -&gt; Result&lt;(), sqlx::Error&gt; {
        let mut tx = self.pool.begin().await?;
        
        for chunk in records.chunks(1000) { // Process in batches of 1000
            let query = self.build_batch_insert_query(chunk);
            sqlx::query(&amp;query).execute(&amp;mut *tx).await?;
        }
        
        tx.commit().await?;
        Ok(())
    }
    
    async fn execute_prepared(&amp;self, statement_name: &amp;str, params: &amp;[&amp;dyn sqlx::Encode&lt;'_, Postgres&gt;]) -&gt; Result&lt;Vec&lt;Row&gt;, sqlx::Error&gt; {
        if let Some(sql) = self.prepared_statements.get(statement_name) {
            let mut query = sqlx::query(sql);
            for param in params {
                query = query.bind(param);
            }
            query.fetch_all(&amp;self.pool).await
        } else {
            Err(sqlx::Error::RowNotFound)
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="workflow-specific-optimizations"><a class="header" href="#workflow-specific-optimizations">Workflow-Specific Optimizations</a></h2>
<h3 id="1-pipeline-optimization"><a class="header" href="#1-pipeline-optimization">1. Pipeline Optimization</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Optimized pipeline with backpressure
use tokio::sync::mpsc;

struct OptimizedPipeline {
    stages: Vec&lt;Box&lt;dyn Actor&gt;&gt;,
    buffer_sizes: Vec&lt;usize&gt;,
    channels: Vec&lt;mpsc::Sender&lt;Message&gt;&gt;,
}

impl OptimizedPipeline {
    fn new() -&gt; Self {
        Self {
            stages: Vec::new(),
            buffer_sizes: Vec::new(),
            channels: Vec::new(),
        }
    }
    
    fn add_stage(&amp;mut self, actor: Box&lt;dyn Actor&gt;, buffer_size: usize) {
        self.stages.push(actor);
        self.buffer_sizes.push(buffer_size);
        
        let (tx, rx) = mpsc::channel(buffer_size);
        self.channels.push(tx);
    }
    
    async fn execute_with_backpressure(&amp;mut self, input: Message) -&gt; Result&lt;Message, ActorError&gt; {
        let mut current_message = input;
        
        for (i, stage) in self.stages.iter_mut().enumerate() {
            // Apply backpressure using channel capacity
            if let Some(tx) = self.channels.get(i) {
                tx.send(current_message.clone()).await
                    .map_err(|_| ActorError::ChannelClosed)?;
            }
            
            let inputs = HashMap::from([("input".to_string(), current_message)]);
            let outputs = stage.process(inputs)?;
            
            current_message = outputs.get("output")
                .ok_or(ActorError::MissingOutput)?
                .clone();
        }
        
        Ok(current_message)
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="2-dynamic-load-balancing"><a class="header" href="#2-dynamic-load-balancing">2. Dynamic Load Balancing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::atomic::{AtomicUsize, Ordering};

struct LoadBalancer {
    workers: Vec&lt;Box&lt;dyn Actor&gt;&gt;,
    load_counters: Vec&lt;AtomicUsize&gt;,
    strategy: LoadBalanceStrategy,
}

impl LoadBalancer {
    fn select_worker(&amp;self) -&gt; usize {
        match self.strategy {
            LoadBalanceStrategy::RoundRobin =&gt; {
                static COUNTER: AtomicUsize = AtomicUsize::new(0);
                COUNTER.fetch_add(1, Ordering::Relaxed) % self.workers.len()
            }
            LoadBalanceStrategy::LeastLoaded =&gt; {
                self.load_counters
                    .iter()
                    .enumerate()
                    .min_by_key(|(_, counter)| counter.load(Ordering::Relaxed))
                    .map(|(index, _)| index)
                    .unwrap_or(0)
            }
            LoadBalanceStrategy::WeightedRoundRobin =&gt; {
                // Implement weighted selection based on worker capacity
                self.select_weighted_worker()
            }
        }
    }
    
    fn update_load_metrics(&amp;self, worker_index: usize, processing_time: Duration) {
        // Update load metrics for adaptive load balancing
        let load_score = self.calculate_load_score(processing_time);
        self.load_counters[worker_index].store(load_score, Ordering::Relaxed);
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="monitoring-and-optimization"><a class="header" href="#monitoring-and-optimization">Monitoring and Optimization</a></h2>
<h3 id="1-real-time-metrics"><a class="header" href="#1-real-time-metrics">1. Real-time Metrics</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use prometheus::{Counter, Histogram, Gauge, register_counter, register_histogram, register_gauge};

struct PerformanceMonitor {
    message_counter: Counter,
    processing_time: Histogram,
    memory_usage: Gauge,
    active_connections: Gauge,
}

impl PerformanceMonitor {
    fn new() -&gt; Self {
        Self {
            message_counter: register_counter!("reflow_messages_total", "Total messages processed").unwrap(),
            processing_time: register_histogram!("reflow_processing_duration_seconds", "Processing time in seconds").unwrap(),
            memory_usage: register_gauge!("reflow_memory_usage_bytes", "Memory usage in bytes").unwrap(),
            active_connections: register_gauge!("reflow_active_connections", "Number of active connections").unwrap(),
        }
    }
    
    fn record_message_processed(&amp;self, processing_time: Duration) {
        self.message_counter.inc();
        self.processing_time.observe(processing_time.as_secs_f64());
    }
    
    fn update_memory_usage(&amp;self, bytes: u64) {
        self.memory_usage.set(bytes as f64);
    }
    
    async fn collect_system_metrics(&amp;self) {
        if let Some(usage) = memory_stats::memory_stats() {
            self.update_memory_usage(usage.physical_mem as u64);
        }
        
        // Collect other system metrics
        let cpu_usage = get_cpu_usage().await;
        // ... record other metrics
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="2-adaptive-optimization"><a class="header" href="#2-adaptive-optimization">2. Adaptive Optimization</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct AdaptiveOptimizer {
    performance_history: VecDeque&lt;PerformanceSnapshot&gt;,
    optimization_strategies: Vec&lt;Box&lt;dyn OptimizationStrategy&gt;&gt;,
    current_config: OptimizationConfig,
}

impl AdaptiveOptimizer {
    async fn optimize_based_on_metrics(&amp;mut self, current_metrics: &amp;PerformanceMetrics) {
        let snapshot = PerformanceSnapshot {
            timestamp: std::time::Instant::now(),
            metrics: current_metrics.clone(),
            config: self.current_config.clone(),
        };
        
        self.performance_history.push_back(snapshot);
        if self.performance_history.len() &gt; 100 {
            self.performance_history.pop_front();
        }
        
        // Analyze trends and apply optimizations
        if let Some(optimization) = self.analyze_and_suggest_optimization() {
            self.apply_optimization(optimization).await;
        }
    }
    
    fn analyze_and_suggest_optimization(&amp;self) -&gt; Option&lt;OptimizationAction&gt; {
        // Machine learning-based optimization suggestions
        let trend_analyzer = TrendAnalyzer::new(&amp;self.performance_history);
        
        if trend_analyzer.detect_memory_pressure() {
            Some(OptimizationAction::ReduceMemoryUsage)
        } else if trend_analyzer.detect_cpu_bottleneck() {
            Some(OptimizationAction::IncreaseParallelism)
        } else if trend_analyzer.detect_io_bottleneck() {
            Some(OptimizationAction::OptimizeIo)
        } else {
            None
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="platform-specific-optimizations"><a class="header" href="#platform-specific-optimizations">Platform-Specific Optimizations</a></h2>
<h3 id="1-linux-specific-optimizations"><a class="header" href="#1-linux-specific-optimizations">1. Linux-Specific Optimizations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(target_os = "linux")]
mod linux_optimizations {
    use libc::{sched_setaffinity, cpu_set_t, CPU_SET, CPU_ZERO};
    
    pub fn set_cpu_affinity(thread_id: u32, cpu_cores: &amp;[usize]) -&gt; Result&lt;(), std::io::Error&gt; {
        unsafe {
            let mut cpuset: cpu_set_t = std::mem::zeroed();
            CPU_ZERO(&amp;mut cpuset);
            
            for &amp;core in cpu_cores {
                CPU_SET(core, &amp;mut cpuset);
            }
            
            let result = sched_setaffinity(
                thread_id, 
                std::mem::size_of::&lt;cpu_set_t&gt;(), 
                &amp;cpuset
            );
            
            if result == 0 {
                Ok(())
            } else {
                Err(std::io::Error::last_os_error())
            }
        }
    }
    
    pub fn configure_memory_policy() {
        // Configure NUMA memory policy for optimal performance
        use libc::{mbind, MPOL_BIND};
        // Implementation details...
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="2-macos-specific-optimizations"><a class="header" href="#2-macos-specific-optimizations">2. macOS-Specific Optimizations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(target_os = "macos")]
mod macos_optimizations {
    use std::ffi::CString;
    use libc::{pthread_t, pthread_self, thread_policy_set, THREAD_PRECEDENCE_POLICY};
    
    pub fn set_thread_priority(priority: i32) -&gt; Result&lt;(), std::io::Error&gt; {
        unsafe {
            let thread = pthread_self();
            let policy = THREAD_PRECEDENCE_POLICY;
            
            let result = thread_policy_set(
                thread as *mut _,
                policy,
                &amp;priority as *const _ as *const _,
                1
            );
            
            if result == 0 {
                Ok(())
            } else {
                Err(std::io::Error::last_os_error())
            }
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-summary-1"><a class="header" href="#best-practices-summary-1">Best Practices Summary</a></h2>
<h3 id="1-general-optimization-principles"><a class="header" href="#1-general-optimization-principles">1. General Optimization Principles</a></h3>
<ul>
<li><strong>Measure First</strong>: Always profile before optimizing</li>
<li><strong>Optimize Bottlenecks</strong>: Focus on the slowest components</li>
<li><strong>Cache Wisely</strong>: Cache expensive computations, not cheap ones</li>
<li><strong>Batch Operations</strong>: Group similar operations together</li>
<li><strong>Use Appropriate Data Structures</strong>: Choose the right tool for the job</li>
</ul>
<h3 id="2-memory-management"><a class="header" href="#2-memory-management">2. Memory Management</a></h3>
<ul>
<li><strong>Pool Resources</strong>: Use object pools for frequently allocated items</li>
<li><strong>Minimize Allocations</strong>: Reuse buffers and data structures</li>
<li><strong>Compress Large Data</strong>: Use compression for large payloads</li>
<li><strong>Monitor Memory Usage</strong>: Track allocation patterns</li>
</ul>
<h3 id="3-concurrency-and-parallelism"><a class="header" href="#3-concurrency-and-parallelism">3. Concurrency and Parallelism</a></h3>
<ul>
<li><strong>Match Threading to Workload</strong>: CPU-bound vs I/O-bound considerations</li>
<li><strong>Avoid Lock Contention</strong>: Use lock-free data structures when possible</li>
<li><strong>Balance Load</strong>: Distribute work evenly across threads</li>
<li><strong>Handle Backpressure</strong>: Prevent memory exhaustion in pipelines</li>
</ul>
<h3 id="4-network-and-io"><a class="header" href="#4-network-and-io">4. Network and I/O</a></h3>
<ul>
<li><strong>Connection Pooling</strong>: Reuse network connections</li>
<li><strong>Batch Network Operations</strong>: Reduce round-trip overhead</li>
<li><strong>Async I/O</strong>: Use non-blocking I/O operations</li>
<li><strong>Buffer Sizing</strong>: Optimize buffer sizes for your workload</li>
</ul>
<h2 id="troubleshooting-performance-issues"><a class="header" href="#troubleshooting-performance-issues">Troubleshooting Performance Issues</a></h2>
<h3 id="common-performance-problems"><a class="header" href="#common-performance-problems">Common Performance Problems</a></h3>
<ol>
<li><strong>Memory Leaks</strong>: Use memory profilers to identify leaks</li>
<li><strong>CPU Hotspots</strong>: Profile CPU usage to find bottlenecks</li>
<li><strong>Lock Contention</strong>: Monitor lock wait times</li>
<li><strong>I/O Blocking</strong>: Identify blocking I/O operations</li>
<li><strong>Network Latency</strong>: Measure network round-trip times</li>
</ol>
<h3 id="performance-testing"><a class="header" href="#performance-testing">Performance Testing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod performance_tests {
    use super::*;
    use criterion::{criterion_group, criterion_main, Criterion};
    
    fn benchmark_workflow_throughput(c: &amp;mut Criterion) {
        c.bench_function("workflow_1000_messages", |b| {
            b.iter(|| {
                let rt = tokio::runtime::Runtime::new().unwrap();
                rt.block_on(async {
                    let network = create_test_network().await;
                    let messages = create_test_messages(1000);
                    
                    let start = std::time::Instant::now();
                    for message in messages {
                        network.process_message(message).await.unwrap();
                    }
                    start.elapsed()
                })
            })
        });
    }
    
    criterion_group!(benches, benchmark_workflow_throughput);
    criterion_main!(benches);
}
<span class="boring">}</span></code></pre></pre>
<h2 id="next-steps-31"><a class="header" href="#next-steps-31">Next Steps</a></h2>
<ul>
<li><a href="tutorials/../architecture/overview.html">Architecture Overview</a> - Understanding Reflow's architecture</li>
<li><a href="tutorials/../api/graph/advanced.html">Advanced Features</a> - Advanced graph operations</li>
<li><a href="tutorials/../reference/troubleshooting-guide.html">Troubleshooting Guide</a> - Common issues and solutions</li>
<li><a href="tutorials/../deployment/native-deployment.html">Deployment Guide</a> - Production deployment strategies</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="distributed-workflow-example"><a class="header" href="#distributed-workflow-example">Distributed Workflow Example</a></h1>
<p>Learn how to build and deploy distributed workflows using Reflow's distributed networking capabilities.</p>
<h2 id="overview-19"><a class="header" href="#overview-19">Overview</a></h2>
<p>This tutorial demonstrates how to create a complete distributed workflow that spans multiple network instances. We'll build a real-world example: a distributed data processing and machine learning pipeline.</p>
<h2 id="what-youll-build"><a class="header" href="#what-youll-build">What You'll Build</a></h2>
<p>A distributed system with three network instances:</p>
<ol>
<li><strong>Data Instance</strong>: Collects and processes raw data</li>
<li><strong>ML Instance</strong>: Trains and evaluates machine learning models</li>
<li><strong>API Instance</strong>: Serves predictions and provides monitoring</li>
</ol>
<pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Data Instance  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  ML Instance    ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  API Instance   ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ
‚îÇ ‚Ä¢ Data Collector‚îÇ    ‚îÇ ‚Ä¢ Feature Eng.  ‚îÇ    ‚îÇ ‚Ä¢ Prediction API‚îÇ
‚îÇ ‚Ä¢ Data Processor‚îÇ    ‚îÇ ‚Ä¢ Model Trainer ‚îÇ    ‚îÇ ‚Ä¢ Monitoring    ‚îÇ
‚îÇ ‚Ä¢ Data Validator‚îÇ    ‚îÇ ‚Ä¢ Model Eval.   ‚îÇ    ‚îÇ ‚Ä¢ Dashboard     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre>
<h2 id="prerequisites-6"><a class="header" href="#prerequisites-6">Prerequisites</a></h2>
<ul>
<li>Rust development environment</li>
<li>Basic understanding of Reflow actors and networks</li>
<li>Familiarity with distributed systems concepts</li>
</ul>
<h2 id="step-1-project-setup"><a class="header" href="#step-1-project-setup">Step 1: Project Setup</a></h2>
<p>Create the project structure:</p>
<pre><code class="language-bash">mkdir distributed_ml_pipeline
cd distributed_ml_pipeline

# Create instance directories
mkdir -p instances/{data,ml,api}
mkdir -p shared/actors
mkdir -p shared/types

# Initialize Cargo workspace
cargo init --name distributed_ml_pipeline
</code></pre>
<h3 id="cargotoml"><a class="header" href="#cargotoml">Cargo.toml</a></h3>
<pre><code class="language-toml">[workspace]
members = [
    "instances/data",
    "instances/ml", 
    "instances/api",
    "shared/actors",
    "shared/types"
]

[workspace.dependencies]
reflow_network = { path = "../../crates/reflow_network" }
actor_macro = { path = "../../crates/actor_macro" }
tokio = { version = "1.0", features = ["full"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
anyhow = "1.0"
tracing = "0.1"
tracing-subscriber = "0.3"
uuid = { version = "1.0", features = ["v4"] }
chrono = { version = "0.4", features = ["serde"] }
</code></pre>
<h2 id="step-2-shared-types-and-actors"><a class="header" href="#step-2-shared-types-and-actors">Step 2: Shared Types and Actors</a></h2>
<h3 id="shared-types"><a class="header" href="#shared-types">Shared Types</a></h3>
<p>Create <code>shared/types/src/lib.rs</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use serde::{Deserialize, Serialize};
use chrono::{DateTime, Utc};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DataRecord {
    pub id: String,
    pub timestamp: DateTime&lt;Utc&gt;,
    pub features: Vec&lt;f64&gt;,
    pub metadata: std::collections::HashMap&lt;String, serde_json::Value&gt;,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ProcessedData {
    pub record_id: String,
    pub processed_features: Vec&lt;f64&gt;,
    pub quality_score: f64,
    pub processing_timestamp: DateTime&lt;Utc&gt;,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TrainingData {
    pub features: Vec&lt;Vec&lt;f64&gt;&gt;,
    pub labels: Vec&lt;f64&gt;,
    pub metadata: TrainingMetadata,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TrainingMetadata {
    pub total_samples: usize,
    pub feature_count: usize,
    pub training_timestamp: DateTime&lt;Utc&gt;,
    pub data_source: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TrainedModel {
    pub model_id: String,
    pub model_data: Vec&lt;u8&gt;, // Serialized model
    pub performance_metrics: ModelMetrics,
    pub training_timestamp: DateTime&lt;Utc&gt;,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelMetrics {
    pub accuracy: f64,
    pub precision: f64,
    pub recall: f64,
    pub f1_score: f64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PredictionRequest {
    pub request_id: String,
    pub features: Vec&lt;f64&gt;,
    pub model_version: Option&lt;String&gt;,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PredictionResponse {
    pub request_id: String,
    pub prediction: f64,
    pub confidence: f64,
    pub model_version: String,
    pub processing_time_ms: u64,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="shared-actors"><a class="header" href="#shared-actors">Shared Actors</a></h3>
<p>Create <code>shared/actors/src/lib.rs</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::{
    actor::{Actor, ActorConfig, ActorContext, ActorLoad, MemoryState, Port},
    message::{Message, EncodableValue},
};
use shared_types::*;
use std::{collections::HashMap, sync::Arc};
use actor_macro::actor;
use anyhow::Error;

/// Logging actor that can be shared across all instances
#[actor(
    DistributedLoggerActor,
    inports::&lt;100&gt;(Input),
    outports::&lt;50&gt;(Output),
    state(MemoryState)
)]
pub async fn distributed_logger_actor(
    context: ActorContext,
) -&gt; Result&lt;HashMap&lt;String, Message&gt;, Error&gt; {
    let payload = context.get_payload();
    let config = context.get_config();
    
    let instance_name = config.get_string("instance_name").unwrap_or("unknown".to_string());
    let log_level = config.get_string("log_level").unwrap_or("info".to_string());
    
    for (port, message) in payload.iter() {
        let timestamp = chrono::Utc::now().format("%Y-%m-%d %H:%M:%S%.3f");
        
        match message {
            Message::String(s) =&gt; {
                println!("[{}] [{}] [{}]: {}", timestamp, instance_name, log_level.to_uppercase(), s);
            },
            Message::Object(obj) =&gt; {
                if let Ok(json_str) = serde_json::to_string_pretty(obj) {
                    println!("[{}] [{}] [{}]:\n{}", timestamp, instance_name, log_level.to_uppercase(), json_str);
                }
            },
            _ =&gt; {
                println!("[{}] [{}] [{}]: {:?}", timestamp, instance_name, log_level.to_uppercase(), message);
            }
        }
    }
    
    Ok(HashMap::new())
}

/// Metrics collector for monitoring distributed system performance
#[actor(
    MetricsCollectorActor,
    inports::&lt;100&gt;(Input),
    outports::&lt;50&gt;(Output, Alert),
    state(MemoryState)
)]
pub async fn metrics_collector_actor(
    context: ActorContext,
) -&gt; Result&lt;HashMap&lt;String, Message&gt;, Error&gt; {
    let payload = context.get_payload();
    let state = context.get_state();
    let mut output = HashMap::new();
    
    for (port, message) in payload.iter() {
        if let Message::Object(metric_data) = message {
            // Store metrics in state
            {
                let mut state_lock = state.lock();
                if let Some(state_data) = state_lock.as_mut_any().downcast_mut::&lt;MemoryState&gt;() {
                    let metrics_key = format!("metrics_{}", chrono::Utc::now().timestamp());
                    state_data.insert(metrics_key, metric_data.as_value().clone());
                    
                    // Keep only last 100 metrics entries
                    let keys: Vec&lt;String&gt; = state_data.data().keys()
                        .filter(|k| k.starts_with("metrics_"))
                        .cloned()
                        .collect();
                    
                    if keys.len() &gt; 100 {
                        let mut sorted_keys = keys;
                        sorted_keys.sort();
                        for key in sorted_keys.into_iter().take(keys.len() - 100) {
                            state_data.data_mut().remove(&amp;key);
                        }
                    }
                }
            }
            
            // Check for alert conditions
            if let Some(error_rate) = metric_data.as_value().get("error_rate").and_then(|v| v.as_f64()) {
                if error_rate &gt; 0.1 { // 10% error rate threshold
                    let alert = Message::object(EncodableValue::from(serde_json::json!({
                        "type": "high_error_rate",
                        "error_rate": error_rate,
                        "timestamp": chrono::Utc::now().to_rfc3339(),
                        "severity": "warning"
                    })));
                    output.insert("Alert".to_string(), alert);
                }
            }
            
            // Forward metrics for further processing
            output.insert("Output".to_string(), message.clone());
        }
    }
    
    Ok(output)
}
<span class="boring">}</span></code></pre></pre>
<h2 id="step-3-data-instance"><a class="header" href="#step-3-data-instance">Step 3: Data Instance</a></h2>
<p>Create the data processing instance in <code>instances/data/src/main.rs</code>:</p>
<pre><pre class="playground"><code class="language-rust">use reflow_network::{
    actor::{Actor, ActorConfig, ActorContext, ActorLoad, MemoryState, Port},
    distributed_network::{DistributedConfig, DistributedNetwork},
    message::{Message, EncodableValue},
    network::NetworkConfig,
};
use shared_actors::{DistributedLoggerActor, MetricsCollectorActor};
use shared_types::*;
use std::{collections::HashMap, sync::Arc, time::Duration};
use actor_macro::actor;
use anyhow::Error;
use tokio::time::sleep;

/// Data collector that simulates collecting raw data
#[actor(
    DataCollectorActor,
    inports::&lt;100&gt;(Trigger),
    outports::&lt;50&gt;(Output, Metrics),
    state(MemoryState)
)]
async fn data_collector_actor(
    context: ActorContext,
) -&gt; Result&lt;HashMap&lt;String, Message&gt;, Error&gt; {
    let payload = context.get_payload();
    let state = context.get_state();
    let mut output = HashMap::new();
    
    if payload.contains_key("Trigger") {
        // Generate sample data
        let record = DataRecord {
            id: uuid::Uuid::new_v4().to_string(),
            timestamp: chrono::Utc::now(),
            features: (0..10).map(|_| rand::random::&lt;f64&gt;()).collect(),
            metadata: HashMap::from([
                ("source".to_string(), serde_json::json!("sensor_array")),
                ("quality".to_string(), serde_json::json!("high")),
            ]),
        };
        
        // Update collection count
        let count = {
            let mut state_lock = state.lock();
            if let Some(state_data) = state_lock.as_mut_any().downcast_mut::&lt;MemoryState&gt;() {
                let count = state_data.get("collection_count")
                    .and_then(|v| v.as_i64())
                    .unwrap_or(0) + 1;
                state_data.insert("collection_count".to_string(), serde_json::json!(count));
                count
            } else {
                1
            }
        };
        
        // Send data for processing
        let data_message = Message::object(EncodableValue::from(serde_json::to_value(record)?));
        output.insert("Output".to_string(), data_message);
        
        // Send metrics
        let metrics = Message::object(EncodableValue::from(serde_json::json!({
            "actor": "data_collector",
            "records_collected": count,
            "timestamp": chrono::Utc::now().to_rfc3339(),
            "instance": "data"
        })));
        output.insert("Metrics".to_string(), metrics);
    }
    
    Ok(output)
}

/// Data processor that cleans and validates data
#[actor(
    DataProcessorActor,
    inports::&lt;100&gt;(Input),
    outports::&lt;50&gt;(Output, Metrics, Log),
    state(MemoryState)
)]
async fn data_processor_actor(
    context: ActorContext,
) -&gt; Result&lt;HashMap&lt;String, Message&gt;, Error&gt; {
    let payload = context.get_payload();
    let mut output = HashMap::new();
    
    for (port, message) in payload.iter() {
        if port == "Input" {
            if let Message::Object(obj) = message {
                if let Ok(record) = serde_json::from_value::&lt;DataRecord&gt;(obj.as_value().clone()) {
                    // Simulate data processing
                    let processed = ProcessedData {
                        record_id: record.id.clone(),
                        processed_features: record.features.iter()
                            .map(|&amp;f| f * 2.0 + 1.0) // Simple transformation
                            .collect(),
                        quality_score: record.features.iter().sum::&lt;f64&gt;() / record.features.len() as f64,
                        processing_timestamp: chrono::Utc::now(),
                    };
                    
                    // Send processed data
                    let processed_message = Message::object(EncodableValue::from(serde_json::to_value(processed)?));
                    output.insert("Output".to_string(), processed_message);
                    
                    // Send log message
                    let log_message = Message::String(
                        format!("Processed data record {} with quality score {:.2}", 
                            record.id, processed.quality_score).into()
                    );
                    output.insert("Log".to_string(), log_message);
                    
                    // Send metrics
                    let metrics = Message::object(EncodableValue::from(serde_json::json!({
                        "actor": "data_processor",
                        "processing_time_ms": 10, // Simulated
                        "quality_score": processed.quality_score,
                        "timestamp": chrono::Utc::now().to_rfc3339(),
                        "instance": "data"
                    })));
                    output.insert("Metrics".to_string(), metrics);
                }
            }
        }
    }
    
    Ok(output)
}

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    tracing_subscriber::fmt::init();
    
    println!("üöÄ Starting Data Instance");
    
    // Configure distributed network
    let config = DistributedConfig {
        network_id: "data_instance".to_string(),
        instance_id: "data_001".to_string(),
        bind_address: "127.0.0.1".to_string(),
        bind_port: 9001,
        discovery_endpoints: vec![],
        auth_token: Some("data_token".to_string()),
        max_connections: 10,
        heartbeat_interval_ms: 30000,
        local_network_config: NetworkConfig::default(),
    };
    
    // Create distributed network
    let mut network = DistributedNetwork::new(config).await?;
    
    // Register local actors
    network.register_local_actor("data_collector", DataCollectorActor::new(), None)?;
    network.register_local_actor("data_processor", DataProcessorActor::new(), None)?;
    network.register_local_actor("logger", DistributedLoggerActor::new(), Some(HashMap::from([
        ("instance_name".to_string(), serde_json::json!("data")),
    ])))?;
    network.register_local_actor("metrics", MetricsCollectorActor::new(), None)?;
    
    // Start the network
    network.start().await?;
    
    // Get local network for workflow setup
    {
        let local_net = network.get_local_network();
        let mut net = local_net.write();
        
        // Create workflow connections
        net.add_connection(reflow_network::connector::Connector {
            from: reflow_network::connector::ConnectionPoint {
                actor: "data_collector".to_string(),
                port: "Output".to_string(),
                ..Default::default()
            },
            to: reflow_network::connector::ConnectionPoint {
                actor: "data_processor".to_string(),
                port: "Input".to_string(),
                ..Default::default()
            },
        })?;
        
        net.add_connection(reflow_network::connector::Connector {
            from: reflow_network::connector::ConnectionPoint {
                actor: "data_processor".to_string(),
                port: "Log".to_string(),
                ..Default::default()
            },
            to: reflow_network::connector::ConnectionPoint {
                actor: "logger".to_string(),
                port: "Input".to_string(),
                ..Default::default()
            },
        })?;
        
        net.add_connection(reflow_network::connector::Connector {
            from: reflow_network::connector::ConnectionPoint {
                actor: "data_processor".to_string(),
                port: "Metrics".to_string(),
                ..Default::default()
            },
            to: reflow_network::connector::ConnectionPoint {
                actor: "metrics".to_string(),
                port: "Input".to_string(),
                ..Default::default()
            },
        })?;
    }
    
    println!("‚úÖ Data Instance ready on 127.0.0.1:9001");
    
    // Start data collection loop
    tokio::spawn(async move {
        loop {
            sleep(Duration::from_secs(5)).await;
            
            // Trigger data collection
            let trigger_message = Message::Boolean(true);
            if let Ok(local_net) = network.get_local_network().try_read() {
                let _ = local_net.send_to_actor("data_collector", "Trigger", trigger_message);
            }
        }
    });
    
    // Keep running
    loop {
        sleep(Duration::from_secs(1)).await;
    }
}</code></pre></pre>
<h2 id="step-4-ml-instance"><a class="header" href="#step-4-ml-instance">Step 4: ML Instance</a></h2>
<p>Create the ML training instance in <code>instances/ml/src/main.rs</code>:</p>
<pre><pre class="playground"><code class="language-rust">use reflow_network::{
    actor::{Actor, ActorConfig, ActorContext, ActorLoad, MemoryState, Port},
    distributed_network::{DistributedConfig, DistributedNetwork},
    message::{Message, EncodableValue},
    network::NetworkConfig,
};
use shared_actors::{DistributedLoggerActor, MetricsCollectorActor};
use shared_types::*;
use std::{collections::HashMap, sync::Arc, time::Duration};
use actor_macro::actor;
use anyhow::Error;
use tokio::time::sleep;

/// Feature engineer that prepares data for ML training
#[actor(
    FeatureEngineerActor,
    inports::&lt;100&gt;(Input),
    outports::&lt;50&gt;(Output, Log, Metrics),
    state(MemoryState)
)]
async fn feature_engineer_actor(
    context: ActorContext,
) -&gt; Result&lt;HashMap&lt;String, Message&gt;, Error&gt; {
    let payload = context.get_payload();
    let state = context.get_state();
    let mut output = HashMap::new();
    
    for (port, message) in payload.iter() {
        if port == "Input" {
            if let Message::Object(obj) = message {
                if let Ok(processed) = serde_json::from_value::&lt;ProcessedData&gt;(obj.as_value().clone()) {
                    // Accumulate features for batch training
                    {
                        let mut state_lock = state.lock();
                        if let Some(state_data) = state_lock.as_mut_any().downcast_mut::&lt;MemoryState&gt;() {
                            let mut features: Vec&lt;Vec&lt;f64&gt;&gt; = state_data.get("accumulated_features")
                                .and_then(|v| serde_json::from_value(v.clone()).ok())
                                .unwrap_or_default();
                            
                            let mut labels: Vec&lt;f64&gt; = state_data.get("accumulated_labels")
                                .and_then(|v| serde_json::from_value(v.clone()).ok())
                                .unwrap_or_default();
                            
                            features.push(processed.processed_features.clone());
                            labels.push(processed.quality_score); // Use quality score as label
                            
                            state_data.insert("accumulated_features".to_string(), serde_json::to_value(&amp;features)?);
                            state_data.insert("accumulated_labels".to_string(), serde_json::to_value(&amp;labels)?);
                            
                            // Send training data when we have enough samples
                            if features.len() &gt;= 10 {
                                let training_data = TrainingData {
                                    features: features.clone(),
                                    labels: labels.clone(),
                                    metadata: TrainingMetadata {
                                        total_samples: features.len(),
                                        feature_count: features[0].len(),
                                        training_timestamp: chrono::Utc::now(),
                                        data_source: "data_instance".to_string(),
                                    },
                                };
                                
                                let training_message = Message::object(EncodableValue::from(serde_json::to_value(training_data)?));
                                output.insert("Output".to_string(), training_message);
                                
                                // Reset accumulation
                                state_data.insert("accumulated_features".to_string(), serde_json::json!([]));
                                state_data.insert("accumulated_labels".to_string(), serde_json::json!([]));
                                
                                let log_message = Message::String(
                                    format!("Generated training batch with {} samples", features.len()).into()
                                );
                                output.insert("Log".to_string(), log_message);
                            }
                        }
                    }
                    
                    // Send metrics
                    let metrics = Message::object(EncodableValue::from(serde_json::json!({
                        "actor": "feature_engineer",
                        "features_processed": 1,
                        "timestamp": chrono::Utc::now().to_rfc3339(),
                        "instance": "ml"
                    })));
                    output.insert("Metrics".to_string(), metrics);
                }
            }
        }
    }
    
    Ok(output)
}

/// Model trainer that trains ML models
#[actor(
    ModelTrainerActor,
    inports::&lt;100&gt;(Input),
    outports::&lt;50&gt;(Output, Log, Metrics),
    state(MemoryState)
)]
async fn model_trainer_actor(
    context: ActorContext,
) -&gt; Result&lt;HashMap&lt;String, Message&gt;, Error&gt; {
    let payload = context.get_payload();
    let mut output = HashMap::new();
    
    for (port, message) in payload.iter() {
        if port == "Input" {
            if let Message::Object(obj) = message {
                if let Ok(training_data) = serde_json::from_value::&lt;TrainingData&gt;(obj.as_value().clone()) {
                    // Simulate model training
                    sleep(Duration::from_millis(100)).await; // Simulate training time
                    
                    let model = TrainedModel {
                        model_id: uuid::Uuid::new_v4().to_string(),
                        model_data: vec![1, 2, 3, 4, 5], // Dummy model data
                        performance_metrics: ModelMetrics {
                            accuracy: 0.85 + rand::random::&lt;f64&gt;() * 0.1,
                            precision: 0.82 + rand::random::&lt;f64&gt;() * 0.15,
                            recall: 0.78 + rand::random::&lt;f64&gt;() * 0.2,
                            f1_score: 0.80 + rand::random::&lt;f64&gt;() * 0.15,
                        },
                        training_timestamp: chrono::Utc::now(),
                    };
                    
                    // Send trained model
                    let model_message = Message::object(EncodableValue::from(serde_json::to_value(model.clone())?));
                    output.insert("Output".to_string(), model_message);
                    
                    // Send log message
                    let log_message = Message::String(
                        format!("Trained model {} with accuracy {:.3}", 
                            model.model_id, model.performance_metrics.accuracy).into()
                    );
                    output.insert("Log".to_string(), log_message);
                    
                    // Send metrics
                    let metrics = Message::object(EncodableValue::from(serde_json::json!({
                        "actor": "model_trainer",
                        "model_id": model.model_id,
                        "accuracy": model.performance_metrics.accuracy,
                        "training_samples": training_data.metadata.total_samples,
                        "timestamp": chrono::Utc::now().to_rfc3339(),
                        "instance": "ml"
                    })));
                    output.insert("Metrics".to_string(), metrics);
                }
            }
        }
    }
    
    Ok(output)
}

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    tracing_subscriber::fmt::init();
    
    println!("üöÄ Starting ML Instance");
    
    // Configure distributed network
    let config = DistributedConfig {
        network_id: "ml_instance".to_string(),
        instance_id: "ml_001".to_string(),
        bind_address: "127.0.0.1".to_string(),
        bind_port: 9002,
        discovery_endpoints: vec![],
        auth_token: Some("ml_token".to_string()),
        max_connections: 10,
        heartbeat_interval_ms: 30000,
        local_network_config: NetworkConfig::default(),
    };
    
    // Create distributed network
    let mut network = DistributedNetwork::new(config).await?;
    
    // Register local actors
    network.register_local_actor("feature_engineer", FeatureEngineerActor::new(), None)?;
    network.register_local_actor("model_trainer", ModelTrainerActor::new(), None)?;
    network.register_local_actor("logger", DistributedLoggerActor::new(), Some(HashMap::from([
        ("instance_name".to_string(), serde_json::json!("ml")),
    ])))?;
    network.register_local_actor("metrics", MetricsCollectorActor::new(), None)?;
    
    // Start the network
    network.start().await?;
    
    // Get local network for workflow setup
    {
        let local_net = network.get_local_network();
        let mut net = local_net.write();
        
        // Create workflow connections
        net.add_connection(reflow_network::connector::Connector {
            from: reflow_network::connector::ConnectionPoint {
                actor: "feature_engineer".to_string(),
                port: "Output".to_string(),
                ..Default::default()
            },
            to: reflow_network::connector::ConnectionPoint {
                actor: "model_trainer".to_string(),
                port: "Input".to_string(),
                ..Default::default()
            },
        })?;
        
        net.add_connection(reflow_network::connector::Connector {
            from: reflow_network::connector::ConnectionPoint {
                actor: "feature_engineer".to_string(),
                port: "Log".to_string(),
                ..Default::default()
            },
            to: reflow_network::connector::ConnectionPoint {
                actor: "logger".to_string(),
                port: "Input".to_string(),
                ..Default::default()
            },
        })?;
        
        net.add_connection(reflow_network::connector::Connector {
            from: reflow_network::connector::ConnectionPoint {
                actor: "model_trainer".to_string(),
                port: "Log".to_string(),
                ..Default::default()
            },
            to: reflow_network::connector::ConnectionPoint {
                actor: "logger".to_string(),
                port: "Input".to_string(),
                ..Default::default()
            },
        })?;
    }
    
    println!("‚úÖ ML Instance ready on 127.0.0.1:9002");
    
    // Connect to data instance
    println!("üîå Connecting to data instance...");
    network.connect_to_network("127.0.0.1:9001").await?;
    
    // Register remote actors from data instance
    network.register_remote_actor("data_processor", "data_instance").await?;
    
    // Connect data processor to feature engineer
    {
        let local_net = network.get_local_network();
        let net = local_net.read();
        // Note: This would connect via the proxy actor created for data_processor
    }
    
    println!("‚úÖ Connected to data instance");
    
    // Keep running
    loop {
        sleep(Duration::from_secs(1)).await;
    }
}</code></pre></pre>
<h2 id="step-5-api-instance"><a class="header" href="#step-5-api-instance">Step 5: API Instance</a></h2>
<p>Create the API serving instance in <code>instances/api/src/main.rs</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::{
    actor::{Actor, ActorConfig, ActorContext, ActorLoad, MemoryState, Port},
    distributed_network::{DistributedConfig, DistributedNetwork},
    message::{Message, EncodableValue},
    network::NetworkConfig,
};
use shared_actors::{DistributedLoggerActor, MetricsCollectorActor};
use shared_types::*;
use std::{collections::HashMap, sync::Arc, time::Duration};
use actor_macro::actor;
use anyhow::Error;
use tokio::time::sleep;

/// Prediction service that serves ML predictions
#[actor(
    PredictionServiceActor,
    inports::&lt;100&gt;(ModelUpdate, PredictionRequest),
    outports::&lt;50&gt;(PredictionResponse, Log, Metrics),
    state(MemoryState)
)]
async fn prediction_service_actor(
    context: ActorContext,
) -&gt; Result&lt;HashMap&lt;String, Message&gt;, Error&gt; {
    let payload = context.get_payload();
    let state = context.get_state();
    let mut output = HashMap::new();
    
    for (port, message) in payload.iter() {
        match port.as_str() {
            "ModelUpdate" =&gt; {
                if let Message::Object(obj) = message {
                    if let Ok(model) = serde_json::from_value::&lt;TrainedModel&gt;(obj.as_value().clone()) {
                        // Store the latest model
                        {
                            let mut state_lock = state.lock();
                            if let Some(state_data) = state_lock.as_mut_any().downcast_mut::&lt;MemoryState&gt;() {
                                state_data.insert("current_model".to_string(), serde_json::to_value(model.clone())?);
                                state_data.insert("model_version".to_string(), serde_json::json!(model.model_id));
                            }
                        }
                        
                        let log_message = Message::String(
                            format!("Updated prediction model to {} (accuracy: {:.3})",
<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="multi-graph-workspace-tutorial"><a class="header" href="#multi-graph-workspace-tutorial">Multi-Graph Workspace Tutorial</a></h1>
<p>Learn how to build and manage complex multi-graph workflows using Reflow's workspace discovery and composition system.</p>
<h2 id="overview-20"><a class="header" href="#overview-20">Overview</a></h2>
<p>This tutorial demonstrates how to create a multi-graph workspace that automatically discovers and composes multiple graph files into a unified workflow. We'll build a complete example with data processing, machine learning, and monitoring components.</p>
<h2 id="what-youll-build-1"><a class="header" href="#what-youll-build-1">What You'll Build</a></h2>
<p>A workspace containing multiple interconnected graphs:</p>
<pre><code>workspace/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ collector.graph.json      # Data collection pipeline
‚îÇ   ‚îî‚îÄ‚îÄ processing/
‚îÇ       ‚îî‚îÄ‚îÄ transformer.graph.json    # Data transformation pipeline
‚îú‚îÄ‚îÄ ml/
‚îÇ   ‚îî‚îÄ‚îÄ training/
‚îÇ       ‚îî‚îÄ‚îÄ trainer.graph.json        # ML training pipeline
‚îú‚îÄ‚îÄ monitoring/
‚îÇ   ‚îî‚îÄ‚îÄ system_monitor.graph.json     # System monitoring
‚îî‚îÄ‚îÄ simple/
    ‚îú‚îÄ‚îÄ generator.graph.json          # Simple data generator
    ‚îî‚îÄ‚îÄ processor.graph.json          # Simple data processor
</code></pre>
<h2 id="prerequisites-7"><a class="header" href="#prerequisites-7">Prerequisites</a></h2>
<ul>
<li>Basic understanding of Reflow actors and graphs</li>
<li>Familiarity with JSON graph definitions</li>
<li>Understanding of dependency management concepts</li>
</ul>
<h2 id="step-1-project-setup-1"><a class="header" href="#step-1-project-setup-1">Step 1: Project Setup</a></h2>
<p>Create the workspace structure:</p>
<pre><code class="language-bash">mkdir multi_graph_workspace
cd multi_graph_workspace

# Create the directory structure
mkdir -p data/ingestion data/processing ml/training monitoring simple src

# Initialize Cargo project
cargo init --name multi_graph_workspace
</code></pre>
<h3 id="cargotoml-1"><a class="header" href="#cargotoml-1">Cargo.toml</a></h3>
<pre><code class="language-toml">[package]
name = "multi_graph_workspace"
version = "0.1.0"
edition = "2021"

[dependencies]
reflow_network = { path = "../../crates/reflow_network" }
actor_macro = { path = "../../crates/actor_macro" }
tokio = { version = "1.0", features = ["full"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
anyhow = "1.0"
tracing = "0.1"
tracing-subscriber = "0.3"
uuid = { version = "1.0", features = ["v4"] }
chrono = { version = "0.4", features = ["serde"] }
</code></pre>
<h2 id="step-2-create-custom-actors"><a class="header" href="#step-2-create-custom-actors">Step 2: Create Custom Actors</a></h2>
<p>First, let's create the custom actors we'll use across our graphs in <code>src/actors.rs</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>//! Custom actors for the multi-graph workspace example

use std::{collections::HashMap, sync::Arc};
use actor_macro::actor;
use anyhow::Error;
use reflow_network::{
    actor::{Actor, ActorConfig, ActorBehavior, ActorContext, ActorLoad, MemoryState, Port},
    message::Message,
    message::EncodableValue
};

/// Simple timer actor that emits periodic events
#[actor(
    SimpleTimerActor,
    inports::&lt;100&gt;(Start),
    outports::&lt;50&gt;(Output),
    state(MemoryState)
)]
pub async fn simple_timer_actor(
    context: ActorContext,
) -&gt; Result&lt;HashMap&lt;String, Message&gt;, Error&gt; {
    let payload = context.get_payload();
    let state = context.get_state();
    let outport_channels = context.get_outports();

    let interval_secs = context.get_config().get_number("interval").unwrap_or(1000.0);

    // Check if we should start the timer
    if let Some(start_msg) = payload.get("Start") {
        let should_start = match start_msg {
            Message::Boolean(b) =&gt; *b,
            Message::Integer(i) =&gt; *i != 0,
            Message::String(s) =&gt; !s.is_empty(),
            _ =&gt; true,
        };

        if should_start {
            // Store timer state
            {
                let mut state_lock = state.lock();
                if let Some(state_data) = state_lock.as_mut_any().downcast_mut::&lt;MemoryState&gt;() {
                    state_data.insert("running", serde_json::json!(true));
                    state_data.insert("interval", serde_json::json!(interval_secs));
                    state_data.insert("tick_count", serde_json::json!(0));
                }
            }

            // Get max ticks (default to 10 for demos)
            let max_ticks = payload
                .get("MaxTicks")
                .and_then(|m| match m {
                    Message::Integer(i) =&gt; Some(*i as u64),
                    Message::Float(f) =&gt; Some(*f as u64),
                    _ =&gt; None,
                })
                .unwrap_or(10);

            // Spawn timer task with proper load management
            let state_clone = state.clone();
            let outports = outport_channels.clone();
            let load = context.get_load();
            
            // Increase load count for the background task
            load.lock().inc();
            
            tokio::spawn(async move {
                let mut tick_count = 0;
                
                // Ensure we decrease load count when the task finishes
                let _load_guard = scopeguard::guard(load.clone(), |load| {
                    load.lock().dec();
                });
                
                loop {
                    // Check if timer should still be running
                    let should_continue = {
                        let state_lock = state_clone.lock();
                        if let Some(state_data) = state_lock.as_any().downcast_ref::&lt;MemoryState&gt;() {
                            let running = state_data
                                .get("running")
                                .and_then(|v| v.as_bool())
                                .unwrap_or(false);
                            let current_ticks = state_data
                                .get("tick_count")
                                .and_then(|v| v.as_i64())
                                .unwrap_or(0) as u64;
                            running &amp;&amp; current_ticks &lt; max_ticks
                        } else {
                            false
                        }
                    };

                    if !should_continue {
                        break;
                    }

                    // Wait for interval
                    tokio::time::sleep(tokio::time::Duration::from_secs(interval_secs as u64)).await;

                    // Increment tick count
                    tick_count += 1;
                    
                    // Update state
                    {
                        let mut state_lock = state_clone.lock();
                        if let Some(state_data) = state_lock.as_mut_any().downcast_mut::&lt;MemoryState&gt;() {
                            state_data.insert("tick_count", serde_json::json!(tick_count));
                        }
                    }

                    // Send tick message
                    let tick_message = Message::object(
                        EncodableValue::from(serde_json::json!({
                            "tick": tick_count,
                            "timestamp": chrono::Utc::now().to_rfc3339(),
                            "source": "SimpleTimerActor",
                            "max_ticks": max_ticks
                        }))
                    );

                    if outports.0.send_async(HashMap::from([
                        ("Output".to_owned(), tick_message)
                    ])).await.is_err() {
                        break;
                    }
                }
            });

            println!("‚úÖ SimpleTimerActor started with interval: {}s", interval_secs);
        }
    }

    Ok(HashMap::new())
}

/// Simple logger actor that logs incoming messages
#[actor(
    SimpleLoggerActor,
    inports::&lt;100&gt;(Input, Prefix),
    outports::&lt;50&gt;(Output),
    state(MemoryState)
)]
pub async fn simple_logger_actor(
    context: ActorContext,
) -&gt; Result&lt;HashMap&lt;String, Message&gt;, Error&gt; {
    let payload = context.get_payload();
    let state = context.get_state();

    if let Some(input_msg) = payload.get("Input") {
        // Get prefix from payload or state
        let prefix = if let Some(Message::String(p)) = payload.get("Prefix") {
            p.clone()
        } else {
            let state_lock = state.lock();
            if let Some(state_data) = state_lock.as_any().downcast_ref::&lt;MemoryState&gt;() {
                state_data
                    .get("prefix")
                    .and_then(|v| v.as_str())
                    .unwrap_or("LOG")
                    .to_string().into()
            } else {
                "LOG".to_string().into()
            }
        };

        // Log the message with timestamp
        let timestamp = chrono::Utc::now().format("%H:%M:%S%.3f");
        println!("[{}] {}: {:?}", timestamp, prefix, input_msg);

        // Update log count in state
        {
            let mut state_lock = state.lock();
            if let Some(state_data) = state_lock.as_mut_any().downcast_mut::&lt;MemoryState&gt;() {
                let count = state_data
                    .get("log_count")
                    .and_then(|v| v.as_i64())
                    .unwrap_or(0) + 1;
                state_data.insert("log_count", serde_json::json!(count));
            }
        }

        // Pass through the input
        Ok(HashMap::from([("Output".to_owned(), input_msg.clone())]))
    } else {
        Ok(HashMap::new())
    }
}

/// Data generator actor that creates sample data
#[actor(
    DataGeneratorActor,
    inports::&lt;100&gt;(Trigger, Type),
    outports::&lt;50&gt;(Output),
    state(MemoryState)
)]
pub async fn data_generator_actor(
    context: ActorContext,
) -&gt; Result&lt;HashMap&lt;String, Message&gt;, Error&gt; {
    let payload = context.get_payload();
    let state = context.get_state();

    if payload.contains_key("Trigger") {
        // Get data type from payload or state
        let data_type = if let Some(Message::String(t)) = payload.get("Type") {
            t.clone()
        } else {
            let state_lock = state.lock();
            if let Some(state_data) = state_lock.as_any().downcast_ref::&lt;MemoryState&gt;() {
                state_data
                    .get("data_type")
                    .and_then(|v| v.as_str())
                    .unwrap_or("number")
                    .to_string().into()
            } else {
                "number".to_string().into()
            }
        };

        // Update generation count
        let generation_count = {
            let mut state_lock = state.lock();
            if let Some(state_data) = state_lock.as_mut_any().downcast_mut::&lt;MemoryState&gt;() {
                let count = state_data
                    .get("generation_count")
                    .and_then(|v| v.as_i64())
                    .unwrap_or(0) + 1;
                state_data.insert("generation_count", serde_json::json!(count));
                count
            } else {
                1
            }
        };

        // Generate data based on type
        let generated_data = match data_type.as_str() {
            "number" =&gt; Message::Integer(generation_count),
            "string" =&gt; Message::String(format!("generated_data_{}", generation_count).into()),
            "object" =&gt; Message::object(
                EncodableValue::from(serde_json::json!({
                    "id": generation_count,
                    "timestamp": chrono::Utc::now().to_rfc3339(),
                    "type": "generated",
                    "value": format!("sample_value_{}", generation_count)
                }))
            ),
            _ =&gt; Message::String(format!("unknown_type_data_{}", generation_count).into()),
        };

        Ok(HashMap::from([("Output".to_owned(), generated_data)]))
    } else {
        Ok(HashMap::new())
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="step-3-define-graph-files"><a class="header" href="#step-3-define-graph-files">Step 3: Define Graph Files</a></h2>
<h3 id="simple-data-generator-simplegeneratorgraphjson"><a class="header" href="#simple-data-generator-simplegeneratorgraphjson">Simple Data Generator (<code>simple/generator.graph.json</code>)</a></h3>
<pre><code class="language-json">{
  "caseSensitive": false,
  "properties": {
    "name": "generator",
    "description": "Simple data generator",
    "version": "1.0.0",
    "namespace": "simple"
  },
  "processes": {
    "timer": {
      "component": "SimpleTimerActor",
      "metadata": {
        "description": "Generates periodic triggers"
      }
    },
    "data_generator": {
      "component": "DataGeneratorActor", 
      "metadata": {
        "description": "Generates sample data"
      }
    }
  },
  "connections": [
    {
      "from": { "nodeId": "timer", "portId": "Output" },
      "to": { "nodeId": "data_generator", "portId": "Trigger" },
      "metadata": {}
    }
  ],
  "inports": {
    "start": {
      "nodeId": "timer",
      "portId": "Start"
    }
  },
  "outports": {
    "data": {
      "nodeId": "data_generator",
      "portId": "Output"
    }
  },
  "groups": [],
  "providedInterfaces": {
    "data_output": {
      "interfaceId": "data_output",
      "processName": "data_generator",
      "portName": "Output",
      "dataType": "GeneratedData",
      "description": "Generated sample data",
      "required": false
    }
  },
  "requiredInterfaces": {},
  "graphDependencies": [],
  "externalConnections": []
}
</code></pre>
<h3 id="simple-data-processor-simpleprocessorgraphjson"><a class="header" href="#simple-data-processor-simpleprocessorgraphjson">Simple Data Processor (<code>simple/processor.graph.json</code>)</a></h3>
<pre><code class="language-json">{
  "caseSensitive": false,
  "properties": {
    "name": "processor",
    "description": "Simple data processor",
    "version": "1.0.0",
    "namespace": "simple",
    "dependencies": ["generator"]
  },
  "processes": {
    "logger": {
      "component": "SimpleLoggerActor",
      "metadata": {
        "description": "Logs processed data"
      }
    }
  },
  "connections": [],
  "inports": {
    "data": {
      "nodeId": "logger",
      "portId": "Input"
    }
  },
  "outports": {
    "processed": {
      "nodeId": "logger",
      "portId": "Output"
    }
  },
  "groups": [],
  "providedInterfaces": {
    "processed_output": {
      "interfaceId": "processed_output",
      "processName": "logger",
      "portName": "Output",
      "dataType": "ProcessedData",
      "description": "Processed data output",
      "required": false
    }
  },
  "requiredInterfaces": {
    "data_input": {
      "interfaceId": "data_input",
      "processName": "logger",
      "portName": "Input",
      "dataType": "GeneratedData",
      "description": "Input data to process",
      "required": true
    }
  },
  "graphDependencies": [
    {
      "graphName": "generator",
      "namespace": "simple",
      "versionConstraint": "&gt;=1.0.0",
      "required": true,
      "description": "Requires data generator for input"
    }
  ],
  "externalConnections": [
    {
      "connectionId": "generator_to_processor",
      "targetGraph": "generator",
      "targetNamespace": "simple",
      "fromProcess": "data_generator",
      "fromPort": "Output",
      "toProcess": "logger",
      "toPort": "Input",
      "description": "Connect generator output to processor input"
    }
  ]
}
</code></pre>
<h3 id="data-collection-pipeline-dataingestioncollectorgraphjson"><a class="header" href="#data-collection-pipeline-dataingestioncollectorgraphjson">Data Collection Pipeline (<code>data/ingestion/collector.graph.json</code>)</a></h3>
<pre><code class="language-json">{
  "caseSensitive": false,
  "properties": {
    "name": "collector",
    "description": "Data collection pipeline",
    "version": "1.0.0",
    "namespace": "data/ingestion"
  },
  "processes": {
    "api_collector": {
      "component": "DataGeneratorActor",
      "metadata": {
        "description": "Collects data from API endpoints",
        "config": {
          "data_type": "object",
          "collection_rate": "high"
        }
      }
    },
    "validator": {
      "component": "SimpleLoggerActor",
      "metadata": {
        "description": "Validates collected data"
      }
    }
  },
  "connections": [
    {
      "from": { "nodeId": "api_collector", "portId": "Output" },
      "to": { "nodeId": "validator", "portId": "Input" },
      "metadata": {}
    }
  ],
  "inports": {
    "trigger": {
      "nodeId": "api_collector",
      "portId": "Trigger"
    }
  },
  "outports": {
    "validated_data": {
      "nodeId": "validator",
      "portId": "Output"
    }
  },
  "groups": [],
  "providedInterfaces": {
    "raw_data_output": {
      "interfaceId": "raw_data_output",
      "processName": "validator",
      "portName": "Output",
      "dataType": "ValidatedData",
      "description": "Validated raw data output",
      "required": false
    }
  },
  "requiredInterfaces": {},
  "graphDependencies": [],
  "externalConnections": []
}
</code></pre>
<h3 id="data-transformation-pipeline-dataprocessingtransformergraphjson"><a class="header" href="#data-transformation-pipeline-dataprocessingtransformergraphjson">Data Transformation Pipeline (<code>data/processing/transformer.graph.json</code>)</a></h3>
<pre><code class="language-json">{
  "caseSensitive": false,
  "properties": {
    "name": "transformer",
    "description": "Data transformation pipeline",
    "version": "1.0.0",
    "namespace": "data/processing",
    "dependencies": ["collector"]
  },
  "processes": {
    "cleaner": {
      "component": "SimpleLoggerActor",
      "metadata": {
        "description": "Cleans and normalizes data"
      }
    },
    "enricher": {
      "component": "DataGeneratorActor",
      "metadata": {
        "description": "Enriches data with additional context"
      }
    }
  },
  "connections": [
    {
      "from": { "nodeId": "cleaner", "portId": "Output" },
      "to": { "nodeId": "enricher", "portId": "Trigger" },
      "metadata": {}
    }
  ],
  "inports": {
    "raw_data": {
      "nodeId": "cleaner",
      "portId": "Input"
    }
  },
  "outports": {
    "clean_data": {
      "nodeId": "enricher",
      "portId": "Output"
    }
  },
  "groups": [],
  "providedInterfaces": {
    "clean_data_output": {
      "interfaceId": "clean_data_output",
      "processName": "enricher",
      "portName": "Output",
      "dataType": "CleanData",
      "description": "Cleaned and enriched data",
      "required": false
    }
  },
  "requiredInterfaces": {
    "raw_data_input": {
      "interfaceId": "raw_data_input",
      "processName": "cleaner",
      "portName": "Input",
      "dataType": "ValidatedData",
      "description": "Raw data input from collector",
      "required": true
    }
  },
  "graphDependencies": [
    {
      "graphName": "collector",
      "namespace": "data/ingestion",
      "versionConstraint": "&gt;=1.0.0",
      "required": true,
      "description": "Requires data collector for input"
    }
  ],
  "externalConnections": [
    {
      "connectionId": "collector_to_transformer",
      "targetGraph": "collector",
      "targetNamespace": "data/ingestion",
      "fromProcess": "validator",
      "fromPort": "Output",
      "toProcess": "cleaner",
      "toPort": "Input",
      "description": "Connect collector output to transformer input"
    }
  ]
}
</code></pre>
<h3 id="ml-training-pipeline-mltrainingtrainergraphjson"><a class="header" href="#ml-training-pipeline-mltrainingtrainergraphjson">ML Training Pipeline (<code>ml/training/trainer.graph.json</code>)</a></h3>
<pre><code class="language-json">{
  "caseSensitive": false,
  "properties": {
    "name": "trainer",
    "description": "ML training pipeline",
    "version": "1.0.0",
    "namespace": "ml/training",
    "dependencies": ["transformer"]
  },
  "processes": {
    "feature_engineer": {
      "component": "SimpleLoggerActor",
      "metadata": {
        "description": "Engineers features for ML training"
      }
    },
    "model_trainer": {
      "component": "DataGeneratorActor",
      "metadata": {
        "description": "Trains ML models",
        "config": {
          "data_type": "object"
        }
      }
    }
  },
  "connections": [
    {
      "from": { "nodeId": "feature_engineer", "portId": "Output" },
      "to": { "nodeId": "model_trainer", "portId": "Trigger" },
      "metadata": {}
    }
  ],
  "inports": {
    "training_data": {
      "nodeId": "feature_engineer",
      "portId": "Input"
    }
  },
  "outports": {
    "trained_model": {
      "nodeId": "model_trainer",
      "portId": "Output"
    }
  },
  "groups": [],
  "providedInterfaces": {
    "model_output": {
      "interfaceId": "model_output",
      "processName": "model_trainer",
      "portName": "Output",
      "dataType": "TrainedModel",
      "description": "Trained ML model",
      "required": false
    }
  },
  "requiredInterfaces": {
    "clean_data_input": {
      "interfaceId": "clean_data_input",
      "processName": "feature_engineer",
      "portName": "Input",
      "dataType": "CleanData",
      "description": "Clean data for training",
      "required": true
    }
  },
  "graphDependencies": [
    {
      "graphName": "transformer",
      "namespace": "data/processing",
      "versionConstraint": "&gt;=1.0.0",
      "required": true,
      "description": "Requires clean data from transformer"
    }
  ],
  "externalConnections": [
    {
      "connectionId": "transformer_to_trainer",
      "targetGraph": "transformer",
      "targetNamespace": "data/processing",
      "fromProcess": "enricher",
      "fromPort": "Output",
      "toProcess": "feature_engineer",
      "toPort": "Input",
      "description": "Connect transformer output to trainer input"
    }
  ]
}
</code></pre>
<h3 id="system-monitor-monitoringsystem_monitorgraphjson"><a class="header" href="#system-monitor-monitoringsystem_monitorgraphjson">System Monitor (<code>monitoring/system_monitor.graph.json</code>)</a></h3>
<pre><code class="language-json">{
  "caseSensitive": false,
  "properties": {
    "name": "system_monitor",
    "description": "System monitoring and metrics collection",
    "version": "1.0.0",
    "namespace": "monitoring",
    "dependencies": ["trainer", "transformer", "collector"]
  },
  "processes": {
    "metrics_collector": {
      "component": "SimpleLoggerActor",
      "metadata": {
        "description": "Collects system metrics"
      }
    },
    "alert_manager": {
      "component": "DataGeneratorActor",
      "metadata": {
        "description": "Manages alerts and notifications"
      }
    }
  },
  "connections": [
    {
      "from": { "nodeId": "metrics_collector", "portId": "Output" },
      "to": { "nodeId": "alert_manager", "portId": "Trigger" },
      "metadata": {}
    }
  ],
  "inports": {
    "metrics": {
      "nodeId": "metrics_collector",
      "portId": "Input"
    }
  },
  "outports": {
    "alerts": {
      "nodeId": "alert_manager",
      "portId": "Output"
    }
  },
  "groups": [],
  "providedInterfaces": {
    "alert_output": {
      "interfaceId": "alert_output",
      "processName": "alert_manager",
      "portName": "Output",
      "dataType": "Alert",
      "description": "System alerts and notifications",
      "required": false
    }
  },
  "requiredInterfaces": {
    "metrics_input": {
      "interfaceId": "metrics_input",
      "processName": "metrics_collector",
      "portName": "Input",
      "dataType": "SystemMetrics",
      "description": "System metrics for monitoring",
      "required": true
    }
  },
  "graphDependencies": [
    {
      "graphName": "trainer",
      "namespace": "ml/training",
      "versionConstraint": "&gt;=1.0.0",
      "required": false,
      "description": "Monitors ML training pipeline"
    },
    {
      "graphName": "transformer",
      "namespace": "data/processing",
      "versionConstraint": "&gt;=1.0.0",
      "required": false,
      "description": "Monitors data processing pipeline"
    },
    {
      "graphName": "collector",
      "namespace": "data/ingestion",
      "versionConstraint": "&gt;=1.0.0",
      "required": false,
      "description": "Monitors data collection pipeline"
    }
  ],
  "externalConnections": []
}
</code></pre>
<h2 id="step-4-workspace-discovery-example"><a class="header" href="#step-4-workspace-discovery-example">Step 4: Workspace Discovery Example</a></h2>
<p>Create the main application in <code>src/main.rs</code>:</p>
<pre><pre class="playground"><code class="language-rust">use reflow_network::{
    multi_graph::{
        workspace::{WorkspaceDiscovery, WorkspaceConfig},
        GraphComposer, GraphComposition, GraphSource,
    },
};
use std::{collections::HashMap, path::PathBuf};

mod actors;
pub use actors::*;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    tracing_subscriber::fmt::init();

    println!("üöÄ Multi-Graph Workspace Example");
    println!("===============================");

    // Configure workspace discovery
    let workspace_config = WorkspaceConfig {
        root_path: PathBuf::from("."),
        graph_patterns: vec![
            "**/*.graph.json".to_string(),
            "**/*.graph.yaml".to_string(),
        ],
        excluded_paths: vec![
            "**/target/**".to_string(),
            "**/.git/**".to_string(),
        ],
        max_depth: Some(5),
        namespace_strategy: reflow_network::multi_graph::NamespaceStrategy::FolderStructure,
    };

    // Discover workspace
    let discovery = WorkspaceDiscovery::new(workspace_config);
    let workspace = discovery.discover_workspace().await?;

    println!("üìä Workspace Discovery Results:");
    println!("  Discovered {} graphs across {} namespaces",
        workspace.graphs.len(),
        workspace.namespaces.len()
    );

    // Print discovered graphs by namespace
    for (namespace, info) in &amp;workspace.namespaces {
        println!("\nüìÅ Namespace: {}", namespace);
        println!("  Path: {}", info.path.display());
        println!("  Graphs:");
        for graph_name in &amp;info.graphs {
            let graph_meta = workspace.graphs.iter()
                .find(|g| g.graph.properties.get("name").and_then(|v| v.as_str()).unwrap_or("") == graph_name)
                .unwrap();
            println!("    üìà {} ({})", graph_name, graph_meta.file_info.path.file_name().unwrap().to_string_lossy());
            
            // Show dependencies
            if let Some(deps) = graph_meta.graph.properties.get("dependencies").and_then(|v| v.as_array()) {
                if !deps.is_empty() {
                    print!("      Dependencies: ");
                    for (i, dep) in deps.iter().enumerate() {
                        if i &gt; 0 { print!(", "); }
                        print!("{}", dep.as_str().unwrap_or("unknown"));
                    }
                    println!();
                }
            }
        }
    }

    // Analyze dependencies
    println!("\nüîç Dependency Analysis:");
    if !workspace.analysis.dependencies.is_empty() {
        for dep in &amp;workspace.analysis.dependencies {
            println!("  üì¶ {} depends on {} ({})",
                dep.dependent_graph,
                dep.dependency_graph,
                if dep.required { "required" } else { "optional" }
            );
        }
    } else {
        println!("  No dependencies declared");
    }

    // Show provided and required interfaces
    println!("\nüîå Interface Analysis:");
    
    if !workspace.analysis.provided_interfaces.is_empty() {
        println!("  Provided Interfaces:");
        for interface in &amp;workspace.analysis.provided_interfaces {
            println!("    üì§ {}: {} provides {}",
                interface.namespace,
                interface.graph_name,
                interface.interface_name
            );
        }
    }

    if !workspace.analysis.required_interfaces.is_empty() {
        println!("  Required Interfaces:");
        for interface in &amp;workspace.analysis.required_interfaces {
            println!("    üì• {}: {} requires {}",
                interface.namespace,
                interface.graph_name,
                interface.interface_name
            );
        }
    }

    // Create graph composition
    println!("\nüîß Creating Graph Composition...");
    
    let sources: Vec&lt;GraphSource&gt; = workspace.graphs.iter()
        .map(|g| GraphSource::GraphExport(g.graph.clone()))
        .collect();

    let composition = GraphComposition {
        sources,
        connections: vec![], // Inter-graph connections would go here
        shared_resources: vec![],
        properties: HashMap::from([
            ("name".to_string(), serde_json::json!("multi_graph_workspace")),
            ("description".to_string(), serde_json::json!("Composed multi-graph workspace")),
        ]),
        case_sensitive: Some(false),
        metadata: None,
    };

    // Compose the graphs
    let mut composer = GraphComposer::new();
    let composed_graph = composer.compose_graphs(composition).await?;

    println!("‚úÖ Successfully composed workspace into unified graph!");
    println!("  Total processes: {}", composed_graph.export().processes.len());
    println!("  Total connections: {}", composed_graph.export().connections.len());

    // Show composed processes by namespace
    println!("\nüìã Composed Graph Structure:");
    let mut namespaced_processes: HashMap&lt;String, Vec&lt;String&gt;&gt; = HashMap::new();
    
    for (process_name, _) in &amp;composed_graph.export().processes {
        if let Some(namespace_sep) = process_name.find('/') {
            let namespace = &amp;process_name[..namespace_sep];
            let process = &amp;process_name[namespace_sep + 1..];
            namespaced_processes
                .entry(namespace.to_string())
                .or_insert_with(Vec::new)
                .push(process.to_string());
        } else {
            namespaced_processes
                .entry("root".to_string())
                .or_insert_with(Vec::new)
                .push(process_name.clone());
        }
    }
    
    for (namespace, processes) in &amp;namespaced_processes {
        println!("  üìÅ {}: {} processes", namespace, processes.len());
        for process in processes {
            println!("    üìà {}", process);
        }
    }

    println!("\nüéØ Workspace composition complete!");
    
    Ok(())
}</code></pre></pre>
<h2 id="step-5-running-the-example"><a class="header" href="#step-5-running-the-example">Step 5: Running the Example</a></h2>
<p>Create a simple workspace example in <code>simple_workspace_example.rs</code>:</p>
<pre><pre class="playground"><code class="language-rust">use reflow_network::{
    multi_graph::workspace::{WorkspaceDiscovery, WorkspaceConfig},
    network::{Network, NetworkConfig},
};
use std::path::PathBuf;

mod actors;
use actors::*;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    tracing_subscriber::fmt::init();

    println!("üöÄ Simple Multi-Graph Workspace Example");

    // Simple workspace discovery
    let workspace_config = WorkspaceConfig {
        root_path: PathBuf::from("simple"),
        graph_patterns: vec!["*.graph.json".to_string()],
        excluded_paths: vec![],
        max_depth: Some(2),
        namespace_strategy: reflow_network::multi_graph::NamespaceStrategy::FolderStructure,
    };

    let discovery = WorkspaceDiscovery::new(workspace_config);
    let workspace = discovery.discover_workspace().await?;

    println!("Found {} graphs:", workspace.graphs.len());
    for graph_meta in &amp;workspace.graphs {
        println!("  - {} ({})", 
            graph_meta.graph.properties.get("name").and_then(|v| v.as_str()).unwrap_or("unnamed"),
            graph_meta.discovered_namespace
        );
    }

    // Create a simple network to test one of the graphs
    let mut network = Network::new(NetworkConfig::default());

    // Register our actors
    network.register_actor("timer", SimpleTimerActor::new())?;
    network.register_actor("generator", DataGeneratorActor::new())?;
    network.register_actor("logger", SimpleLoggerActor::new())?;

    // Create simple workflow nodes
    network.add_node("timer_node", "timer", None)?;
    network.add_node("generator_node", "generator", None)?;
    network.add_node("logger_node", "logger", None)?;

    // Connect them
    network.add_connection(reflow_network::connector::Connector {
        from: reflow_network::connector::ConnectionPoint {
            actor: "timer_node".to_string(),
            port: "Output".to_string(),
            ..Default::default()
        },
        to: reflow_network::connector::ConnectionPoint {
            actor: "generator_node".to_string(),
            port: "Trigger".to_string(),
            ..Default::default()
        },
    })?;

    network.add_connection(reflow_network::connector::Connector {
        from: reflow_network::connector::ConnectionPoint {
            actor: "generator_node".to_string(),
            port: "Output".to_string(),
            ..Default::default()
        },
        to: reflow_network::connector::ConnectionPoint {
            actor: "logger_node".to_string(),
            port: "Input".to_string(),
            ..Default::default()
        },
    })?;

    // Start the network
    network.start().await?;

    println!("‚úÖ Network started. Starting timer...");

    // Start the timer
    network.send_to_actor("timer_node", "Start", reflow_network::message::Message::Boolean(true))?;

    // Let it run for a bit
    tokio::time::sleep(tokio::time::Duration::from_secs(15)).await;

    network.shutdown();
    println!("üéØ Simple example complete!");

    Ok(())
}</code></pre></pre>
<h2 id="usage"><a class="header" href="#usage">Usage</a></h2>
<h3 id="running-the-full-workspace-example"><a class="header" href="#running-the-full-workspace-example">Running the Full Workspace Example</a></h3>
<pre><code class="language-bash"># In your workspace directory
cargo run --bin multi_graph_workspace
</code></pre>
<p>Expected output:</p>
<pre><code>üöÄ Multi-Graph Workspace Example
üìä Workspace Discovery Results:
  Discovered 6 graphs across 4 namespaces

üìÅ Namespace: simple
  Path: ./simple
  Graphs:
    üìà generator (generator.graph.json)
    üìà processor (processor.graph.json)
      Dependencies: generator

üìÅ Namespace: data/ingestion
  Path: ./data/ingestion
  Graphs:
    üìà collector (collector.graph.json)

üìÅ Namespace: data/processing
  Path: ./data/processing
  Graphs:
    üìà transformer (transformer.graph.json)
      Dependencies: collector

üìÅ Namespace: ml/training
  Path: ./ml/training
  Graphs:
    üìà trainer (trainer.graph.json)
      Dependencies: transformer

üìÅ Namespace: monitoring
  Path: ./monitoring
  Graphs:
    üìà system_monitor (system_monitor.graph.json)
      Dependencies: trainer, transformer, collector

üîç Dependency Analysis:
  üì¶ processor depends on generator (required)
  üì¶ transformer depends on collector (required)
  üì¶ trainer depends on transformer (required)
  üì¶ system_monitor depends on trainer (optional)
  üì¶ system_monitor depends on transformer (optional)
  üì¶ system_monitor depends on collector (optional)

üîå Interface Analysis:
  Provided Interfaces:
    üì§ simple: generator provides data_output
    üì§ simple: processor provides processed_output
    üì§ data/ingestion: collector provides raw_data_output
    üì§ data/processing: transformer provides clean_data_output
    üì§ ml/training: trainer provides model_output
    üì§ monitoring: system_monitor provides alert_output
  Required Interfaces:
    üì• simple: processor requires data_input
    üì• data/processing: transformer requires raw_data_input
    üì• ml/training: trainer requires clean_data_input
    üì• monitoring: system_monitor requires metrics_input

üîß Creating Graph Composition...
‚úÖ Successfully composed workspace into unified graph!
  Total processes: 12
  Total connections: 8

üìã Composed Graph Structure:
  üìÅ simple: 3 processes
    üìà timer
    üìà data_generator
    üìà logger
  üìÅ data: 3 processes
    üìà api_collector
    üìà validator
    üìà cleaner
    üìà enricher
  üìÅ ml: 2 processes
    üìà feature_engineer
    üìà model_trainer
  üìÅ monitoring: 2 processes
    üìà metrics_collector
    üìà alert_manager

üéØ Workspace composition complete!
</code></pre>
<h3 id="running-the-simple-example"><a class="header" href="#running-the-simple-example">Running the Simple Example</a></h3>
<pre><code class="language-bash">cargo run --bin simple_workspace_example
</code></pre>
<p>Expected output:</p>
<pre><code>üöÄ Simple Multi-Graph Workspace Example
Found 2 graphs:
  - generator (simple)
  - processor (simple)
‚úÖ Network started. Starting timer...
[12:34:56.123] LOG: {"tick":1,"timestamp":"2023-12-01T12:34:56.123Z","source":"SimpleTimerActor","max_ticks":10}
[12:34:57.124] LOG: {"tick":2,"timestamp":"2023-12-01T12:34:57.124Z","source":"SimpleTimerActor","max_ticks":10}
...
üéØ Simple example complete!
</code></pre>
<h2 id="key-concepts-demonstrated-1"><a class="header" href="#key-concepts-demonstrated-1">Key Concepts Demonstrated</a></h2>
<h3 id="1-automatic-discovery"><a class="header" href="#1-automatic-discovery">1. <strong>Automatic Discovery</strong></a></h3>
<ul>
<li>Workspace automatically finds all <code>.graph.json</code> files</li>
<li>Uses folder structure as natural namespaces</li>
<li>Handles dependency analysis</li>
</ul>
<h3 id="2-namespace-organization"><a class="header" href="#2-namespace-organization">2. <strong>Namespace Organization</strong></a></h3>
<ul>
<li><code>simple/</code> ‚Üí <code>simple</code> namespace</li>
<li><code>data/ingestion/</code> ‚Üí <code>data/ingestion</code> namespace</li>
<li><code>ml/training/</code> ‚Üí <code>ml/training</code> namespace</li>
</ul>
<h3 id="3-dependency-management"><a class="header" href="#3-dependency-management">3. <strong>Dependency Management</strong></a></h3>
<ul>
<li>Graphs declare dependencies on other graphs</li>
<li>System validates and orders graphs by dependencies</li>
<li>Supports optional and required dependencies</li>
</ul>
<h3 id="4-interface-definitions"><a class="header" href="#4-interface-definitions">4. <strong>Interface Definitions</strong></a></h3>
<ul>
<li>Graphs declare provided and required interfaces</li>
<li>System analyzes interface compatibility</li>
<li>Enables automatic connection suggestions</li>
</ul>
<h3 id="5-graph-composition"><a class="header" href="#5-graph-composition">5. <strong>Graph Composition</strong></a></h3>
<ul>
<li>Multiple graphs composed into unified workflow</li>
<li>Namespace prefixes prevent name conflicts</li>
<li>Maintains original graph structure and relationships</li>
</ul>
<h2 id="advanced-features-6"><a class="header" href="#advanced-features-6">Advanced Features</a></h2>
<h3 id="custom-namespace-strategies-1"><a class="header" href="#custom-namespace-strategies-1">Custom Namespace Strategies</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::NamespaceStrategy;

// Custom semantic-based namespacing
let custom_strategy = NamespaceStrategy::custom("semantic_based", None)?;

let workspace_config = WorkspaceConfig {
    namespace_strategy: custom_strategy,
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h3 id="selective-graph-loading"><a class="header" href="#selective-graph-loading">Selective Graph Loading</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Only load graphs matching specific patterns
let workspace_config = WorkspaceConfig {
    graph_patterns: vec![
        "data/**/*.graph.json".to_string(),  // Only data pipelines
        "ml/**/*.graph.json".to_string(),    // Only ML pipelines
    ],
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h3 id="interface-based-connections-2"><a class="header" href="#interface-based-connections-2">Interface-Based Connections</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::multi_graph::GraphConnectionBuilder;

// Connect graphs using interface definitions
let mut connection_builder = GraphConnectionBuilder::new(workspace);

connection_builder
    .connect_interface(
        "generator",     // Source graph
        "data_output",   // Source interface
        "processor",     // Target graph
        "data_input"     // Target interface
    )?;

let connections = connection_builder.build();
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-22"><a class="header" href="#best-practices-22">Best Practices</a></h2>
<h3 id="1-graph-organization"><a class="header" href="#1-graph-organization">1. <strong>Graph Organization</strong></a></h3>
<ul>
<li>Use descriptive folder structures</li>
<li>Group related graphs in same namespace</li>
<li>Keep dependencies minimal and explicit</li>
</ul>
<h3 id="2-interface-design"><a class="header" href="#2-interface-design">2. <strong>Interface Design</strong></a></h3>
<ul>
<li>Define clear input/output interfaces</li>
<li>Use descriptive interface names</li>
<li>Document expected data types</li>
</ul>
<h3 id="3-dependency-management-1"><a class="header" href="#3-dependency-management-1">3. <strong>Dependency Management</strong></a></h3>
<ul>
<li>Declare all dependencies explicitly</li>
<li>Use version constraints for stability</li>
<li>Minimize circular dependencies</li>
</ul>
<h3 id="4-testing"><a class="header" href="#4-testing">4. <strong>Testing</strong></a></h3>
<ul>
<li>Test individual graphs before composition</li>
<li>Validate interfaces between graphs</li>
<li>Test composed workflows end-to-end</li>
</ul>
<h2 id="next-steps-32"><a class="header" href="#next-steps-32">Next Steps</a></h2>
<ol>
<li><strong>Try the distributed networks tutorial</strong> to learn about cross-network communication</li>
<li><strong>Explore the graph composition API</strong> for advanced composition scenarios</li>
<li><strong>Build your own multi-graph workspace</strong> with domain-specific actors and workflows</li>
</ol>
<p>The multi-graph workspace system enables you to build complex, modular workflows that scale naturally with your project's complexity while maintaining clean separation of concerns.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="wasm-actor-development-tutorial"><a class="header" href="#wasm-actor-development-tutorial">WASM Actor Development Tutorial</a></h1>
<p>Learn how to develop actors specifically for browser environments using Reflow's WebAssembly bindings.</p>
<h2 id="overview-21"><a class="header" href="#overview-21">Overview</a></h2>
<p>This tutorial covers creating actors that leverage browser APIs, handle asynchronous operations, and provide interactive user experiences. We'll build several example actors that demonstrate common patterns in browser-based workflow development.</p>
<h2 id="prerequisites-8"><a class="header" href="#prerequisites-8">Prerequisites</a></h2>
<ul>
<li>Basic understanding of JavaScript and async programming</li>
<li>Familiarity with <a href="tutorials/../getting-started/basic-concepts.html">Reflow's actor concepts</a></li>
<li><a href="tutorials/../deployment/browser-deployment.html">WASM setup completed</a></li>
</ul>
<h2 id="tutorial-structure"><a class="header" href="#tutorial-structure">Tutorial Structure</a></h2>
<p>We'll build increasingly complex actors:</p>
<ol>
<li><strong>Data Transformation Actor</strong> - Basic processing patterns</li>
<li><strong>Web API Client Actor</strong> - HTTP requests and async operations</li>
<li><strong>File Processing Actor</strong> - Browser file handling</li>
<li><strong>Real-time Data Actor</strong> - WebSocket connections and streaming</li>
<li><strong>Interactive UI Actor</strong> - DOM manipulation and user interaction</li>
</ol>
<h2 id="1-data-transformation-actor"><a class="header" href="#1-data-transformation-actor">1. Data Transformation Actor</a></h2>
<p>Let's start with a versatile data transformation actor that handles various data formats.</p>
<h3 id="creating-the-actor"><a class="header" href="#creating-the-actor">Creating the Actor</a></h3>
<pre><code class="language-javascript">class DataTransformActor {
    constructor() {
        this.inports = ["data", "config"];
        this.outports = ["result", "error", "stats"];
        
        // Default transformation configuration
        this.config = {
            operation: "normalize",  // normalize, aggregate, filter, map
            outputFormat: "json",    // json, csv, xml
            precision: 2,           // for numeric operations
            batchSize: 100          // for batch processing
        };
    }

    run(context) {
        // Update configuration if provided
        if (context.input.config) {
            this.updateConfig(context.input.config);
        }

        // Process incoming data
        if (context.input.data !== undefined) {
            try {
                const result = this.transform(context.input.data, context);
                this.updateStats(context, result);
                context.send({ result });
            } catch (error) {
                this.handleError(error, context);
            }
        }
    }

    updateConfig(newConfig) {
        this.config = { ...this.config, ...newConfig };
        console.log("Configuration updated:", this.config);
    }

    transform(data, context) {
        switch (this.config.operation) {
            case "normalize":
                return this.normalizeData(data);
            case "aggregate": 
                return this.aggregateData(data, context);
            case "filter":
                return this.filterData(data);
            case "map":
                return this.mapData(data);
            default:
                throw new Error(`Unknown operation: ${this.config.operation}`);
        }
    }

    normalizeData(data) {
        if (!Array.isArray(data)) {
            data = [data];
        }

        return data.map(item =&gt; {
            if (typeof item === 'number') {
                return Number(item.toFixed(this.config.precision));
            }
            
            if (typeof item === 'string') {
                return item.trim().toLowerCase();
            }
            
            if (typeof item === 'object' &amp;&amp; item !== null) {
                const normalized = {};
                for (const [key, value] of Object.entries(item)) {
                    // Normalize keys to camelCase
                    const normalizedKey = key.replace(/_([a-z])/g, (g) =&gt; g[1].toUpperCase());
                    normalized[normalizedKey] = typeof value === 'string' ? 
                        value.trim() : value;
                }
                return normalized;
            }
            
            return item;
        });
    }

    aggregateData(data, context) {
        if (!Array.isArray(data)) {
            data = [data];
        }

        // Get existing aggregation state
        const aggregated = context.state.get('aggregated') || [];
        const combined = aggregated.concat(data);
        
        // Keep only recent data based on batch size
        const recent = combined.slice(-this.config.batchSize);
        context.state.set('aggregated', recent);

        // Calculate statistics
        const numbers = recent.filter(x =&gt; typeof x === 'number');
        const result = {
            count: recent.length,
            numericCount: numbers.length,
            sum: numbers.reduce((a, b) =&gt; a + b, 0),
            average: numbers.length &gt; 0 ? 
                numbers.reduce((a, b) =&gt; a + b, 0) / numbers.length : 0,
            min: numbers.length &gt; 0 ? Math.min(...numbers) : null,
            max: numbers.length &gt; 0 ? Math.max(...numbers) : null,
            latest: recent[recent.length - 1],
            timestamp: Date.now()
        };

        return result;
    }

    filterData(data) {
        if (!Array.isArray(data)) {
            return data;
        }

        // Apply various filters based on configuration
        return data.filter(item =&gt; {
            // Filter out null/undefined
            if (item == null) return false;
            
            // Filter by type if specified
            if (this.config.filterType) {
                if (typeof item !== this.config.filterType) return false;
            }
            
            // Filter by value range for numbers
            if (typeof item === 'number') {
                if (this.config.minValue !== undefined &amp;&amp; item &lt; this.config.minValue) return false;
                if (this.config.maxValue !== undefined &amp;&amp; item &gt; this.config.maxValue) return false;
            }
            
            // Filter by pattern for strings
            if (typeof item === 'string' &amp;&amp; this.config.pattern) {
                const regex = new RegExp(this.config.pattern, 'i');
                if (!regex.test(item)) return false;
            }
            
            return true;
        });
    }

    mapData(data) {
        if (!Array.isArray(data)) {
            data = [data];
        }

        return data.map((item, index) =&gt; {
            const mapped = {
                original: item,
                index: index,
                timestamp: Date.now(),
                processed: true
            };

            // Apply transformations based on type
            if (typeof item === 'number') {
                mapped.doubled = item * 2;
                mapped.squared = item * item;
                mapped.formatted = item.toFixed(this.config.precision);
            }
            
            if (typeof item === 'string') {
                mapped.length = item.length;
                mapped.uppercase = item.toUpperCase();
                mapped.words = item.split(/\s+/).length;
            }
            
            if (typeof item === 'object' &amp;&amp; item !== null) {
                mapped.keys = Object.keys(item);
                mapped.keyCount = Object.keys(item).length;
            }

            return mapped;
        });
    }

    updateStats(context, result) {
        const stats = context.state.get('stats') || {
            processedCount: 0,
            lastProcessed: null,
            totalDataSize: 0,
            operationCounts: {}
        };

        stats.processedCount++;
        stats.lastProcessed = Date.now();
        stats.totalDataSize += JSON.stringify(result).length;
        
        const operation = this.config.operation;
        stats.operationCounts[operation] = (stats.operationCounts[operation] || 0) + 1;

        context.state.set('stats', stats);
        
        // Send stats periodically
        if (stats.processedCount % 10 === 0) {
            context.send({ stats });
        }
    }

    handleError(error, context) {
        const errorInfo = {
            message: error.message,
            operation: this.config.operation,
            timestamp: Date.now(),
            config: this.config
        };

        console.error("DataTransformActor error:", errorInfo);
        context.send({ error: errorInfo });
    }
}
</code></pre>
<h3 id="testing-the-transform-actor"><a class="header" href="#testing-the-transform-actor">Testing the Transform Actor</a></h3>
<pre><code class="language-javascript">// Test the data transformation actor
async function testDataTransformActor() {
    const graph = new Graph("DataTransformTest", true);
    
    // Add the transform actor
    graph.addNode("transformer", "DataTransformActor", {
        x: 200, y: 100,
        description: "Data transformation processor"
    });

    // Add test data
    const testData = [
        1.23456, 2.67890, 3.14159,
        "  Hello World  ", "  JAVASCRIPT  ",
        { first_name: "John", last_name: "Doe", age: 30 },
        { product_id: 123, product_name: "Widget", price: 9.99 }
    ];

    graph.addInitial(testData, "transformer", "data");
    
    // Test different operations
    const operations = [
        { operation: "normalize", precision: 2 },
        { operation: "aggregate", batchSize: 50 },
        { operation: "filter", filterType: "number", minValue: 2 },
        { operation: "map" }
    ];

    const network = new GraphNetwork(graph);
    network.registerActor("DataTransformActor", new DataTransformActor());

    // Monitor results
    network.next((event) =&gt; {
        if (event._type === "FlowTrace" &amp;&amp; event.to.port === "result") {
            console.log("Transform result:", event.from.data);
        }
    });

    await network.start();

    // Test different operations
    for (const config of operations) {
        console.log(`\nTesting operation: ${config.operation}`);
        const result = await network.executeActor("transformer", {
            data: testData,
            config: config
        });
        console.log("Result:", result);
    }
}
</code></pre>
<h2 id="2-web-api-client-actor"><a class="header" href="#2-web-api-client-actor">2. Web API Client Actor</a></h2>
<p>Now let's build an actor that makes HTTP requests and handles various web APIs.</p>
<h3 id="creating-the-api-client-actor"><a class="header" href="#creating-the-api-client-actor">Creating the API Client Actor</a></h3>
<pre><code class="language-javascript">class WebAPIClientActor {
    constructor() {
        this.inports = ["request", "config"];
        this.outports = ["response", "error", "progress"];
        
        this.config = {
            baseURL: "",
            timeout: 10000,
            retries: 3,
            retryDelay: 1000,
            headers: {
                "Content-Type": "application/json"
            }
        };
    }

    async run(context) {
        // Update configuration
        if (context.input.config) {
            this.config = { ...this.config, ...context.input.config };
        }

        // Process request
        if (context.input.request) {
            await this.makeRequest(context.input.request, context);
        }
    }

    async makeRequest(request, context) {
        const url = this.buildURL(request.url);
        const options = this.buildRequestOptions(request);
        
        try {
            const response = await this.fetchWithRetry(url, options, context);
            const data = await this.parseResponse(response, request.responseType);
            
            context.send({
                response: {
                    data: data,
                    status: response.status,
                    statusText: response.statusText,
                    headers: Object.fromEntries(response.headers.entries()),
                    url: response.url,
                    timestamp: Date.now()
                }
            });

        } catch (error) {
            context.send({
                error: {
                    message: error.message,
                    type: error.name,
                    url: url,
                    request: request,
                    timestamp: Date.now()
                }
            });
        }
    }

    buildURL(url) {
        if (url.startsWith('http')) {
            return url;
        }
        return `${this.config.baseURL}${url}`;
    }

    buildRequestOptions(request) {
        const options = {
            method: request.method || 'GET',
            headers: { ...this.config.headers, ...request.headers }
        };

        if (request.body) {
            if (typeof request.body === 'object') {
                options.body = JSON.stringify(request.body);
            } else {
                options.body = request.body;
            }
        }

        return options;
    }

    async fetchWithRetry(url, options, context) {
        let lastError;
        
        for (let attempt = 1; attempt &lt;= this.config.retries; attempt++) {
            try {
                // Set up timeout
                const controller = new AbortController();
                const timeoutId = setTimeout(() =&gt; controller.abort(), this.config.timeout);
                
                options.signal = controller.signal;

                // Send progress update
                context.send({
                    progress: {
                        attempt: attempt,
                        maxAttempts: this.config.retries,
                        url: url,
                        status: "requesting"
                    }
                });

                const response = await fetch(url, options);
                clearTimeout(timeoutId);

                if (!response.ok) {
                    throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                }

                return response;

            } catch (error) {
                lastError = error;
                
                if (attempt &lt; this.config.retries) {
                    const delay = this.config.retryDelay * Math.pow(2, attempt - 1);
                    
                    context.send({
                        progress: {
                            attempt: attempt,
                            maxAttempts: this.config.retries,
                            error: error.message,
                            retryIn: delay,
                            status: "retrying"
                        }
                    });

                    await new Promise(resolve =&gt; setTimeout(resolve, delay));
                }
            }
        }
        
        throw lastError;
    }

    async parseResponse(response, responseType = 'json') {
        switch (responseType.toLowerCase()) {
            case 'json':
                return await response.json();
            case 'text':
                return await response.text();
            case 'blob':
                return await response.blob();
            case 'arraybuffer':
                return await response.arrayBuffer();
            default:
                return await response.json();
        }
    }
}
</code></pre>
<h3 id="api-actor-examples"><a class="header" href="#api-actor-examples">API Actor Examples</a></h3>
<pre><code class="language-javascript">// Example: Weather API actor
class WeatherAPIActor extends WebAPIClientActor {
    constructor() {
        super();
        this.inports = ["location", "config"];
        this.outports = ["weather", "error"];
        
        this.config = {
            ...this.config,
            baseURL: "https://api.openweathermap.org/data/2.5",
            apiKey: "" // Set your API key
        };
    }

    async run(context) {
        if (context.input.location) {
            const request = {
                url: `/weather?q=${encodeURIComponent(context.input.location)}&amp;appid=${this.config.apiKey}&amp;units=metric`,
                method: "GET",
                responseType: "json"
            };

            await this.makeRequest(request, context);
        }
    }
}

// Example: REST API actor
class RESTAPIActor extends WebAPIClientActor {
    constructor() {
        super();
        this.inports = ["operation", "config"];
        this.outports = ["result", "error"];
    }

    async run(context) {
        if (context.input.config) {
            this.config = { ...this.config, ...context.input.config };
        }

        if (context.input.operation) {
            const op = context.input.operation;
            const request = {
                url: op.endpoint,
                method: op.method || 'GET',
                headers: op.headers,
                body: op.data,
                responseType: op.responseType || 'json'
            };

            await this.makeRequest(request, context);
        }
    }
}
</code></pre>
<h2 id="3-file-processing-actor"><a class="header" href="#3-file-processing-actor">3. File Processing Actor</a></h2>
<p>Let's create an actor that handles file operations in the browser.</p>
<pre><code class="language-javascript">class FileProcessorActor {
    constructor() {
        this.inports = ["file", "operation", "config"];
        this.outports = ["content", "metadata", "progress", "error"];
        
        this.config = {
            chunkSize: 64 * 1024, // 64KB chunks
            supportedTypes: ['text', 'json', 'csv', 'xml'],
            maxFileSize: 10 * 1024 * 1024 // 10MB
        };
    }

    run(context) {
        if (context.input.config) {
            this.config = { ...this.config, ...context.input.config };
        }

        if (context.input.file &amp;&amp; context.input.operation) {
            this.processFile(context.input.file, context.input.operation, context);
        }
    }

    processFile(file, operation, context) {
        // Validate file
        if (!file || !(file instanceof File)) {
            context.send({ error: "Valid File object required" });
            return;
        }

        if (file.size &gt; this.config.maxFileSize) {
            context.send({ 
                error: `File too large: ${file.size} bytes (max: ${this.config.maxFileSize})` 
            });
            return;
        }

        // Send file metadata
        context.send({
            metadata: {
                name: file.name,
                size: file.size,
                type: file.type,
                lastModified: new Date(file.lastModified),
                operation: operation
            }
        });

        // Process based on operation
        switch (operation.type) {
            case 'read':
                this.readFile(file, operation, context);
                break;
            case 'parse':
                this.parseFile(file, operation, context);
                break;
            case 'analyze':
                this.analyzeFile(file, operation, context);
                break;
            default:
                context.send({ error: `Unknown operation: ${operation.type}` });
        }
    }

    readFile(file, operation, context) {
        const reader = new FileReader();
        
        reader.onprogress = (event) =&gt; {
            if (event.lengthComputable) {
                context.send({
                    progress: {
                        loaded: event.loaded,
                        total: event.total,
                        percentage: (event.loaded / event.total) * 100,
                        operation: 'reading'
                    }
                });
            }
        };

        reader.onload = (event) =&gt; {
            const result = event.target.result;
            context.send({
                content: {
                    data: result,
                    encoding: operation.encoding || 'utf-8',
                    format: operation.format || 'text',
                    size: result.length || result.byteLength
                }
            });
        };

        reader.onerror = () =&gt; {
            context.send({
                error: `Failed to read file: ${reader.error.message}`
            });
        };

        // Choose reading method
        const format = operation.format || 'text';
        switch (format) {
            case 'text':
                reader.readAsText(file, operation.encoding || 'utf-8');
                break;
            case 'dataurl':
                reader.readAsDataURL(file);
                break;
            case 'binary':
                reader.readAsArrayBuffer(file);
                break;
            default:
                reader.readAsText(file);
        }
    }

    parseFile(file, operation, context) {
        const reader = new FileReader();
        
        reader.onload = (event) =&gt; {
            try {
                const text = event.target.result;
                let parsed;

                switch (operation.format) {
                    case 'json':
                        parsed = JSON.parse(text);
                        break;
                    case 'csv':
                        parsed = this.parseCSV(text);
                        break;
                    case 'xml':
                        parsed = this.parseXML(text);
                        break;
                    default:
                        parsed = text;
                }

                context.send({
                    content: {
                        data: parsed,
                        format: operation.format,
                        recordCount: Array.isArray(parsed) ? parsed.length : 1
                    }
                });

            } catch (error) {
                context.send({
                    error: `Failed to parse ${operation.format}: ${error.message}`
                });
            }
        };

        reader.readAsText(file);
    }

    parseCSV(text) {
        const lines = text.split('\n').filter(line =&gt; line.trim());
        if (lines.length === 0) return [];

        const headers = lines[0].split(',').map(h =&gt; h.trim());
        const data = [];

        for (let i = 1; i &lt; lines.length; i++) {
            const values = lines[i].split(',').map(v =&gt; v.trim());
            const row = {};
            
            headers.forEach((header, index) =&gt; {
                row[header] = values[index] || '';
            });
            
            data.push(row);
        }

        return data;
    }

    parseXML(text) {
        const parser = new DOMParser();
        const doc = parser.parseFromString(text, 'text/xml');
        
        if (doc.querySelector('parsererror')) {
            throw new Error('Invalid XML format');
        }

        return this.xmlToObject(doc.documentElement);
    }

    xmlToObject(element) {
        const obj = {};
        
        // Add attributes
        if (element.attributes.length &gt; 0) {
            obj['@attributes'] = {};
            for (const attr of element.attributes) {
                obj['@attributes'][attr.name] = attr.value;
            }
        }

        // Add child elements
        for (const child of element.children) {
            const name = child.tagName;
            const value = child.children.length &gt; 0 ? 
                this.xmlToObject(child) : child.textContent;
            
            if (obj[name]) {
                if (!Array.isArray(obj[name])) {
                    obj[name] = [obj[name]];
                }
                obj[name].push(value);
            } else {
                obj[name] = value;
            }
        }

        return obj;
    }

    analyzeFile(file, operation, context) {
        const reader = new FileReader();
        
        reader.onload = (event) =&gt; {
            const text = event.target.result;
            const analysis = {
                size: text.length,
                lines: text.split('\n').length,
                words: text.split(/\s+/).filter(w =&gt; w).length,
                characters: text.length,
                charactersNoSpaces: text.replace(/\s/g, '').length,
                encoding: 'utf-8',
                detectedFormat: this.detectFormat(text, file.name),
                timestamp: Date.now()
            };

            context.send({ content: analysis });
        };

        reader.readAsText(file);
    }

    detectFormat(text, filename) {
        const extension = filename.split('.').pop().toLowerCase();
        
        // Try to detect format
        try {
            JSON.parse(text);
            return 'json';
        } catch {}

        if (text.includes('&lt;?xml') || text.includes('&lt;html')) {
            return 'xml';
        }

        if (text.includes(',') &amp;&amp; text.split('\n').length &gt; 1) {
            return 'csv';
        }

        return extension || 'text';
    }
}
</code></pre>
<h2 id="4-real-time-data-actor"><a class="header" href="#4-real-time-data-actor">4. Real-time Data Actor</a></h2>
<p>Let's build an actor that handles real-time data streams via WebSockets.</p>
<pre><code class="language-javascript">class WebSocketActor {
    constructor() {
        this.inports = ["connect", "disconnect", "send", "config"];
        this.outports = ["message", "status", "error"];
        
        this.config = {
            reconnectAttempts: 5,
            reconnectDelay: 1000,
            pingInterval: 30000,
            maxMessageSize: 1024 * 1024 // 1MB
        };
        
        this.socket = null;
        this.reconnectCount = 0;
        this.pingTimer = null;
    }

    run(context) {
        if (context.input.config) {
            this.config = { ...this.config, ...context.input.config };
        }

        if (context.input.connect) {
            this.connect(context.input.connect, context);
        }

        if (context.input.disconnect) {
            this.disconnect(context);
        }

        if (context.input.send) {
            this.sendMessage(context.input.send, context);
        }
    }

    connect(connectionInfo, context) {
        if (this.socket &amp;&amp; this.socket.readyState === WebSocket.OPEN) {
            context.send({ status: "Already connected" });
            return;
        }

        try {
            this.socket = new WebSocket(connectionInfo.url, connectionInfo.protocols);
            
            this.socket.onopen = () =&gt; {
                this.reconnectCount = 0;
                context.send({ 
                    status: {
                        type: "connected",
                        url: connectionInfo.url,
                        timestamp: Date.now()
                    }
                });
                
                // Start ping timer
                this.startPing(context);
            };

            this.socket.onmessage = (event) =&gt; {
                try {
                    const data = this.parseMessage(event.data);
                    context.send({
                        message: {
                            data: data,
                            timestamp: Date.now(),
                            size: event.data.length
                        }
                    });
                } catch (error) {
                    context.send({
                        error: {
                            message: "Failed to parse incoming message",
                            data: event.data,
                            error: error.message
                        }
                    });
                }
            };

            this.socket.onclose = (event) =&gt; {
                this.stopPing();
                
                const closeInfo = {
                    type: "disconnected",
                    code: event.code,
                    reason: event.reason,
                    wasClean: event.wasClean,
                    timestamp: Date.now()
                };

                context.send({ status: closeInfo });

                // Attempt reconnection if not a clean close
                if (!event.wasClean &amp;&amp; this.reconnectCount &lt; this.config.reconnectAttempts) {
                    this.attemptReconnect(connectionInfo, context);
                }
            };

            this.socket.onerror = (error) =&gt; {
                context.send({
                    error: {
                        message: "WebSocket error",
                        timestamp: Date.now()
                    }
                });
            };

        } catch (error) {
            context.send({
                error: {
                    message: "Failed to create WebSocket connection",
                    error: error.message,
                    url: connectionInfo.url
                }
            });
        }
    }

    attemptReconnect(connectionInfo, context) {
        this.reconnectCount++;
        const delay = this.config.reconnectDelay * Math.pow(2, this.reconnectCount - 1);

        context.send({
            status: {
                type: "reconnecting",
                attempt: this.reconnectCount,
                maxAttempts: this.config.reconnectAttempts,
                delay: delay
            }
        });

        setTimeout(() =&gt; {
            this.connect(connectionInfo, context);
        }, delay);
    }

    disconnect(context) {
        if (this.socket) {
            this.stopPing();
            this.socket.close(1000, "Client disconnect");
            this.socket = null;
        }

        context.send({
            status: {
                type: "disconnected",
                reason: "Client initiated",
                timestamp: Date.now()
            }
        });
    }

    sendMessage(messageData, context) {
        if (!this.socket || this.socket.readyState !== WebSocket.OPEN) {
            context.send({
                error: {
                    message: "WebSocket not connected",
                    messageData: messageData
                }
            });
            return;
        }

        try {
            const message = this.formatMessage(messageData);
            
            if (message.length &gt; this.config.maxMessageSize) {
                context.send({
                    error: {
                        message: "Message too large",
                        size: message.length,
                        maxSize: this.config.maxMessageSize
                    }
                });
                return;
            }

            this.socket.send(message);
            
            context.send({
                status: {
                    type: "message_sent",
                    size: message.length,
                    timestamp: Date.now()
                }
            });

        } catch (error) {
            context.send({
                error: {
                    message: "Failed to send message",
                    error: error.message,
                    messageData: messageData
                }
            });
        }
    }

    parseMessage(data) {
        // Try to parse as JSON first
        try {
            return JSON.parse(data);
        } catch {
            return data; // Return as string if not JSON
        }
    }

    formatMessage(data) {
        if (typeof data === 'string') {
            return data;
        }
        return JSON.stringify(data);
    }

    startPing(context) {
        this.stopPing();
        
        this.pingTimer = setInterval(() =&gt; {
            if (this.socket &amp;&amp; this.socket.readyState === WebSocket.OPEN) {
                this.socket.send(JSON.stringify({ type: 'ping', timestamp: Date.now() }));
            }
        }, this.config.pingInterval);
    }

    stopPing() {
        if (this.pingTimer) {
            clearInterval(this.pingTimer);
            this.pingTimer = null;
        }
    }
}
</code></pre>
<h2 id="5-interactive-ui-actor"><a class="header" href="#5-interactive-ui-actor">5. Interactive UI Actor</a></h2>
<p>Finally, let's create an actor that can interact with the DOM and handle user interactions.</p>
<pre><code class="language-javascript">class UIInteractionActor {
    constructor() {
        this.inports = ["createElement", "updateElement", "removeElement", "addEventListener"];
        this.outports = ["element", "event", "error"];
        
        this.config = {
            containerSelector: "#app",
            eventTypes: ["click", "input", "change", "submit"]
        };
        
        this.elements = new Map(); // Track created elements
        this.listeners = new Map(); // Track event listeners
    }

    run(context) {
        if (context.input.createElement) {
            this.createElement(context.input.createElement, context);
        }

        if (context.input.updateElement) {
            this.updateElement(context.input.updateElement, context);
        }

        if (context.input.removeElement) {
            this.removeElement(context.input.removeElement, context);
        }

        if (context.input.addEventListener) {
            this.addEventListener(context.input.addEventListener, context);
        }
    }

    createElement(elementData, context) {
        try {
            const element = document.createElement(elementData.tag || 'div');
            
            // Set attributes
            if (elementData.attributes) {
                for (const [key, value] of Object.entries(elementData.attributes)) {
                    element.setAttribute(key, value);
                }
            }

            // Set properties
            if (elementData.properties) {
                for (const [key, value] of Object.entries(elementData.properties)) {
                    element[key] = value;
                }
            }

            // Set styles
            if (elementData.styles) {
                for (const [key, value] of Object.entries(elementData.styles)) {
                    element.style[key] = value;
                }
            }

            // Set content
            if (elementData.textContent) {
                element.textContent = elementData.textContent;
            }
            
            if (elementData.innerHTML) {
                element.innerHTML = elementData.innerHTML;
            }

            // Add to container
            const container = document.querySelector(this.config.containerSelector);
            if (container) {
                container.appendChild(element);
            }

            // Generate unique ID if not provided
            const elementId = elementData.id || `element_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
            if (!element.id) {
                element.id = elementId;
            }

            // Store element reference
            this.elements.set(elementId, element);

            context.send({
                element: {
                    id: elementId,
                    tag: element.tagName.toLowerCase(),
                    created: true,
                    timestamp: Date.now()
                }
            });

        } catch (error) {
            context.send({
                error: {
                    message: "Failed to create element",
                    error: error.message,
                    elementData: elementData
                }
            });
        }
    }

    updateElement(updateData, context) {
        try {
            const element = this.elements.get(updateData.id) || 
                           document.getElementById(updateData.id);
            
            if (!element) {
                context.send({
                    error: {
                        message: "Element not found",
                        id: updateData.id
                    }
                });
                return;
            }

            // Update attributes
            if (updateData.attributes) {
                for (const [key, value] of Object.entries(updateData.attributes)) {
                    if (value === null) {
                        element.removeAttribute(key);
                    } else {
                        element.setAttribute(key, value);
                    }
                }
            }

            // Update properties
            if (updateData.properties) {
                for (const [key, value] of Object.entries(updateData.properties)) {
                    element[key] = value;
                }
            }

            // Update styles
            if (updateData.styles) {
                for (const [key, value] of Object.entries(updateData.styles)) {
                    element.style[key] = value;
                }
            }

            // Update content
            if (updateData.textContent !== undefined) {
                element.textContent = updateData.textContent;
            }
            
            if (updateData.innerHTML !== undefined) {
                element.innerHTML = updateData.innerHTML;
            }

            context.send({
                element: {
                    id: updateData.id,
                    updated: true,
                    timestamp: Date.now()
                }
            });

        } catch (error) {
            context.send({
                error: {
                    message: "Failed to update element",
                    error: error.message,
                    updateData: updateData
                }
            });
        }
    }

    removeElement(removeData, context) {
        try {
            const element = this.elements.get(removeData.id) || 
                           document.getElementById(removeData.id);
            
            if (!element) {
                context.send({
                    error: {
                        message: "Element not found",
                        id: removeData.id
                    }
                });
                return;
            }

            // Remove event listeners
            const listeners = this.listeners.get(removeData.id);
            if (listeners) {
                for (const listener of listeners) {
                    element.removeEventListener(listener.type, listener.handler);
                }
                this.listeners.delete(removeData.id);
            }

            // Remove from DOM
            element.remove();

            // Remove from tracking
            this.elements.delete(removeData.id);

            context.send({
                element: {
                    id: removeData.id,
                    removed: true,
                    timestamp: Date.now()
                }
            });

        } catch (error) {
            context.send({
                error: {
                    message: "Failed to remove element",
                    error: error.message,
                    removeData: removeData
                }
            });
        }
    }

    addEventListener(listenerData, context) {
        try {
            const element = this.elements.get(listenerData.elementId) || 
                           document.getElementById(listenerData.elementId);
            
            if (!element) {
                context.send({
                    error: {
                        message: "Element not found",
                        id: listenerData.elementId
                    }
                });
                return;
            }

            const handler = (event) =&gt; {
                const eventData = {
                    type: event.type,
                    elementId: listenerData.elementId,
                    timestamp: Date.now(),
                    target: {
                        id: event.target.id,
                        tagName: event.target.tagName,
                        value: event.target.value,
                        checked: event.target.checked
                    }
                };

                // Add specific event data
                if (event.type === 'click') {
                    eventData.coordinates = {
                        clientX: event.clientX,
                        clientY: event.clientY,
                        pageX: event.pageX,
                        pageY: event.pageY
                    };
                }

                if (event.type === 'input' || event.type === 'change') {
                    eventData.value = event.target.value;
                }

                context.send({ event: eventData });
            };

            element.addEventListener(listenerData.eventType, handler);

            // Track the listener
            if (!this.listeners.has(listenerData.elementId)) {
                this.listeners.set(listenerData.elementId, []);
            }
            this.listeners.get(listenerData.elementId).push({
                type: listenerData.eventType,
                handler: handler
            });

            context.send({
                element: {
                    id: listenerData.elementId,
                    eventType: listenerData.eventType,
                    listenerAdded: true,
                    timestamp: Date.now()
                }
            });

        } catch (error) {
            context.send({
                error: {
                    message: "Failed to add event listener",
                    error: error.message,
                    listenerData: listenerData
                }
            });
        }
    }
}
</code></pre>
<h2 id="complete-working-example"><a class="header" href="#complete-working-example">Complete Working Example</a></h2>
<p>Let's build a complete application that uses all the actors we've created:</p>
<pre><code class="language-javascript">// Complete WASM Actor Demo Application
class WASMActorDemo {
    constructor() {
        this.graph = null;
        this.network = null;
        this.isRunning = false;
    }

    async initialize() {
        // Initialize WASM
        await init();
        init_panic_hook();

        // Create demo graph
        this.createDemoGraph();
        
        // Register all actors
        this.registerActors();
        
        // Setup UI
        this.setupUI();
        
        console.log("‚úÖ WASM Actor Demo initialized");
    }

    createDemoGraph() {
        this.graph = new Graph("WASMActorDemo", true, {
            description: "Comprehensive WASM actor demonstration",
            version: "1.0.0"
        });

        // Add actors
        this.graph.addNode("dataTransform", "DataTransformActor", {
            x: 100, y: 100,
            description: "Data transformation processor"
        });

        this.graph.addNode("fileProcessor", "FileProcessorActor", {
            x: 300, y: 100,
            description: "File processing handler"
        });

        this.graph.addNode("apiClient", "WebAPIClientActor", {
            x: 500, y: 100,
            description: "Web API client"
        });

        this.graph.addNode("websocket", "WebSocketActor", {
            x: 100, y: 300,
            description: "WebSocket connection"
        });

        this.graph.addNode("uiManager", "UIInteractionActor", {
            x: 300, y: 300,
            description: "UI interaction manager"
        });

        // Create connections
        this.graph.addConnection("dataTransform", "result", "fileProcessor", "operation");
        this.graph.addConnection("fileProcessor", "content", "apiClient", "request");
        this.graph.addConnection("apiClient", "response", "websocket", "send");
        this.graph.addConnection("websocket", "message", "uiManager", "createElement");

        // Add some initial data
        this.graph.addInitial([1, 2, 3, 4, 5], "dataTransform", "data");
    }

    registerActors() {
        this.network = new GraphNetwork(this.graph);
        
        this.network.registerActor("DataTransformActor", new DataTransformActor());
        this.network.registerActor("FileProcessorActor", new FileProcessorActor());
        this.network.registerActor("WebAPIClientActor", new WebAPIClientActor());
        this.network.registerActor("WebSocketActor", new WebSocketActor());
        this.network.registerActor("UIInteractionActor", new UIInteractionActor());

        // Monitor network events
        this.network.next((event) =&gt; {
            this.handleNetworkEvent(event);
        });
    }

    setupUI() {
        document.body.innerHTML = `
            &lt;div id="demo-app"&gt;
                &lt;h1&gt;WASM Actor Development Demo&lt;/h1&gt;
                
                &lt;div class="controls"&gt;
                    &lt;button id="startNetwork"&gt;Start Network&lt;/button&gt;
                    &lt;button id="stopNetwork"&gt;Stop Network&lt;/button&gt;
                    &lt;button id="testDataTransform"&gt;Test Data Transform&lt;/button&gt;
                    &lt;button id="testFileUpload"&gt;Test File Upload&lt;/button&gt;
                    &lt;button id="testAPI"&gt;Test API Call&lt;/button&gt;
                    &lt;button id="testWebSocket"&gt;Test WebSocket&lt;/button&gt;
                &lt;/div&gt;
                
                &lt;div class="output"&gt;
                    &lt;h3&gt;Network Events:&lt;/h3&gt;
                    &lt;div id="events" style="height: 200px; overflow-y: auto; border: 1px solid #ccc; padding: 10px;"&gt;&lt;/div&gt;
                &lt;/div&gt;
                
                &lt;div class="file-upload"&gt;
                    &lt;h3&gt;File Upload Test:&lt;/h3&gt;
                    &lt;input type="file" id="fileInput" /&gt;
                    &lt;select id="fileOperation"&gt;
                        &lt;option value="read"&gt;Read&lt;/option&gt;
                        &lt;option value="parse"&gt;Parse&lt;/option&gt;
                        &lt;option value="analyze"&gt;Analyze&lt;/option&gt;
                    &lt;/select&gt;
                &lt;/div&gt;
                
                &lt;div id="dynamic-content"&gt;
                    &lt;h3&gt;Dynamic UI Elements:&lt;/h3&gt;
                    &lt;!-- UI actor will add elements here --&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        `;

        // Add event listeners
        document.getElementById('startNetwork').onclick = () =&gt; this.startNetwork();
        document.getElementById('stopNetwork').onclick = () =&gt; this.stopNetwork();
        document.getElementById('testDataTransform').onclick = () =&gt; this.testDataTransform();
        document.getElementById('testFileUpload').onclick = () =&gt; this.testFileUpload();
        document.getElementById('testAPI').onclick = () =&gt; this.testAPI();
        document.getElementById('testWebSocket').onclick = () =&gt; this.testWebSocket();
    }

    async startNetwork() {
        if (!this.isRunning) {
            await this.network.start();
            this.isRunning = true;
            this.logEvent("Network started");
        }
    }

    stopNetwork() {
        if (this.isRunning) {
            this.network.shutdown();
            this.isRunning = false;
            this.logEvent("Network stopped");
        }
    }

    async testDataTransform() {
        const testData = [
            Math.random() * 100,
            Math.random() * 100,
            "  Test String  ",
            { test_field: "value", another_field: 123 }
        ];

        const result = await this.network.executeActor("dataTransform", {
            data: testData,
            config: { operation: "normalize", precision: 2 }
        });

        this.logEvent("Data transform result", result);
    }

    testFileUpload() {
        const fileInput = document.getElementById('fileInput');
        const operation = document.getElementById('fileOperation').value;
        
        if (fileInput.files.length &gt; 0) {
            const file = fileInput.files[0];
            this.network.executeActor("fileProcessor", {
                file: file,
                operation: { type: operation, format: 'auto' }
            });
        } else {
            alert("Please select a file first");
        }
    }

    async testAPI() {
        // Test with a public API
        const result = await this.network.executeActor("apiClient", {
            request: {
                url: "https://jsonplaceholder.typicode.com/posts/1",
                method: "GET",
                responseType: "json"
            }
        });

        this.logEvent("API call result", result);
    }

    testWebSocket() {
        // Test WebSocket connection (you'll need a WebSocket server)
        this.network.executeActor("websocket", {
            connect: {
                url: "wss://echo.websocket.org/",
                protocols: []
            }
        });
    }

    handleNetworkEvent(event) {
        switch (event._type) {
            case "FlowTrace":
                this.logEvent(`Data flow: ${event.from.actorId}:${event.from.port} ‚Üí ${event.to.actorId}:${event.to.port}`, event.from.data);
                break;
                
            case "ActorStarted":
                this.logEvent(`Actor started: ${event.actorId}`);
                break;
                
            case "ActorStopped":
                this.logEvent(`Actor stopped: ${event.actorId}`);
                break;
                
            case "ProcessError":
                this.logEvent(`Error in ${event.actorId}: ${event.error}`, null, "error");
                break;
                
            default:
                this.logEvent(`Network event: ${event._type}`, event);
        }
    }

    logEvent(message, data = null, type = "info") {
        const eventsDiv = document.getElementById('events');
        const timestamp = new Date().toLocaleTimeString();
        
        const eventElement = document.createElement('div');
        eventElement.className = `event event-${type}`;
        eventElement.style.marginBottom = '5px';
        eventElement.style.padding = '5px';
        eventElement.style.backgroundColor = type === 'error' ? '#ffe6e6' : '#e6f3ff';
        
        let content = `[${timestamp}] ${message}`;
        if (data) {
            content += `\nData: ${JSON.stringify(data, null, 2)}`;
        }
        
        eventElement.textContent = content;
        eventsDiv.appendChild(eventElement);
        eventsDiv.scrollTop = eventsDiv.scrollHeight;
    }
}

// Initialize the demo when the page loads
document.addEventListener('DOMContentLoaded', async () =&gt; {
    const demo = new WASMActorDemo();
    await demo.initialize();
});
</code></pre>
<h2 id="best-practices-and-performance-tips"><a class="header" href="#best-practices-and-performance-tips">Best Practices and Performance Tips</a></h2>
<h3 id="1-state-management"><a class="header" href="#1-state-management">1. State Management</a></h3>
<pre><code class="language-javascript">// ‚úÖ Good: Batch state operations
class EfficientActor {
    run(context) {
        const state = context.state.getAll();
        
        // Modify locally
        state.counter = (state.counter || 0) + 1;
        state.lastUpdate = Date.now();
        state.processedItems = (state.processedItems || []);
        state.processedItems.push(context.input.data);
        
        // Write once
        context.state.setAll(state);
    }
}

// ‚ùå Avoid: Multiple state operations
class InefficientActor {
    run(context) {
        const counter = context.state.get('counter') || 0;
        context.state.set('counter', counter + 1);
        context.state.set('lastUpdate', Date.now());
        
        const items = context.state.get('processedItems') || [];
        items.push(context.input.data);
        context.state.set('processedItems', items);
    }
}
</code></pre>
<h3 id="2-error-handling"><a class="header" href="#2-error-handling">2. Error Handling</a></h3>
<pre><code class="language-javascript">class RobustActor {
    run(context) {
        try {
            this.processInput(context);
        } catch (error) {
            this.handleError(error, context);
        }
    }
    
    handleError(error, context) {
        // Log error details
        console.error(`${this.constructor.name} error:`, error);
        
        // Send structured error information
        context.send({
            error: {
                message: error.message,
                stack: error.stack,
                input: context.input,
                timestamp: Date.now(),
                actorType: this.constructor.name
            }
        });
        
        // Update error statistics
        const stats = context.state.get('errorStats') || { count: 0, lastError: null };
        stats.count++;
        stats.lastError = Date.now();
        context.state.set('errorStats', stats);
    }
}
</code></pre>
<h3 id="3-memory-management"><a class="header" href="#3-memory-management">3. Memory Management</a></h3>
<pre><code class="language-javascript">class MemoryAwareActor {
    constructor() {
        this.inports = ["input"];
        this.outports = ["output"];
        this.config = { maxCacheSize: 1000 };
    }
    
    run(context) {
        // Clean up old cache entries
        this.cleanupCache(context);
        
        // Process input
        const result = this.processData(context.input.input);
        
        // Cache result if within limits
        this.cacheResult(result, context);
        
        context.send({ output: result });
    }
    
    cleanupCache(context) {
        const cache = context.state.get('cache') || {};
        const entries = Object.entries(cache);
        
        if (entries.length &gt; this.config.maxCacheSize) {
            // Sort by timestamp and keep only recent entries
            const sorted = entries.sort((a, b) =&gt; b[1].timestamp - a[1].timestamp);
            const cleaned = Object.fromEntries(sorted.slice(0, this.config.maxCacheSize));
            context.state.set('cache', cleaned);
        }
    }
}
</code></pre>
<h2 id="conclusion-1"><a class="header" href="#conclusion-1">Conclusion</a></h2>
<p>This tutorial covered the essential patterns for developing WASM actors in browser environments:</p>
<ol>
<li><strong>Data Transformation</strong> - Processing and manipulating data with stateful operations</li>
<li><strong>Web API Integration</strong> - Making HTTP requests with retry logic and error handling</li>
<li><strong>File Processing</strong> - Handling browser file operations with progress tracking</li>
<li><strong>Real-time Communication</strong> - WebSocket connections with automatic reconnection</li>
<li><strong>UI Interaction</strong> - DOM manipulation and event handling</li>
</ol>
<h3 id="key-takeaways"><a class="header" href="#key-takeaways">Key Takeaways</a></h3>
<ul>
<li><strong>State Management</strong>: Use batch operations for better performance</li>
<li><strong>Error Handling</strong>: Implement comprehensive error reporting and recovery</li>
<li><strong>Async Operations</strong>: Handle promises and timeouts properly</li>
<li><strong>Memory Management</strong>: Clean up resources and limit cache sizes</li>
<li><strong>Browser APIs</strong>: Leverage native browser capabilities effectively</li>
</ul>
<h3 id="next-steps-33"><a class="header" href="#next-steps-33">Next Steps</a></h3>
<ul>
<li><strong><a href="tutorials/../api/wasm/getting-started.html">Complete WASM API Reference</a></strong> - Full API documentation</li>
<li><strong><a href="tutorials/../api/wasm/actors-in-browser.html">Browser Actors Guide</a></strong> - Detailed actor patterns</li>
<li><strong><a href="tutorials/browser-workflow-editor.html">Browser Workflow Editor</a></strong> - Building visual editors</li>
<li><strong><a href="tutorials/performance-optimization.html">Performance Optimization</a></strong> - Advanced optimization techniques</li>
</ul>
<p>The examples in this tutorial provide a solid foundation for building sophisticated browser-based workflow applications using Reflow's WASM bindings.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="actorconfig-migration-guide"><a class="header" href="#actorconfig-migration-guide">ActorConfig Migration Guide</a></h1>
<p>This guide helps you migrate existing actors from the old HashMap-based configuration approach to the new ActorConfig system, providing a smooth transition path with minimal breaking changes.</p>
<h2 id="migration-overview"><a class="header" href="#migration-overview">Migration Overview</a></h2>
<p>The ActorConfig system replaces the previous <code>set_config(HashMap&lt;String, serde_json::Value&gt;)</code> method with a more robust <code>create_process(ActorConfig)</code> approach that provides:</p>
<ul>
<li><strong>Type Safety</strong>: Strongly typed configuration with validation</li>
<li><strong>Better Error Handling</strong>: Clear configuration error messages</li>
<li><strong>Dynamic Updates</strong>: Runtime configuration changes</li>
<li><strong>Multiple Sources</strong>: Support for JSON, YAML, environment variables</li>
<li><strong>Schema Validation</strong>: Built-in validation and defaults</li>
</ul>
<h2 id="quick-migration-steps"><a class="header" href="#quick-migration-steps">Quick Migration Steps</a></h2>
<h3 id="1-update-actor-trait-implementation"><a class="header" href="#1-update-actor-trait-implementation">1. Update Actor Trait Implementation</a></h3>
<p><strong>Before (Old Pattern):</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::actor::{Actor, ActorContext};
use std::collections::HashMap;

pub struct DataProcessor {
    batch_size: usize,
    timeout: Duration,
    enable_retry: bool,
}

impl Actor for DataProcessor {
    fn set_config(&amp;mut self, config: HashMap&lt;String, serde_json::Value&gt;) {
        self.batch_size = config.get("batch_size")
            .and_then(|v| v.as_f64())
            .unwrap_or(10.0) as usize;
        
        self.timeout = Duration::from_millis(
            config.get("timeout_ms")
                .and_then(|v| v.as_f64()) 
                .unwrap_or(5000.0) as u64
        );
        
        self.enable_retry = config.get("enable_retry")
            .and_then(|v| v.as_bool())
            .unwrap_or(true);
    }
    
    async fn run(&amp;self, context: ActorContext) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt; {
        // Actor logic using self.batch_size, self.timeout, etc.
        // ...
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>After (New Pattern):</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::actor::{Actor, ActorConfig, ActorContext};
use std::collections::HashMap;

pub struct DataProcessor;

impl DataProcessor {
    pub fn new() -&gt; Self {
        Self
    }
}

impl Actor for DataProcessor {
    fn create_process(&amp;self, config: ActorConfig) -&gt; Pin&lt;Box&lt;dyn Future&lt;Output = ()&gt; + Send + 'static&gt;&gt; {
        // Extract configuration values
        let batch_size = config.get_number("batch_size").unwrap_or(10.0) as usize;
        let timeout = Duration::from_millis(config.get_number("timeout_ms").unwrap_or(5000.0) as u64);
        let enable_retry = config.get_boolean("enable_retry").unwrap_or(true);
        
        Box::pin(async move {
            // Actor logic using configuration values
            // ...
        })
    }
    
    // Remove the old set_config method
    // fn set_config(&amp;mut self, config: HashMap&lt;String, serde_json::Value&gt;) { ... }
    
    // Remove the old run method  
    // async fn run(&amp;self, context: ActorContext) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt; { ... }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="2-update-actor-registration"><a class="header" href="#2-update-actor-registration">2. Update Actor Registration</a></h3>
<p><strong>Before:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut network = Network::new();
let mut processor = DataProcessor::new();

// Configure actor with HashMap
let config = HashMap::from([
    ("batch_size".to_string(), serde_json::Value::Number(50.into())),
    ("timeout_ms".to_string(), serde_json::Value::Number(10000.into())),
    ("enable_retry".to_string(), serde_json::Value::Bool(false)),
]);

processor.set_config(config);
network.register_actor("processor", processor)?;
<span class="boring">}</span></code></pre></pre>
<p><strong>After:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut network = Network::new();
let processor = DataProcessor::new();

// Configuration is provided when adding to network
let config = ActorConfig::from_json(r#"
{
    "batch_size": 50,
    "timeout_ms": 10000,
    "enable_retry": false
}
"#)?;

network.register_actor("processor", processor)?;
network.add_node_with_config("processor", "processor", Some(config))?;
<span class="boring">}</span></code></pre></pre>
<h2 id="migration-patterns"><a class="header" href="#migration-patterns">Migration Patterns</a></h2>
<h3 id="pattern-1-simple-state-based-actor"><a class="header" href="#pattern-1-simple-state-based-actor">Pattern 1: Simple State-Based Actor</a></h3>
<p><strong>Before:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct TimerActor {
    interval_ms: u64,
    max_ticks: Option&lt;u64&gt;,
    current_ticks: u64,
}

impl Actor for TimerActor {
    fn set_config(&amp;mut self, config: HashMap&lt;String, serde_json::Value&gt;) {
        self.interval_ms = config.get("interval_ms")
            .and_then(|v| v.as_f64())
            .unwrap_or(1000.0) as u64;
        
        self.max_ticks = config.get("max_ticks")
            .and_then(|v| v.as_f64())
            .map(|v| v as u64);
    }
    
    async fn run(&amp;self, context: ActorContext) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt; {
        let mut output = HashMap::new();
        
        if self.current_ticks &lt; self.max_ticks.unwrap_or(u64::MAX) {
            // Emit tick
            output.insert("tick".to_string(), Message::Integer(self.current_ticks as i64));
        }
        
        Ok(output)
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>After:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct TimerActor;

impl Actor for TimerActor {
    fn create_process(&amp;self, config: ActorConfig) -&gt; Pin&lt;Box&lt;dyn Future&lt;Output = ()&gt; + Send + 'static&gt;&gt; {
        let interval_ms = config.get_number("interval_ms").unwrap_or(1000.0) as u64;
        let max_ticks = config.get_number("max_ticks").map(|v| v as u64);
        
        Box::pin(async move {
            let mut current_ticks = 0u64;
            let interval = Duration::from_millis(interval_ms);
            
            loop {
                if let Some(max) = max_ticks {
                    if current_ticks &gt;= max {
                        break;
                    }
                }
                
                // Emit tick
                current_ticks += 1;
                
                tokio::time::sleep(interval).await;
            }
        })
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="pattern-2-complex-configuration-with-validation"><a class="header" href="#pattern-2-complex-configuration-with-validation">Pattern 2: Complex Configuration with Validation</a></h3>
<p><strong>Before:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct DatabaseActor {
    connection_string: String,
    pool_size: u32,
    query_timeout: Duration,
}

impl Actor for DatabaseActor {
    fn set_config(&amp;mut self, config: HashMap&lt;String, serde_json::Value&gt;) {
        self.connection_string = config.get("connection_string")
            .and_then(|v| v.as_str())
            .unwrap_or("postgresql://localhost/db")
            .to_string();
        
        let pool_size = config.get("pool_size")
            .and_then(|v| v.as_f64())
            .unwrap_or(10.0) as u32;
        
        // Manual validation
        self.pool_size = if pool_size &gt; 0 &amp;&amp; pool_size &lt;= 100 {
            pool_size
        } else {
            eprintln!("Invalid pool_size {}, using default", pool_size);
            10
        };
        
        self.query_timeout = Duration::from_millis(
            config.get("query_timeout_ms")
                .and_then(|v| v.as_f64())
                .unwrap_or(30000.0) as u64
        );
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>After (with typed configuration):</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use serde::{Deserialize, Serialize};

#[derive(Debug, Serialize, Deserialize)]
struct DatabaseConfig {
    #[serde(default = "default_connection_string")]
    connection_string: String,
    
    #[serde(default = "default_pool_size")]
    pool_size: u32,
    
    #[serde(default = "default_query_timeout")]
    query_timeout_ms: u64,
}

fn default_connection_string() -&gt; String {
    "postgresql://localhost/db".to_string()
}

fn default_pool_size() -&gt; u32 { 10 }
fn default_query_timeout() -&gt; u64 { 30000 }

impl ActorConfigSchema for DatabaseConfig {
    fn validate(&amp;self) -&gt; Result&lt;(), String&gt; {
        if self.connection_string.is_empty() {
            return Err("connection_string cannot be empty".to_string());
        }
        
        if self.pool_size == 0 || self.pool_size &gt; 100 {
            return Err("pool_size must be between 1 and 100".to_string());
        }
        
        if self.query_timeout_ms == 0 {
            return Err("query_timeout_ms must be positive".to_string());
        }
        
        Ok(())
    }
}

struct DatabaseActor;

impl Actor for DatabaseActor {
    fn create_process(&amp;self, config: ActorConfig) -&gt; Pin&lt;Box&lt;dyn Future&lt;Output = ()&gt; + Send + 'static&gt;&gt; {
        // Parse and validate configuration
        let db_config: DatabaseConfig = config.parse_typed().expect("Invalid configuration");
        
        let connection_string = db_config.connection_string;
        let pool_size = db_config.pool_size;
        let query_timeout = Duration::from_millis(db_config.query_timeout_ms);
        
        Box::pin(async move {
            // Database actor implementation
            // Configuration is guaranteed to be valid
        })
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="pattern-3-actors-with-complex-state-management"><a class="header" href="#pattern-3-actors-with-complex-state-management">Pattern 3: Actors with Complex State Management</a></h3>
<p><strong>Before:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct StatefulProcessor {
    state: Arc&lt;Mutex&lt;ProcessorState&gt;&gt;,
    config: ProcessorConfig,
}

#[derive(Clone)]
struct ProcessorConfig {
    batch_size: usize,
    processing_mode: ProcessingMode,
}

impl Actor for StatefulProcessor {
    fn set_config(&amp;mut self, config: HashMap&lt;String, serde_json::Value&gt;) {
        self.config.batch_size = config.get("batch_size")
            .and_then(|v| v.as_f64())
            .unwrap_or(10.0) as usize;
        
        let mode_str = config.get("processing_mode")
            .and_then(|v| v.as_str())
            .unwrap_or("sequential");
        
        self.config.processing_mode = match mode_str {
            "parallel" =&gt; ProcessingMode::Parallel,
            "batch" =&gt; ProcessingMode::Batch,
            _ =&gt; ProcessingMode::Sequential,
        };
    }
    
    async fn run(&amp;self, context: ActorContext) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt; {
        // Use self.config and self.state
        // ...
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>After:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct StatefulProcessor;

impl Actor for StatefulProcessor {
    fn create_process(&amp;self, config: ActorConfig) -&gt; Pin&lt;Box&lt;dyn Future&lt;Output = ()&gt; + Send + 'static&gt;&gt; {
        let batch_size = config.get_number("batch_size").unwrap_or(10.0) as usize;
        let processing_mode = match config.get_string("processing_mode").as_deref() {
            Some("parallel") =&gt; ProcessingMode::Parallel,
            Some("batch") =&gt; ProcessingMode::Batch,
            _ =&gt; ProcessingMode::Sequential,
        };
        
        Box::pin(async move {
            // Create state inside the process
            let state = Arc::new(Mutex::new(ProcessorState::new()));
            
            // Actor implementation with local state
            // ...
        })
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="graph-migration"><a class="header" href="#graph-migration">Graph Migration</a></h2>
<h3 id="updating-graph-definitions"><a class="header" href="#updating-graph-definitions">Updating Graph Definitions</a></h3>
<p><strong>Before:</strong></p>
<pre><code class="language-json">{
  "processes": {
    "processor": {
      "component": "DataProcessor",
      "metadata": {
        "batch_size": 50,
        "timeout_ms": 10000,
        "enable_retry": false
      }
    }
  }
}
</code></pre>
<p><strong>After:</strong></p>
<pre><code class="language-json">{
  "processes": {
    "processor": {
      "component": "DataProcessor", 
      "metadata": {
        "config": {
          "batch_size": 50,
          "timeout_ms": 10000,
          "enable_retry": false
        }
      }
    }
  }
}
</code></pre>
<p>The configuration is now nested under a <code>"config"</code> key in the metadata, which the system automatically extracts and converts to an ActorConfig.</p>
<h2 id="migration-utilities"><a class="header" href="#migration-utilities">Migration Utilities</a></h2>
<h3 id="automatic-configuration-migration"><a class="header" href="#automatic-configuration-migration">Automatic Configuration Migration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::actor::ActorConfig;

// Helper to migrate old graph metadata format
pub fn migrate_graph_metadata(old_metadata: &amp;serde_json::Value) -&gt; serde_json::Value {
    if let Some(obj) = old_metadata.as_object() {
        // Check if it already has a "config" key
        if obj.contains_key("config") {
            return old_metadata.clone(); // Already migrated
        }
        
        // Wrap existing metadata in "config" key
        let mut new_metadata = serde_json::Map::new();
        new_metadata.insert("config".to_string(), old_metadata.clone());
        
        serde_json::Value::Object(new_metadata)
    } else {
        old_metadata.clone()
    }
}

// Helper to migrate legacy HashMap config to ActorConfig
impl ActorConfig {
    pub fn from_legacy_hashmap(legacy: HashMap&lt;String, serde_json::Value&gt;) -&gt; Self {
        let mut config = ActorConfig::default();
        
        for (key, value) in legacy {
            config.set(&amp;key, value);
        }
        
        config
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="migration-script"><a class="header" href="#migration-script">Migration Script</a></h3>
<pre><pre class="playground"><code class="language-rust">// migration_script.rs - Tool to migrate existing graph files
use std::path::Path;
use tokio::fs;

pub async fn migrate_graph_file(path: &amp;Path) -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let content = fs::read_to_string(path).await?;
    let mut graph: serde_json::Value = serde_json::from_str(&amp;content)?;
    
    // Migrate processes metadata
    if let Some(processes) = graph.get_mut("processes").and_then(|p| p.as_object_mut()) {
        for (_, process) in processes.iter_mut() {
            if let Some(metadata) = process.get_mut("metadata") {
                *metadata = migrate_graph_metadata(metadata);
            }
        }
    }
    
    // Write back the migrated graph
    let migrated_content = serde_json::to_string_pretty(&amp;graph)?;
    fs::write(path, migrated_content).await?;
    
    println!("Migrated: {}", path.display());
    Ok(())
}

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let graph_files = glob::glob("**/*.graph.json")?;
    
    for entry in graph_files {
        if let Ok(path) = entry {
            migrate_graph_file(&amp;path).await?;
        }
    }
    
    println!("Migration completed!");
    Ok(())
}</code></pre></pre>
<h2 id="backward-compatibility"><a class="header" href="#backward-compatibility">Backward Compatibility</a></h2>
<h3 id="temporary-compatibility-layer"><a class="header" href="#temporary-compatibility-layer">Temporary Compatibility Layer</a></h3>
<p>If you need to maintain compatibility with old and new systems during migration:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::actor::ActorConfig;

pub struct CompatibilityActor {
    // Store configuration in both formats during transition
    legacy_config: Option&lt;HashMap&lt;String, serde_json::Value&gt;&gt;,
    actor_config: Option&lt;ActorConfig&gt;,
}

impl CompatibilityActor {
    pub fn new() -&gt; Self {
        Self {
            legacy_config: None,
            actor_config: None,
        }
    }
    
    // Helper to get config value from either format
    fn get_config_value&lt;T&gt;(&amp;self, key: &amp;str) -&gt; Option&lt;T&gt; 
    where
        T: serde::de::DeserializeOwned + Clone,
    {
        // Try new format first
        if let Some(config) = &amp;self.actor_config {
            if let Ok(value) = config.get::&lt;T&gt;(key) {
                return Some(value);
            }
        }
        
        // Fall back to legacy format
        if let Some(legacy) = &amp;self.legacy_config {
            if let Some(value) = legacy.get(key) {
                if let Ok(parsed) = serde_json::from_value::&lt;T&gt;(value.clone()) {
                    return Some(parsed);
                }
            }
        }
        
        None
    }
}

impl Actor for CompatibilityActor {
    // Support old method during transition
    fn set_config(&amp;mut self, config: HashMap&lt;String, serde_json::Value&gt;) {
        self.legacy_config = Some(config);
    }
    
    // Implement new method
    fn create_process(&amp;self, config: ActorConfig) -&gt; Pin&lt;Box&lt;dyn Future&lt;Output = ()&gt; + Send + 'static&gt;&gt; {
        // Use helper method to get values from either format
        let batch_size = self.get_config_value::&lt;f64&gt;("batch_size").unwrap_or(10.0) as usize;
        let timeout_ms = self.get_config_value::&lt;f64&gt;("timeout_ms").unwrap_or(5000.0) as u64;
        
        Box::pin(async move {
            // Actor implementation
        })
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="testing-migration"><a class="header" href="#testing-migration">Testing Migration</a></h2>
<h3 id="unit-tests-for-migrated-actors"><a class="header" href="#unit-tests-for-migrated-actors">Unit Tests for Migrated Actors</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod migration_tests {
    use super::*;
    use reflow_network::actor::testing::TestActorConfig;
    
    #[tokio::test]
    async fn test_migrated_actor_with_legacy_values() {
        // Test that migrated actor works with old-style values
        let config = TestActorConfig::builder()
            .with_number("batch_size", 50.0)
            .with_number("timeout_ms", 10000.0)
            .with_boolean("enable_retry", false)
            .build();
        
        let actor = DataProcessor::new();
        
        // Should not panic with valid configuration
        let process = actor.create_process(config.into());
        
        // Test that process can be spawned
        let handle = tokio::spawn(process);
        
        // Clean shutdown for test
        tokio::time::sleep(Duration::from_millis(100)).await;
        handle.abort();
    }
    
    #[test]
    fn test_configuration_migration_helper() {
        let legacy_config = HashMap::from([
            ("batch_size".to_string(), serde_json::Value::Number(25.into())),
            ("timeout_ms".to_string(), serde_json::Value::Number(15000.into())),
        ]);
        
        let actor_config = ActorConfig::from_legacy_hashmap(legacy_config);
        
        assert_eq!(actor_config.get_number("batch_size"), Some(25.0));
        assert_eq!(actor_config.get_number("timeout_ms"), Some(15000.0));
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="common-migration-issues"><a class="header" href="#common-migration-issues">Common Migration Issues</a></h2>
<h3 id="issue-1-missing-configuration-values"><a class="header" href="#issue-1-missing-configuration-values">Issue 1: Missing Configuration Values</a></h3>
<p><strong>Problem:</strong> Actor expects configuration values that aren't provided.</p>
<p><strong>Solution:</strong> Use default values and graceful degradation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Before: Could panic
let batch_size = config.get("batch_size").unwrap().as_f64().unwrap() as usize;

// After: Graceful with defaults
let batch_size = config.get_number("batch_size").unwrap_or(10.0) as usize;
<span class="boring">}</span></code></pre></pre>
<h3 id="issue-2-type-conversion-errors"><a class="header" href="#issue-2-type-conversion-errors">Issue 2: Type Conversion Errors</a></h3>
<p><strong>Problem:</strong> Configuration values have different types than expected.</p>
<p><strong>Solution:</strong> Use explicit type checking and conversion:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Robust type handling
let batch_size = match config.get_number("batch_size") {
    Some(size) if size &gt; 0.0 =&gt; size as usize,
    Some(invalid) =&gt; {
        eprintln!("Invalid batch_size: {}, using default", invalid);
        10
    },
    None =&gt; {
        println!("No batch_size specified, using default");
        10
    }
};
<span class="boring">}</span></code></pre></pre>
<h3 id="issue-3-state-management-migration"><a class="header" href="#issue-3-state-management-migration">Issue 3: State Management Migration</a></h3>
<p><strong>Problem:</strong> Actors with complex internal state need restructuring.</p>
<p><strong>Solution:</strong> Move state into the process:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Before: State as struct fields
struct StatefulActor {
    state: ProcessorState,
    config: Config,
}

// After: State managed in process
impl Actor for StatefulActor {
    fn create_process(&amp;self, config: ActorConfig) -&gt; Pin&lt;Box&lt;dyn Future&lt;Output = ()&gt; + Send + 'static&gt;&gt; {
        Box::pin(async move {
            let mut state = ProcessorState::new();
            
            loop {
                // Process using local state
                // ...
            }
        })
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="migration-checklist"><a class="header" href="#migration-checklist">Migration Checklist</a></h2>
<h3 id="pre-migration"><a class="header" href="#pre-migration">Pre-Migration</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
Identify all actors using <code>set_config</code></li>
<li><input disabled="" type="checkbox"/>
Document current configuration formats</li>
<li><input disabled="" type="checkbox"/>
Create backup of existing graph files</li>
<li><input disabled="" type="checkbox"/>
Plan migration order (dependencies first)</li>
</ul>
<h3 id="during-migration"><a class="header" href="#during-migration">During Migration</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
Update actor trait implementations</li>
<li><input disabled="" type="checkbox"/>
Migrate configuration extraction logic</li>
<li><input disabled="" type="checkbox"/>
Add typed configuration schemas (recommended)</li>
<li><input disabled="" type="checkbox"/>
Update graph file metadata format</li>
<li><input disabled="" type="checkbox"/>
Update actor registration code</li>
</ul>
<h3 id="post-migration"><a class="header" href="#post-migration">Post-Migration</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
Test all actors with new configuration system</li>
<li><input disabled="" type="checkbox"/>
Verify graph loading and execution</li>
<li><input disabled="" type="checkbox"/>
Remove old <code>set_config</code> implementations</li>
<li><input disabled="" type="checkbox"/>
Update documentation and examples</li>
<li><input disabled="" type="checkbox"/>
Performance testing with new system</li>
</ul>
<h3 id="validation"><a class="header" href="#validation">Validation</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
All actors receive expected configuration</li>
<li><input disabled="" type="checkbox"/>
Configuration validation works correctly</li>
<li><input disabled="" type="checkbox"/>
Default values are applied appropriately</li>
<li><input disabled="" type="checkbox"/>
Error handling for invalid configurations</li>
<li><input disabled="" type="checkbox"/>
Dynamic configuration updates (if used)</li>
</ul>
<h2 id="performance-considerations-7"><a class="header" href="#performance-considerations-7">Performance Considerations</a></h2>
<h3 id="before-and-after-performance"><a class="header" href="#before-and-after-performance">Before and After Performance</a></h3>
<p>The new ActorConfig system provides better performance in several areas:</p>
<ol>
<li><strong>Configuration Parsing</strong>: One-time parsing vs repeated HashMap lookups</li>
<li><strong>Type Safety</strong>: Compile-time validation reduces runtime errors</li>
<li><strong>Memory Usage</strong>: More efficient internal representation</li>
<li><strong>Validation</strong>: Built-in validation vs manual checking</li>
</ol>
<h3 id="benchmarking-migration"><a class="header" href="#benchmarking-migration">Benchmarking Migration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// benchmark_migration.rs
use criterion::{black_box, criterion_group, criterion_main, Criterion};

fn benchmark_old_config(c: &amp;mut Criterion) {
    let config = HashMap::from([
        ("batch_size".to_string(), serde_json::Value::Number(50.into())),
        ("timeout_ms".to_string(), serde_json::Value::Number(10000.into())),
    ]);
    
    c.bench_function("old_config_extraction", |b| b.iter(|| {
        let batch_size = black_box(config.get("batch_size")
            .and_then(|v| v.as_f64())
            .unwrap_or(10.0) as usize);
        let timeout = black_box(config.get("timeout_ms")
            .and_then(|v| v.as_f64())
            .unwrap_or(5000.0) as u64);
    }));
}

fn benchmark_new_config(c: &amp;mut Criterion) {
    let config = ActorConfig::from_json(r#"
    {
        "batch_size": 50,
        "timeout_ms": 10000
    }
    "#).unwrap();
    
    c.bench_function("new_config_extraction", |b| b.iter(|| {
        let batch_size = black_box(config.get_number("batch_size").unwrap_or(10.0) as usize);
        let timeout = black_box(config.get_number("timeout_ms").unwrap_or(5000.0) as u64);
    }));
}

criterion_group!(benches, benchmark_old_config, benchmark_new_config);
criterion_main!(benches);
<span class="boring">}</span></code></pre></pre>
<h2 id="next-steps-34"><a class="header" href="#next-steps-34">Next Steps</a></h2>
<p>After completing the migration:</p>
<ol>
<li><strong>Remove Legacy Code</strong>: Clean up old <code>set_config</code> implementations</li>
<li><strong>Add Validation</strong>: Implement typed configuration schemas for better validation</li>
<li><strong>Dynamic Configuration</strong>: Consider adding runtime configuration updates</li>
<li><strong>Documentation</strong>: Update all examples and documentation</li>
<li><strong>Monitoring</strong>: Add configuration monitoring and alerting</li>
</ol>
<h2 id="getting-help-1"><a class="header" href="#getting-help-1">Getting Help</a></h2>
<p>If you encounter issues during migration:</p>
<ol>
<li><strong>Check Examples</strong>: Look at migrated examples in the documentation</li>
<li><strong>Configuration Validation</strong>: Use typed schemas to catch issues early</li>
<li><strong>Testing</strong>: Write comprehensive tests for migrated actors</li>
<li><strong>Community</strong>: Ask for help in the Reflow community forums</li>
<li><strong>GitHub Issues</strong>: Report bugs or ask for clarification</li>
</ol>
<p>The migration to ActorConfig provides significant benefits in terms of type safety, validation, and maintainability. While it requires some initial effort, the improved developer experience and runtime reliability make it worthwhile.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="native-deployment"><a class="header" href="#native-deployment">Native Deployment</a></h1>
<p>This guide covers deploying Reflow workflows as native applications on various platforms.</p>
<h2 id="overview-22"><a class="header" href="#overview-22">Overview</a></h2>
<p>Native deployment provides:</p>
<ul>
<li><strong>Maximum performance</strong> - Direct OS integration</li>
<li><strong>Resource efficiency</strong> - No containerization overhead</li>
<li><strong>Platform integration</strong> - Native system services</li>
<li><strong>Debugging capabilities</strong> - Full toolchain access</li>
</ul>
<h2 id="deployment-options"><a class="header" href="#deployment-options">Deployment Options</a></h2>
<h3 id="standalone-binary"><a class="header" href="#standalone-binary">Standalone Binary</a></h3>
<p>Compile workflows into self-contained executables:</p>
<pre><code class="language-bash"># Build optimized release binary
cargo build --release

# Binary includes all dependencies
./target/release/my-workflow

# Cross-compilation for different targets
cargo build --release --target x86_64-pc-windows-gnu
cargo build --release --target aarch64-apple-darwin
</code></pre>
<h3 id="system-service"><a class="header" href="#system-service">System Service</a></h3>
<p>Deploy as a system service for automatic startup:</p>
<h4 id="linux-systemd"><a class="header" href="#linux-systemd">Linux (systemd)</a></h4>
<p>Create <code>/etc/systemd/system/reflow-workflow.service</code>:</p>
<pre><code class="language-ini">[Unit]
Description=Reflow Workflow Service
After=network.target
Wants=network.target

[Service]
Type=exec
User=reflow
Group=reflow
ExecStart=/opt/reflow/bin/my-workflow
ExecReload=/bin/kill -HUP $MAINPID
Restart=always
RestartSec=5
StandardOutput=journal
StandardError=journal

# Environment variables
Environment=RUST_LOG=info
Environment=REFLOW_CONFIG=/etc/reflow/config.toml

# Security settings
NoNewPrivileges=true
ProtectSystem=strict
ProtectHome=true
ReadWritePaths=/var/lib/reflow /var/log/reflow

[Install]
WantedBy=multi-user.target
</code></pre>
<p>Enable and start the service:</p>
<pre><code class="language-bash">sudo systemctl enable reflow-workflow
sudo systemctl start reflow-workflow
sudo systemctl status reflow-workflow
</code></pre>
<h4 id="macos-launchd"><a class="header" href="#macos-launchd">macOS (launchd)</a></h4>
<p>Create <code>/Library/LaunchDaemons/com.yourcompany.reflow.plist</code>:</p>
<pre><code class="language-xml">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd"&gt;
&lt;plist version="1.0"&gt;
&lt;dict&gt;
    &lt;key&gt;Label&lt;/key&gt;
    &lt;string&gt;com.yourcompany.reflow&lt;/string&gt;
    
    &lt;key&gt;ProgramArguments&lt;/key&gt;
    &lt;array&gt;
        &lt;string&gt;/usr/local/bin/my-workflow&lt;/string&gt;
    &lt;/array&gt;
    
    &lt;key&gt;RunAtLoad&lt;/key&gt;
    &lt;true/&gt;
    
    &lt;key&gt;KeepAlive&lt;/key&gt;
    &lt;true/&gt;
    
    &lt;key&gt;StandardOutPath&lt;/key&gt;
    &lt;string&gt;/usr/local/var/log/reflow.log&lt;/string&gt;
    
    &lt;key&gt;StandardErrorPath&lt;/key&gt;
    &lt;string&gt;/usr/local/var/log/reflow.error.log&lt;/string&gt;
    
    &lt;key&gt;EnvironmentVariables&lt;/key&gt;
    &lt;dict&gt;
        &lt;key&gt;RUST_LOG&lt;/key&gt;
        &lt;string&gt;info&lt;/string&gt;
    &lt;/dict&gt;
&lt;/dict&gt;
&lt;/plist&gt;
</code></pre>
<p>Load the service:</p>
<pre><code class="language-bash">sudo launchctl load /Library/LaunchDaemons/com.yourcompany.reflow.plist
</code></pre>
<h4 id="windows-service"><a class="header" href="#windows-service">Windows Service</a></h4>
<p>Using the <code>windows-service</code> crate:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Cargo.toml
[dependencies]
windows-service = "0.6"

// src/main.rs
use windows_service::{
    define_windows_service,
    service::{
        ServiceAccess, ServiceErrorControl, ServiceInfo, ServiceStartType,
        ServiceState, ServiceType,
    },
    service_control_handler::{self, ServiceControlHandlerResult},
    service_dispatcher, Result,
};

define_windows_service!(ffi_service_main, my_service_main);

fn my_service_main(arguments: Vec&lt;std::ffi::OsString&gt;) {
    if let Err(_e) = run_service(arguments) {
        // Handle error
    }
}

fn run_service(_arguments: Vec&lt;std::ffi::OsString&gt;) -&gt; Result&lt;()&gt; {
    let event_handler = move |control_event| -&gt; ServiceControlHandlerResult {
        match control_event {
            ServiceControl::Stop =&gt; {
                // Stop the workflow
                ServiceControlHandlerResult::NoError
            }
            ServiceControl::Interrogate =&gt; ServiceControlHandlerResult::NoError,
            _ =&gt; ServiceControlHandlerResult::NotImplemented,
        }
    };

    let status_handle = service_control_handler::register("reflow", event_handler)?;

    // Start workflow
    start_workflow();

    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h2 id="configuration-management-3"><a class="header" href="#configuration-management-3">Configuration Management</a></h2>
<h3 id="configuration-files-1"><a class="header" href="#configuration-files-1">Configuration Files</a></h3>
<p>Create hierarchical configuration:</p>
<pre><code class="language-toml"># /etc/reflow/config.toml (system-wide)
[runtime]
thread_pool_size = 8
max_memory_mb = 1024

[logging]
level = "info"
output = "/var/log/reflow/app.log"

[network]
bind_address = "0.0.0.0:8080"
</code></pre>
<pre><code class="language-toml"># ~/.config/reflow/config.toml (user-specific)
[runtime]
thread_pool_size = 4  # Override system setting

[development]
hot_reload = true
debug_mode = true
</code></pre>
<h3 id="environment-variables-2"><a class="header" href="#environment-variables-2">Environment Variables</a></h3>
<p>Support environment variable overrides:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use config::{Config, Environment, File};

fn load_config() -&gt; Result&lt;AppConfig, config::ConfigError&gt; {
    let mut settings = Config::builder()
        // Start with default values
        .add_source(File::with_name("config/default"))
        // Add environment-specific config
        .add_source(File::with_name(&amp;format!("config/{}", env)).required(false))
        // Add local config
        .add_source(File::with_name("config/local").required(false))
        // Add environment variables with REFLOW_ prefix
        .add_source(Environment::with_prefix("REFLOW"))
        .build()?;

    settings.try_deserialize()
}

// Environment variables:
// REFLOW_RUNTIME__THREAD_POOL_SIZE=16
// REFLOW_LOGGING__LEVEL=debug
// REFLOW_NETWORK__BIND_ADDRESS=127.0.0.1:9090
<span class="boring">}</span></code></pre></pre>
<h2 id="resource-management-2"><a class="header" href="#resource-management-2">Resource Management</a></h2>
<h3 id="memory-configuration"><a class="header" href="#memory-configuration">Memory Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tikv_jemallocator::Jemalloc;

#[global_allocator]
static GLOBAL: Jemalloc = Jemalloc;

fn configure_memory() {
    // Set memory limits
    std::env::set_var("MALLOC_CONF", "lg_dirty_mult:8,lg_muzzy_mult:8");
    
    // Configure actor memory limits
    let config = ActorSystemConfig {
        max_actors: 10000,
        max_memory_per_actor: 100 * 1024 * 1024, // 100MB
        gc_threshold: 0.8,
    };
}
<span class="boring">}</span></code></pre></pre>
<h3 id="file-descriptors"><a class="header" href="#file-descriptors">File Descriptors</a></h3>
<pre><code class="language-bash"># Increase file descriptor limits
echo "reflow soft nofile 65536" &gt;&gt; /etc/security/limits.conf
echo "reflow hard nofile 65536" &gt;&gt; /etc/security/limits.conf

# For systemd services
echo "LimitNOFILE=65536" &gt;&gt; /etc/systemd/system/reflow-workflow.service
</code></pre>
<h3 id="cpu-affinity"><a class="header" href="#cpu-affinity">CPU Affinity</a></h3>
<p>Pin actors to specific CPU cores:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use core_affinity;

fn configure_cpu_affinity() {
    let core_ids = core_affinity::get_core_ids().unwrap();
    
    // Pin high-priority actors to specific cores
    for (i, actor) in high_priority_actors.iter().enumerate() {
        let core_id = core_ids[i % core_ids.len()];
        
        tokio::spawn(async move {
            core_affinity::set_for_current(core_id);
            actor.run().await;
        });
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="monitoring-and-observability-2"><a class="header" href="#monitoring-and-observability-2">Monitoring and Observability</a></h2>
<h3 id="logging-configuration"><a class="header" href="#logging-configuration">Logging Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tracing::{info, warn, error};
use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};

fn setup_logging() {
    tracing_subscriber::registry()
        .with(
            tracing_subscriber::EnvFilter::try_from_default_env()
                .unwrap_or_else(|_| "reflow=info".into()),
        )
        .with(tracing_subscriber::fmt::layer())
        .with(
            tracing_appender::rolling::daily("/var/log/reflow", "app.log")
        )
        .init();
}
<span class="boring">}</span></code></pre></pre>
<h3 id="metrics-integration"><a class="header" href="#metrics-integration">Metrics Integration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use prometheus::{Encoder, TextEncoder, register_counter, register_histogram};

lazy_static! {
    static ref MESSAGES_PROCESSED: prometheus::Counter = register_counter!(
        "reflow_messages_processed_total",
        "Total number of messages processed"
    ).unwrap();
    
    static ref MESSAGE_PROCESSING_TIME: prometheus::Histogram = register_histogram!(
        "reflow_message_processing_seconds",
        "Time spent processing messages"
    ).unwrap();
}

// Expose metrics endpoint
async fn metrics_handler() -&gt; impl warp::Reply {
    let encoder = TextEncoder::new();
    let metric_families = prometheus::gather();
    let mut buffer = Vec::new();
    encoder.encode(&amp;metric_families, &amp;mut buffer).unwrap();
    
    warp::reply::with_header(buffer, "content-type", "text/plain")
}
<span class="boring">}</span></code></pre></pre>
<h3 id="health-checks-2"><a class="header" href="#health-checks-2">Health Checks</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use warp::Filter;

#[derive(Serialize)]
struct HealthStatus {
    status: String,
    actors: usize,
    uptime: u64,
    memory_usage: u64,
}

async fn health_check() -&gt; Result&lt;impl warp::Reply, warp::Rejection&gt; {
    let status = HealthStatus {
        status: "healthy".to_string(),
        actors: get_active_actor_count(),
        uptime: get_uptime_seconds(),
        memory_usage: get_memory_usage(),
    };
    
    Ok(warp::reply::json(&amp;status))
}

let health = warp::path("health")
    .and(warp::get())
    .and_then(health_check);
<span class="boring">}</span></code></pre></pre>
<h2 id="security-considerations-1"><a class="header" href="#security-considerations-1">Security Considerations</a></h2>
<h3 id="user-permissions"><a class="header" href="#user-permissions">User Permissions</a></h3>
<p>Run with minimal privileges:</p>
<pre><code class="language-bash"># Create dedicated user
sudo useradd -r -s /bin/false reflow
sudo mkdir -p /var/lib/reflow /var/log/reflow
sudo chown reflow:reflow /var/lib/reflow /var/log/reflow
</code></pre>
<h3 id="file-system-sandboxing"><a class="header" href="#file-system-sandboxing">File System Sandboxing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::os::unix::fs::PermissionsExt;

fn setup_sandbox() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Create chroot environment
    let sandbox_dir = "/var/lib/reflow/sandbox";
    std::fs::create_dir_all(sandbox_dir)?;
    
    // Set restrictive permissions
    let mut perms = std::fs::metadata(sandbox_dir)?.permissions();
    perms.set_mode(0o700);
    std::fs::set_permissions(sandbox_dir, perms)?;
    
    // Change root directory (requires root privileges)
    // unsafe { libc::chroot(sandbox_dir.as_ptr()) };
    
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h3 id="network-security-2"><a class="header" href="#network-security-2">Network Security</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tokio::net::TcpListener;
use rustls::{Certificate, PrivateKey, ServerConfig};

async fn start_secure_server() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Load TLS certificates
    let certs = load_certs("cert.pem")?;
    let key = load_private_key("key.pem")?;
    
    let config = ServerConfig::builder()
        .with_safe_defaults()
        .with_no_client_auth()
        .with_single_cert(certs, key)?;
    
    let acceptor = tokio_rustls::TlsAcceptor::from(Arc::new(config));
    let listener = TcpListener::bind("0.0.0.0:8443").await?;
    
    while let Ok((stream, _)) = listener.accept().await {
        let acceptor = acceptor.clone();
        
        tokio::spawn(async move {
            if let Ok(tls_stream) = acceptor.accept(stream).await {
                handle_connection(tls_stream).await;
            }
        });
    }
    
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-optimization-10"><a class="header" href="#performance-optimization-10">Performance Optimization</a></h2>
<h3 id="profile-guided-optimization"><a class="header" href="#profile-guided-optimization">Profile-Guided Optimization</a></h3>
<pre><code class="language-bash"># Build with instrumentation
RUSTFLAGS="-Cprofile-generate=/tmp/pgo-data" \
    cargo build --release

# Run with representative workload
./target/release/my-workflow --benchmark

# Rebuild with optimization data
RUSTFLAGS="-Cprofile-use=/tmp/pgo-data" \
    cargo build --release
</code></pre>
<h3 id="link-time-optimization"><a class="header" href="#link-time-optimization">Link-Time Optimization</a></h3>
<pre><code class="language-toml"># Cargo.toml
[profile.release]
lto = true
codegen-units = 1
panic = "abort"
</code></pre>
<h3 id="memory-pool-configuration"><a class="header" href="#memory-pool-configuration">Memory Pool Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use object_pool::Pool;

lazy_static! {
    static ref MESSAGE_POOL: Pool&lt;HashMap&lt;String, Message&gt;&gt; = Pool::new(1000, || {
        HashMap::with_capacity(16)
    });
}

fn get_message_buffer() -&gt; object_pool::Reusable&lt;HashMap&lt;String, Message&gt;&gt; {
    MESSAGE_POOL.try_pull().unwrap_or_else(|| {
        MESSAGE_POOL.attach(HashMap::with_capacity(16))
    })
}
<span class="boring">}</span></code></pre></pre>
<h2 id="deployment-scripts"><a class="header" href="#deployment-scripts">Deployment Scripts</a></h2>
<h3 id="automated-deployment"><a class="header" href="#automated-deployment">Automated Deployment</a></h3>
<pre><code class="language-bash">#!/bin/bash
# deploy.sh

set -e

APP_NAME="reflow-workflow"
SERVICE_USER="reflow"
INSTALL_DIR="/opt/reflow"
CONFIG_DIR="/etc/reflow"
LOG_DIR="/var/log/reflow"

echo "Deploying $APP_NAME..."

# Stop existing service
sudo systemctl stop $APP_NAME || true

# Create directories
sudo mkdir -p $INSTALL_DIR/bin $CONFIG_DIR $LOG_DIR
sudo chown $SERVICE_USER:$SERVICE_USER $LOG_DIR

# Copy binary
sudo cp target/release/$APP_NAME $INSTALL_DIR/bin/
sudo chmod +x $INSTALL_DIR/bin/$APP_NAME

# Copy configuration
sudo cp config/production.toml $CONFIG_DIR/config.toml
sudo chown root:$SERVICE_USER $CONFIG_DIR/config.toml
sudo chmod 640 $CONFIG_DIR/config.toml

# Install service file
sudo cp scripts/$APP_NAME.service /etc/systemd/system/
sudo systemctl daemon-reload

# Start service
sudo systemctl enable $APP_NAME
sudo systemctl start $APP_NAME

echo "Deployment complete. Checking status..."
sudo systemctl status $APP_NAME
</code></pre>
<h3 id="rollback-script"><a class="header" href="#rollback-script">Rollback Script</a></h3>
<pre><code class="language-bash">#!/bin/bash
# rollback.sh

APP_NAME="reflow-workflow"
BACKUP_DIR="/opt/reflow/backups"

echo "Rolling back $APP_NAME..."

# Stop current service
sudo systemctl stop $APP_NAME

# Restore previous version
LATEST_BACKUP=$(ls -t $BACKUP_DIR/*.tar.gz | head -n1)
sudo tar -xzf $LATEST_BACKUP -C /opt/reflow/

# Restart service
sudo systemctl start $APP_NAME
sudo systemctl status $APP_NAME

echo "Rollback complete."
</code></pre>
<h2 id="troubleshooting-9"><a class="header" href="#troubleshooting-9">Troubleshooting</a></h2>
<h3 id="common-issues-7"><a class="header" href="#common-issues-7">Common Issues</a></h3>
<p><strong>High Memory Usage:</strong></p>
<pre><code class="language-bash"># Check memory allocation
echo "Memory usage by process:"
ps aux --sort=-%mem | grep reflow

# Monitor real-time usage
top -p $(pgrep reflow)

# Check for memory leaks
valgrind --tool=memcheck --leak-check=full ./my-workflow
</code></pre>
<p><strong>Performance Issues:</strong></p>
<pre><code class="language-bash"># Profile CPU usage
perf record -g ./my-workflow
perf report

# Check system resources
iostat -x 1
vmstat 1
</code></pre>
<p><strong>File Descriptor Limits:</strong></p>
<pre><code class="language-bash"># Check current limits
ulimit -n

# Check process usage
lsof -p $(pgrep reflow) | wc -l

# Monitor file descriptor usage
watch -n 1 'ls /proc/$(pgrep reflow)/fd | wc -l'
</code></pre>
<h3 id="log-analysis"><a class="header" href="#log-analysis">Log Analysis</a></h3>
<pre><code class="language-bash"># Real-time log monitoring
tail -f /var/log/reflow/app.log

# Search for errors
grep -i error /var/log/reflow/app.log

# Analyze performance patterns
awk '/processing_time/ {sum += $3; count++} END {print "Average:", sum/count}' app.log
</code></pre>
<h2 id="best-practices-23"><a class="header" href="#best-practices-23">Best Practices</a></h2>
<h3 id="deployment-checklist"><a class="header" href="#deployment-checklist">Deployment Checklist</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
Resource limits configured</li>
<li><input disabled="" type="checkbox"/>
Security permissions set</li>
<li><input disabled="" type="checkbox"/>
Monitoring enabled</li>
<li><input disabled="" type="checkbox"/>
Health checks implemented</li>
<li><input disabled="" type="checkbox"/>
Backup strategy defined</li>
<li><input disabled="" type="checkbox"/>
Rollback procedure tested</li>
<li><input disabled="" type="checkbox"/>
Documentation updated</li>
</ul>
<h3 id="production-readiness"><a class="header" href="#production-readiness">Production Readiness</a></h3>
<ol>
<li><strong>Load Testing</strong> - Validate performance under expected load</li>
<li><strong>Failure Testing</strong> - Test recovery from various failure scenarios</li>
<li><strong>Security Audit</strong> - Review permissions and access controls</li>
<li><strong>Monitoring Setup</strong> - Ensure comprehensive observability</li>
<li><strong>Backup Verification</strong> - Test backup and restore procedures</li>
</ol>
<h2 id="next-steps-35"><a class="header" href="#next-steps-35">Next Steps</a></h2>
<ul>
<li><a href="deployment/./container-deployment.html">Container Deployment</a> - Docker and Kubernetes</li>
<li><a href="deployment/./cloud-deployment.html">Cloud Deployment</a> - AWS, GCP, Azure</li>
<li><a href="deployment/./monitoring-setup.html">Monitoring Setup</a> - Comprehensive observability</li>
<li><a href="deployment/./security-hardening.html">Security Hardening</a> - Production security</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="browser-deployment-guide"><a class="header" href="#browser-deployment-guide">Browser Deployment Guide</a></h1>
<p>Learn how to deploy Reflow workflows in web browsers using WebAssembly (WASM) bindings.</p>
<h2 id="overview-23"><a class="header" href="#overview-23">Overview</a></h2>
<p>Reflow provides complete WebAssembly bindings that allow you to run actor-based workflows directly in web browsers. This enables:</p>
<ul>
<li><strong>Interactive workflow editors</strong> with real-time visualization</li>
<li><strong>Client-side data processing</strong> without server dependencies</li>
<li><strong>Hybrid applications</strong> combining browser UI with Rust performance</li>
<li><strong>Educational tools</strong> for learning workflow concepts</li>
</ul>
<h2 id="quick-start-1"><a class="header" href="#quick-start-1">Quick Start</a></h2>
<h3 id="1-build-wasm-bindings"><a class="header" href="#1-build-wasm-bindings">1. Build WASM Bindings</a></h3>
<p>First, build the WebAssembly bindings using <code>wasm-pack</code>:</p>
<pre><code class="language-bash"># Install wasm-pack if you haven't already
curl https://rustwasm.github.io/wasm-pack/installer/init.sh -sSf | sh

# Navigate to the reflow_network crate
cd crates/reflow_network

# Build the WASM bindings for web
wasm-pack build --target web --out-dir pkg
</code></pre>
<p>This generates the <code>pkg/</code> directory with:</p>
<ul>
<li><code>reflow_network.js</code> - JavaScript bindings</li>
<li><code>reflow_network.d.ts</code> - TypeScript definitions</li>
<li><code>reflow_network_bg.wasm</code> - WebAssembly binary</li>
</ul>
<h3 id="2-create-a-basic-html-page"><a class="header" href="#2-create-a-basic-html-page">2. Create a Basic HTML Page</a></h3>
<pre><code class="language-html">&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
    &lt;meta charset="UTF-8"&gt;
    &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt;
    &lt;title&gt;Reflow Browser Example&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;h1&gt;Reflow in the Browser&lt;/h1&gt;
    &lt;button id="runWorkflow"&gt;Run Workflow&lt;/button&gt;
    &lt;div id="output"&gt;&lt;/div&gt;

    &lt;script type="module"&gt;
        import init, { 
            Network, 
            Graph, 
            MemoryState,
            init_panic_hook 
        } from './pkg/reflow_network.js';

        // Initialize WASM
        await init();
        init_panic_hook();

        // Your workflow code here
        console.log('Reflow WASM loaded successfully!');
    &lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<h3 id="3-serve-with-a-local-server"><a class="header" href="#3-serve-with-a-local-server">3. Serve with a Local Server</a></h3>
<p>WASM requires files to be served via HTTP (not <code>file://</code>):</p>
<pre><code class="language-bash"># Using Python 3
python -m http.server 8000

# Using Node.js
npx http-server -p 8000

# Using any other static file server
</code></pre>
<p>Navigate to <code>http://localhost:8000</code> to view your application.</p>
<h2 id="core-wasm-api"><a class="header" href="#core-wasm-api">Core WASM API</a></h2>
<h3 id="initialization"><a class="header" href="#initialization">Initialization</a></h3>
<pre><code class="language-javascript">import init, { 
    Network, 
    Graph, 
    GraphNetwork,
    GraphHistory,
    MemoryState,
    WasmActorContext,
    JsWasmActor,
    ActorRunContext,
    init_panic_hook 
} from './pkg/reflow_network.js';

// Initialize WASM module
await init();

// Set up better error reporting
init_panic_hook();
</code></pre>
<h3 id="creating-actors-for-browser"><a class="header" href="#creating-actors-for-browser">Creating Actors for Browser</a></h3>
<p>Actors in the browser use a simplified JavaScript interface:</p>
<pre><code class="language-javascript">class MyActor {
    constructor() {
        this.inports = ["input"];
        this.outports = ["output"];
        this.state = null; // Managed by WASM bridge
        this.config = { /* actor configuration */ };
    }

    /**
     * Main actor execution method
     * @param {ActorRunContext} context - Execution context
     */
    run(context) {
        // Access input data
        const inputData = context.input.input;
        
        // Read/write state
        const currentCount = context.state.get('count') || 0;
        context.state.set('count', currentCount + 1);
        
        // Process data
        const result = {
            processed: inputData,
            count: currentCount + 1,
            timestamp: Date.now()
        };
        
        // Send output
        context.send({ output: result });
    }
}
</code></pre>
<h3 id="graph-creation-1"><a class="header" href="#graph-creation-1">Graph Creation</a></h3>
<p>Create graphs with visual positioning for browser-based editors:</p>
<pre><code class="language-javascript">// Create a new graph
const graph = new Graph("MyWorkflow", true, {
    description: "A browser-based workflow",
    version: "1.0.0"
});

// Add nodes with positioning
graph.addNode("generator", "GeneratorActor", {
    x: 100, y: 100,
    description: "Generates data"
});

graph.addNode("processor", "ProcessorActor", {
    x: 300, y: 100,
    description: "Processes data"
});

// Add connections
graph.addConnection("generator", "output", "processor", "input", {
    label: "Data flow",
    color: "#4CAF50"
});

// Add initial data
graph.addInitial({ start: true }, "generator", "trigger");

// Add graph-level ports
graph.addInport("start", "generator", "trigger", { type: "flow" });
graph.addOutport("results", "processor", "output", { type: "object" });
</code></pre>
<h3 id="network-composition"><a class="header" href="#network-composition">Network Composition</a></h3>
<p>Create and run networks in the browser:</p>
<pre><code class="language-javascript">// Create network from graph
const network = new GraphNetwork(graph);

// Register actor implementations
network.registerActor("GeneratorActor", new GeneratorActor());
network.registerActor("ProcessorActor", new ProcessorActor());

// Set up event monitoring
let eventCount = 0;
network.next((event) =&gt; {
    eventCount++;
    console.log(`Event #${eventCount}:`, {
        type: event._type,
        actor: event.actorId,
        port: event.port,
        hasData: !!event.data
    });
});

// Start the network
await network.start();

// The network will now process data according to your graph
</code></pre>
<h3 id="state-management-4"><a class="header" href="#state-management-4">State Management</a></h3>
<p>Share state between JavaScript and Rust:</p>
<pre><code class="language-javascript">// Create a memory state
const state = new MemoryState();

// Set values
state.set("counter", 42);
state.set("message", "Hello from JavaScript");
state.set("config", { enabled: true, level: "debug" });

// Get values
const counter = state.get("counter");
const message = state.get("message");

// Check existence
if (state.has("config")) {
    console.log("Config exists");
}

// Get all state as an object
const allState = state.getAll();

// Clear state
state.clear();

// Get state size
const size = state.size();
</code></pre>
<h2 id="advanced-features-7"><a class="header" href="#advanced-features-7">Advanced Features</a></h2>
<h3 id="graph-history-with-undoredo-1"><a class="header" href="#graph-history-with-undoredo-1">Graph History with Undo/Redo</a></h3>
<pre><code class="language-javascript">// Create graph with history support
const [graph, history] = Graph.withHistoryAndLimit(50);

// Make changes to the graph
graph.addNode("newNode", "MyActor", { x: 200, y: 200 });

// Process events to update history
history.processEvents(graph);

// Check if undo/redo is available
const state = history.getState();
console.log("Can undo:", state.can_undo);
console.log("Can redo:", state.can_redo);

// Perform undo/redo operations
if (state.can_undo) {
    history.undo(graph);
}

if (history.getState().can_redo) {
    history.redo(graph);
}
</code></pre>
<h3 id="real-time-event-monitoring"><a class="header" href="#real-time-event-monitoring">Real-time Event Monitoring</a></h3>
<pre><code class="language-javascript">// Set up comprehensive event monitoring
network.next((event) =&gt; {
    switch (event._type) {
        case "FlowTrace":
            console.log(`Flow: ${event.from.actorId}:${event.from.port} ‚Üí ${event.to.actorId}:${event.to.port}`);
            break;
        case "ActorStarted":
            console.log(`Actor started: ${event.actorId}`);
            break;
        case "ActorStopped":
            console.log(`Actor stopped: ${event.actorId}`);
            break;
        case "NetworkStarted":
            console.log("Network started");
            break;
        case "NetworkStopped":
            console.log("Network stopped");
            break;
        default:
            console.log("Other event:", event);
    }
});
</code></pre>
<h3 id="direct-actor-execution-1"><a class="header" href="#direct-actor-execution-1">Direct Actor Execution</a></h3>
<p>Execute actors directly for testing:</p>
<pre><code class="language-javascript">// Execute an actor and get results
const result = await network.executeActor("myActor", {
    command: "process",
    data: { value: 100 }
});

console.log("Execution result:", result);
</code></pre>
<h2 id="deployment-considerations"><a class="header" href="#deployment-considerations">Deployment Considerations</a></h2>
<h3 id="1-file-serving"><a class="header" href="#1-file-serving">1. File Serving</a></h3>
<ul>
<li><strong>CORS</strong>: Ensure proper CORS headers if serving from different domains</li>
<li><strong>MIME Types</strong>: Configure server to serve <code>.wasm</code> files with correct MIME type</li>
<li><strong>Compression</strong>: Enable gzip/brotli compression for WASM files</li>
</ul>
<h3 id="2-bundle-size-optimization"><a class="header" href="#2-bundle-size-optimization">2. Bundle Size Optimization</a></h3>
<pre><code class="language-bash"># Build optimized release version
wasm-pack build --target web --release --out-dir pkg

# Further optimization with wee_alloc (add to Cargo.toml)
[dependencies]
wee_alloc = "0.4"

# In your lib.rs
#[global_allocator]
static ALLOC: wee_alloc::WeeAlloc = wee_alloc::WeeAlloc::INIT;
</code></pre>
<h3 id="3-loading-strategies"><a class="header" href="#3-loading-strategies">3. Loading Strategies</a></h3>
<pre><code class="language-javascript">// Lazy loading for large applications
async function loadReflowWhenNeeded() {
    const { default: init, Network } = await import('./pkg/reflow_network.js');
    await init();
    return { Network };
}

// Progressive loading with loading indicators
function showLoadingIndicator() {
    document.getElementById('loading').style.display = 'block';
}

function hideLoadingIndicator() {
    document.getElementById('loading').style.display = 'none';
}

showLoadingIndicator();
await init();
hideLoadingIndicator();
</code></pre>
<h3 id="4-error-handling"><a class="header" href="#4-error-handling">4. Error Handling</a></h3>
<pre><code class="language-javascript">try {
    await init();
    init_panic_hook();
    
    // Your workflow code
    const network = new Network();
    await network.start();
    
} catch (error) {
    console.error("WASM initialization or execution failed:", error);
    
    // Show user-friendly error message
    document.getElementById('error').textContent = 
        "Failed to load workflow engine. Please refresh the page.";
}
</code></pre>
<h2 id="browser-compatibility"><a class="header" href="#browser-compatibility">Browser Compatibility</a></h2>
<h3 id="supported-browsers"><a class="header" href="#supported-browsers">Supported Browsers</a></h3>
<ul>
<li><strong>Chrome/Edge</strong>: 57+ (full WebAssembly support)</li>
<li><strong>Firefox</strong>: 52+ (full WebAssembly support)</li>
<li><strong>Safari</strong>: 11+ (full WebAssembly support)</li>
<li><strong>Mobile</strong>: iOS 11+, Android Chrome 57+</li>
</ul>
<h3 id="feature-detection"><a class="header" href="#feature-detection">Feature Detection</a></h3>
<pre><code class="language-javascript">function checkWebAssemblySupport() {
    return typeof WebAssembly === 'object' 
        &amp;&amp; typeof WebAssembly.instantiate === 'function';
}

if (!checkWebAssemblySupport()) {
    alert('Your browser does not support WebAssembly. Please update to a modern browser.');
}
</code></pre>
<h2 id="performance-tips-2"><a class="header" href="#performance-tips-2">Performance Tips</a></h2>
<h3 id="1-memory-management-1"><a class="header" href="#1-memory-management-1">1. Memory Management</a></h3>
<pre><code class="language-javascript">// Clean up resources when done
network.shutdown();

// Clear large state objects
state.clear();

// Avoid memory leaks in event listeners
const unsubscribe = network.next(handleEvent);
// Later: unsubscribe();
</code></pre>
<h3 id="2-batch-operations"><a class="header" href="#2-batch-operations">2. Batch Operations</a></h3>
<pre><code class="language-javascript">// Batch multiple graph modifications
graph.addNode("node1", "Actor1", { x: 100, y: 100 });
graph.addNode("node2", "Actor2", { x: 200, y: 100 });
graph.addConnection("node1", "output", "node2", "input");

// Process all changes at once
history.processEvents(graph);
</code></pre>
<h3 id="3-efficient-data-passing"><a class="header" href="#3-efficient-data-passing">3. Efficient Data Passing</a></h3>
<pre><code class="language-javascript">// Prefer structured data over strings
const efficientData = { 
    type: "sensor_reading",
    value: 42.5,
    timestamp: Date.now()
};

// Avoid large JSON strings
const inefficientData = JSON.stringify(largeObject);
</code></pre>
<h2 id="troubleshooting-10"><a class="header" href="#troubleshooting-10">Troubleshooting</a></h2>
<h3 id="common-issues-8"><a class="header" href="#common-issues-8">Common Issues</a></h3>
<ol>
<li>
<p><strong>WASM Module Not Found</strong></p>
<ul>
<li>Ensure <code>pkg/</code> directory exists and contains generated files</li>
<li>Check file paths in import statements</li>
<li>Verify files are served from the same origin</li>
</ul>
</li>
<li>
<p><strong>CORS Errors</strong></p>
<ul>
<li>Use a local web server instead of opening files directly</li>
<li>Configure proper CORS headers if needed</li>
</ul>
</li>
<li>
<p><strong>Import/Export Errors</strong></p>
<ul>
<li>Use a modern browser with ES6 module support</li>
<li>Check that all imports are correctly spelled</li>
<li>Ensure <code>type="module"</code> in script tags</li>
</ul>
</li>
<li>
<p><strong>Network Startup Failures</strong></p>
<ul>
<li>Verify all actors are properly registered</li>
<li>Check browser console for detailed error messages</li>
<li>Ensure graph structure is valid before starting network</li>
</ul>
</li>
</ol>
<h3 id="debug-mode-1"><a class="header" href="#debug-mode-1">Debug Mode</a></h3>
<pre><code class="language-javascript">// Enable debug logging
console.log("Network actors:", network.getActorNames());
console.log("Active actors:", network.getActiveActors());
console.log("Actor count:", network.getActorCount());

// Export graph for inspection
const graphData = graph.toJSON();
console.log("Graph structure:", JSON.stringify(graphData, null, 2));
</code></pre>
<h2 id="next-steps-36"><a class="header" href="#next-steps-36">Next Steps</a></h2>
<ul>
<li><strong><a href="deployment/../api/wasm/getting-started.html">WASM API Reference</a></strong> - Detailed API documentation</li>
<li><strong><a href="deployment/../tutorials/wasm-actor-development.html">Browser Actors Tutorial</a></strong> - Building actors for browser</li>
<li><strong><a href="deployment/../tutorials/browser-workflow-editor.html">Interactive Graph Editor</a></strong> - Creating visual workflow editors</li>
<li><strong><a href="deployment/../api/wasm/state-management.html">State Management Guide</a></strong> - Advanced state handling</li>
</ul>
<p>The browser deployment of Reflow opens up exciting possibilities for client-side workflow automation, interactive data processing, and educational applications. Start with the examples above and explore the comprehensive API documentation for advanced usage.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="examples-and-tutorials"><a class="header" href="#examples-and-tutorials">Examples and Tutorials</a></h1>
<p>This section provides practical examples and tutorials for building workflows with Reflow.</p>
<h2 id="quick-reference"><a class="header" href="#quick-reference">Quick Reference</a></h2>
<h3 id="tutorials"><a class="header" href="#tutorials">Tutorials</a></h3>
<ul>
<li><strong><a href="examples/./tutorials/audio-processing-flow.html">Audio Processing Flow</a></strong> - Real-time audio processing pipeline</li>
<li><strong><a href="examples/./tutorials/data-etl-pipeline.html">Data ETL Pipeline</a></strong> - Extract, transform, load workflow</li>
<li><strong><a href="examples/./tutorials/web-api-integration.html">Web API Integration</a></strong> - REST API consumption and processing</li>
<li><strong><a href="examples/./tutorials/real-time-analytics.html">Real-time Analytics</a></strong> - Stream processing and aggregation</li>
</ul>
<h3 id="use-cases-2"><a class="header" href="#use-cases-2">Use Cases</a></h3>
<ul>
<li><strong><a href="examples/./use-cases/iot-data-processing.html">IoT Data Processing</a></strong> - Sensor data collection and analysis</li>
<li><strong><a href="examples/./use-cases/log-processing.html">Log Processing</a></strong> - Log aggregation and monitoring</li>
<li><strong><a href="examples/./use-cases/image-processing.html">Image Processing</a></strong> - Computer vision workflows</li>
<li><strong><a href="examples/./use-cases/financial-trading.html">Financial Trading</a></strong> - Trading algorithms and risk management</li>
</ul>
<h3 id="code-samples"><a class="header" href="#code-samples">Code Samples</a></h3>
<ul>
<li><strong><a href="examples/./code-samples/simple-examples.html">Simple Examples</a></strong> - Basic workflow patterns</li>
<li><strong><a href="examples/./code-samples/advanced-patterns.html">Advanced Patterns</a></strong> - Complex workflow compositions</li>
<li><strong><a href="examples/./code-samples/error-handling.html">Error Handling</a></strong> - Robust error management</li>
<li><strong><a href="examples/./code-samples/performance-optimization.html">Performance Optimization</a></strong> - High-throughput workflows</li>
</ul>
<h2 id="getting-started-examples"><a class="header" href="#getting-started-examples">Getting Started Examples</a></h2>
<h3 id="hello-world-workflow"><a class="header" href="#hello-world-workflow">Hello World Workflow</a></h3>
<p>The simplest possible workflow:</p>
<pre><pre class="playground"><code class="language-rust">use reflow_network::Network;
use reflow_components::{utility::LoggerActor, data_operations::MapActor};

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let mut network = Network::new();
    
    // Create a simple transformer
    let transformer = MapActor::new(|payload| {
        let mut result = HashMap::new();
        result.insert("message".to_string(), 
                     Message::string("Hello, World!"));
        Ok(result)
    });
    
    // Create a logger
    let logger = LoggerActor::new()
        .level(LogLevel::Info)
        .format(LogFormat::Pretty);
    
    // Add to network
    network.add_actor("transformer", Box::new(transformer)).await?;
    network.add_actor("logger", Box::new(logger)).await?;
    
    // Connect them
    network.connect("transformer", "output", "logger", "input").await?;
    
    // Start the network
    network.start().await?;
    
    Ok(())
}</code></pre></pre>
<h3 id="basic-data-processing"><a class="header" href="#basic-data-processing">Basic Data Processing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::*;

async fn create_basic_pipeline() -&gt; Result&lt;Network, Box&lt;dyn std::error::Error&gt;&gt; {
    let mut network = Network::new();
    
    // 1. Data source (HTTP endpoint)
    let source = integration::HttpRequestActor::new()
        .timeout(Duration::from_secs(30));
    
    // 2. Data validation
    let validator = data_operations::ValidatorActor::new()
        .add_rule("required", |v| !matches!(v, Message::Null))
        .add_rule("positive", |v| {
            if let Message::Integer(n) = v { *n &gt; 0 } else { true }
        });
    
    // 3. Data transformation
    let transformer = data_operations::MapActor::new(|payload| {
        let mut result = HashMap::new();
        
        // Transform each field
        for (key, value) in payload {
            let transformed = match value {
                Message::String(s) =&gt; Message::String(s.to_uppercase()),
                Message::Integer(n) =&gt; Message::Integer(n * 2),
                other =&gt; other.clone(),
            };
            result.insert(format!("transformed_{}", key), transformed);
        }
        
        Ok(result)
    });
    
    // 4. Output logging
    let logger = utility::LoggerActor::new();
    
    // Build network
    network.add_actor("source", Box::new(source)).await?;
    network.add_actor("validator", Box::new(validator)).await?;
    network.add_actor("transformer", Box::new(transformer)).await?;
    network.add_actor("logger", Box::new(logger)).await?;
    
    // Connect pipeline
    network.connect("source", "output", "validator", "input").await?;
    network.connect("validator", "valid", "transformer", "input").await?;
    network.connect("transformer", "output", "logger", "input").await?;
    
    Ok(network)
}
<span class="boring">}</span></code></pre></pre>
<h2 id="javascript-integration-1"><a class="header" href="#javascript-integration-1">JavaScript Integration</a></h2>
<h3 id="deno-script-actor"><a class="header" href="#deno-script-actor">Deno Script Actor</a></h3>
<pre><code class="language-javascript">// scripts/data_processor.js
function process(inputs, context) {
    const data = inputs.data;
    
    if (!Array.isArray(data)) {
        return { error: "Expected array input" };
    }
    
    // Process data
    const processed = data
        .filter(item =&gt; item.value &gt; 0)
        .map(item =&gt; ({
            ...item,
            processed: true,
            timestamp: new Date().toISOString(),
            hash: calculateHash(item)
        }))
        .sort((a, b) =&gt; b.value - a.value);
    
    return {
        processed_data: processed,
        count: processed.length,
        max_value: processed[0]?.value || 0
    };
}

function calculateHash(item) {
    // Simple hash function
    return btoa(JSON.stringify(item)).slice(0, 8);
}

exports.process = process;
</code></pre>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Rust integration
use reflow_script::{ScriptActor, ScriptConfig, ScriptRuntime, ScriptEnvironment};

let script_config = ScriptConfig {
    environment: ScriptEnvironment::SYSTEM,
    runtime: ScriptRuntime::JavaScript,
    source: std::fs::read("scripts/data_processor.js")?,
    entry_point: "process".to_string(),
    packages: None,
};

let script_actor = ScriptActor::new(script_config);
<span class="boring">}</span></code></pre></pre>
<h2 id="real-world-patterns"><a class="header" href="#real-world-patterns">Real-World Patterns</a></h2>
<h3 id="error-handling-with-retry"><a class="header" href="#error-handling-with-retry">Error Handling with Retry</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::{flow_control::ConditionalActor, utility::RetryActor};

async fn create_robust_pipeline() -&gt; Result&lt;Network, Box&lt;dyn std::error::Error&gt;&gt; {
    let mut network = Network::new();
    
    // Main processor (might fail)
    let processor = data_operations::MapActor::new(|payload| {
        // Simulate occasional failures
        if payload.contains_key("trigger_error") {
            return Err(anyhow::anyhow!("Simulated processing error"));
        }
        
        // Normal processing
        Ok(payload.clone())
    });
    
    // Error detector
    let error_detector = ConditionalActor::new(|payload| {
        payload.contains_key("error")
    });
    
    // Retry actor
    let retry_actor = RetryActor::new()
        .max_attempts(3)
        .backoff_strategy(BackoffStrategy::Exponential)
        .base_delay(Duration::from_millis(100));
    
    // Success logger
    let success_logger = utility::LoggerActor::new()
        .level(LogLevel::Info);
    
    // Error logger
    let error_logger = utility::LoggerActor::new()
        .level(LogLevel::Error);
    
    // Build network
    network.add_actor("processor", Box::new(processor)).await?;
    network.add_actor("error_detector", Box::new(error_detector)).await?;
    network.add_actor("retry_actor", Box::new(retry_actor)).await?;
    network.add_actor("success_logger", Box::new(success_logger)).await?;
    network.add_actor("error_logger", Box::new(error_logger)).await?;
    
    // Connect main flow
    network.connect("processor", "output", "error_detector", "input").await?;
    network.connect("error_detector", "false", "success_logger", "input").await?;
    network.connect("error_detector", "true", "retry_actor", "input").await?;
    
    // Retry loop
    network.connect("retry_actor", "retry", "processor", "input").await?;
    network.connect("retry_actor", "failed", "error_logger", "input").await?;
    
    Ok(network)
}
<span class="boring">}</span></code></pre></pre>
<h3 id="high-throughput-processing"><a class="header" href="#high-throughput-processing">High-Throughput Processing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::{flow_control::LoadBalancerActor, synchronization::BatchActor};

async fn create_high_throughput_pipeline() -&gt; Result&lt;Network, Box&lt;dyn std::error::Error&gt;&gt; {
    let mut network = Network::new();
    
    // Input batching
    let batcher = BatchActor::new()
        .batch_size(100)
        .timeout(Duration::from_millis(50));
    
    // Load balancer
    let load_balancer = LoadBalancerActor::new()
        .strategy(LoadBalanceStrategy::RoundRobin)
        .worker_count(4);
    
    // Worker actors (parallel processing)
    for i in 0..4 {
        let worker = data_operations::MapActor::new(|payload| {
            // CPU-intensive processing
            process_batch(payload)
        });
        
        network.add_actor(&amp;format!("worker_{}", i), Box::new(worker)).await?;
        network.connect("load_balancer", &amp;format!("output_{}", i),
                       &amp;format!("worker_{}", i), "input").await?;
    }
    
    // Result aggregator
    let aggregator = data_operations::AggregateActor::new()
        .window_size(4) // Collect from all workers
        .timeout(Duration::from_secs(1))
        .aggregation_fn(|results| {
            // Combine results from all workers
            combine_worker_results(results)
        });
    
    // Connect workers to aggregator
    for i in 0..4 {
        network.connect(&amp;format!("worker_{}", i), "output",
                       "aggregator", "input").await?;
    }
    
    network.add_actor("batcher", Box::new(batcher)).await?;
    network.add_actor("load_balancer", Box::new(load_balancer)).await?;
    network.add_actor("aggregator", Box::new(aggregator)).await?;
    
    network.connect("batcher", "output", "load_balancer", "input").await?;
    
    Ok(network)
}

fn process_batch(payload: &amp;HashMap&lt;String, Message&gt;) -&gt; Result&lt;HashMap&lt;String, Message&gt;, anyhow::Error&gt; {
    // Simulate CPU-intensive work
    thread::sleep(Duration::from_millis(10));
    Ok(payload.clone())
}

fn combine_worker_results(results: &amp;[HashMap&lt;String, Message&gt;]) -&gt; HashMap&lt;String, Message&gt; {
    let mut combined = HashMap::new();
    
    let total_processed = results.len() as i64;
    combined.insert("total_processed".to_string(), Message::Integer(total_processed));
    combined.insert("timestamp".to_string(), 
                   Message::String(chrono::Utc::now().to_rfc3339()));
    
    combined
}
<span class="boring">}</span></code></pre></pre>
<h2 id="testing-workflows"><a class="header" href="#testing-workflows">Testing Workflows</a></h2>
<h3 id="unit-testing-2"><a class="header" href="#unit-testing-2">Unit Testing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod tests {
    use super::*;
    use tokio::time::{timeout, Duration};
    
    #[tokio::test]
    async fn test_data_pipeline() {
        let network = create_basic_pipeline().await.unwrap();
        
        // Send test data
        let test_data = HashMap::from([
            ("value".to_string(), Message::Integer(42)),
            ("name".to_string(), Message::String("test".to_string())),
        ]);
        
        // Get input port and send data
        let input_port = network.get_actor_input("source").unwrap();
        input_port.send_async(test_data).await.unwrap();
        
        // Wait for processing
        timeout(Duration::from_secs(5), async {
            // Check that data was processed
            // This would require network introspection capabilities
        }).await.unwrap();
    }
    
    #[tokio::test]
    async fn test_error_handling() {
        let network = create_robust_pipeline().await.unwrap();
        
        // Send data that triggers error
        let error_data = HashMap::from([
            ("trigger_error".to_string(), Message::Boolean(true)),
        ]);
        
        // Verify error handling works correctly
        // Implementation depends on network monitoring capabilities
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="integration-testing-4"><a class="header" href="#integration-testing-4">Integration Testing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::Arc;
use tokio::sync::Mutex;

#[tokio::test]
async fn test_full_workflow_integration() {
    // Shared state for test validation
    let results = Arc::new(Mutex::new(Vec::new()));
    let results_clone = results.clone();
    
    // Create custom sink actor for testing
    let test_sink = TestSinkActor::new(move |payload| {
        let results = results_clone.clone();
        Box::pin(async move {
            let mut results_guard = results.lock().await;
            results_guard.push(payload.clone());
            Ok(HashMap::new())
        })
    });
    
    let mut network = Network::new();
    
    // Build test network
    let source = create_test_source();
    let processor = create_test_processor();
    
    network.add_actor("source", Box::new(source)).await.unwrap();
    network.add_actor("processor", Box::new(processor)).await.unwrap();
    network.add_actor("sink", Box::new(test_sink)).await.unwrap();
    
    network.connect("source", "output", "processor", "input").await.unwrap();
    network.connect("processor", "output", "sink", "input").await.unwrap();
    
    // Start network
    let handle = tokio::spawn(async move {
        network.start().await
    });
    
    // Send test data
    // ... implementation details
    
    // Wait and verify results
    tokio::time::sleep(Duration::from_secs(2)).await;
    
    let final_results = results.lock().await;
    assert!(!final_results.is_empty());
    assert_eq!(final_results.len(), 3); // Expected number of processed messages
    
    handle.abort();
}
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-examples"><a class="header" href="#performance-examples">Performance Examples</a></h2>
<h3 id="benchmarking"><a class="header" href="#benchmarking">Benchmarking</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use criterion::{black_box, criterion_group, criterion_main, Criterion};

fn benchmark_message_processing(c: &amp;mut Criterion) {
    let rt = tokio::runtime::Runtime::new().unwrap();
    
    c.bench_function("process_1000_messages", |b| {
        b.iter(|| {
            rt.block_on(async {
                let network = create_high_throughput_pipeline().await.unwrap();
                
                // Send 1000 messages
                for i in 0..1000 {
                    let message = HashMap::from([
                        ("id".to_string(), Message::Integer(i)),
                        ("data".to_string(), Message::String(format!("data_{}", i))),
                    ]);
                    
                    // Send message
                    black_box(send_message(&amp;network, message).await);
                }
                
                // Wait for completion
                wait_for_completion(&amp;network).await;
            })
        })
    });
}

criterion_group!(benches, benchmark_message_processing);
criterion_main!(benches);
<span class="boring">}</span></code></pre></pre>
<h3 id="memory-profiling"><a class="header" href="#memory-profiling">Memory Profiling</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use memory_stats::memory_stats;

async fn profile_memory_usage() {
    let initial_memory = memory_stats().unwrap().physical_mem;
    println!("Initial memory: {} bytes", initial_memory);
    
    // Create large workflow
    let network = create_memory_intensive_workflow().await.unwrap();
    
    let after_creation = memory_stats().unwrap().physical_mem;
    println!("After creation: {} bytes", after_creation);
    println!("Creation overhead: {} bytes", after_creation - initial_memory);
    
    // Process data
    for batch in 0..10 {
        process_large_batch(&amp;network, batch).await;
        
        let current_memory = memory_stats().unwrap().physical_mem;
        println!("After batch {}: {} bytes", batch, current_memory);
    }
    
    // Cleanup
    drop(network);
    tokio::time::sleep(Duration::from_secs(1)).await; // Allow GC
    
    let final_memory = memory_stats().unwrap().physical_mem;
    println!("Final memory: {} bytes", final_memory);
}
<span class="boring">}</span></code></pre></pre>
<h2 id="configuration-examples-2"><a class="header" href="#configuration-examples-2">Configuration Examples</a></h2>
<h3 id="environment-based-configuration-1"><a class="header" href="#environment-based-configuration-1">Environment-Based Configuration</a></h3>
<pre><code class="language-toml"># config/development.toml
[runtime]
thread_pool_size = 2
log_level = "debug"
hot_reload = true

[performance]
batch_size = 10
timeout_ms = 1000

[scripts]
enable_deno = true
enable_python = false
</code></pre>
<pre><code class="language-toml"># config/production.toml
[runtime]
thread_pool_size = 16
log_level = "info"
hot_reload = false

[performance]
batch_size = 1000
timeout_ms = 5000

[scripts]
enable_deno = true
enable_python = true
</code></pre>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Configuration loading
use config::{Config, Environment, File};

#[derive(Debug, Deserialize)]
struct AppConfig {
    runtime: RuntimeConfig,
    performance: PerformanceConfig,
    scripts: ScriptConfig,
}

fn load_configuration() -&gt; Result&lt;AppConfig, config::ConfigError&gt; {
    let env = std::env::var("REFLOW_ENV").unwrap_or_else(|_| "development".into());
    
    let settings = Config::builder()
        .add_source(File::with_name("config/default"))
        .add_source(File::with_name(&amp;format!("config/{}", env)).required(false))
        .add_source(File::with_name("config/local").required(false))
        .add_source(Environment::with_prefix("REFLOW").separator("__"))
        .build()?;
    
    settings.try_deserialize()
}
<span class="boring">}</span></code></pre></pre>
<h2 id="deployment-examples"><a class="header" href="#deployment-examples">Deployment Examples</a></h2>
<h3 id="docker-composition"><a class="header" href="#docker-composition">Docker Composition</a></h3>
<pre><code class="language-yaml"># docker-compose.yml
version: '3.8'

services:
  reflow-app:
    build: .
    ports:
      - "8080:8080"
    environment:
      - REFLOW_ENV=production
      - RUST_LOG=info
    volumes:
      - ./config:/app/config:ro
      - ./data:/app/data
    depends_on:
      - postgres
      - redis
    restart: unless-stopped
    
  postgres:
    image: postgres:13
    environment:
      POSTGRES_DB: reflow
      POSTGRES_USER: reflow
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    
  redis:
    image: redis:6-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data

volumes:
  postgres_data:
  redis_data:
</code></pre>
<h3 id="kubernetes-deployment-1"><a class="header" href="#kubernetes-deployment-1">Kubernetes Deployment</a></h3>
<pre><code class="language-yaml"># k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: reflow-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: reflow-app
  template:
    metadata:
      labels:
        app: reflow-app
    spec:
      containers:
      - name: reflow-app
        image: reflow:latest
        ports:
        - containerPort: 8080
        env:
        - name: REFLOW_ENV
          value: "production"
        - name: RUST_LOG
          value: "info"
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
</code></pre>
<h2 id="next-steps-37"><a class="header" href="#next-steps-37">Next Steps</a></h2>
<p>Explore specific tutorials and use cases:</p>
<ul>
<li><strong><a href="examples/./tutorials/audio-processing-flow.html">Audio Processing Tutorial</a></strong> - Build a real-time audio pipeline</li>
<li><strong><a href="examples/./tutorials/data-etl-pipeline.html">Data ETL Tutorial</a></strong> - Create a data processing workflow</li>
<li><strong><a href="examples/./tutorials/web-api-integration.html">API Integration Tutorial</a></strong> - Connect to external services</li>
<li><strong><a href="examples/./use-cases/iot-data-processing.html">IoT Use Case</a></strong> - Process sensor data streams</li>
</ul>
<p>For more advanced topics:</p>
<ul>
<li><strong><a href="examples/../architecture/performance-considerations.html">Performance Optimization</a></strong></li>
<li><strong><a href="examples/./code-samples/advanced-patterns.html">Advanced Patterns</a></strong></li>
<li><strong><a href="examples/../components/custom-components.html">Custom Components</a></strong></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="api-reference"><a class="header" href="#api-reference">API Reference</a></h1>
<p>Complete API reference for Reflow components and systems.</p>
<h2 id="core-apis"><a class="header" href="#core-apis">Core APIs</a></h2>
<h3 id="graph-api"><a class="header" href="#graph-api">Graph API</a></h3>
<ul>
<li><a href="reference/../api/graph/creating-graphs.html">Creating Graphs</a> - Basic graph operations and management</li>
<li><a href="reference/../api/graph/analysis.html">Graph Analysis</a> - Validation and performance analysis</li>
<li><a href="reference/../api/graph/layout.html">Graph Layout</a> - Positioning and visualization</li>
<li><a href="reference/../api/graph/advanced.html">Advanced Features</a> - History, optimization, and extensions</li>
</ul>
<h3 id="actor-api"><a class="header" href="#actor-api">Actor API</a></h3>
<ul>
<li><a href="reference/../api/actors/creating-actors.html">Creating Actors</a> - Actor implementation and lifecycle</li>
<li><a href="reference/../architecture/message-passing.html">Message Passing</a> - Communication patterns</li>
<li><a href="reference/../architecture/actor-model.html">Actor Model</a> - Architectural concepts</li>
</ul>
<h3 id="network-api"><a class="header" href="#network-api">Network API</a></h3>
<ul>
<li><a href="reference/../api/networking/network-management.html">Network Management</a> - Network creation and control</li>
<li><a href="reference/../api/networking/connections.html">Connection Handling</a> - Connection management</li>
<li><a href="reference/../api/networking/events.html">Event System</a> - Network events and monitoring</li>
</ul>
<h3 id="messaging-api"><a class="header" href="#messaging-api">Messaging API</a></h3>
<ul>
<li><a href="reference/../api/messaging/message-types.html">Message Types</a> - Supported message formats</li>
<li><a href="reference/../api/messaging/ports.html">Port Management</a> - Input/output port handling</li>
<li><a href="reference/../api/messaging/routing.html">Message Routing</a> - Message routing and delivery</li>
</ul>
<h2 id="runtime-apis"><a class="header" href="#runtime-apis">Runtime APIs</a></h2>
<h3 id="javascriptdeno-runtime"><a class="header" href="#javascriptdeno-runtime">JavaScript/Deno Runtime</a></h3>
<ul>
<li><a href="reference/../scripting/javascript/deno-runtime.html">Deno Runtime</a> - JavaScript execution environment</li>
<li><a href="reference/../scripting/javascript/modules.html">Module System</a> - Module loading and management</li>
<li><a href="reference/../scripting/javascript/permissions.html">Permissions</a> - Security and sandboxing</li>
</ul>
<h3 id="python-runtime-1"><a class="header" href="#python-runtime-1">Python Runtime</a></h3>
<ul>
<li><a href="reference/../scripting/python/python-runtime.html">Python Runtime</a> - Python execution environment</li>
<li><a href="reference/../scripting/python/packages.html">Package Management</a> - Python package handling</li>
<li><a href="reference/../scripting/python/environments.html">Virtual Environments</a> - Isolation and dependencies</li>
</ul>
<h3 id="webassembly-runtime-1"><a class="header" href="#webassembly-runtime-1">WebAssembly Runtime</a></h3>
<ul>
<li><a href="reference/../scripting/wasm/wasm-runtime.html">WASM Runtime</a> - WebAssembly execution</li>
<li><a href="reference/../scripting/wasm/modules.html">Module Loading</a> - WASM module management</li>
<li><a href="reference/../scripting/wasm/memory.html">Memory Management</a> - Memory allocation and cleanup</li>
</ul>
<h2 id="component-apis"><a class="header" href="#component-apis">Component APIs</a></h2>
<h3 id="standard-library-1"><a class="header" href="#standard-library-1">Standard Library</a></h3>
<ul>
<li><a href="reference/../components/standard-library.html">Component Library</a> - Built-in components</li>
<li><a href="reference/../components/custom-components.html">Custom Components</a> - Creating custom components</li>
<li><a href="reference/../components/lifecycle.html">Component Lifecycle</a> - Component management</li>
</ul>
<h3 id="data-operations-1"><a class="header" href="#data-operations-1">Data Operations</a></h3>
<ul>
<li><a href="reference/../components/data-operations.html">Data Transformation</a> - Data processing components</li>
<li><a href="reference/../components/validation.html">Validation</a> - Data validation components</li>
<li><a href="reference/../components/aggregation.html">Aggregation</a> - Data aggregation operations</li>
</ul>
<h3 id="flow-control-1"><a class="header" href="#flow-control-1">Flow Control</a></h3>
<ul>
<li><a href="reference/../components/flow-control.html">Conditional Logic</a> - Branching and conditions</li>
<li><a href="reference/../components/loops.html">Loops and Iteration</a> - Iterative processing</li>
<li><a href="reference/../components/error-handling.html">Error Handling</a> - Error management</li>
</ul>
<h2 id="configuration-reference"><a class="header" href="#configuration-reference">Configuration Reference</a></h2>
<h3 id="runtime-configuration-1"><a class="header" href="#runtime-configuration-1">Runtime Configuration</a></h3>
<pre><code class="language-toml">[runtime]
thread_pool_size = 8      # Number of worker threads
log_level = "info"        # Logging level: trace, debug, info, warn, error
hot_reload = false        # Enable hot reloading in development

[memory]
max_heap_size = "1GB"     # Maximum heap size
gc_frequency = 100        # Garbage collection frequency
</code></pre>
<h3 id="network-configuration-1"><a class="header" href="#network-configuration-1">Network Configuration</a></h3>
<pre><code class="language-toml">[network]
max_connections = 1000    # Maximum concurrent connections
timeout_ms = 5000        # Connection timeout in milliseconds
buffer_size = 8192       # Message buffer size

[websocket]
enable = true            # Enable WebSocket support
port = 8080             # WebSocket port
max_frame_size = 65536  # Maximum frame size
</code></pre>
<h3 id="script-configuration"><a class="header" href="#script-configuration">Script Configuration</a></h3>
<pre><code class="language-toml">[scripts.deno]
enable = true
allow_net = false        # Network access permission
allow_read = true        # File read permission
allow_write = false      # File write permission

[scripts.python]
enable = true
virtual_env = "venv"     # Virtual environment path
requirements = "requirements.txt"

[scripts.wasm]
enable = true
max_memory = "64MB"      # Maximum WASM memory
stack_size = "1MB"       # Stack size
</code></pre>
<h2 id="error-codes"><a class="header" href="#error-codes">Error Codes</a></h2>
<h3 id="runtime-errors"><a class="header" href="#runtime-errors">Runtime Errors</a></h3>
<ul>
<li><code>E001</code> - Actor initialization failed</li>
<li><code>E002</code> - Message routing error</li>
<li><code>E003</code> - Network connection failed</li>
<li><code>E004</code> - Script execution error</li>
<li><code>E005</code> - Memory allocation failed</li>
</ul>
<h3 id="graph-errors"><a class="header" href="#graph-errors">Graph Errors</a></h3>
<ul>
<li><code>G001</code> - Invalid graph structure</li>
<li><code>G002</code> - Cycle detected in graph</li>
<li><code>G003</code> - Port type mismatch</li>
<li><code>G004</code> - Orphaned node detected</li>
<li><code>G005</code> - Invalid connection</li>
</ul>
<h3 id="component-errors"><a class="header" href="#component-errors">Component Errors</a></h3>
<ul>
<li><code>C001</code> - Component not found</li>
<li><code>C002</code> - Invalid component configuration</li>
<li><code>C003</code> - Component lifecycle error</li>
<li><code>C004</code> - Port compatibility error</li>
<li><code>C005</code> - Component execution timeout</li>
</ul>
<h2 id="type-definitions"><a class="header" href="#type-definitions">Type Definitions</a></h2>
<h3 id="core-types"><a class="header" href="#core-types">Core Types</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Graph types
pub struct Graph {
    pub name: String,
    pub directed: bool,
    pub metadata: HashMap&lt;String, Value&gt;,
}

pub struct GraphNode {
    pub id: String,
    pub component: String,
    pub metadata: HashMap&lt;String, Value&gt;,
}

pub struct GraphConnection {
    pub from_node: String,
    pub from_port: String,
    pub to_node: String,
    pub to_port: String,
    pub metadata: Option&lt;HashMap&lt;String, Value&gt;&gt;,
}

// Message types
pub enum Message {
    Null,
    Boolean(bool),
    Integer(i64),
    Float(f64),
    String(String),
    Array(Vec&lt;Message&gt;),
    Object(HashMap&lt;String, Message&gt;),
    Binary(Vec&lt;u8&gt;),
}

// Actor types
pub trait Actor: Send + Sync {
    fn process(&amp;mut self, inputs: HashMap&lt;String, Message&gt;) -&gt; Result&lt;HashMap&lt;String, Message&gt;, ActorError&gt;;
    fn get_input_ports(&amp;self) -&gt; Vec&lt;PortDefinition&gt;;
    fn get_output_ports(&amp;self) -&gt; Vec&lt;PortDefinition&gt;;
}
<span class="boring">}</span></code></pre></pre>
<h3 id="configuration-types"><a class="header" href="#configuration-types">Configuration Types</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct RuntimeConfig {
    pub thread_pool_size: usize,
    pub log_level: String,
    pub hot_reload: bool,
}

pub struct NetworkConfig {
    pub max_connections: usize,
    pub timeout_ms: u64,
    pub buffer_size: usize,
}

pub struct ScriptConfig {
    pub runtime: ScriptRuntime,
    pub source: String,
    pub entry_point: String,
    pub permissions: ScriptPermissions,
}
<span class="boring">}</span></code></pre></pre>
<h2 id="webassembly-exports"><a class="header" href="#webassembly-exports">WebAssembly Exports</a></h2>
<h3 id="graph-management"><a class="header" href="#graph-management">Graph Management</a></h3>
<pre><code class="language-javascript">// Create and manage graphs
const graph = new Graph("MyGraph", true, {});
graph.addNode("node1", "Component", {});
graph.addConnection("node1", "out", "node2", "in", {});

// Graph analysis
const validation = graph.validate();
const cycles = graph.detectCycles();
const layout = graph.calculateLayout();
</code></pre>
<h3 id="network-operations"><a class="header" href="#network-operations">Network Operations</a></h3>
<pre><code class="language-javascript">// Network management
const network = new Network();
network.addActor("processor", processorActor);
network.connect("source", "output", "processor", "input");
await network.start();
</code></pre>
<h3 id="message-handling"><a class="header" href="#message-handling">Message Handling</a></h3>
<pre><code class="language-javascript">// Message creation and handling
const message = Message.fromJson({"key": "value"});
const result = await actor.process({"input": message});
</code></pre>
<h2 id="environment-variables-3"><a class="header" href="#environment-variables-3">Environment Variables</a></h2>
<h3 id="runtime-environment"><a class="header" href="#runtime-environment">Runtime Environment</a></h3>
<ul>
<li><code>REFLOW_LOG_LEVEL</code> - Override logging level</li>
<li><code>REFLOW_THREAD_POOL_SIZE</code> - Override thread pool size</li>
<li><code>REFLOW_CONFIG_PATH</code> - Configuration file path</li>
</ul>
<h3 id="development-environment-1"><a class="header" href="#development-environment-1">Development Environment</a></h3>
<ul>
<li><code>REFLOW_DEV_MODE</code> - Enable development features</li>
<li><code>REFLOW_HOT_RELOAD</code> - Enable hot reloading</li>
<li><code>REFLOW_DEBUG_ACTORS</code> - Enable actor debugging</li>
</ul>
<h3 id="production-environment"><a class="header" href="#production-environment">Production Environment</a></h3>
<ul>
<li><code>REFLOW_PRODUCTION</code> - Enable production optimizations</li>
<li><code>REFLOW_METRICS_ENDPOINT</code> - Metrics collection endpoint</li>
<li><code>REFLOW_HEALTH_CHECK_PORT</code> - Health check port</li>
</ul>
<h2 id="performance-considerations-8"><a class="header" href="#performance-considerations-8">Performance Considerations</a></h2>
<h3 id="memory-management-8"><a class="header" href="#memory-management-8">Memory Management</a></h3>
<ul>
<li>Use memory pooling for frequently allocated objects</li>
<li>Configure appropriate garbage collection settings</li>
<li>Monitor memory usage with built-in profiling tools</li>
</ul>
<h3 id="concurrency"><a class="header" href="#concurrency">Concurrency</a></h3>
<ul>
<li>Balance thread pool size with available CPU cores</li>
<li>Use async operations for I/O bound tasks</li>
<li>Implement backpressure for high-throughput scenarios</li>
</ul>
<h3 id="optimization"><a class="header" href="#optimization">Optimization</a></h3>
<ul>
<li>Enable compiler optimizations for production builds</li>
<li>Use profile-guided optimization when available</li>
<li>Monitor performance metrics and bottlenecks</li>
</ul>
<h2 id="next-steps-38"><a class="header" href="#next-steps-38">Next Steps</a></h2>
<ul>
<li><a href="reference/troubleshooting-guide.html">Troubleshooting Guide</a> - Common issues and solutions</li>
<li><a href="reference/../tutorials/performance-optimization.html">Performance Optimization</a> - Advanced optimization techniques</li>
<li><a href="reference/../advanced/extending-reflow/custom-runtimes.html">Extended APIs</a> - Creating custom extensions</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="troubleshooting-guide"><a class="header" href="#troubleshooting-guide">Troubleshooting Guide</a></h1>
<p>Common issues and solutions when working with Reflow.</p>
<h2 id="installation-issues"><a class="header" href="#installation-issues">Installation Issues</a></h2>
<h3 id="rust-compilation-errors"><a class="header" href="#rust-compilation-errors">Rust Compilation Errors</a></h3>
<p><strong>Problem</strong>: Build fails with compiler errors</p>
<pre><code>error[E0432]: unresolved import `reflow_network::Graph`
</code></pre>
<p><strong>Solution</strong>:</p>
<ol>
<li>Ensure you have the latest Rust version (1.70+)</li>
<li>Update dependencies: <code>cargo update</code></li>
<li>Clean build cache: <code>cargo clean &amp;&amp; cargo build</code></li>
</ol>
<p><strong>Problem</strong>: Missing system dependencies</p>
<pre><code>error: linking with `cc` failed: exit status: 1
</code></pre>
<p><strong>Solution</strong>:</p>
<ul>
<li><strong>Linux</strong>: Install build essentials: <code>sudo apt-get install build-essential</code></li>
<li><strong>macOS</strong>: Install Xcode command line tools: <code>xcode-select --install</code></li>
<li><strong>Windows</strong>: Install Visual Studio Build Tools</li>
</ul>
<h3 id="webassembly-build-issues"><a class="header" href="#webassembly-build-issues">WebAssembly Build Issues</a></h3>
<p><strong>Problem</strong>: wasm-pack fails to build</p>
<pre><code>Error: failed to execute `wasm-pack build`: No such file or directory
</code></pre>
<p><strong>Solution</strong>:</p>
<ol>
<li>Install wasm-pack: <code>curl https://rustwasm.github.io/wasm-pack/installer/init.sh -sSf | sh</code></li>
<li>Add wasm target: <code>rustup target add wasm32-unknown-unknown</code></li>
<li>Verify installation: <code>wasm-pack --version</code></li>
</ol>
<h2 id="runtime-issues"><a class="header" href="#runtime-issues">Runtime Issues</a></h2>
<h3 id="actor-initialization-failures"><a class="header" href="#actor-initialization-failures">Actor Initialization Failures</a></h3>
<p><strong>Problem</strong>: Actors fail to start</p>
<pre><code>Error: Actor 'data_processor' failed to initialize: E001
</code></pre>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p>Check actor configuration:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Verify all required ports are defined
fn get_input_ports(&amp;self) -&gt; Vec&lt;PortDefinition&gt; {
    vec![
        PortDefinition::new("input", PortType::Any),
    ]
}
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p>Validate actor state:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Ensure actor is in valid initial state
impl Actor for MyActor {
    fn process(&amp;mut self, inputs: HashMap&lt;String, Message&gt;) -&gt; Result&lt;HashMap&lt;String, Message&gt;, ActorError&gt; {
        if !self.initialized {
            return Err(ActorError::NotInitialized);
        }
        // ... processing logic
    }
}
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p>Check dependencies:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Verify all dependencies are available
impl MyActor {
    pub fn new() -&gt; Result&lt;Self, ActorError&gt; {
        let dependency = SomeDependency::connect()
            .map_err(|_| ActorError::DependencyUnavailable)?;
        
        Ok(Self { dependency, initialized: true })
    }
}
<span class="boring">}</span></code></pre></pre>
</li>
</ol>
<h3 id="message-routing-errors"><a class="header" href="#message-routing-errors">Message Routing Errors</a></h3>
<p><strong>Problem</strong>: Messages not reaching destination actors</p>
<pre><code>Warning: Message dropped - no route to 'processor.input'
</code></pre>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p>Verify connections:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Check connection exists
network.connect("source", "output", "processor", "input").await?;

// Verify actor and port names
let actors = network.list_actors();
println!("Available actors: {:?}", actors);
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p>Check port compatibility:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Ensure port types match
source_actor.get_output_ports(); // Returns Vec&lt;PortDefinition&gt;
processor_actor.get_input_ports(); // Should have compatible types
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p>Monitor message flow:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>network.enable_message_tracing(true);
// Check logs for message routing information
<span class="boring">}</span></code></pre></pre>
</li>
</ol>
<h3 id="memory-issues"><a class="header" href="#memory-issues">Memory Issues</a></h3>
<p><strong>Problem</strong>: Out of memory errors</p>
<pre><code>Error: Memory allocation failed: E005
</code></pre>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p>Configure memory limits:</p>
<pre><code class="language-toml">[memory]
max_heap_size = "2GB"
gc_frequency = 50
enable_memory_pooling = true
</code></pre>
</li>
<li>
<p>Implement proper cleanup:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl Drop for MyActor {
    fn drop(&amp;mut self) {
        // Clean up resources
        self.cleanup_connections();
        self.release_buffers();
    }
}
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p>Use memory profiling:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use memory_stats::memory_stats;

if let Some(usage) = memory_stats() {
    println!("Memory usage: {} bytes", usage.physical_mem);
}
<span class="boring">}</span></code></pre></pre>
</li>
</ol>
<h2 id="network-issues"><a class="header" href="#network-issues">Network Issues</a></h2>
<h3 id="connection-timeouts"><a class="header" href="#connection-timeouts">Connection Timeouts</a></h3>
<p><strong>Problem</strong>: Network operations timeout</p>
<pre><code>Error: Connection timeout after 5000ms: E003
</code></pre>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p>Increase timeout values:</p>
<pre><code class="language-toml">[network]
timeout_ms = 30000  # Increase to 30 seconds
</code></pre>
</li>
<li>
<p>Implement retry logic:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::utility::RetryActor;

let retry_actor = RetryActor::new()
    .max_attempts(3)
    .backoff_strategy(BackoffStrategy::Exponential)
    .base_delay(Duration::from_millis(100));
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p>Check network connectivity:</p>
<pre><code class="language-bash"># Test connectivity
curl -I http://your-endpoint
ping your-server
</code></pre>
</li>
</ol>
<h3 id="websocket-connection-issues"><a class="header" href="#websocket-connection-issues">WebSocket Connection Issues</a></h3>
<p><strong>Problem</strong>: WebSocket connections fail</p>
<pre><code>Error: WebSocket connection failed: Connection refused
</code></pre>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p>Verify server configuration:</p>
<pre><code class="language-toml">[websocket]
enable = true
port = 8080
bind_address = "0.0.0.0"
</code></pre>
</li>
<li>
<p>Check firewall settings:</p>
<pre><code class="language-bash"># Linux
sudo ufw allow 8080

# macOS
sudo pfctl -f /etc/pf.conf
</code></pre>
</li>
<li>
<p>Test WebSocket endpoint:</p>
<pre><code class="language-javascript">// Test in browser console
const ws = new WebSocket('ws://localhost:8080');
ws.onopen = () =&gt; console.log('Connected');
ws.onerror = (error) =&gt; console.error('Error:', error);
</code></pre>
</li>
</ol>
<h2 id="script-runtime-issues"><a class="header" href="#script-runtime-issues">Script Runtime Issues</a></h2>
<h3 id="deno-permission-errors"><a class="header" href="#deno-permission-errors">Deno Permission Errors</a></h3>
<p><strong>Problem</strong>: Deno scripts fail due to permissions</p>
<pre><code>Error: Requires read access to "./data", run again with --allow-read
</code></pre>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p>Configure permissions:</p>
<pre><code class="language-toml">[scripts.deno]
allow_read = true
allow_net = false
allow_write = false
</code></pre>
</li>
<li>
<p>Specify allowed paths:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = ScriptConfig {
    runtime: ScriptRuntime::JavaScript,
    permissions: ScriptPermissions {
        allow_read: Some(vec!["./data".to_string(), "./config".to_string()]),
        allow_net: Some(vec!["api.example.com".to_string()]),
        allow_write: None,
    },
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
</li>
</ol>
<h3 id="python-import-errors"><a class="header" href="#python-import-errors">Python Import Errors</a></h3>
<p><strong>Problem</strong>: Python modules not found</p>
<pre><code>ModuleNotFoundError: No module named 'requests'
</code></pre>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p>Install dependencies:</p>
<pre><code class="language-bash">pip install -r requirements.txt
</code></pre>
</li>
<li>
<p>Configure virtual environment:</p>
<pre><code class="language-toml">[scripts.python]
virtual_env = "./venv"
requirements = "requirements.txt"
</code></pre>
</li>
<li>
<p>Verify Python path:</p>
<pre><code class="language-python">import sys
print(sys.path)
</code></pre>
</li>
</ol>
<h3 id="webassembly-module-loading"><a class="header" href="#webassembly-module-loading">WebAssembly Module Loading</a></h3>
<p><strong>Problem</strong>: WASM modules fail to load</p>
<pre><code>Error: Invalid WASM module format
</code></pre>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p>Verify WASM file:</p>
<pre><code class="language-bash">wasm-objdump -h module.wasm
</code></pre>
</li>
<li>
<p>Check module exports:</p>
<pre><code class="language-bash">wasm-objdump -x module.wasm | grep Export
</code></pre>
</li>
<li>
<p>Validate memory configuration:</p>
<pre><code class="language-toml">[scripts.wasm]
max_memory = "64MB"
stack_size = "1MB"
</code></pre>
</li>
</ol>
<h2 id="graph-issues"><a class="header" href="#graph-issues">Graph Issues</a></h2>
<h3 id="cycle-detection-errors"><a class="header" href="#cycle-detection-errors">Cycle Detection Errors</a></h3>
<p><strong>Problem</strong>: Graph contains cycles</p>
<pre><code>Error: Cycle detected in graph: node1 -&gt; node2 -&gt; node3 -&gt; node1
</code></pre>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p>Analyze graph structure:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let analysis = graph.analyze_structure();
if analysis.has_cycles {
    println!("Cycles found: {:?}", analysis.cycles);
}
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p>Remove problematic connections:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Remove cycle-causing connection
graph.remove_connection("node3", "output", "node1", "input")?;
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p>Implement cycle breaking:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let cycles = graph.detect_cycles();
for cycle in cycles {
    // Break cycle by removing weakest connection
    let weakest_connection = find_weakest_connection(&amp;cycle);
    graph.remove_connection_by_id(&amp;weakest_connection.id)?;
}
<span class="boring">}</span></code></pre></pre>
</li>
</ol>
<h3 id="port-type-mismatches"><a class="header" href="#port-type-mismatches">Port Type Mismatches</a></h3>
<p><strong>Problem</strong>: Incompatible port types</p>
<pre><code>Error: Port type mismatch: Cannot connect String output to Integer input
</code></pre>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p>Add type conversion:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::data_operations::ConverterActor;

let converter = ConverterActor::new()
    .add_conversion(PortType::String, PortType::Integer, |value| {
        if let Message::String(s) = value {
            s.parse::&lt;i64&gt;().map(Message::Integer).ok()
        } else {
            None
        }
    });
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p>Use flexible port types:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>PortDefinition::new("input", PortType::Any)
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p>Implement custom validation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn validate_connection(&amp;self, output_type: &amp;PortType, input_type: &amp;PortType) -&gt; bool {
    match (output_type, input_type) {
        (PortType::String, PortType::Integer) =&gt; true, // Allow with conversion
        (PortType::Any, _) =&gt; true,
        (_, PortType::Any) =&gt; true,
        (a, b) =&gt; a == b,
    }
}
<span class="boring">}</span></code></pre></pre>
</li>
</ol>
<h2 id="performance-issues"><a class="header" href="#performance-issues">Performance Issues</a></h2>
<h3 id="high-cpu-usage"><a class="header" href="#high-cpu-usage">High CPU Usage</a></h3>
<p><strong>Problem</strong>: Actors consuming excessive CPU</p>
<pre><code>Warning: Actor 'data_processor' CPU usage: 95%
</code></pre>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p>Profile actor performance:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::time::Instant;

impl Actor for MyActor {
    fn process(&amp;mut self, inputs: HashMap&lt;String, Message&gt;) -&gt; Result&lt;HashMap&lt;String, Message&gt;, ActorError&gt; {
        let start = Instant::now();
        
        // ... processing logic
        
        let duration = start.elapsed();
        if duration.as_millis() &gt; 100 {
            log::warn!("Slow processing: {:?}", duration);
        }
        
        Ok(result)
    }
}
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p>Implement batching:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_components::synchronization::BatchActor;

let batcher = BatchActor::new()
    .batch_size(100)
    .timeout(Duration::from_millis(50));
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p>Use async processing:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>async fn process_async(&amp;mut self, inputs: HashMap&lt;String, Message&gt;) -&gt; Result&lt;HashMap&lt;String, Message&gt;, ActorError&gt; {
    // Use tokio::task::yield_now() to yield control
    tokio::task::yield_now().await;
    
    // CPU-intensive work
    let result = heavy_computation(inputs).await;
    
    Ok(result)
}
<span class="boring">}</span></code></pre></pre>
</li>
</ol>
<h3 id="memory-leaks"><a class="header" href="#memory-leaks">Memory Leaks</a></h3>
<p><strong>Problem</strong>: Memory usage continuously increases</p>
<pre><code>Warning: Memory usage increased to 2.1GB (threshold: 2GB)
</code></pre>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p>Monitor memory allocation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use reflow_network::profiling::MemoryProfiler;

let profiler = MemoryProfiler::new();
profiler.start_monitoring();

// ... run workflows

let report = profiler.generate_report();
println!("Memory hotspots: {:?}", report.hotspots);
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p>Implement proper cleanup:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl Actor for MyActor {
    fn process(&amp;mut self, inputs: HashMap&lt;String, Message&gt;) -&gt; Result&lt;HashMap&lt;String, Message&gt;, ActorError&gt; {
        // Process inputs
        let result = self.do_processing(inputs)?;
        
        // Clean up temporary data
        self.cleanup_temp_data();
        
        Ok(result)
    }
}
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p>Use memory limits:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = ActorConfig {
    memory_limit: Some(100 * 1024 * 1024), // 100MB limit
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
</li>
</ol>
<h2 id="debugging-tips"><a class="header" href="#debugging-tips">Debugging Tips</a></h2>
<h3 id="enable-debug-logging"><a class="header" href="#enable-debug-logging">Enable Debug Logging</a></h3>
<pre><code class="language-toml">[logging]
level = "debug"
targets = [
    "reflow_network=debug",
    "reflow_components=info",
    "my_app=trace"
]
</code></pre>
<h3 id="use-network-introspection"><a class="header" href="#use-network-introspection">Use Network Introspection</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Enable network monitoring
network.enable_monitoring(true);

// Get network statistics
let stats = network.get_statistics();
println!("Messages processed: {}", stats.total_messages);
println!("Average latency: {:?}", stats.average_latency);

// List active actors
let actors = network.list_active_actors();
for (id, status) in actors {
    println!("Actor {}: {:?}", id, status);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="actor-state-inspection"><a class="header" href="#actor-state-inspection">Actor State Inspection</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Enable actor introspection
actor.enable_introspection(true);

// Get actor state
let state = actor.get_internal_state();
println!("Actor state: {:?}", state);

// Monitor port activity
let port_stats = actor.get_port_statistics();
for (port, stats) in port_stats {
    println!("Port {}: {} messages", port, stats.message_count);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="graph-visualization"><a class="header" href="#graph-visualization">Graph Visualization</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Export graph for visualization
let dot_format = graph.export_dot();
std::fs::write("graph.dot", dot_format)?;

// Generate SVG visualization
// Use graphviz: dot -Tsvg graph.dot -o graph.svg
<span class="boring">}</span></code></pre></pre>
<h2 id="common-error-patterns"><a class="header" href="#common-error-patterns">Common Error Patterns</a></h2>
<h3 id="error-e001-actor-initialization-failed"><a class="header" href="#error-e001-actor-initialization-failed">Error E001: Actor Initialization Failed</a></h3>
<ul>
<li>Check actor dependencies</li>
<li>Verify configuration parameters</li>
<li>Ensure required resources are available</li>
</ul>
<h3 id="error-e002-message-routing-error"><a class="header" href="#error-e002-message-routing-error">Error E002: Message Routing Error</a></h3>
<ul>
<li>Verify connection exists</li>
<li>Check port names and types</li>
<li>Ensure target actor is running</li>
</ul>
<h3 id="error-e003-network-connection-failed"><a class="header" href="#error-e003-network-connection-failed">Error E003: Network Connection Failed</a></h3>
<ul>
<li>Check network connectivity</li>
<li>Verify server endpoints</li>
<li>Review firewall settings</li>
</ul>
<h3 id="error-g002-cycle-detected"><a class="header" href="#error-g002-cycle-detected">Error G002: Cycle Detected</a></h3>
<ul>
<li>Analyze graph structure</li>
<li>Remove cycle-causing connections</li>
<li>Consider using async patterns</li>
</ul>
<h3 id="error-c004-port-compatibility-error"><a class="header" href="#error-c004-port-compatibility-error">Error C004: Port Compatibility Error</a></h3>
<ul>
<li>Check port type definitions</li>
<li>Add type conversion actors</li>
<li>Use flexible port types</li>
</ul>
<h2 id="getting-help-2"><a class="header" href="#getting-help-2">Getting Help</a></h2>
<ol>
<li><strong>Check logs</strong>: Enable debug logging for detailed information</li>
<li><strong>Use monitoring tools</strong>: Enable network and actor monitoring</li>
<li><strong>Review configuration</strong>: Verify all configuration parameters</li>
<li><strong>Test in isolation</strong>: Create minimal test cases</li>
<li><strong>Community support</strong>: Open issues on GitHub with detailed error information</li>
</ol>
<h2 id="diagnostic-tools"><a class="header" href="#diagnostic-tools">Diagnostic Tools</a></h2>
<h3 id="health-check-endpoint-1"><a class="header" href="#health-check-endpoint-1">Health Check Endpoint</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Add health check to your application
use warp::Filter;

let health = warp::path("health")
    .map(|| {
        let status = check_system_health();
        warp::reply::json(&amp;status)
    });

warp::serve(health)
    .run(([127, 0, 0, 1], 8080))
    .await;
<span class="boring">}</span></code></pre></pre>
<h3 id="metrics-collection-1"><a class="header" href="#metrics-collection-1">Metrics Collection</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use prometheus::{Counter, Histogram, register_counter, register_histogram};

let message_counter = register_counter!("reflow_messages_total", "Total messages processed").unwrap();
let processing_time = register_histogram!("reflow_processing_duration_seconds", "Processing time").unwrap();

// In actor processing
message_counter.inc();
let _timer = processing_time.start_timer();
<span class="boring">}</span></code></pre></pre>
<h3 id="performance-profiling-1"><a class="header" href="#performance-profiling-1">Performance Profiling</a></h3>
<pre><code class="language-bash"># CPU profiling
cargo install flamegraph
cargo flamegraph --bin reflow-app

# Memory profiling  
cargo install heaptrack
heaptrack target/release/reflow-app
</code></pre>
<p>For additional help, see:</p>
<ul>
<li><a href="reference/api-reference.html">API Reference</a> - Complete API documentation</li>
<li><a href="reference/../architecture/overview.html">Architecture Overview</a> - System architecture</li>
<li><a href="reference/../tutorials/performance-optimization.html">Performance Optimization</a> - Optimization techniques</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="glossary"><a class="header" href="#glossary">Glossary</a></h1>
<h2 id="a"><a class="header" href="#a">A</a></h2>
<p><strong>Actor</strong>
: A fundamental unit of computation in Reflow that processes messages and can create other actors, send messages, or designate behavior for the next message.</p>
<p><strong>Actor Model</strong>
: A mathematical model of concurrent computation that treats actors as the universal primitives of concurrent computation.</p>
<p><strong>API</strong>
: Application Programming Interface - A set of protocols and tools for building software applications.</p>
<h2 id="c"><a class="header" href="#c">C</a></h2>
<p><strong>Component</strong>
: A reusable unit of functionality in Reflow that can be connected to other components to build workflows.</p>
<p><strong>Connection</strong>
: A link between two components that allows data or control flow to pass from one component to another.</p>
<p><strong>Concurrent Computation</strong>
: Multiple computations executing at the same time, potentially interacting with each other.</p>
<h2 id="d"><a class="header" href="#d">D</a></h2>
<p><strong>Deno</strong>
: A secure runtime for JavaScript and TypeScript built on V8, Chrome's JavaScript engine.</p>
<p><strong>Deployment</strong>
: The process of releasing and configuring a Reflow application to run in a production environment.</p>
<h2 id="e"><a class="header" href="#e">E</a></h2>
<p><strong>Edge</strong>
: In graph terminology, a connection between two nodes (components) that represents data or control flow.</p>
<p><strong>Event</strong>
: A signal or message that indicates something has happened in the system.</p>
<h2 id="f"><a class="header" href="#f">F</a></h2>
<p><strong>Flow-Based Programming (FBP)</strong>
: A programming paradigm that defines applications as networks of "black box" processes exchanging data across predefined connections.</p>
<h2 id="g"><a class="header" href="#g">G</a></h2>
<p><strong>Graph</strong>
: A data structure consisting of nodes (vertices) and edges that represent the connections between them. In Reflow, graphs represent workflows.</p>
<p><strong>GraphQL</strong>
: A query language and runtime for APIs that provides a complete description of data in your API.</p>
<h2 id="i"><a class="header" href="#i">I</a></h2>
<p><strong>Inport</strong>
: An input connection point on a component that receives data or control signals.</p>
<p><strong>Initial Information Packet (IIP)</strong>
: A data packet that provides initial values to component inputs at the start of execution.</p>
<h2 id="m"><a class="header" href="#m">M</a></h2>
<p><strong>Message</strong>
: A unit of communication between actors containing data and metadata.</p>
<p><strong>Message Passing</strong>
: The primary means of communication between actors, where information is sent via discrete messages.</p>
<p><strong>Metadata</strong>
: Data that provides information about other data, such as component properties or connection details.</p>
<h2 id="n"><a class="header" href="#n">N</a></h2>
<p><strong>Node</strong>
: In graph terminology, a vertex that represents a component or processing unit in a workflow.</p>
<p><strong>Network</strong>
: A collection of connected components that form a complete workflow or application.</p>
<h2 id="o"><a class="header" href="#o">O</a></h2>
<p><strong>Outport</strong>
: An output connection point on a component that sends data or control signals to other components.</p>
<h2 id="p"><a class="header" href="#p">P</a></h2>
<p><strong>Port</strong>
: A connection point on a component, either an inport (input) or outport (output).</p>
<p><strong>Process</strong>
: A running instance of a component that can receive and send messages.</p>
<p><strong>Protocol</strong>
: A set of rules that define how actors communicate with each other.</p>
<h2 id="r"><a class="header" href="#r">R</a></h2>
<p><strong>ReactFlow</strong>
: A library for building node-based editors and interactive diagrams with React.</p>
<p><strong>Runtime</strong>
: The execution environment where Reflow applications run, including the JavaScript/Deno runtime.</p>
<h2 id="s"><a class="header" href="#s">S</a></h2>
<p><strong>Serialization</strong>
: The process of converting data structures or objects into a format that can be stored or transmitted.</p>
<p><strong>Subgraph</strong>
: A subset of a larger graph that can be treated as a single component.</p>
<h2 id="t"><a class="header" href="#t">T</a></h2>
<p><strong>TypeScript</strong>
: A strongly typed programming language that builds on JavaScript by adding static type definitions.</p>
<p><strong>Trait</strong>
: A characteristic or property that defines the behavior or type of a port or component.</p>
<h2 id="v"><a class="header" href="#v">V</a></h2>
<p><strong>Visual Editor</strong>
: A graphical user interface that allows users to create and modify workflows by dragging and dropping components.</p>
<h2 id="w"><a class="header" href="#w">W</a></h2>
<p><strong>WebAssembly (WASM)</strong>
: A binary instruction format for a stack-based virtual machine, designed to be fast and portable.</p>
<p><strong>Workflow</strong>
: A sequence of connected components that process data or perform tasks in a specific order.</p>
<p><strong>Web Worker</strong>
: A JavaScript API that allows web pages to run scripts in background threads separate from the main execution thread.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="contributing-to-reflow"><a class="header" href="#contributing-to-reflow">Contributing to Reflow</a></h1>
<p>Thank you for your interest in contributing to Reflow! This document provides guidelines and information for contributors.</p>
<h2 id="getting-started-1"><a class="header" href="#getting-started-1">Getting Started</a></h2>
<h3 id="prerequisites-9"><a class="header" href="#prerequisites-9">Prerequisites</a></h3>
<p>Before contributing, ensure you have:</p>
<ul>
<li><strong>Rust</strong> (latest stable version)</li>
<li><strong>Node.js</strong> (version 18 or higher)</li>
<li><strong>Git</strong> for version control</li>
<li><strong>mdBook</strong> for documentation (optional)</li>
</ul>
<h3 id="setting-up-the-development-environment"><a class="header" href="#setting-up-the-development-environment">Setting Up the Development Environment</a></h3>
<ol>
<li>
<p><strong>Clone the repository:</strong></p>
<pre><code class="language-bash">git clone https://github.com/your-org/reflow.git
cd reflow
</code></pre>
</li>
<li>
<p><strong>Install Rust dependencies:</strong></p>
<pre><code class="language-bash">cargo build
</code></pre>
</li>
<li>
<p><strong>Install Node.js dependencies:</strong></p>
<pre><code class="language-bash">cd examples/audio-flow
npm install
</code></pre>
</li>
<li>
<p><strong>Run tests:</strong></p>
<pre><code class="language-bash">cargo test
</code></pre>
</li>
</ol>
<h2 id="how-to-contribute"><a class="header" href="#how-to-contribute">How to Contribute</a></h2>
<h3 id="reporting-issues"><a class="header" href="#reporting-issues">Reporting Issues</a></h3>
<ul>
<li>Use the <a href="https://github.com/your-org/reflow/issues">GitHub Issues</a> page</li>
<li>Provide detailed information about the bug or feature request</li>
<li>Include relevant code examples and error messages</li>
<li>Search existing issues before creating new ones</li>
</ul>
<h3 id="submitting-pull-requests"><a class="header" href="#submitting-pull-requests">Submitting Pull Requests</a></h3>
<ol>
<li><strong>Fork the repository</strong> and create a new branch</li>
<li><strong>Make your changes</strong> with clear, descriptive commits</li>
<li><strong>Add tests</strong> for new functionality</li>
<li><strong>Update documentation</strong> as needed</li>
<li><strong>Submit a pull request</strong> with a clear description</li>
</ol>
<h3 id="code-style-guidelines"><a class="header" href="#code-style-guidelines">Code Style Guidelines</a></h3>
<h4 id="rust-code"><a class="header" href="#rust-code">Rust Code</a></h4>
<ul>
<li>Follow the <a href="https://doc.rust-lang.org/nightly/style-guide/">Rust Style Guide</a></li>
<li>Use <code>cargo fmt</code> to format code</li>
<li>Use <code>cargo clippy</code> to catch common mistakes</li>
<li>Write comprehensive documentation comments (<code>///</code>)</li>
</ul>
<h4 id="javascripttypescript-code"><a class="header" href="#javascripttypescript-code">JavaScript/TypeScript Code</a></h4>
<ul>
<li>Use Prettier for formatting</li>
<li>Follow ESLint recommendations</li>
<li>Use meaningful variable and function names</li>
<li>Write JSDoc comments for public APIs</li>
</ul>
<h4 id="documentation"><a class="header" href="#documentation">Documentation</a></h4>
<ul>
<li>Use clear, concise language</li>
<li>Include code examples where appropriate</li>
<li>Test all code examples to ensure they work</li>
<li>Follow the existing documentation structure</li>
</ul>
<h2 id="development-workflow-1"><a class="header" href="#development-workflow-1">Development Workflow</a></h2>
<h3 id="branch-naming-convention"><a class="header" href="#branch-naming-convention">Branch Naming Convention</a></h3>
<ul>
<li><code>feature/description</code> - for new features</li>
<li><code>fix/description</code> - for bug fixes</li>
<li><code>docs/description</code> - for documentation updates</li>
<li><code>refactor/description</code> - for code refactoring</li>
</ul>
<h3 id="commit-message-format"><a class="header" href="#commit-message-format">Commit Message Format</a></h3>
<pre><code>type(scope): brief description

Detailed explanation of the change, if necessary.

Fixes #123
</code></pre>
<p><strong>Types:</strong></p>
<ul>
<li><code>feat</code>: New feature</li>
<li><code>fix</code>: Bug fix</li>
<li><code>docs</code>: Documentation changes</li>
<li><code>style</code>: Code style changes (formatting, etc.)</li>
<li><code>refactor</code>: Code refactoring</li>
<li><code>test</code>: Adding or updating tests</li>
<li><code>chore</code>: Maintenance tasks</li>
</ul>
<h3 id="testing"><a class="header" href="#testing">Testing</a></h3>
<h4 id="unit-tests-1"><a class="header" href="#unit-tests-1">Unit Tests</a></h4>
<pre><code class="language-bash">cargo test
</code></pre>
<h4 id="integration-tests-1"><a class="header" href="#integration-tests-1">Integration Tests</a></h4>
<pre><code class="language-bash">cargo test --test integration
</code></pre>
<h4 id="documentation-tests"><a class="header" href="#documentation-tests">Documentation Tests</a></h4>
<pre><code class="language-bash">cargo test --doc
</code></pre>
<h4 id="end-to-end-tests"><a class="header" href="#end-to-end-tests">End-to-End Tests</a></h4>
<pre><code class="language-bash">cd examples/audio-flow
npm test
</code></pre>
<h2 id="documentation-guidelines"><a class="header" href="#documentation-guidelines">Documentation Guidelines</a></h2>
<h3 id="writing-style"><a class="header" href="#writing-style">Writing Style</a></h3>
<ul>
<li>Use active voice</li>
<li>Write in present tense</li>
<li>Be clear and concise</li>
<li>Include practical examples</li>
<li>Explain the "why" not just the "how"</li>
</ul>
<h3 id="code-examples"><a class="header" href="#code-examples">Code Examples</a></h3>
<ul>
<li>Test all code examples</li>
<li>Include imports and setup code</li>
<li>Show expected output where relevant</li>
<li>Use realistic, meaningful examples</li>
</ul>
<h3 id="api-documentation"><a class="header" href="#api-documentation">API Documentation</a></h3>
<ul>
<li>Document all public functions and types</li>
<li>Include parameter descriptions</li>
<li>Provide return value information</li>
<li>Add usage examples</li>
</ul>
<h2 id="community-guidelines"><a class="header" href="#community-guidelines">Community Guidelines</a></h2>
<h3 id="code-of-conduct"><a class="header" href="#code-of-conduct">Code of Conduct</a></h3>
<p>We are committed to providing a welcoming and inclusive environment for all contributors. Please:</p>
<ul>
<li>Be respectful and considerate</li>
<li>Focus on constructive feedback</li>
<li>Help others learn and grow</li>
<li>Celebrate diverse perspectives</li>
</ul>
<h3 id="communication-channels-1"><a class="header" href="#communication-channels-1">Communication Channels</a></h3>
<ul>
<li><strong>GitHub Issues</strong>: Bug reports and feature requests</li>
<li><strong>GitHub Discussions</strong>: General questions and community discussion</li>
<li><strong>Discord</strong>: Real-time chat (invite link in README)</li>
</ul>
<h2 id="release-process"><a class="header" href="#release-process">Release Process</a></h2>
<h3 id="versioning"><a class="header" href="#versioning">Versioning</a></h3>
<p>We follow <a href="https://semver.org/">Semantic Versioning</a>:</p>
<ul>
<li><code>MAJOR.MINOR.PATCH</code></li>
<li>Breaking changes increment MAJOR</li>
<li>New features increment MINOR</li>
<li>Bug fixes increment PATCH</li>
</ul>
<h3 id="release-checklist"><a class="header" href="#release-checklist">Release Checklist</a></h3>
<ol>
<li>Update version numbers in <code>Cargo.toml</code></li>
<li>Update <code>CHANGELOG.md</code></li>
<li>Run full test suite</li>
<li>Update documentation</li>
<li>Create GitHub release</li>
<li>Publish to crates.io (maintainers only)</li>
</ol>
<h2 id="architecture-guidelines"><a class="header" href="#architecture-guidelines">Architecture Guidelines</a></h2>
<h3 id="actor-design-principles"><a class="header" href="#actor-design-principles">Actor Design Principles</a></h3>
<p>When creating new actors:</p>
<ul>
<li><strong>Single Responsibility</strong>: Each actor should have one clear purpose</li>
<li><strong>Immutable Messages</strong>: Messages should be immutable data structures</li>
<li><strong>Error Handling</strong>: Handle errors gracefully and provide meaningful messages</li>
<li><strong>Documentation</strong>: Include comprehensive examples and usage guidelines</li>
</ul>
<h3 id="component-design"><a class="header" href="#component-design">Component Design</a></h3>
<p>For new components:</p>
<ul>
<li><strong>Composability</strong>: Components should work well with others</li>
<li><strong>Configuration</strong>: Use clear, typed configuration options</li>
<li><strong>Performance</strong>: Consider memory usage and execution speed</li>
<li><strong>Testing</strong>: Include unit tests and integration tests</li>
</ul>
<h3 id="api-design"><a class="header" href="#api-design">API Design</a></h3>
<p>When designing APIs:</p>
<ul>
<li><strong>Consistency</strong>: Follow existing patterns and conventions</li>
<li><strong>Type Safety</strong>: Use strong typing where possible</li>
<li><strong>Documentation</strong>: Provide clear documentation and examples</li>
<li><strong>Backwards Compatibility</strong>: Consider impact on existing users</li>
</ul>
<h2 id="getting-help-3"><a class="header" href="#getting-help-3">Getting Help</a></h2>
<p>If you need help with contributing:</p>
<ol>
<li>Check the <a href="appendices/../README.html">documentation</a></li>
<li>Search <a href="https://github.com/your-org/reflow/issues">existing issues</a></li>
<li>Ask in <a href="https://github.com/your-org/reflow/discussions">GitHub Discussions</a></li>
<li>Join our <a href="appendices/discord-invite-link">Discord community</a></li>
</ol>
<h2 id="recognition"><a class="header" href="#recognition">Recognition</a></h2>
<p>Contributors are recognized in:</p>
<ul>
<li>The project README</li>
<li>Release notes</li>
<li>Annual contributor reports</li>
</ul>
<p>We appreciate all contributions, whether they're code, documentation, testing, or community support!</p>
<h2 id="license-1"><a class="header" href="#license-1">License</a></h2>
<p>By contributing to Reflow, you agree that your contributions will be licensed under the same license as the project (see <a href="appendices/../../LICENSE">LICENSE</a> file).</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
